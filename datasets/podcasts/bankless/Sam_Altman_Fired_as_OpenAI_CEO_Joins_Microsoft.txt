Speaker A: Sam Altman was just fired by the board of directors of OpenAI. Why? What did he do? And why are over 500 employees of OpenAI signing a letter of protest? Where is Sam Altman going to go next? This is a pretty big deal for tech, for Silicon Valley, for the future of the AI industry. Ryan, have you been following this? Were you tapped in this weekend?
Speaker B: I have, but I think high level, and I know you've been assembling the details here, and that's what we're going to talk about today. So, David, give us the details. What happened to Sam Altmande? OpenAI? What in the world are they doing over there?
Speaker A: Yeah. End of day, Friday, November 17, the OpenAI Twitter account tweets out, OpenAI announces leadership transition. And everyone knows a leadership transition means somebody got fired. And there's not that many leaders. There's kind of just Sam Altman. So everyone reading this is like, what automatically is, like, what the hell is going on? There was an entire blog post that was linked in this tweet, and it was all the explanation of what's going on and what's happening next. So two main quotes from this blog post says, the board of directors of OpenAI announced that Sam Altman will depart as CEO. Mira Muradi, the CTO of OpenAI, will serve as interim CEO, effective immediately. Mister Altman's departure follows a deliberative review process by the board, which concluded that he was not consistently candid in his communications with the board, hindering its ability to exercise its responsibilities. The board no longer has confidence in his ability to lead open AI. Pretty big words. And I think when I was reading this, and I think most people across Twitter and across the tech landscape as well, is like, oh, my God, what did Sam do?
Speaker B: That was my immediate reaction. I was like, okay, he hasn't been candid. This is code for he's lied to us. And in order to get fired from a company for lying, it can't be like, it seems to me it can't be a, especially somebody with the, the I think, press of Sam Altman. It can't be a small lie. Has to be like a pretty big lie. So my initial reaction was, yeah, something really bad just came out of some skeleton that Sam had in the closet. Just came out and popped its head out. That's, that was my reading of this. But it seems like maybe we haven't gotten fully clarity on what he was not being candid about. And this is now three days later. Is that the case, David?
Speaker A: Yeah. Over the weekend, it was just three, two and a half days of chaos. We do have a lot more clarity as to where this whole mess is going. It was a tumultuous weekend. There was speculation going on left and right. Sam was going to get rehired by the board. But then Sam is now elsewhere at Microsoft now. So let's kind of like run through the details as to what happened this weekend, because it was just a peak drama in Silicon Valley. First, after Sam was let go by the board on Friday, Friday evening, not even afternoon, Friday evening, Sam tweets out, I loved my time at OpenAI. It was transformative for me personally and hopefully the world a little bit. Most of all, I loved working with such talented people. We'll have more to say about what's next later. Saluti emoji. So actually, like, not really any questions being answered here, just understand, no answer.
Speaker B: To the why still.
Speaker A: Yeah, so still kind of confused. But this is when we start to get a glimpse of like, okay, there is trouble brewing. There's not as alright, in OpenAI. And that's when Greg Brockmande, who is the president of OpenAI and one of its co founders, was also removed from the board by the board. And so Sam Altman also was on the board and he is the CEO. And then he was fired. So. Fired. Removed from the board. Greg Brockman, president, was removed from the board, but not fired. He was just removed.
Speaker B: Well, that's a huge slap in the face, right? Like you're a co founder, you're, we're going to let you have your job, but you're no longer on the board. Right. I mean, that would be pretty frustrating, I would imagine.
Speaker A: And we should probably talk about what is a board and what does it do. So Sam Altman and Greg Brockman are executives. They're making the decisions, they are leading the company, and the board is generally not doing anything at all. They're generally just overseeing governance and high level direction. And they have the power to remove people but not make really any executive decisions. So the board, the governance over Openaid, removes Sam Altman and also removes President Greg Brockman. And so Greg Brockman is retweeting Sam Altman's tweet that he says, I loved my time at OpenAI. Basically his farewell tweet from OpenAI. And Greg tweets out, retweeting Sam, after learning today's news. This is the message I have sent to the OpenAI team. And it's just a screenshot of his notes app writing. In his notes app, he goes hi, everyone. I'm super proud of what we've all built together since starting this in my apartment eight years ago. We've been through tough and great times accomplishing so much just by all the reasons that should have been impossible. But based on today's news, I quit. So he just quits on Twitter. I mean, maybe. Maybe he, like, messaged the board, but he basically just resigns via Twitter.
Speaker B: Do you know what this reminds me of? Do you remember Og, Spider man? No man? Norman Osborn getting fired from Oscar? Do you remember that scene?
Speaker A: Right?
Speaker B: You can't do this to me. Do you know how much I've sacrificed? That's what this reminds me of. Like, two of the co founders basically getting fired. I guess Greg was not fired technically, but, like, getting pushed out of their own company.
Speaker A: Yeah, yeah, that's exactly right. And so everyone is realizing, okay, number one, at number two of OpenAI, perhaps the most important defining company of the modern age, are out one. One fired, one quitting in solidarity. And so everyone is really trying to ask, like, what the hell is going on? And with Greg quitting in solidarity with Sam, people have stopped asking the questions, what did Sam do? Like, what was he up to? Did he lie? Did he steal? Did he cheat? And now everyone is like, oh, what? What is the board up to? What?
Speaker B: So this is the why being revealed at first. At first, the initial inclination is, oh, Sam must have done something really bad. There's some skeleton in the closet. But then when you have other employees, other co founders also resigning in protest, then you start to think, well, maybe the board was doing something. Maybe. Maybe this was a division not based on some sort of issue revolving around Sam's character. Maybe this is some kind of a schism around a set of issues or a direction for the company.
Speaker A: So then this brings up the question, who the hell is the board of OpenAI? Who are these people that made this governance decision to remove the one and two of OpenAI and cause just a massive amount of chaos in Silicon Valley? Because this isn't, Ryan, just about OpenAI. This is about OpenAI and the cambrian explosion of startups that are built on top of OpenAI because this impacts everything downstream. So this is people's jobs, this is people's salaries, this is vc investment. Since so much, since OpenAI is a platform, the governance decisions over OpenAI and what the board is up to is impacting an entire industry and really the entire city of San Francisco and maybe.
Speaker B: All of society, right? If AI is going to be the most transformative technology that we'll see in the decades to come. This has ripple effects for, for that. And it affects how maybe nation state geopolitics like it could affect so much downstream, certainly.
Speaker A: So this has brought up the question of who is the board of OpenAI? There are now four members. There used to be six. Two of them are recently gone. So four. Four left. Ilya Suitsgever, a co founder and chief scientist at OpenAI, is one of them. Adam D'Angelo, who is the CEO of Quora and an independent director on the board. It's pretty normal to have independent directors on boards, just like having kind of like one arm of removal. Tasha McAuley, who is a tech entrepreneur that not very many people have too many details about, like, who is she and why is she on the board of directors? Technology entrepreneur is in her bio on, like, LinkedIn, but no one really knows what that means or, like, what she was an entrepreneur about. Fun fact, Ryan. She's Joseph Gordon Levitt's wife.
Speaker B: Ah, they're rock from the sun.
Speaker A: Right?
Speaker B: Another thing.
Speaker A: And then last one, Helen Toner, a member of Georgetown center for Security and Emerging Technology, also an independent director. So this is your board. These are the people that voted out Sam and then also caused the departure of Greg.
Speaker B: Okay, so one other co founder and then three independents, it looks like.
Speaker A: Exactly, yeah. Three independents, one being Joseph Corden Levitt's wife. So these are the people that we're trying to ask, like, yo, like, can you explain yourselves? Like, why, why remove Sam? Because to this day, to this moment, at the time of recording, Monday morning, noon eastern time, we have not gotten an explanation other than the Sam is not being appropriately candid with the board, which, again, leaves a lot left to be desired. And so this is where we were left all of weekend. All this weekend, just kind of asking what the hell is going on. Sunday afternoon, Sam tweets out this funny picture of him holding up a badge as a visitor badge to openaide with the caption, first and last, I ever wear one of these. Kind of like a polite, a polite troll. Like, Sam's a nice guy. He hasn't, he doesn't cause anyone any. He's not like a bully or anything, but definitely, like, leaning into some of the drama. Like, I'm wearing a visitor's badge to OpenAI, and it'll be the last time that I wear one of these things. To me, I'm like, is he, is he coming back to OpenAI? Like, are they bringing him back? Like, why, why tweet this? And just just to bring this up, because I thought this was funny. Someone tweets a photo of him taking the photo.
Speaker B: Just kind of funny behind the influencer. This is the best part. Wow.
Speaker A: Yeah.
Speaker B: I thought it was great someone saw him do this.
Speaker A: Okay. Yeah. Where I found this photo was actually, he just retweeted it, so he thought it was funny, too. And so the rumors, Ryan, start going around on Sunday that the board wants to do an oopsie, a reverse uno card, and. Okay, okay, no, we made a mistake. Let's get Sam back.
Speaker B: A nice little takes backsy. They're sorry.
Speaker A: So the board instated the CTO, Mira Murati, as CEO. And so as an interim CEO. And Mira was like, okay, well, as CEO, I plan to rehire Sam Altman and also president Greg in a capacity that's yet to be finalized.
Speaker B: Yeah, but he was CEO. Right. So you're going to rehire him under, like, working for someone else?
Speaker A: Well, I think the deal is, like, Mira, who's now interim CEO, is like, well, the board just effed up. I'm bringing him back. I'm in charge of this company. I'm going to do what's best for this company. What's best for this company is getting Sam back into the company. These are the rumors that are going around Sunday. So then everyone's like, oh, okay, Sam was fired, but now he's going to get rehired inside of, like, 36 hours. And that's the drama. And again, this is just rumors coming out. Emily Chang put out this tweet that linked to this Bloomberg article that had one important paragraph that started to indicate, like, why was Sam fired? Which says the quote from the article. Altman, who spearheaded efforts to transform OpenAI from a nonprofit into a commercially viable business, clashed with board members who were concerned that he was moving too quickly without sufficient concern to the safety implications of a technology that, left unchecked, could create content capable of harming the public. So this, Ryan, was our first indication that this is an AI safety issue.
Speaker B: Now we are starting to see it. It's actually sort of a schism around a belief system. Right? Which is like one of, let's accelerate, let's move faster into the AI frontier. And the other is like, let's slow down. Let's be careful. Let's stall our progress and make sure it's safe before we, before we push updates into the world.
Speaker A: So the speculation becomes, okay. Sam and Greg, the board members of OpenAI, were the gas pedal part of the board, and the rest of the board were the brakes, were the AI safety people? Interestingly, the next decision by the board was to hire as the new CEO, replacing the interim CEO, Kira Emmett Scheer, as the new CEO of OpenAI. Who is Emmett Scheer?
Speaker B: Wait, wait. So just really quick, though. The previous CEO, Mira, was only CEO.
Speaker A: Like, very temporarily for the weekend. Yeah, just like a weekend.
Speaker B: You could do that. And now they're replacing her with yet another CEO.
Speaker A: I guess you always have to have somebody calling shots at all moments of time. You can't have a void that's just chaos. Okay.
Speaker B: She was very much interim. Like, 48 hours interim CEO.
Speaker A: Yeah. I don't even know if she made it 48 hours because the board brings in Emmett Shear. And who is Emmett Shear? He is a part time partner at Y Combinator, former Twitch CEO. So another tech executive, and importantly, Emmett Scheer, is an AI decelerationist. So here's a tweet from Emmett that says, I specifically say I'm in favor of slowing down, which is sort of like pausing AI development, except slowing down. We're at a speed of ten right now. A pause is reducing to zero. I think we should aim for a one to two instead. So this is the conversation about how fast do we develop AI, or, like, versus how safe do we want to be? And Emmett Scherer is just placing him on that spectrum at, like, a one to two, which, if I put in, like, miles per hour terms, is like a solid 15 miles an hour.
Speaker B: Because the context is this. AI technology is dangerous. At least many people believe it's dangerous. And this has been a debate that's been raging quite publicly for the last year or so between decelerationists, AI decelerationists, and regulators. And even the White House has weighed in on this, and accelerationists who say, no, we got to move faster. We can create a better future. This is key to productivity, jobs. This is the next wave of tech that's going to set our species free, all of these things. And so Emmett is very much a decelerationist, I suppose. But, I mean, if you are all the way decelerationist, why in the world would you work on OpenAI? You're just like. I mean, there's one extreme here which is just shut OpenAI down entirely. And then what happens? Does the rest of the world stop? I guess that's the meta question here.
Speaker A: I think that's been some of the takes that have been going around the Twitter sphere lately is like, well, the board of directors vision for AI is OpenAI is for OpenAI to like self destruct to not exist. So this is kind of like the, like the dividing by zero approach of the board of governance is very much at conflict with, well, a, it's employees, B, Sam and Greg and C, general Silicon Valley tech innovation. At its very core, Silicon Valley is always like go, go, go. And so this is just a conflict of interest and direction and the future. And it's weird to have OpenAI no matter what you believe. Like maybe you do believe AI is dangerous and that deceleration is good, but you can still accept the take that a company that's in charge of developing AI should not have an AI decelerationist as its leader. Like, that's just a conflict. That's a conflict.
Speaker B: But this is why it's kind of a microcosm of the debate and sort of proves, I think, one side more right than the other because we actually get to test what happens when you start to shut the doors of accelerationism. What happens? And I think the next thing that you're going to explain tells us exactly what that happens. But the first thing that happens, this is a take from Jason Calcanis. A lot of value was just destroyed, at least value from OpenAI. So shareholders in OpenAI cannot be happy. This is Jason Calcana saying the employees at OpenAI just lost billions of dollars in secondary share sales that were about to happen at a $90 billion valuation. That's over, done. I think OpenAI will lose half their employees, the twelve to 18 month lead and 90% of their valuation in 2024. Just insane value destruction. So that is kind of the investor VC take. The question though is where does this talent go? Where does this energy around AI accelerationism? Where does it go? Does it just stop? Because OpenAI has said we're going to put the brakes on our organization and the board has decided to slow things down. Is that the end of the story here or like what happens next here?
Speaker A: Oh no, this is about halfway over. Interestingly, when it was announced that Sam was removed as CEO, Microsoft is one of the bigger owners of OpenAI shares. They're one of the biggest investors. And if Jason has this paper napkin math valuation of OpenAI. Right? Well actually if you look at the Microsoft stock, it decreased by evaluation commensurate with the paper math that Jason is putting forward here. So the market is repricing Microsoft, the owner of OpenAI, down because of the destruction of value that Jason is talking about.
Speaker B: Why? Because Microsoft is providing cloud services to.
Speaker A: OpenAI is that it owns the equity, it owns shares of the company. Right.
Speaker B: Okay.
Speaker A: Yeah. So like OpenAI independent organization, but has investors. And one of the largest investors is Microsoft.
Speaker B: Yeah.
Speaker A: So Microsoft, the price goes down. Not it doesn't tank, but it goes down.
Speaker B: So that's our public market view. Right. Because we can't see. Exactly. Because OpenAI is still private valuation. It doesn't have any shares in the public exchange. So that's a proxy for that then.
Speaker A: Right. But Ryan this morning tweeted out at 03:00 a.m. eastern time, Sadia Nadella tweets out, we remain committed to our partnership with OpenAI. Not only is Microsoft one of the largest shareholders of OpenAI, they also have a partnership with them, a business deal. We'll talk about that. So we remain committed to their partnership with OpenAI and have confidence in their product roadmap and their ability to continue to innovate. With everything announced at Microsoft, we are extremely excited to share the news that Sam Altman and Greg Brockman together with colleagues will be joining Microsoft to lead a new advanced AI research team.
Speaker B: Oh, my God.
Speaker A: I'm guessing over the weekend, Sadia, the managing director of Microsoft, was like, this is my moment. There's a free agent. His name is Sam Altman. I want him on Team Microsoft. I'm going to burn the midnight oil and get whatever is going to be let go by OpenAI. And they're going to come to Microsoft.
Speaker B: This is like the greatest maybe aqua hire of all time here.
Speaker A: It's an aqua hire, but without. So one of the big conversations going around is like, Microsoft would have never been able to buy OpenAI because of antitrust regulations. It would have been too big. But when OpenAI just fires Sam Altman and then Greg leaves and then you could only presume that some amount of employees are going to follow. Well, Microsoft is like, well, this is free real estate and we don't even have to go and ask for permission from the feds. And so this is just like a right routing around antitrust and now they're going to take the largest talent pool around AI and bring it in house. So huge win for Microsoft.
Speaker B: So, David, is this all confirmed? Is, is Sam on board with this?
Speaker A: Well, he retweets, Sam Altman retweets this tweet saying the mission continues. So you could only imagine that Sam is on board with this. Yeah.
Speaker B: Balaji had to take care.
Speaker A: Yeah. He says Sadia wins reflexes of a startup CEO again, just talking about moving fast, moving quickly. The resources of a trillion dollar company. I'm pretty sure. Microsoft is the number one highest valued company that exists. And pulling this all together in 48 hours from a cold start gets it signed and over before the markets opened again. This announcement got tweeted out 03:00 a.m. eastern time, about 6 hours before the markets open this morning. And so that hole in the Microsoft valuation, the one to 2% drop as a result of OpenAI losing Sam Altman. Microsoft stocks just rebound. So it's like, oh, well, Microsoft lost, but then it recovered it. And actually it recovered it in a more internal fashion, rather than just being an owner of, OpenAI is now an owner of the talent. Do you see this meme?
Speaker B: No, I did. Okay. This is somebody's photoshopped a Microsoft badge on, you know, Sam Altman's previous guest pass version.
Speaker A: Yeah, that's exactly right. And so now, now the meetings are like, well, now Sam Altman works at Microsoft. Okay, so that's the story of Sam Altman. And that is as much information as we have about where Sam Altman is going next. Along with Greg, they're going to Microsoft. That is, there's no much more information around that, but there's big questions about, okay, what's left for OpenAI? Well, like, what's the next step of the direction? If you scroll through Sam Altman's Twitter account, there's this line that says, OpenAI is nothing without its people. And so many employees of OpenAI are tweeting out this line, OpenAI is nothing without its people. Mira Maradi, the CTO that we talked about, had tweeted out, Brad Lightcap, the COO of OpenAI, tweeted that out. And Sam is just the exact same phrase.
Speaker B: OpenAI is nothing without its people. They're all, it's like a chorus. It's almost like a collective social media chant at this point. OpenAI is nothing without its people.
Speaker A: Yeah. It's like a call to solidarity of OpenAI employees. And so this is OpenAI employees in my mind, like, banding together, in protesting. Like, yo, like, if you do not align with the employees, the people of OpenAI, then you're not going. You're going to lose. You're going to lose out.
Speaker B: Well, that's why this is an interesting schism, because it's a schism based on what you believe. To take a lesson from crypto, it seems like this all settles down to the social layer, what we call a crypto, the layer zero, basically. And so if Sam is saying, hey, no, we want to be an eight or a nine on the accelerationism right. And the board is saying, no, we want to be a one or a two. Right. Ultimately, who actually decides? It's the tech developers, it's the employees, it's the people at OpenAI. Because if OpenAI is not going to provide them an eight or a nine, they'll go somewhere that does. Maybe they'll go to Microsoft. And that sounds like exactly what Sam and his fellow co founder are doing in this case.
Speaker A: And I think it got even more explicit than that when at 08:48 a.m. this morning, eastern time, 550 of these 700 employees of OpenAI wrote a letter to the board telling them to resign.
Speaker B: Wow. 550 of 700 employees. That's basically all of them.
Speaker A: That's basically all of them. And you can imagine that the remaining 150 might just like, we're just too lazy or some reason post is pretty, pretty damning. We don't have time to read it all here, but there's a link in the show notes. I'll just read the last paragraph. Your actions have made it obvious that you are incapable of overseeing OpenAI. We are unable to work for or with people that lack the competence, judgment and care for our mission and employees. We, the undersigned, may choose to resign from OpenAI and join the newly announced Microsoft subsidiary run by Sam Altman and Greg Brockmandhenne. Microsoft has assured us that there are positions for all OpenAI employees at this new subsidiary, should we choose to join. Wow. Wow. Okay. And 550 of the 700 employees of OpenAI are signing this thing. So, yeah, and so this is when Baldur was saying, yeah, like Microsoft has a trillion dollar, is a multi trillion dollar company. They have all the resources they can pay these people. They can get all of these salaries.
Speaker B: Well, that's the thing. I mean, the OpenAI board was trying to fork in a different direction. And the runners of the OpenAI node, the employees namely, said, no, we're going to maintain this. We're not going to allow you to do that. It's a massive pushback here.
Speaker A: Interestingly, the last signer on this letter, it says, it signed by 550, but we can see the first twelve. Number twelve, Ilya Suitskyvere, suit skipper is one of the guys on the board back. He signed that own letter about, look.
Speaker B: At this, David, this just happened. He tweeted out, I deeply regret my participation in the board's actions. This is Ilya, fellow board member, one of those additional four that we were talking about in that earlier in the episode. I never intended to harm OpenAI. I love everything we've built together, and I will do everything I can to reunite the company. Wow.
Speaker A: Basically saying, oops, we effed up. So those are the details. As it stands, Ryan, as of Monday morning, this is all of all that we have. Half, over half of OpenAI employees are threatening to leave to go to Microsoft, where Sam and Greg already are. But really, we need to talk about what does this all mean? What is the future of AI in Silicon Valley? Why is this accelerationism versus decelerationism defining the landscape? I want to unpack this part with you because I think this is going to have probably very, like, sweeping, broad implications for this entire country and really the future of this entire globe, because we all know how big of a deal AI is. So we're going to get to all of those thoughts and reflections, but first, a moment to talk about some of these fantastic sponsors that make the show possible.
Speaker B: All right, David, so now the question is, what does all of this mean, and how will it define the decades to come? So it seems like this is planting the seeds for maybe a schism in tech and a schismeheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheh uh, just in general with how the world addresses this technology. And so Sam being fired was just a symptom of decelerationist versus accelerationism and their outlook on, uh, on artificial intelligence. So what do you think this means for the future of AI?
Speaker A: This atlantic article came out just now that I thought put it very, very well, or at least defined the playing board very, very well. So I'll read two quick passages here. To truly understand the events of this past weekend, one must understand that OpenAI is not a technology company. OpenAI was deliberately structured to resist the values that drive much of the tech industry. A relentless pursuit of scale, a build first, asks questions later approach to launching consumer products. In this conception, OpenAI would operate much more like a research facility or a think tank. The company's charter bluntly states that OpenAI's primary fiduciary duty is to humanity, not to investors or even employees. And when you understand that, Ryan, I feel like you can actually justify the board's governance decisions. If that is the vision of OpenAI, if that's what they did, that sounds in alignment with what their original vision is. It just sounds like the 550 employees that sign that letter don't give a, you know, a rat's ass about that, that alignment, that vision. They are all here to build tech. So the second passage that I'll read here, in conversations between the Atlantic and ten former and current employees at Openaiden, a picture emerged of a transformation at the company that created an unsustainable division among leadership. Together, the accounts of OpenAI employees illustrate how the pressure on the for profit arm to commercialize grew by the day and clashed with the company's stated mission. Until everything came to head with Chat GPT and other products that launched rapidly following after chat GPT, there was a clear path to revenue and profit, said one of the employees. You could no longer make a case for being an idealistic research lab. There were customers looking to be served here and now. I think this defines the schism pretty damn well. OpenAI was, once upon a time a research division trying to research AI for humanity, to improve humanity with AI. And then they made chat GPT, and like, well, this is a very commercial product, and now we are in the race of Silicon Valley and Silicon Valley equity incentives. And so I think with the advent of chat. When did chatgbt come out? Like a little, maybe two years ago, it went public.
Speaker B: Yeah, about just over a year ago, David Chat GPT four came out and was available to the public.
Speaker A: And so I'm guessing at that moment there was a divide that was created which was like, one part, let's research AI for humanity, and the other part was like, let's make an extremely valuable tech company. And it looks like that forking of the company finally has come to a head, and now we're going to see which part gets unbundled and which goes wherever.
Speaker B: I guess I have a few takeaways from this, but maybe the main takeaway is there's no stopping this train, is there? This tech is going to be developed, isn't it? Unless some greater force actually puts a stop to it. I think it would take at this point in time a government threatening to throw people in jail for this to stop, at least in the United States. And then this is the game theory of it. If you stop in the United States, why wouldn't China continue? Why wouldn't Europe continue? Some other nation state apparatus? And I think this is what, maybe there's a way to view this. Okay, so your takeaways from this will all be about how optimistic versus pessimistic you are on artificial intelligence. If you are Eliezer Yudkowski and you think that this is a world ending humanity ending technology, then this is exactly what you would have predicted. This is exactly what you are afraid of, because you are essentially saying that this is a runaway train, and Silicon Valley capitalist incentives will make sure that this technology gets developed to its utmost, because to not develop this technology is to lose out on a lot of shareholder profit, a lot of money, or maybe a competitive advantage versus all of your other, all the other countries. And so this is what Eliezer was afraid of on the other side of things. If you are very optimistic, maybe you're a techno accelerationist yourself. If you're somebody like Mark Andreessen, you're investing in this space, but you also believe that this technology is going to ultimately be good for the world and we'll navigate these thorny problems. And the best way through is for maximum competition. Like AI's being developed in various places, and keeping one AI is checking the power of another AI. And so nobody gets a competitive advantage. It doesn't get captured by regulatory agencies. Maybe that is the more optimistic view. Then this is also what you would have predicted. But you see this as a win, you see this as a gain. And you see OpenAI trying to artificially pump the gas pedal on progress for AI accelerationism. You look at this and you say, we told you this is exactly what's going to happen. You can't stop this. The people don't want it stopped. This technology is going to manifest, so you better have it in the borders of the United States or else it'll go elsewhere. And this is what somebody like Mark Andreessen would probably say as a result. So the one thing that, that I'm coming to a conclusion of is there's no stopping this train. And I don't know how it stops. And it's not clear to me, David, I still haven't made my own mind up onto whether I'm like more team Eliezer Yukowski or more team Marc Andreessen. I just don't know. And I don't know if anyone does.
Speaker A: Those are my takeaways as well. I think there's one thing that we can be sure. It goes back to the Balaji tweet that we saw earlier where I mean, OpenAI at $90 billion of value. If all those employees go to Microsoft. And who are the employees that are going to go to Microsoft? They're going to be the accelerationists who want to move fast and break things and make shareholder profit. And that is exactly the fear that people like Eliezer Yukowski have. Like, well, yeah, all the profit aligned people are going to make a profit aligned company and they're going to accelerate AI. And then, of course, if you're also like Eliezer UCLA, you think that the acceleration of AI leads to the doom of humanity. It is exactly how you would predict. Now we have no accelerationists being buffered by decelerationists because all the accelerationists have, have forked off into the pro accelerationist arena, which is now Microsoft. I think Haseeb put this really, really well. Haseeb of Dragonfly. He says this weekend we all witnessed how a culture war is born. Effective accelerationists now have their original sin that they can point back to what he's referring to as the destruction of $90 billion of shareholder profit, of shareholder equity. This will become the new thing that people will feel compelled to take a side on. Accelerationism versus decelerationism and nuance or middle ground will get punished. So I think this is the schism that is unfolding that we are watching people take sides on. And it's unfortunate if you're on the L Azer Utkowski AI will bring us doom camp. You're seeing all of the people who want to increase shareholder equity, to want to increase market cap, increase value. They're going to the acceleration side. And all the deceleration aside are losing because they're destroying value. And no one is on that side anymore. It is the prisoner's dilemma trap of like, well, everyone's going to choose to profit and therefore they're going to choose to accelerate.
Speaker B: That is the takeaway and this is the schism. And what an epic schism it will be, because I think through the events that just played out, both sides will come away from this feeling like they're right and they're vindicated and all of their concerns and, you know, the energy and the momentum of their arguments were just deemed valid. And so, yeah, it's going to be quite the religious fight ahead. And I do call it a religious fight because I do think that there is some dogmatic belief associated on the extremes of both sides. I'm hopeful, David, we're able to find some happy medium that gives us the promise and benefit of technology like artificial intelligence, and doesn't cause the collapse and destruction of all of humanity. That is certainly the hope. And it'd be great if we were able to thread that needle, right?
Speaker A: Yeah, it really would. It would be more than great. It'd be kind of critical. But at least that is, that ends this current saga of this drama of what is now the fight of Silicon Valley, which is accelerationism versus decelerationism.
Speaker B: Bankless nation will have some more episodes for you on this divide, I'm sure, in the near future. Hope you enjoyed the show. If you're not familiar with bankless, make sure you like and subscribe. We'll get more of this content coming your way.
