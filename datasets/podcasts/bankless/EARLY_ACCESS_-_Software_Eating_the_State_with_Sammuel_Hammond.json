[
    {
        "speaker": "A",
        "text": "As technology accelerates and crypto is very fast and AI is even faster, governance isn't going to be able to keep up. Hence, where we end up, which is just technology just wins. And that makes you optimistic, Sam?"
    },
    {
        "speaker": "B",
        "text": "It makes me."
    },
    {
        "speaker": "C",
        "text": "Welcome to bankless, where we explore the frontier of Internet money and Internet finance. This is how to get started, how to get better, how to front run the opportunity. This is Ryan. Sean Adams. I'm here with David Hoffman, and we're here to help you become more bankless guys. The bankless journey takes us to some interesting places, and this is certainly one of them in today's episode. The topic today is software eating the nation state. Technologies like crypto and AI are about to fundamentally restructure society from the bottom up. We certainly believe that at bankless. And economist and writer Sam Hammond is our guest today, and he's predicting how society will be reorganized under this new paradigm and how those in power will respond. What will the nation states have to say about it? A few topics we get into today. Number one, we talk about crypto. It's under attack in the US, and Sam has a framework to help us understand why. Number two, we talk about America. It was once pro tech, pro Internet. Now it's anti crypto and anti AI. What changed? Number three, we talk about AI. How is the world responding to this new technology? How can AI further unlock crypto? And number four, we end with Sam's predictions that are concrete, very concrete, for the next two decades, which Sam says will be weird, including what happens to the US and what happens to countries that embrace Internet technologies. From the firmware level up, themes of this episode, technology and freedom and how we balance those. And, David, of course, those are themes we often express on bank list. David, why is this episode significant to you?"
    },
    {
        "speaker": "A",
        "text": "We always say in the intro, we're here to front run the opportunity. And this is one of those, I would say, classic bankless episodes where it's definitely, this knowledge is extremely valuable for being prepared for the future, but also you're going to listen to it, and tomorrow's going to be totally the same. Like, you're not going to be able to do anything. That's totally front running the opportunity. But the world will be significantly different in the future, and it will be different in a very specific and unique and directional ways. And episodes like this, I think, help map out the contours of what that future chaotic world looks like. Well, tomorrow will be unimpacted for you. Bankless listener, understanding how crazy the future is. Early as possible will still nevertheless help you prep for it. I think this episode with Sam where we navigate concepts like technology and the state in the year 2023 versus technology and the state in the year 2040 and how those change over time and the role that AI has to do with this are all very. We should be knowing these things more or less. We should be fluent in these conversations, because as AI does progress in capabilities and consumer products, as it's at your fingertips, bankless listener, the realities that Sam is illustrating here on this episode today will become more and more relevant."
    },
    {
        "speaker": "C",
        "text": "Speaking of being fluent, there was a term used in today's episode. Sam used it, called IAC, that stands for effective accelerationism. If you've not heard it before, it's a term you might be hearing in the future as well. It's this idea of techno optimism, of welcoming the future. It's a movement that wants to accelerate our technical progress as a speech and not slow it down. All right, guys, let's get right to the episode with Sam. But before we do, we want to thank the sponsors that made this possible. Bankless nation, we are incredibly excited to introduce you to Sam Hammond. He is an economist for the foundation for American Innovation, which is a think tank that advises policies in DC. And if you go to their website, their slogan reads, build tech, promote freedom. I think freedom and tech, these are two things we definitely like on bankless, and we're also very much tied up with and concerned with the project of how to protect them in a world where it seems like software is starting to eat the nation state, and the nation state is maybe feeling a little bit threatened. That is the topic for today. I'm sure we'll touch on AI, crypto economics, polarization, and how politics really works. Sam, welcome to bankless."
    },
    {
        "speaker": "B",
        "text": "Thanks for having me, Sam."
    },
    {
        "speaker": "C",
        "text": "I know your primary subject matter is not crypto, yet. This is a crypto podcast. Though bankless listeners know we have had some recent flings with AI, and we touch on economics, sociology, politics. Basically, all of these things are crypto, crypto adjacent. But since this is, I guess, officially a crypto podcast, I feel compelled to ask this question as we begin. Sam, what is your take on crypto?"
    },
    {
        "speaker": "B",
        "text": "Geez. If I pull back a bit, I think there's a bigger take on crypto as an example of a counter economics or using technology to advance freedom. Sometimes under the label agristhenne, I think there's crypto summers. Crypto winters. But the general idea that we can use a technology to advance social change is, I think, a correct one. And obviously, something that's much more powerful than lobbying or writing manifestos here or there. Technology is this interesting exception to the rule where if you can invent a better way of doing things, you don't necessarily need permission to put it out into the world, and that technology can lead to dramatic social changes. There's a famous book that argues that the invention of the stirrup was what led to feudalism. This one small invention led to the ability for horseback knights to control land and so on and so forth. Inventing technologies to advance freedom is a great idea. Crypto is an awesome application of that into the monetary realm. I think really it's been just looking for its killer app. I'm also interested in crypto as a potential solution to a lot of the issues that AI is creating. In that sense, AI creating the conditions to give blockchain a kind of functional use case. We think about this in terms of content provenance and tracking deepfakes and so on and so forth. I think these two movements to people working in AI and the people working in crypto have a lot to learn from each other and potentially collaborate on solutions that combine those two fields. Think about genuinely smart contracts. If we had smart contracts that were running little AI agents inside them."
    },
    {
        "speaker": "C",
        "text": "Yeah, absolutely. I think this theme that we'll return to throughout this episode is maybe a major one, which is technology's ability to impact social change. And when social change happens, there are winners and losers in the outcomes of that social change. And I think one thing that maybe AI has a parallel with crypto today is crypto very much feels like it's under nation state attack. I don't know, Sam. If you've heard about Elizabeth Warren's anti crypto army, we've got privacy developers in jail, the developers of tornado cash, for instance. We've got Gary Gensler, regulator at the sec. He thinks everything is under his control. Everything that's tokenized is his, I guess. I have a question for you that is general. Help us make sense of this. Why does it seem like the nation state is attacking crypto? Is it all in our head, or is this related to the idea that you opened with this idea that technology impacts social change and restructures societies and some people don't like that change and are resisting it? Is that what we're experiencing in crypto, some of that resistance?"
    },
    {
        "speaker": "B",
        "text": "Yeah, I mean, we'll get into this later, but liberal democracy as we understand it in the modern nation state is a product of a particular technological equilibrium. Institutions are adapted to the state of technology. And therefore, it's one thing if you're inventing a better mousetrap. If you invent new firmware to run the economy on, you pose a direct threat to the sovereign, so to speak. And so I think it's not surprising, political theory 101, that if you pose a direct threat to the sovereignty, the sovereign is going to hit back. And in some ways, it's sort of like a huge endorsement to crypto. The more there is this attention from the Gary Genslers of the world, the more you should think that there's. They're there where there's smoke, there's fire, that this actually poses a sort of challenge to their regulatory oversight. And it's also interesting, Gensler's also had a foray into AI now, where he's brought up AI as a potential systemic risk to financial markets."
    },
    {
        "speaker": "C",
        "text": "He's done the AI pivot as well, hasn't he?"
    },
    {
        "speaker": "B",
        "text": "Sam, are we all."
    },
    {
        "speaker": "A",
        "text": "Yeah. Sam, if I wanted to, like, reinterpret what you said, I think the meaning I got out of that is that the state lags technology, as in, like, technology moves forward, and then the state has to, like, catch up to it. Right. There's. There's some sort of equilibrium of about the inventions that humans produce, and then the state naturally responds to that new equilibrium. They are not promoting. They are not the pinnacle of society. Right. They have to catch up and establish new governance over the system. And so one thing I see as a big friction between the state, and then also AI and crypto, crypto and AI pair, is that cryptos are so fast. If you exist in this industry, we move so quickly, we go in four year cycles. But if you were looking at crypto four years ago, it's irrecognizable to where it is today. And I kind of think AI is more or less the same. AI is also just increasingly accelerating in its velocity of what it can impact change in society. And there seems to be a friction here, right? Well, if technology is moving faster and faster and faster and the state is always lagging technology, there seems to be just a friction that is produced between that gap. Do you see that friction as well?"
    },
    {
        "speaker": "B",
        "text": "Oh, absolutely. I mean, we're talking about exponential technologies running up against linear or even sub linear institutions. There's going to be a natural thing that they fall out of step. Congress is only just now getting its hands around social media, and arguably not even that. So it does pose sort of, Peter Thiel has this indefinite optimism, definite optimism. Indefinite pessimism. Definite pessimism. Technology provides forms of indefinite optimism. We can just imagine a better world with technology. But for people in incumbent positions, in government or other institutions, even incumbent corporations, that could be disrupted by technology, there's a sense in which there's an ominousness to new technology that they have to do something about by default because it poses a threat to existing ways of doing business. I don't think this is any different. Nation states, not only do they act slowly, but think about our administrative bureaucracies relative to other nation states, they act even slower. If you want a new regulation, you go through multi year notice and comment periods where the public can really, by the public, we mean lobbyists get a chance to give their two cent, and then that has to go through interagency review process, and that whole thing gets challenged in court. New York can't even introduce congestion pricing without being sued for multiple years. Ironically, that slowness actually creates a demand for alternative modes, alternative modalities. If you can exit the system, so to speak, and accelerate through a different track, through an alternative economic arrangement, through alternative, alternative distribution channels, then you can just end run the entire system. And that's fundamentally why I think there's been this crackdown both on social media and new media from incumbent media groups and now also from the incumbent financial interests. A crackdown on crypto. It's not necessarily that they see the technology as inherently bad. It's that it's moving quicker than they can keep up with. And so their solution is to try to slow things down so that they can catch up rather than just letting things rip."
    },
    {
        "speaker": "C",
        "text": "So you're saying their solution is to slow things down, although sometimes it feels like they're doing more than slowing things down. Sam, they're trying to actually stop things. They're trying to shut them down. They're trying to ban them. They're trying to make them illegal. And the thing that has surprised me, I guess, a little bit, is you said that technology can often bring a political threat to the sovereign. And yet I would assume that in some societies, that political threat would be more severe than others. For instance, America, at least american values as purported on paper, in its best light, and we don't often live up to these values, is a nation state and a society that is supposed to value technology. It's supposed to value freedom. These are supposed to be enshrined in our values. And so the pushback from the US on crypto in particular has been a little jarring for me. I guess maybe some might say that's naive. Like Ryan, you should have anticipated that, but it just feels very much in conflict with the values that we put in the american white paper. I'm wondering if you could reflect on that. And then I'm hoping we can dig into these words like freedom and technology and what they actually mean and why they're important."
    },
    {
        "speaker": "B",
        "text": "Yeah, I mean, if you look back at history, other transformative technologies take the printing press, right? Printing press, early 15 hundreds. It really doesn't start to diffuse, though, until the next century. In the early 16 hundreds, that's when you start to see every little township, every little shire in England having their own printing press. And actually, up until that point, the uk parliament had an ecclesiastical licensing regime. If you wanted to print a book in England, you had to get the licensing board's permission. And it was a bunch of priests that made sure it didn't offend anybody. And that was consistent with the Church of England and so forth. Once printing reached a kind of point of criticality, where it was so diffused across the countryside, enforcement completely broke down. You know, the licensing board collapsed. There was this explosion of new publications, you know, the nonconformists, the Presbyterians, the new Puritans, all these. All these minority religious groups that finally had a chance to speak. It was. It was very. It's very reminiscent, actually, of, like, what. What the Internet did. And what happened out of that was there was, you know, the civil war. There were also the broader wars of religion in Europe. And at the other end, we get modern nation states, and in particular, we get the founding of the american republic. And in some ways, the american republic was not just a founder country, but it was also the first sort of printing press, native country. The founders of the United States were sort of post printing revolution and designing the society around that reality. And so one hopes that we can undergo absorb these new technologies consistent with our existing institutional setup. But then that brings in people like Balaji Srinivasan and others, who sort of take this as inspiration that we need to found new institutions to be native to the Internet age, to the crypto age, to the AI age. And that's going to be a running tension, I think, through the century. What institutions are able to evolve with technology, and where do we need to just displace and start over?"
    },
    {
        "speaker": "C",
        "text": "So that's a really interesting framing of the US, which is like one of the first societies built on a post printing press set of protocols. And I guess what you're referring to, Sam, is maybe some protections in the constitution, sort of the entrance of freedom of speech and First Amendment type protections? Is that what you mean?"
    },
    {
        "speaker": "B",
        "text": "Yeah, absolutely. And also just the milieu. It was a republic of letters, like the federalist papers. These were like early. This was like 17th century Usenet."
    },
    {
        "speaker": "C",
        "text": "Well, it's very interesting because now we have these post printing press societies, and America's now close to 250 years old, but we don't have any societies that have been built, that have built on the native protocol of the Internet. Maybe that gets into what some of Balaji is basically saying, is that our existing institutions are sort of fraying around the edges. And maybe that's what you're saying as well. Sam, the governments of the world haven't been able to adopt to technology fast enough. So the protocols aren't Internet, native tech, native type protocols. Is there something to that?"
    },
    {
        "speaker": "B",
        "text": "Oh, usually. I mean, you know, take Social Security numbers, you know, a nine digit number that was created in 1935. Right. It's no wonder our system is so full of fraud. The IR's. The IR's was the IR's individual master file, which basically runs the entire tax system, dates to the Kennedy administration, and is written in assembly. You know, we had a. We had during the pandemic, this explosion in unemployment rolls, and people were lining up around the blocks because literally the websites would go down at 09:00 p.m. the amazing thing about the Internet is it doesn't have to have business hours, but it had to in this case, because our systems are so outdated, purely on a technical, institutional, firmware level. We have this growing chasm between sort of what you could describe as the UX experience between the public and private sector. We get annoyed if our Uber doesn't arrive in three minutes when that barely existed 510 years ago. And yet we are sort of masochists about government inefficiency, where we just have come to expect it as par for the course."
    },
    {
        "speaker": "C",
        "text": "But obviously, the DMV line is eternal and inherent."
    },
    {
        "speaker": "B",
        "text": "I. Yeah, and I'm sure the DMV these days is better than it was in the seventies. But again, this is sort of linear improvements against exponential improvements in the background. And the more these things get out of step, the more we will not have sort of a gentle transition, the more there will be just things breaking."
    },
    {
        "speaker": "A",
        "text": "Sam, there's a passage in one of your articles that we were reading for this podcast I want to read because it's about the continuity of the printing press into the Internet and how these similar technologies have shaped the contours of nation states. So your passage reads, for generations, it was an implicit assumption of us foreign policy that economic liberalization and free trade would push autocratic regimes to democratize information. Technologies that give voice to the voiceless were key to this grand strategy. A kind of glass nost in a bottle. This is why the Department of Defense invested so heavily in the early Internet. And while our international development agencies promoted Internet access abroad, as one USAID report puts it, connecting people, transforming nations, the idea that technology can precipitate a regime change is thus not foreign to us political establishment. They just assumed our relative openness would keep those dynamics from playing out at home. And so this kind of puts a specific light on the United States as a country of, you know, doing the things that are in line with american values, promoting these technologies of the printing press and the Internet to spread freedom. But as kind of. Ryan opened up with this podcast, we don't seem like we're getting that same kind of treatment with crypto, and we're also kind of not getting that same kind of treatment. What we're seeing is with AI as well. And so I'm wondering, Sam, why is crypto and AI, why is it different from the Internet? When the american establishment, way back when, was so apt to promote the Internet, what changed?"
    },
    {
        "speaker": "B",
        "text": "I don't think anything changed. I think there's always been a deep hypocrisy in how we approach this geopolitically, similar to how Reagan talked a big game about free trade and cutting the budget while running bigger deficits and actually doing his own defense industrial policy. So we've always said one thing and done another, and the same is true in the Internet. The Internet, yes. We promoted abroad. We tried to, we use it to help the dissidents in Iran rise up against the shah or whatever. But when those same trends play out at home, our establishment treats it as a problem. They treat it as this growing cancer of disinformation. And it's something that's, once you step back and looked at it, it's so obviously cynical. Where we have, most recently, the New York Times rushing to publish a headline about Israel blowing up a hospital with no verification, spreading major disinformation to a massive audience and just wiping their hands of impunity. Meanwhile, if one random person tweets something that's false on twitter, it indicts the entire concept of social media. So I think even in the realm of the Internet, there is sort of a be careful what you wish for dynamic, where as the Internet was being developed, we had all these highfalutin values around openness and transparency and connecting people. And really, that tune I think Balaji has also documented this quite extensively. The kind of tech clash really set in post 2015, 2016, when we saw how the Internet was also giving. Making it possible for outsiders like Trump to kind of hack the political game. And suddenly, the same people who are writing articles about how the Obama campaign is harnessing Facebook to reach likely voters is basically taking the exact same story and saying, but switching the valence, and all of a sudden, it's like populists are using social media to destroy democracy. So I don't think it's a. I don't think, actually, there's a disconnect between how the elite talks about the Internet and these other technologies. I think what really changed was 2016, making them wake up and realize that this isn't going the way they planned. And in some ways, the technology as sort of an asset, an institutional asset that dissolves corruption in the same way that the printing press allowed us to speak up against the corrupt church and so forth, is coming for them. And that makes them very uncomfortable. And so that's where you start to see new attempts to try to regulate social media and to create a kind of corporatist framework so that the government can do via Facebook and Twitter and these other platforms, things that would be illegal for it to do itself. And so crypto and AI are just the next iteration in that exact same trend."
    },
    {
        "speaker": "C",
        "text": "So, basically, our elites like when technology drives social change. They just don't like when that technology and social change is used against them or diminishes their power in some way. But I want to make sure we hone on the case, hone in on the case, because I do think you're right. In the US and in other places around the world, there is this tech backlash. And I think whenever there's a backlash, where there's some momentum for an idea, we have a tendency to get into polarized extremes. And I'm wondering if you think that there is the right word for this and the right approaches, is balance. Let me give you two extremes in the social fabric of the US and the narratives that are playing out. The question is, really, what about tech? Is technology good? Is it bad, or is it neutral? I want to ask your take specifically about that, Sam. And maybe there's two counterpoints here. One is the Marc Andreessen. I don't know if you saw his recent techno optimist manifesto and have thoughts on that. Effective accelerationism is a related topic. And this is very like a pro tech type of movement. Marc Andreessen starts with this. He says, lies. We are being lied to. We are told that technology takes our jobs, reduces our wages, increases inequality, threatens our health, ruins the environment, degrades our society, corrupts our children, threatens our future, and is ever on the verge of ruining everything. We are told to be pessimistic, angry, bitter, resentful. And he flips this, and he says, the truth is, our civilization was built on technology. Our civilization was built on technology. Without technology, we are nothing. This is our manifest destiny. This is quite the passionate manifesto call to arms for Marc Andreessen. It's just that is very much putting forth the idea that tech is good. And then also we have, I think, many in the political establishment, but even among kind of the tech thinkers like the Elie Orkowskis of the world, which is basically this idea that AI specifically. But in general, tech is dangerous. AI specifically, like, we're going to kill ourselves. It invokes ideas of Oppenheimer and Prometheus and Frankenstein's monster, and humanity could create this leviathan thing that could destroy us all. And we have to be very careful, our parents, our managers, our governments, to really oversee this for us. Is there some balance to be found in those two worldviews? Or how would you answer that question of, is tech good? Is it bad, or is it neutral?"
    },
    {
        "speaker": "B",
        "text": "Yeah, I would describe myself as a techno realist rather than either optimist or pessimist. And I think that's what we need today, especially with AI. Technology is always double edged, especially technologies that affect what it means to be human. Right? The kind of things that touch on the human condition, like sort of attempts to build sort of transhumanist man. What could go wrong? So I think it's always complicated. Like, I've done a lot of writing on how technology influenced the development of institutions. And the exact same technology that we thought spreading the Internet abroad would lead to freedom led to the Arab Spring. If we were having Internet safety discussions circa 2010, we would have been talking about child online safety or identity theft. We wouldn't have been talking about how social media would lead to mass mobilizations that would topple governments in Cairo and Tunisia and China was watching that the entire time and responded by using the same technology, not to open up their society, but to build an unprecedented digital surveillance state at Panopticon. So technology, it's not even fair to say it's neutral. It's a fact of the matter. And how we adapt to it is really the open question, what values do we approach it with, and how do we balance the ways that technology shapes the cost structure of institutions in a way that preserves the things that we value. An open society like freedom, like privacy. Those things don't just happen automatically. They happen because humans with their agency, have designed things that way."
    },
    {
        "speaker": "C",
        "text": "So, Sam, maybe we could steel man the argument a little bit. So if what you say is true, that technology is a double edged sword, then why not slow it down? Maybe the regulators are right. Let's slow things down to figure out what the use cases are and gradually inject it into our society. Is that a good approach? Are they maybe the good guys in this story? If technology is a double edged sword, if there's harm as well as benefit."
    },
    {
        "speaker": "B",
        "text": "Well, there are cases, right? You'd be hard pressed to find somebody who's. So I ack that the person who develops the first open source pathogen synthesis platform should just rush and put that out on hugging face. There are issues there, right? And part of this, part of my message is the more we can restrain ourselves voluntarily from rushing into that sort of having the George hot's kind of chaotic neutral sort of mentality, the more we can also push off, inviting a backlash. Often technologies that empower the individual paradoxically lead to a kind of hobbesian crackdown on that very technology if they're not introduced in a reasonable way. And this isn't something that regulators can do. Regulation is a very blunt instrument. And also the whole notion of slowing down, like this AI pause letter, for instance, it was worth the pixels it was written on because nothing paused. And even with all the tech CEO's of those companies agreeing that there are existential risks, nothing paused. Why did nothing pause? Because it's nothing. Because we're in a kind of prisoner's dilemma. We're in a kind of competitive arms race. And at this point, with a technology like AI in particular, we should shift the frame from how do we stop it to how do we brace for impact? Because I do think it's going to be incredibly disruptive in good and bad ways. Like we just talked about the printing press. The printing press came out all right, but it also led to the bloodiest wars of religion that Europe has ever seen, where like a third of the population died. That's not great, but it's also something that we can't stop. It's something you have to go through. Right?"
    },
    {
        "speaker": "A",
        "text": "What does bracing for impact look like to you? If regulation is such a blunt instrument and we desire something a little bit more precise and a little bit more effective, how do we do that?"
    },
    {
        "speaker": "B",
        "text": "Well, this sort of gets into my AI and Leviathan series, where I talk about these dynamics. The way I've been putting it is we kind of have to get to Estonia. People have often said getting to Denmark is the end goal. We need to get to Estonia. Why Estonia? Well, Estonia, we were just talking about America as a printing press native country. Estonia is an Internet native country. After the fall of the Soviet Union, they had basically a blank slate, and they also had this enduring threat of Russia on their border. And the civil servants in Estonia in the mid nineties were very young. They kind of had a hacker ethic, and they built the first, and to this day, still most sophisticated e government in the world. They actually pioneered an early version of blockchain. It wasn't called blockchain, it's called xroad. But their entire government is basically built on a blockchain. It's a distributed data exchange layer where if the Department of Education blows up one day, your files aren't lost because they're distributed all around, and the whole process enables. It unlocks all kinds of automation, because if you are born, you file a birth certificate, your child is automatically enrolled in school when they turn five or six, because the system is just able to do that automatically. They're both able to fortify their institutions against, in this case, the threat of cyber attack from Russia, but also build in the process a sort of government as a platform where they could open up government through API for private actors, e banking, all kinds of stuff. Property titles, all that stuff is able to sort of integrate with government databases in a way that actually shrunk the employment footprint of their civil service. That's where we need to get to. They're the polar opposite of us in terms of the tech stack and their government."
    },
    {
        "speaker": "A",
        "text": "Right? It kind of seems like Estonia would be the government that you would make if you were making a government in the most modern era possible. Like, what if you were charged with building a government using the technology that we have today? This kind of is like the image that you're illustrating, right?"
    },
    {
        "speaker": "B",
        "text": "And as the AI wave washes over and we start having AI doctors and AI lawyers and AI accountants and major job dislocations, so on and so forth, malware bots that are spreading across the Internet and attacking our infrastructure, like we were going to be wishing that we had the cybersecurity that Estonia has built for itself, not just for security and defensive purposes, but also for the new kinds of public goods that they're going to be able to build on that government as a platform."
    },
    {
        "speaker": "A",
        "text": "One of the dichotomies that I really think separates crypto finance from banking finance is that even though bank and Gary Gensler would love to conflate these two things because he thinks the dollar is already digital, but our commercial banking layer and also our government are still like pen and paper logic systems. A lot of the idiosyncrasies of the commercial banking layers comes from the fact that while they still have this pen and paper logic embedded in them, the pen and paper logic is just now in digital form. But that doesn't make it a new age platform. I think what you're saying, what I'm seeing is friction here, is that we have so much tech debt in our social structures, in our financial system, in our government, that progressing forward doesn't seem to be the correct path because we have to go back, remove the debt, and then rebuild a social structure using the technology that we have. Is this what you see?"
    },
    {
        "speaker": "B",
        "text": "Yeah. It's sort of like an innovator's dilemma, but for governments, and the issue with the innovators dilemma for governments is governments are the one institution that's not allowed to fail. And the beauty of the market, I think Joseph Schumpeter had the best way of understanding creative destruction in this context. It's not that markets lead to market clearing prices or that competition pushes down prices, increases product quality. That neoclassical story is important, but it's not. I think the main thing. The main thing is that markets create a space for new kinds of organizations to be built. If you walk outside today and you look around, you don't see the market. The market doesn't exist. You see organizations. Markets are only this abstraction, this liminal thing that exists when two organizations contract with each other. But really, what the world is, is a bunch of different organizations. There's government organizations, there's private organizations. And one of the reasons private organizations tend to be more competent is not magic. Like corporate bureaucracies and government bureaucracies both have some of the same pathologies. The difference is that private organizations are contested. They're always at risk of the startup that comes and displaces them if they're not on their heels, assuming they don't have a legal monopoly. And that contested nature is the most important thing, because you can have very stale companies that have that innovator's dilemma, that have all these legacy processes that they're unable to reform from within and just disappear. In a matter of a decade, their market cap wiped out, all those resources reallocated to the new upstart, all that talent being able to bring it to bear in a new company with a new form. That can't happen with governments. And that's really the most scary thing, is the more eggs we put in the government basket, the more we're counting on, the less we can count on competency to happen by magic. I think this was the original insight of the founders and why they wanted to have the separation of powers so the government can do just the basic things, set the basic framework of rights and so forth, because the core institutions that we have to rely on are inevitably going to change. And it's much better those change in a dynamic setting than have to undergo complete system failure and be rebuilt from scratch after some revolution."
    },
    {
        "speaker": "C",
        "text": "Yeah, and this is an interesting point, I think may as a side point, Sam, but you say that governments aren't contested, and I can see how that's very much true in the short run and maybe the medium run. But is that also true in the long run? Or do you also think basically nation states, this is kind of a sovereign, individual type of idea, but nation states are actually competing for talent, for populations, for economics, for demographics, against one another in this whole world game that we're playing?"
    },
    {
        "speaker": "B",
        "text": "Oh, absolutely. There's a, I see the world as, like I said, sort of through an organizational lens. And the kinds of organizations we have are shaped by transaction costs. Sort of coast as original Ronald coast with this theory of the firm. Why do we have corporations in the first place? Well, because some things are more efficient to do in house. Some things are more efficient to contract over. And those transaction costs, the cost of bargaining, the cost of search information, the cost of monitoring. If you have a contractor, you don't know if they're doing the job well because you don't have direct monitoring over them. That determines the boundary of the firm. It also determines the boundary of the nation state. There are certain things that countries do. Most western countries provide health insurance. Only a few, like England, provide actually nationalized healthcare. Like what countries are doing is solving for the market failure and insurance. They don't care about private practices and private doctors and private hospitals and so forth. So understanding it through that lens, you start to see this echo between the kinds of corporate governance we have in the private sector and the kinds of governance we have in the public sector. Right. Like social democracies like Denmark or Sweden are kind of like mutual insurance companies. Right. Versus. They're kind of cooperative, right. Democracy is also kind of like a co op or like a members co op where we all get one vote. Then you have countries like Singapore, that are much more sort of like a joint stock corporation where they have some areas of democracy, but really it's a very hierarchical system, top down. And that system can make sense because they're a small country. They were literally a trading post of the East India company. So they have this sort of corporate legacy to their institutions. And when you're a small country, you really do feel that competition because you're fighting over capital, you're fighting over foreign investment. Like you said, you're fighting over people and talent and so forth. There's actually this well known phenomena, sort of stylized fact in international economics, which is that small, open countries tend to have better governance because they're buffeted by the winds of trade, by the winds of capital, by the bondholders. When you're a large, relatively closed country, that's where things can go really wrong. And that's what the United States is. We're a quarter of the world economy. We're separated by oceans. We feel invincible. But the world is not. No longer the world is deterritorializing. Those oceans are getting less and less meaningful over time. And there's a question whether we're actually at the right scale. Are we like a corporation that has built an empire and now has too many stranded assets? And how do we reintroduce some of that competition into our institutions so that they can actually adapt? Instead, we have to end up inventing new enemies. The cold war kind of kept us in check for a while. Now we're inventing enemies, not even really inventing actual adversaries in the form of China. But that's not ideal. We shouldn't have to have the threat of world War three be the thing that gets our act together."
    },
    {
        "speaker": "C",
        "text": "I mean, there's also this question of how much the oceans and separation by oceans actually matters on the Internet. I mean, how much does geography even matter on the Internet? And so we're talking about this idea of what would a, you know, we saw the early us being sort of a post printing press nation set up operating system. What would a post Internet operating system for a country, for a nation look like? And you pointed at Estonia and you talked about its adoption of technology and creating almost like government as a service, an entire API. There's one other dimension beyond technology that I feel like we have to talk about. And maybe you talked about this balance between tech accelerationism and tech doomerism. Is there also a balance with this idea of freedom? How much freedom does a post Internet society actually give to its citizens? Is there a tension between freedom and control. And have you seen examples of what a post Internet operating system that enshrines freedoms actually looks like? One idea I have for you, Sam, is just, it seems very much to me like we need some sort of protocolization, I would say, of a digital bill of rights, if that makes sense. I mean, like, just the basic right for a citizen to encrypt their own private keys or encrypt their own data. The right of a citizen to hold crypto, for example. I don't know where these rights are preserved. I mean, some legal expert might say it's somewhere hidden in the constitution and will get a Supreme Court ruling that actually preserves these rights. I'm not so sure. And I'd feel really good if they were enshrined at a far deeper level. Have you seen any examples of that? And what is, what about this tension between freedom and control? How does a nation state run its operating system on that in the post Internet era?"
    },
    {
        "speaker": "B",
        "text": "Yeah, these are excellent questions, hard questions. Thomas Hobbes wrote his Leviathan, sort of the first entry into political science at the end of the english civil war. Right? And so when Hobbes talks about the state of nature being a war of all against all, he's not really talking about, like, hunter gatherer societies, although that's still true. He's talking about his own nation, his own comrades, his own countrymen who murdered each other viciously over religion. And his solution was this idea of the Leviathan, where freedom or peace and order are kind of restored by circumscribing our natural liberties, to some extent, my liberty, to kill you or strong arm you or rob from you. And by ceding that power to a higher power, we're able to find a new peace."
    },
    {
        "speaker": "C",
        "text": "That higher power, by the way, Sam, that's the government. Right. And their monopoly on violence, correct?"
    },
    {
        "speaker": "B",
        "text": "Right. And so in some ways, like what we associate with the classical liberal tradition, arose not out of a weak state, but a strong state. A state that was able to raise revenues through professional tax administration, was able to fortify the border through modern armies, and impose an impersonal rule of law that actually takes quite a bit of administrative capacity to do. Actual anarchy. Actual weak states look like northern Mexico or Afghanistan. You may have some freedoms there that you don't have other places, but it's actually closer to the state of nature. The question is one way to interpret that is that as you increase the capabilities of an individual, the sovereign individual, that leads to negative externalities. If I suddenly had x ray glasses and I could see through the wall that enhances my capabilities. But if you also have those glasses, suddenly my privacy is being violated. And then we have a new sort of conflict at the boundary of our intersecting spheres of influence that invites demand for a new leviathan. And so China's answer to this is to assume total power, and to have cameras in every corner that can recognize your gate and ding your social credit score if you jaywalk. That does not seem like a very pleasant world to go to. I think the challenge in the post AI, post Internet world is how do we preserve some concept of a public sphere, of an open sphere where we have freedom, where that freedom is actually felt and lived, rather than having a reaction to technology that seems emancipatory on the front end, but leads to a backlash, where we end up building our fences higher."
    },
    {
        "speaker": "C",
        "text": "I would assume, Sam, you are willing to say some technologies are just too dangerous for individuals to have freedom over. That would be part of your pragmatic approach. And how do we know which technologies are like that in advance?"
    },
    {
        "speaker": "B",
        "text": "It's hard to know. I mean, historically, we don't know what they are in advance. Outside of atom bombs and pathogens, we've learned through trial and error, and often bloody trial and error. I think there is genuine risk around AI. And I know you've talked about this in a show before. It's also going to be a technology that, at least for the most powerful systems, is inherently centralizing, because you need access to compute. And as the models scale up, the people and the organizations with access to that compute is going to get fewer and fewer, because these scaling laws are logarithmic. So if you want to build the 1000 X version of chat GPT, you're going to need not a billion dollars, but $10 billion to train it. And so this is a technology that by its nature, is going to be concentrating power. And I wonder, to what extent is the state, with the right political leadership, the only thing that can really counterbalance that? When we talk about privacy preserving technology, for example, it took those policy hackers in Estonia to want to build that in, into the firmware level, where they were basically tying their hands. And in some ways, what classical liberalism is, what the 18th century ideal was. Like I said, it wasn't a weak state, but it was a constrained leviathan. It was a state that was able to preserve what Hayek called ordered liberty, where the government limited government, where we tied our hands about the kinds of things we could use technology to do even if it was available, and do it in a way that was credible, that wasn't just written on paper. So when I look around, I think there's also this competition with China vis a vis the kind of technologies we export abroad, where China is building this tech stack for digital surveillance. State, insofar as you think the Internet and AI are going to lead to new crises of authority, new sort of sources of social disorder, a la the Arab Spring, there's going to be a demand from every Tim park dictator to import their own technology stack to restore order. There's technology that can do that in a way that's just unbridled, and there's potential technologies that do some of that surveillance, do some of that policing and law enforcement and so on and so forth, but in a way that has civil liberties and privacy engineered into it. And so I think that this is sort of like the package deal that we're faced with. It's not all sunshine and roses. There are actually really hard trade offs here. And some technologies sort of bring good and bad at the same time. And we have to figure out a way to balance those, and not just balance them in a technical level, but find new institutional arrangements that are credible and consistent over time. Because a piece of paper is worth the paper it's written on."
    },
    {
        "speaker": "C",
        "text": "One last topic before you leave this, and focus a bit more on AI and your thoughts. But I'm endlessly fascinated with this idea of thinking of nation states as a tech stack, as an operating system. I think in this post Internet world, that's how we should think about this. These bundles of services and this bundles of software, this is this last idea, which might be a potential solution, which is hinted at in crypto and then other technologies like AI. There was a line, I think you gave an episode I listened to on Eric Thornburg's podcast where you said software is eating the state. Software eating the state. And this is like a 16 Z Marc Andreessen idea as well, is like software eats the world. And so why shouldn't it eat the state? And indeed, this has been a crypto ideal from the very beginning, right? Which is like the idea that crypto, at least an element, can start to eat at the money system. We can have a separation of money and state, at least to some degree. We are not dependent on a fiat money system. We can use bitcoin or ether as our denominator. Ethereum, the idea of a digital property rights system that is self sovereign and without the nation state protecting it. These ideas are powerful. And some of this, I guess, philosophy and solutioning is I think manifest in Balaji's idea of the network state. I want to ask you to what extent you think that could be a potential solution for us. On my rosier days, I'm all in on the network state. I think we could do this. I think networks can replace functions of government. Not everything. We're not going to build roads and hospitals, but maybe in the area of property rights, maybe in the area of banking, that sort of thing. On other days, I think, oh, shit, what a mess. Like, hey, Gary, come bail us out. Do you know what I mean? It depends on the day. How much of the network state ideas embedded in Balaji's philosophy do you think is actually pragmatic and can work? And how much is the pie in the sky idealism never going to happen, will always revert back to the legal code. Forget code is law. Which law is law? Court systems for a reason."
    },
    {
        "speaker": "B",
        "text": "Yeah, I think what Balaji is trying to do, it's sort of a libertarian Marxism, if I could put that term on it. Because what Marx said was, the philosophers have only interpreted the world. The point is to change it. And coming off of Hegel's progressive dialectical view of history, the idea was, could we somehow skip ahead and see the next stage of history and try to make it come sooner? And I have a piece on libertarian Marxist, where I sort of talk about the resonance between. You can read the communist manifesto, and you could read George Stigler's essay on regulatory capture. And they actually sound kind of similar. So I think Bellagio's actually onto something. He's never going to be exactly right, because you can't predict the future. But if you get a grasp of some of these deeper structural trends, to sort of dialectics and history, maybe you can try to get a prophecy, pull forward some information about what's coming. I think where the network state idea breaks down is, again, the limits of deterritorializing. The original public good was security, the kingdom that could build a wall around you. My sense is that aihdenite and the diffusion of AI is going to lead to all kinds of new security threats, whether it's novel pathogens, or drone swarms, or nitpick or poison. And there are still going to be agglomeration economies to having people co located in one area. So you can build those EMP guns and stuff like that around you, by the way, Sam."
    },
    {
        "speaker": "C",
        "text": "And by security, you mean actual, physical, in real life security. Because sometimes in crypto, when we say security, we mean things like encryption or the economic cost to attack the network via proof of stake or something like this. But you're actually talking about literal physical security here."
    },
    {
        "speaker": "B",
        "text": "Yeah, both. And. But especially the physical side of that. And, you know, in the future, maybe we'll have, you know, you know, my vision is sort of like an America dotted with an archipelago of city states. Wherever we have, as your autonomous vehicle is driving into the free city of California, it's automatically being scanned for contraband or what have you, and we have an iron dome that's constantly shooting at drones. All that stuff is going to require being physically co located. And actually, I think similar to the Internet, a lot of the early Internet pioneers predicted the Internet would lead to a kind of disintegration of a need to, to have these economies of scale in cities, and we just all would work remotely and so forth. That never really came true. And even with VR and with better high bandwidth Internet, land values in cities have never been higher. Some people still like to live nearby. And a lot of the core public goods that states provide aren't just that title protocols and so on and so forth. It is actually that physical security that's sort of like the primeval public good, and that's not going to go away. That doesn't mean that there can't be sort of intersecting and maybe like a marble cake kind of arrangement where you do have sort of interlocking network protocols and so forth that are providing different kinds of social services. I know the folks at Prospera, right, and Honduras, like every one of their parcels of land, has its own jurisdiction. That's pretty cool. So all that stuff seems possible to me. I think he's onto the right track in trying to intuit what the next stage is. My take is that the things that people hope for with crypto are more likely to come true because of AI. And that bears on the fact that AI directly affects these core transaction costs, like monitoring, bargaining, search, information, agency costs. We will have AI agents that do our bidding and don't steal from the till, don't shirk. They actually follow orders, and that's going to lead to people like individuals with 50,000 person corporations under them, of AI, effective employees. That unlocks a huge potential for new forms of collective action, new kinds of institutional arrangements, and potentially, like I said at the start of this talk, giving new life to crypto and blockchain as a highly complimentary technology."
    },
    {
        "speaker": "C",
        "text": "It is true that the AI robots will all need to be banked, and I doubt they'll be able to go to Wells Fargo and open an account so they'll have to turn somewhere."
    },
    {
        "speaker": "B",
        "text": "Yeah. There are these things like federated learning, for example. It's a big open area where you need a lot of compute and you need a lot of data to train these models. And how do you compensate people for that data, and how do you distribute that compute in a federated way? That's a core area where crypto technology and AI are intersecting and leading to something that's greater than the sum of the parts."
    },
    {
        "speaker": "A",
        "text": "Sam, I don't know if you are on Twitter or following me on Twitter, but my Twitter handle is trustlessstate. And it's always been with this very far out notion of in the future, there will be this nation state, this virtual nation state in the cloud, enabled by property rights on a blockchain that will produce some version of a coordinated organization, a coordinated governance, and as trustless state, using the trustless state machine as ethereum. It's a double entendre."
    },
    {
        "speaker": "C",
        "text": "Very proud of it, by the way. David. Now, Sam should tell you his Twitter handle. Do you know this?"
    },
    {
        "speaker": "A",
        "text": "No, what's yours?"
    },
    {
        "speaker": "B",
        "text": "Sam Hayman. Cheese, like the sandwich."
    },
    {
        "speaker": "A",
        "text": "These are different things. Okay. But going into single entendre."
    },
    {
        "speaker": "C",
        "text": "David, Sam's last name? Hammond. Hammond Chase."
    },
    {
        "speaker": "A",
        "text": "Yes. Going back to the whole idea of our current nation state is a pen and paper nation state. It also happens to be just the leading empire, which tends to have a lot of momentum. That tends to be a very hard ship to steer. And you've already talked about, just like, the anti tech sentiment that's come out of post 2016. And so we're seeing a lot of this resistance towards adapting while we have this very adaptive new technologies, crypto and AI, to name the two, foremost. And while I have these very optimistic visions about what a future trustless state could look like enabled by future, I was definitely brought back down to earth in 2022 when I realized that the things that my industry did during this last rise into fame was promote people like Sam, Bankman, Fried and three arrows, capital, et cetera, et cetera. I still 100% believe in the fullness of time, this optimistic vision of some sort of society organized inside of the cloud, the trustless state, and very much agree that AI is a very powerful component, a part of that. But I now realizing that there is the trials of having to get there. And in your article, you talked about first order and second order consequences of AI safety. And I think maybe there's probably first order and second order consequences of bringing crypto into the fold, whereas in the fullness of time, I believe in my vision on the way there, there might be some frictions and some frauds along the way. So how do you think about just this relationship in this very high potential technologies like AI and crypto that in their immaturity phases get resistance from the nation states and the lack of support from the nation states, and yet also cause a bunch of trauma along the way? How do you think about these things? Do you share my optimism and that in the fullness of time, we will be able to have this more optimistic future that we see here?"
    },
    {
        "speaker": "B",
        "text": "The only reason I would say I'm not sure is because just how quickly AI is ramping up and how quickly things could change, and all my predictions could go out the window. So caveating that anytime there are sort of $1000 bills on the sidewalk and we can all see those thousand dollar bills on the sidewalk, it takes heroic efforts to contain capitalism from trying to grab those bills. Right? And I'd start talking about this as like regime change in micro. The idea that technology can induce a regime change sounds dramatic, but we went through one. It was called Uber and Lyft, right? Like circa 2014. Uber start 2009. But, like, it still was picking up around then. People thought you were a weirdo if you took a ride with a stranger. And in that course of those next five years, the number of rides in New York that were delivered by taxi commissions versus Uber completely flipped from 90 ten to 1090. And that was a regime change in micro. We went from a system that was organized by legal monopolies, public regulatory commissions, with formal licensing and exams, and massive corruption in many jurisdictions, to using technology, basically forcing an entire regime change where now the typical person is riding in a car that still has governance, but it's not legal fiat governance with the force of a gun. It's governance through these platform mechanisms like reputation rankings, the search and matching platform that Uber provides so you don't have to haggle with the taxi driver. All those things represented sort of $1000 bills that were on the sidewalk. Once we had mobile and a phone in everyone's pocket, and everyone had Internet connection. And so it was just a matter of time before someone developed it. Unfortunately, in the case of tax exemptions, things were local enough and there was enough jurisdictional competition where you could get your foothold in a market and demonstrate the technology and prove that it was safe. And not just safe, but better and more reliable and faster and cheaper. And so I think in the fullness of time, and this goes to sort of like the core, if you will, that there is a sort of autocatalytic, self fulfilling dynamic to capitalism, to what Andreessen calls the techno capital machine, that once these technologies are, once the Pandora's box is open, so to speak, it's really hard to contain. And people will fight all the way through and you'll get variations on a theme, but we're going to punch through this one way or the other. And my hope is that we can at least try to steer it in a maximally positive direction because it's so easy to imagine ways that AI could go wrong and lead to bad forms of bad outcomes that aren't just bad, but are potentially locked in for eternity."
    },
    {
        "speaker": "C",
        "text": "I definitely want to touch that again, bad, but potentially locked in to eternity. But now let's shift the conversation wholly to AI and let's talk about the present. So we've been talking about these dynamics of technology and how they can transform society and how the elites and those in power often feel threatened by that transformation. But also there should be a technological pragmatism. Sometimes technology is actually dangerous. And I want to talk about the present and the us reaction to AI right now. This was, I believe, a week ago. Maybe this happened last week, Sam, President Biden issues an executive order, called it on the safe, secure, and trustworthy artificial intelligence. This was an executive order on AI. And maybe you can tell us the ins and outs of how enforceable this executive order actually is. But it does seem to ascribe some intent. And the interesting thing here in this executive order for crypto listeners is, as I read some of the provisions of this order, crypto listeners, you might see some themes. The first is there is this idea implicit in the order that if you're building a large model, large language model, or large AI model of some sort, you have to report to the government. So come in and register. You guys ever heard that from our friend Gary Gensler? There's also an implied restriction on open source model weights. Feels kind of permissioned, I would say. There's a provision in here that those with large compute resources have to actually disclose where those resources are. So where are the GPU's? Where are the server farms? Disclose your location. Starts to sound a lot like in crypto. Disclose your assets. What do you actually own? The government needs to know infra providers. So if you are a infrastructure provider for AI services and there are foreign persons who are using your services, you have to register those foreign persons. Okay, this is like AML KYC for compute. This is the parallels to me, Sam, between how regulators and government are responding to AI and crypto are just like, like nearly one to one here. But zoom out for us. What do you think of this executive order? Where is it coming from? What's your take on it? Overall?"
    },
    {
        "speaker": "B",
        "text": "I thought that was a great summary, especially of, I think really the core provisions that have teeth. The vast majority of the executive order, outside of that stuff, is basically reporting like interagency reports. HHS has to develop a big report in all the ways they're going to use AI and healthcare. I think all that stuff is just sort of anodyne. The key thing are this, especially this compute threshold requirement that companies that are training models on ten to the 26 flops, the number of operations used to train the model, are going to have to, again, merely reporting. But often reporting is a prestigious regulatory action later down the line."
    },
    {
        "speaker": "C",
        "text": "Oh, we know. We certainly know about that."
    },
    {
        "speaker": "B",
        "text": "We'll have to report both that they're doing the training and also what safety testing they have done. And presumably at some point, NIST has also been asked the National Institute of Standards Technology to develop sort of best practices for red teaming and testing models that will probably serve as the benchmark for evaluating those safety tests. I kind of ambivalent on this relative to what Europe has done, which has essentially outlawed open source altogether and brought in a genuine registry where everyone's model is going to be in this giant registry. And what they consider high risk in Europe is LinkedIn, because LinkedIn has algorithms for job recruiters that could be biased. What they deem high risk is trivial in my mind. The fact that they're targeting or segmenting these really large training runs, I think is actually a good sign in the sense that they're taking most seriously the, the core AI safety risks that you hear from folks like Eliezer, that really the thing to keep your eye on is the emerging capabilities these systems will have as they scale. And to date, like the largest model trained to date is either GPT four or palm two, depending on who you ask. And that's probably on the order of ten to the 24 flops of training. And so we're still like a year or two out from any company on earth training a model big enough to actually be hit by that threshold. I was actually kind of pleasantly surprised by that, because it shows that this is in some sense, the light touch approach. They're zeroing in on the core AGI risks that we hear talk about, and there is lots in there about housing and urban development, has to make sure that they're, their housing algorithms aren't racist and all that stuff. I find all that stuff kind of somewhere between annoying to counterproductive, but that's sort of like a must have for any democratic administration. The fact that they didn't do that to the exclusion of focusing on, I think the core safety concerns is, I think, a huge positive and reflective of the fact that the administration actually was listening to some folks in the AI safety EA world."
    },
    {
        "speaker": "C",
        "text": "So Sam, your take over all is this wasn't too bad. It could have been worse. And Europe, in fact is pursuing worse policy around AI."
    },
    {
        "speaker": "B",
        "text": "Yeah, exactly. I mean, you get a bunch of reports, government loves reports. I think the KYC stuff and reporting your compute, that's something to keep an eye on. It is part of a broader trend towards, and I've talked about this a bit in my other piece towards nationalizing of compute infrastructure and telecom infrastructure more broadly. And you can sort of see why this is happening. We had export controls on chips back in 2022, the October 7 export controls that essentially embargoed China from having access to the most advanced GPU's. Those were updated last month to get rid of the interconnect bandwidth requirements. Now it includes basically all kinds of gaming GPU's, including h, so forth. There's ways that you can exempt those, but the National Security Administration and broader national security community is taking this really seriously. And if we do have an AI takeoff like owning our compute infrastructure and making sure that we don't have foreign agents at these companies is, I think, going to be really important. And it really, really makes clear the extent to which these technologies are dual use. They do talk about dual use foundation models in the executive order. And what does that mean? Well, you can't build a self driving car that only works in red cars but not blue cars. The whole point of general intelligence is it is general, and being able to do things outside your training distribution is the core test of generality. Having autonomous agents that are truly general and superhuman is going to be something that we've never had before. It is, I think, a huge exception to my normal rule of go faster, particularly in the context of geopolitics."
    },
    {
        "speaker": "C",
        "text": "Sam, we talked about the US. We talked about Europe a little bit. How about China? How does this juxtapose between China's approach to AI? This from one of your recent sub stack posts about China. I believe democratized AI is a much greater regime change threat than the Internet, and the CCP is treating it as such. What's China doing with respect to AI?"
    },
    {
        "speaker": "B",
        "text": "So they have draft regulations which are, I think they're basically enforced, but they're still being refined. But the draft regulations essentially say that you can't build a large language model like chat GPT unless you undergo security review. And even then, they have very strict rules about what it can be trained on and very vigorous testing before it can be deployed. China, in the bigger picture, is probably at par with the US, or maybe even ahead of us on the purely science research side of AI. Like if you just restrict to AI papers with the top ten percentile of citations, China is actually ahead of us. But in terms of diffusion, in terms of actually deploying the models, they're taking a very, very conservative approach. And for obvious reasons, like we talked about, the way they respond to the Arab Spring by fortifying their surveillance state. AI is like that on steroids, right? I often think about there's this old State Department program where they used to drop USB sticks into Cuba that had Wikipedia and Netflix and a whole bunch of stuff on it, so people who don't have access to the Internet could see what they're missing. And you can think about dropping LLMs into China will tell you about Tiananmen Square and tell you about all kinds of things that the regime doesn't want you to know. And more generally, as the technology develops and diffuses give massive capabilities to society vis a vis the state, the way the technology is rolled out to date has been sort of one sided, where the state can use it to monitor your every move. But what happens when those technologies become offensive and people can use those technologies for resistance? And so this is why I situate this in a geopolitical frame where I'm not that upset that the US is taking a more sort of national champion approach to the semiconductor sector and to compute more broadly, because we are in this arms race in the technology space, not for military per se, but for defining the new governance model. And I have more faith that a positive version of a post AGI governance, future governance will emerge from the United States and from the west than I do from China. I could easily see if China gets there first, them having runaway economic and technological power, and just subsuming the country in a model that I don't particularly approve of."
    },
    {
        "speaker": "C",
        "text": "We've been talking about technology this entire time as a double edged sword. I think if you go and you ask a person on the street about Aih, they won't be able to tell you concretely what they think about it. Like, I also remember the Internet back in the nineties, and that was heralded as everyone was excited about it. Everyone was incredibly enthusiastic about this new communications protocol that would unify the world, unite the world. That is not the feeling you get from AI, right? Often it ranges into dystopian sort of territory. And I find myself actually not sure about AI. It's like, on the one hand, again, on those sunny, rosy days, I could see the potential for democratizing technology of freedom here. On the other, I see large models deployed by nation states to just basically control all information inflow to citizens. Is this just the double edged sword that we're dealing with? Or is there a clear kind of, this is a freedom technology, or is this a technology of enslavement? Where do you fall on that?"
    },
    {
        "speaker": "B",
        "text": "I think the biggest risk in the west is that we end up enslaving ourselves. If you think about the decline of free range parenting, maybe peak free range parenting was the seventies, which happened to be peak crime wave. Paradoxically, now crime is way low. Gps trackers on your kids, and they're not allowed to leave like a mile radius of your home. And so there's this weird, paradoxical effect where, like, greater transparency we see, every time someone's murdered, we see every crazy thing happening in the world, I think has made people turn inward in a weird way. Even though they now have the technology to not be a helicopter parent, in the same way that everyone having a camera on them at all times, you know, leads people to maybe be a little. To not cause a scene on the bus because they're going to go viral. And so that fact that everyone basically has in their pocket recording devices and things can go viral quickly and be basically permanent. We sort of built this bottom up surveillance state. We're sort of like living in an east Germany of our own making. You can see how this could go way worse with AI, where we have vision models now, multimodal models, that you can give them an image and just prompt them to say what is happening in this image? And they are remarkably good. I tested GPT four's vision capabilities. It identified the breed of my dog. It said it looked comfortable, and it said the home it was in, it looked cozy. And it's like, oh, wow, how does it know all that? Well, you can also imagine prompting the model, is anyone committing a crime right now? And just having it repeatedly be prompted, is anyone committing a crime? No longer do you have to be super specific. You can just use these vague semantic categories. And because it has a broader world model, it's able to just take in that vague input and give you an answer. And that's something I could see North Korea doing. I could see North Korea putting cameras everywhere and having them constantly be prompted as anyone committing a crime. And it sort of solves the paradox of 1984. When I read 1984 as a kid, I was always wondering, how do they have as many people on the other side of the cameras as they have watching as big brother? And we sort of solve that problem. We can do that at scale. Now, I don't see that happening in the United States, but what I could see happening is us all building a bottom up leviathan where we all want to have the ring camera for our security, more power to us. But suddenly we're constantly surveilling each other in the same way that, like, you know, it didn't used to be a thing where, you know, you see these TikToks where, like, they'll run. They'll run into a couple on the street and ask them to. They'll test their trust. You'll look, do you want to look at each other's message history? And just having that as an option, right. Just having that as an option opens up all kinds of crazy things."
    },
    {
        "speaker": "A",
        "text": "The prompt is, anyone committing a crime right now is an interesting one because it does imply some sort of perfect information by the prompter. Whoever has access to what's got to be having the most compute, because whoever's going to have the most. If you want to actually be effective in producing security, you're going to need to have the strongest amount of compute in order to actually come up with an accurate answer to the question, is someone committing a crime right now? So it's going to be the most central powerful monopoly, which is, of course, going to be the state. But then wouldn't the prompts USB isn't some or who is about to commit a crime. And that kind of just turns into minority report, where you have the pre op saying, like, predicting, like, oh, that guy's about to commit a crime. And then we have, like, the ethical judgment of, like, do we try people before they commit a crime because we stop them from committing a crime?"
    },
    {
        "speaker": "C",
        "text": "I mean, you guys are making my point here. This is all starting to sound very dystopian, right? Like, this is not the world."
    },
    {
        "speaker": "B",
        "text": "The future is going to be weird, and I think it's going to be uncomfortable to a lot of people. And, yeah, it is very double. So one of the things the EU AI does is preemptively prohibit the use of predictive police AI and predictive policing. And I'm very ambivalent about that as well, I could see AI leading it to all kinds of social disorder where predictive policing could come in handy. And, like, what is predictive policing? Where do you draw the line? Is just having a Bayesian prior about, like, who's more likely to commit a crime? Stepfathers are disproportionately responsible for kidnappings, and so if your kid goes missing, you should start by interviewing the family members. It's very unlikely to be kidnapped by a stranger. Those basic statistics that informs the way we do policing, the fact that there's more crime in a particular neighborhood means they should put more patrol cars there. There was a recent paper using machine learning that used, like, 600,000 victimization and criminal records in Chicago and was able to identify 500 people who were most likely to be shot within the next 18 months. And sure enough, 13% of those 500 people were shot in the next 18 months."
    },
    {
        "speaker": "C",
        "text": "Wow."
    },
    {
        "speaker": "B",
        "text": "If you could allocate resources in a way that would stop that, you should. But this goes to the point of having to engineer civil and privacy liberties into the technology itself, because we want to have the good part. We want to have the constrained Leviathan while avoiding the unbridled Leviathan that could result. It's going to be really weird. And this goes to my point in the essay series where I talk about the likelihood of this stuff just leading to government fragmenting, because I actually disagree. I don't think government is going to have the most compute. I think it's going to be the private sector. Government, if they wanted to, couldn't build a large public cloud. Private cloud. They don't have the engineering capabilities. What that means is we're going to end up being sorted into new walled gardens, new forms of vertically integrated social protection, social regulation. That could seem, in some ways, much more draconian on paper, things that government aren't allowed to do. But of course, a church can deny you membership if you're not. If you don't ascribe to their thick beliefs, you don't have freedom of speech when you're in Walmart. Private institutions are the exception to our openness as an open society. And so think about the fact that when you go to a comedy club these days, they'll take your phone away. That didn't used to happen, but that happens now, because now we all have cameras in our phone that we can instantly put the person set on TikTok, and they don't want that, right? And so as our technologies get more capable, we're going, you know, if I could walk through an office space with a recording device, transcribe all the conversations that are happening and also use audio cues to like keylog the people that are typing. We're going to need metal detectors that like, tell you you can't bring your phone into the office. Or maybe we'll all be issued, there'll be like places that only let you have like the Nokia keyboard phone or something like that."
    },
    {
        "speaker": "A",
        "text": "So I'm actually kind of reminded by that, by some sort of semblance of Balaji's network state concept where. So if the net, if the nation state isn't going to have the largest access to compute because they don't have the engineering talent, what you're saying is then, well, the private sector will get it. And the private sector isn't going to have a monopoly over one central large pool of compute. It's going to be, you know, pockets of strong compute spread out over very large, well capitalized entities. And then they get to kind of set the rules for their little fiefdoms, their little, wherever they control. This is my interpretation, and so, of what you're saying. So check me if I'm wrong, but that kind of sounds like, well, each different, like, region as determined by the surveillance of that particular arena. Those will be the rules. And kind of goes back to the whole title of, or the line that Ryan pulled out of your old podcast, which is software is eating the state. Is this kind of the progression that you see?"
    },
    {
        "speaker": "B",
        "text": "Yeah, I mean, like, what is the state like, what are bureaucracies but flushy APIs? Right. You know, the government actually owns a mine in Pennsylvania where every morning people climb into a bus. The bus goes underground into the, into the abandoned mine that has been retrofitted, and it's part of the Social Security Administration. They have a bunch of archives down there. Their job is to print out PDF's and scan them back into the computer like all day long. Right. And I don't mean to trivialize what civil servants, public servants do, but you move a layer up. A lot of what it is is just applying a little bit of human judgment, human context, to a checklist and then hitting send. Later this year, when Office 365 copilot rolls out, Microsoft is putting GPT four into everything, into all of Office, into Windows eleven. There's going to be people at the Bureau of Labor Statistics that are showing up to work to do the monthly jobs report, and they're going to have a CSV file and they're going to tell Excel, find me the five most interesting trends, and write a blog post around it, then their job is done. It seems to me that bureaucracy is incredibly exposed to this technology and also the broader professional managerial class. And this is why they will be the locus of the butler in jihad, right? They are the people that are most directly threatened by this, but it also opens up new ways of doing government in the same way that we saw a shift from taxicab commissions to Uber and Lyft. Imagine if we had cameras with multimodal models equipped in every farm. And would we need a USDA? USDA sends farm inspectors manually to go to different firms and make sure they're not like, you know, abusing the chickens or whatever. Like, you could have cameras that are always running and generating reports. Automatically they get sent back to the underwriter and then provide, you know, adopting compliance standards that are far more dynamic, far more adaptable than anything the USDA regulator could put out. And just like you would subscribe to Uber as a platform, you would subscribe to this, you know, farm regulator as a service company that is selling you something that's much higher trust AI as a potential to remake how we do governance while also restoring the trust that I think has been in decline since Vietnam."
    },
    {
        "speaker": "A",
        "text": "One of the things that you said was that humans would all be able to check on other humans with the assistance of AI little pets, like our little AI assistant. I always assume I'm a big, hey, siri guy, and I'm just about to go trigger her. I use her all the time, and one day I'm assuming she's just going to become like a super sentient AI, and that will be my little native AI assistant or the Microsoft version or however that comes out. Every human has their own little AI assistant, and one of the stories I like to say about the emergence of money comes from just the inherent pro social behaviors that are found in many, many species. I've given this talk so many times. I just gave it in Lisbon a week ago, and it was about how bats, vampire bats learn to have prosocial behaviors where they will all go out and feed. Some will get lucky with food, and some won't get lucky with food, and then the unlucky ones will nudge their neighbor and be like, hey, I didn't get any food today. Can you lend me some food via regurgitation? It's kind of gross. And then they will have prosocial behavior and they will spread out the food, and the bats that are selfish are stingy. Those end up getting shunned, and they don't ever get any reciprocity and they, those genes removed from the, from the gene pool. Uh, and this is how like, prosocial behavior came about. Uh, concepts of internalized in your own brain balances of debits and credits turned into the need to have ledgers. Fun fact, double entry bookkeeping in our commercial banking layer is actually just a system of all ledgers pointing at all the other ledgers and keeping everyone else in check. And so this system of individuals in society having the tools they need to keep others in check is actually an ancient tool set that has developed over and progressed over the years. And so if you're telling me that, like, oh, we have potentially a future in which AI is actually a democratized technology and humans have the power, the capabilities of doing checks on their local environment, to me that doesn't sound like there's the total of the top down AI overlord, eye of Sauron powers that other people have articulated. There seems to be some amount of balance here. What would you say to all this?"
    },
    {
        "speaker": "B",
        "text": "It's all about managing the transition. I think one of the ways that AI could be most useful in this realm is restoring forms of credible commitment. If you could voluntarily submit yourself to an AI monitor that verified trust, but verified that you did the thing that you were going to do, then you can completely eliminate the residual lack of trust that you might have in hiring someone to do a job for you. So that seems like it could be a boon for trust. On the other hand, like we were saying, this exact same technology could be used to massively scale censorship. I think about Activision recently announced that they're going to be using large language models to police speech on Call of Duty, which historically, luck with that. Well, historically, the way companies would do this, and the same with content moderation on Facebook or whatever, is you have a list of banned words, right? And you have them on YouTube too. Like if you people on YouTube will say unalived, right, because it will avoid being downright in the algorithm, right? But LLMs aren't fooled by that, right? LLMs aren't just stochastic parrots. They understand, they have a world model. They understand deeper semantic representations. And so you can instruct the LLM as it's listening to call of duty chats, to just flag people who are talking about things that are inappropriate. You can just give something as vague as that. This enables potentially that you could paint this as a positive light. Maybe we don't want bad words being said on Call of Duty. Maybe we want the nanny state to make sure we're on our best behavior. But it all comes down to who's in control. Is it Elizabeth Warren that's setting the terms? Or are we going to circumscribe this power and ensure that we have this better future where it's democratized in a way that's kept in balance? Because I just don't think that happens automatically. I think most countries don't have our protections, don't have our bill of rights, and they'll lead to a more centralized answer and places that do have these protections. By the very dent of those protections, it will lead to a decentralization where the state ends up fragmenting and we end up with, with these new sort of micro nations being formed in its wake. Maybe the government persists around some core competencies, but the need to restore order through ways, through things that seem draconian on their face, in the same way that taking away your cell phone if you go to a comedy club seems draconian to the extent that the value of those sort of things rise, that we'll want neighborhoods gated, communities that have all kinds of AIH surveillance, but in a way that the community has agreed to and opted into, that leads to a world that in some ways looks is neither libertarian or statist. Some people will opt into the Mormon AI state or whatever that makes sure that you can't drink coffee and that you don't say bad words. There will be a lot of variations. And my big question is just how do we manage that transition? Well, because as a student of history, I see it going poorly, especially from her current position and especially from an establishment that is trying its hardest to keep a lid on the technology. Because theyre afraid of change. Theyre not afraid of change in the abstract. Theyre afraid of them having to change. Right? Like once we have fully autonomous cars, will we need a national highway traffic safety Administration? Probably not, right? But we already have studies showing that Waymo is much safer than a human driver. Like they even have lower insurance rates. Right. And nonetheless, San Francisco has just kicked Waymo out or cruise. But either way, we have self driving cars that are now safer than humans and we're not just massively embracing it like what is going on."
    },
    {
        "speaker": "C",
        "text": "I mean, one thing I think that resonates with us and how we manage this change, this transition period, is this phrase decentralization. I mean, it is quite the 1984 esque prospect of having central powers with the ability to kind of censor at the level of an artificial intelligence wherever they can. So that seems to be something that we'll want to preserve. And, Sam, as we kind of draw this to a close, I want to, in this last portion of our conversation, allow you to get kind of vivid about some of your predictions, because you put together this fantastic post, and this was actually part of the genesis for my reaching out to you, Sam is just so fascinating. This is a three part post on substack. It's called AI and the Leviathan. We'll include a link in the show notes many of the themes and topics that we've been discussing, only in kind of narrative form. The third part of that post, you actually start to get into predictions for the next 20 to 30 years, and you break this out in some periods of time and where some changes might happen, you kind of describe those changes, and that's kind of the vivid depiction that, honestly, I needed. And whether this exactly happens to your timeline or not, there's a Sci-Fi element to this. And of course, the future is unknowable and unpredictable. I think there's some ring of truth into it, at least with respect to this transition. So I want to go through that. So you start this third part of your article, and you say my null hypothesis is that the democratization of powerful AI capabilities will be at least as destabilizing as the printing press. Then you start this chronology of 2024, which is next year, all the way to the want to go through some of these time periods and allow you to tell us what you think could happen. But before we do this, frame this up for us. How much of this is like Sam Hammond ham and cheese Sci-Fi versus what you actually think will happen?"
    },
    {
        "speaker": "B",
        "text": "Like I say, it's my default path. So in the specifics, the exact timing, but in broad strokes, I think this is what happens by default. I sort of frame it as we're sort of on this knife edge between sort of chinese panopticon on one side or snow crashing anarchy on the other, where what real anarchy looks like is not just everyone living peacefully in freedom, but an archipelago of gated communities that are restoring order locally."
    },
    {
        "speaker": "C",
        "text": "Well, that's kind of zipping to the end. So let me go through these and draw out some of the keywords that I found. Now you reflect. So 2024 to 2027 next year, and up to 2027, vast majority of our content goes synthetic. So the Internet becomes AI generated. Is that the idea? Something that we could see in the next three to five years here?"
    },
    {
        "speaker": "B",
        "text": "Yeah. So in general, I have very short timelines to AGI relative to, I think, the person on the street probably not relative to people who follow this, but in the next couple of years, really, starting this year and next year, AI is going to be hitting enterprise in a big way. Right? I think we're going to see a downsizing wave that rivals the late nineties, probably much bigger."
    },
    {
        "speaker": "C",
        "text": "What do you mean by downsizing? Downsizing, like job losses ramp up? Is that the sort of thing you call this event in the late twenty twenty s? The great repricing? What is that?"
    },
    {
        "speaker": "B",
        "text": "Yeah, like the great asset repricing. I've been wondering, we have these amazing image generators, for example, why is Shutterstock still dollar 50 stock? Stock. You can make an argument that they have access to all this data, all these images that they have the copyright to, so they can train a better model. It's like, well, maybe it seems like that's cannibalizing their own business. You would think that the stock would plummet. And so the only thing I can conclude is that markets are a little bit myopic, especially like the dominance of institutional investors. They don't really, the AGI being near has clearly not hit asset prices, but when it does, I think there's sort of multiple equilibria. Some stocks go to zero, some stocks go to the moon, and that's going to be a very disruptive event. So there's that component to it. Then I also talk about, like you prefaced the rise of sort of synthetic content in the Internet. I think this is also sort of a Neal Stephenson sort of idea. Just the idea that the Internet can become sort of flooded with and become a miasma where you don't even know what's going on. I think we already seed of hints of what that looks like. But once you have AI agents, like amazing catfish bots that have rich profiles and history, we're going to have to, I think, shift a lot of our communications back into private channels, like telegram or signal, in places where we have some kind of zero knowledge protocol that can verify our humaneness. And that requires closing the API in some sense, because we can no longer trust that being able to generate text that passes the Turing test is proof that you're human."
    },
    {
        "speaker": "C",
        "text": "And by the way, those AI catfish bots, they're coming for your cryptocurrency, guys. Let me tell you, okay, they're going to be hitting you up for that. We get to the late two thousand twenty s and you've got AGI is indistinguishable from humans for most work activities. The great repricing which we talked about, new data centers can't be built fast enough, Congress in panic. And then we get to kind of the mid two thousand thirty s. And you talk about the new deal beginning to crack. This is FDR's new deal, I believe, which is sort of the, I guess the patchwork system applied to western liberal democracies, including the US, to sort of patch up the flaws of the industrial revolution. And that whole entire system starts to crack by the mid 2030s. You say there's also, on the good side, an explosion in life saving drugs, but on maybe the bad side for the government. Tax revenues drop, income shifts to capital from labor. That could cause some destabilization, I would imagine. Private regulation starts to emerge. So tell us about the mid 2030s. What's happening there?"
    },
    {
        "speaker": "B",
        "text": "Yeah, just to set this up, I have another post called why AGI is closer than you think, where I walked through some of the neuroscience, sort of theoretical deep learning behind why we should have forecasts of AGI being pretty close. And one of the core ideas is that one way you can get to AGI is just by brute forcing a human emulator, by taking human generated data. And once you have a certain scale of compute and you extrapolate the scaling laws, it just becomes. It gives you an upper bound on when we should expect sort of ideal human emulators to emerge. And there's a group called Epoch AI. They have a model called the direct approach that sort of puts all these variables in. And the modal estimate is around 2028, 2029. So that's when, in principle, we should be able to essentially emulate any human task at human level performance and beyond. And so what that looks like in the immediate term? Well, it looks like, first of all, massive labor market dislocation. It looks like talking about the sort of institutional infrastructure. It looks like people developing sort of AI native corporations that are moving at inference speeds, right? Like two or three person companies that have 50,000, 100,000 effective employees. This ends up becoming a throughput issue for legacy institutions. Our court systems, for example, are already inundated. They're already overwhelmed. Most things that go to court settle most criminals plea. Then there's this long, extensive margin of court cases that never get brought because people don't have the money to pay for the expenses. But once everyone has an expert AI litigator in their pocket, that changes. And so the courts, if they don't adopt technology, which I don't expect them to, they'll basically fail. They'll have sort of a denial of service attack. And you can sort of see similar sort of DDoS style attacks across all our institutions. And so what happens in the court case? If the courts are overwhelmed? We go to a private arbitrator, or maybe people sell the ideal AI judge. That always renders a neutral decision in sort of a provably audible way. And then, so we start to shift legal proceedings into a parallel system. Then you start to see the same thing happening in medicine. If FDA, FDA took a freaking vacation for Thanksgiving before approving the second booster, they're not exactly in a rush. And in a typical year, the FDA approves something like 50 new molecules for drug discovery. And if that becomes 50,000, they're just not going to handle that throughput. This repeats down the line. I talk about in the piece the rise of these large partnerships, multi tiered partnerships. So beginning with the. In the early two thousands, they represented maybe 1% of all partnerships. Now they're over 30% of all partnerships. And the thing about these partnerships is they may be only, like, five people, but they have, like, 20 plus tiers. 20. It's like the lower bound, often up to 100 tiers. And the network diagram of these companies is incredibly complicated. Like, no one can understand what they are. And the reason they exist is because the Internet made it easier to build these kind of limited partnerships. And they're incredibly useful if you're trying to hide money from the IR's, because every node in that network is something the IR's, in principal, is able to audit. So if the IR's is lagging behind in their adoption of AI, then they just get overwhelmed as well, because we all have the AI CPA in our pocket who's able to shelter our income and complexify our liability. So just multiply this across everything, everywhere, all at once. You start to see why things could start to crack."
    },
    {
        "speaker": "C",
        "text": "Finishing this off. And we get to the late two thousand, thirty s, and then the 2040s, because some of this, I guess, the government services have been kind of decoupled, tax revenues dropping, the federal government is starting to crack. Maybe we start to get to see strong AGI around this time. And then you're predicting this end state possibility into maybe the 2040s, where we have three different nation states that are left. We've got the police states of the world. Maybe a totalitarian CCP party is an example of this. In China, then you've got the failed states. I mean, pick your favorite failed state. I think we were picking on Afghanistan earlier in the show. So you got failed states, and then you've got tech forward, post Internet states like the estonias of the world, and these are the three types of states. And then for the US, your thought there is failed state. It would be a failed state except for the fact that it has an archipelago of micro jurisdictions. So almost not quite Bellagian network states, because they also have territory that's manifest in real life, but certainly much dissolved from the large federal structure that we have today. That's where we."
    },
    {
        "speaker": "A",
        "text": "Soft landing failed."
    },
    {
        "speaker": "C",
        "text": "Yeah, and all of this. Okay, all of this. Again, bankless listener. I'm asking for Sam to kind of predict this in the way that a crypto guest might predict the price of ether in bitcoin by 2030. Right. So they might be off in the dates, but directionally, this is where you think it's going. Tell us where the 2040s end up after this massive wave of AI technology transformation. Sam."
    },
    {
        "speaker": "B",
        "text": "Yeah, it's hard to get the specifics right, but one thing I'm highly confident of is that the government by 2040 will look as different one way or the other as to us. Now, as the government in, say, 1940 looked to people from 1850, I think it's going to be that dramatic. Probably more dramatic. And so I'm wearing my singularity 2045 shirt. So this is the date that Ray Kurzweil set for the real singularity. Human level intelligence is just one thing, but once we have humanity scale computers attached to some fusion reactor, that's a whole other beast. Because in principle, a humanity scale computer could model every human mind and predict what everyone is doing all at once. That's the line where the compute buildup at that point will be so great, we'll all have exascale computers in our backyard that you can really start to see the real singularity, where there is real takeoff, where in a matter of months, or building Dyson spheres, that sort of thing, that's where my mental model completely breaks down. Because by definition, the singularity is something that you can't see past the event horizon. But in the context of the piece, I sort of talk about whether we want to go and rush into that post human oblivion or not. If we're struggling under this sort of fragmented empire, we may not have a choice, right? Because fragmented nation states are much more adversarial, much more competitive. And if the government has essentially collapsed in all but name, who's going to stop the free city of California with all the ML AGI trillionaires from turning on their supercomputer? But even leading up to this, I think you can see how this is really not that wild of an extrapolation from where we already are, circa the 1930s and forties, we did our own Manhattan project. We did it in house. We had basically a startup structure that built an atom bomb in three years that marshalled 100,000 people working in secret. We could never do that again. Same with the Apollo project. The Apollo project. We went to the moon in ten years. These days, if we want to do an Apollo project, we contract SpaceX. Our government, because of the broader decline in state capacity, is already trending towards being just a glorified nexus of competitive contracts. And so if all the government is at this point is sort of just a bunch of vendors that are and sort of a payment processor in the middle, you start to see how, amid broad system failure, you can just remove that payment processor and all the core institutions still exist, but like you said, they're not decoupled."
    },
    {
        "speaker": "A",
        "text": "Ryan brought up an early theme in the very beginning of this episode. It was technology and freedom. And I think we've also been touching on governance throughout this entire episode. And freedom and governance very, very correlated. Right? Like, how do you have the idea of good governance is that promotes freedom? To me, this theme of this episode has been the tension between technology and governance. And also, like I said at the very beginning, it's like how you identified governance lags. Governance lags technology, maybe. My conclusion, one of my big takeaways for this episode is as technology accelerates, hence all the accelerationists out there, and crypto is very fast and AI is even faster, governance isn't going to be able to keep up. Hence, where we end up, which is just technology just wins. That makes you optimistic, Sam."
    },
    {
        "speaker": "B",
        "text": "It makes me detached. I don't know, like, you know, old me was ready to run, you know, upload my brain and become part of the hive mind and achieve transcendence. Nowadays, I am much more ambivalent. Like, I think. I think the world over the next 15 years is going to be a renaissance in many ways. Incredible new discoveries, incredible riches. Like Elon says, it's not universal basic income, it's universal high income. We're going to be. It's going to feel amazing. And I hope we can find a way of sort of finding that narrow path right, where we. Where we preserve the good and avoid the bad and hopefully not make the Lias or world predictions come true, because people will dismiss Eliezer as a bit of an alarmist. And I think one of the things he does when he talks is he tries to solve for the equilibrium in a way he tries to steal man the one risk that will be remaining when all the other risks are dealt with. And I think that's led to a very polarized debate in the AI domain where you have people on one side who are like, it's going to be amazing. It's all great. Intelligence is the root of civilization, and you have other people who are like, oh, it's going to literally kill us all. And I think there's this huge dearth of middle ground scenarios where some things go well, some things go bad. Thinking about these second order effects, that is completely under theorized. And so at least as a provocation, that's what I hope my series gets people to thinking about."
    },
    {
        "speaker": "A",
        "text": "Beautiful."
    },
    {
        "speaker": "C",
        "text": "Sam, thank you so much for joining us. This has been an absolute pleasure to have a conversation with you about all of these deep topics, and I listed a bunch of things that we were going to touch upon in this episode, philosophy, politics, governance and all of these things, and I feel like we hit so many of them. It's been such an enjoyable conversation. So thank you so much."
    },
    {
        "speaker": "B",
        "text": "Thanks, Ryan David action items for you."
    },
    {
        "speaker": "C",
        "text": "Bankless nation we mentioned the post a number of times. It's all found on Sam's sub stack. It is at secondbest, CA. The AI and the Leviathan article series is the one you want to look for. Also, Sam think tank, the foundation for American Innovation, has a fantastic podcast, is called the dynamist. We'll include a link to that in the show notes more about what his organization is up to. Up to. And since we mentioned it so many times, we got to include a link in the show notes. The Eliezer Udkowski episode entitled, quite aptly, we're all going to die. If you missed that episode on why he is concerned, greatly concerned, about AI and alignment and safety and all of those issues, go check it out. Recent disclaimers of course, none of this has been financial advice. I don't think we dispensed felt any advice that could even resemble financial advice on today's episode. Got to let you know, crypto is risky. So is AI, man. So are the next couple of decades. I hope we make it. You could lose what you put in, though. We are headed west. This is a frontier. It's not for everyone. But we're glad you're with us on the bankless journey. As always. Thanks a lot."
    }
]