[
    {
        "speaker": "A",
        "text": "Hey, guys, welcome to the debrief after our episode with Haseeb and Eric on this debate. EAC versus EA or tech acceleration versus deceleration? All right. Yeah. What do you think of that? Where do you land? Has that changed your opinion at all? Was your opinion different going into this conversation coming out of it?"
    },
    {
        "speaker": "B",
        "text": "No, I really like the synthesis idea where these things need to be in tension with each other, and that's actually how they become more effective. Towards the end, as they brought in ethics people, it felt a little like Game of Thrones y, where, like, we have all these different houses fighting over the throne, but, like, the real fight is actually the white walkers coming from the north that everyone's ignoring. And it's like, yeah, so, like, the EA and the IC people are going at each other's throats, but just like, it's the woke, like, woke totalitarianism. Like, people that are actually the censorship people. Yeah, the censorship people. Yeah, the big government people. Yeah, everyone's them, but we're ignoring them."
    },
    {
        "speaker": "A",
        "text": "I think people can get lost in these terms, right. There's so much like, even when they were called the EA ethics people was one term for them. What else did hisie call them?"
    },
    {
        "speaker": "B",
        "text": "Ea bias. Ea bias or AI bias."
    },
    {
        "speaker": "A",
        "text": "AI bias people."
    },
    {
        "speaker": "B",
        "text": "AI ethics. AI woke. AI bias."
    },
    {
        "speaker": "A",
        "text": "Yeah, that's right. I sort of get lost in all these terms, but I think that the vibe of that group is just basically, like, we want to inject some sort of ideology into the models, right? Like, we want to censor them. We want, like, there to be the notion of, like, wrong speech imbued inside of them. And. Yeah, that very clearly, I think most tech people, most kind of, like, certainly crypto people in general, crypto ethos is, like, very much against injecting that level of bias."
    },
    {
        "speaker": "B",
        "text": "Well, it's probably the outcome of just, like, people who don't understand your technology, but they have their desires for civilization, and so they're. They're regulating with their desires for civilization without understanding the technology is probably the outcome of that."
    },
    {
        "speaker": "A",
        "text": "Yeah, well, a lot of people want that, do you think?"
    },
    {
        "speaker": "B",
        "text": "No one inside of an Internet."
    },
    {
        "speaker": "A",
        "text": "None of us want that. Yeah, crypto people don't want that. Generally, it seems like the AI rationalist people, like, don't want strong kind of censorship, and neither do the EAC people. But I do think that is what a lot of politicians want."
    },
    {
        "speaker": "B",
        "text": "I do think that's what big government people want. Big government, right."
    },
    {
        "speaker": "A",
        "text": "Yeah, I think that's what the kind of the nation state say sort of wants. Like, if the boogeyman is kind of some manifestation of the CCP in your mind. This is certainly what they want, isn't it? They want to influence and tilt hearts and minds. They want propaganda. They want a central message. They want some element of control of thought and speech. Yeah. The problem with that, though, is I feel like it's much easier to co op the AI safety that, like, the AI safety side of the equation and move it more towards AI ethics or AI bias, like this AI censorship type take. It's very difficult for them to do that with the IAC side."
    },
    {
        "speaker": "B",
        "text": "Yeah, IAC and I think government are almost directly opposed with each other. And like, towards the end of the podcast, when I was saying, like, hey, we have all of these accelerating technologies, so it makes sense that government is like the natural breaking force. Like, that's. That's. That's the generous perspective of what the government is doing. The government's only a breaking force on accelerationism because they are trying to learn how to bring it into the fold of government."
    },
    {
        "speaker": "A",
        "text": "Like breaking, like decelerating, slowing down the brakes."
    },
    {
        "speaker": "B",
        "text": "Yeah, yeah. Hitting the brakes. Right. And so as soon as they subsume the movement and it becomes a part of the government, then they're totally happy with it. Like increasing in scope, because that's what the government wants."
    },
    {
        "speaker": "A",
        "text": "Yeah, that's why I'm more. And I probably side a bit more towards Torenberg's points toward the end where he was like, yeah, haseeb, they're gonna co op the AI ethicist people. Ethics people are gonna totally co opt AI safety. They're gonna call it safety. Like, they'll just use fear, right? Hey, this could be incredibly dangerous technology. What if someone uses it to sort of, like, make a bomb? They probably won't be able to sell the public on kind of the Terminator vision, but it'll be more like, what about the predators? What about the terrorists? What about all of these bad people who could kind of use this technology? That's why we need to sort of put these safeguards in place. Right? And that's always, like, a euphemism for, like, censorship. And so that's why I get worried about aligning with that. That's why I don't know if we get out of choosing a tribe. That's like, the problem of all of this with Haseepi's, like, well, don't. Don't choose a tribe. And, like, that resonates to me. But ultimately, in order to get something done, at least in kind of the nation state we live in, you and I live in which is the United States and many other coordination with other people. Yeah. And so you have to, like, pick a platform, so you have to, like, support one group or the other. Right. At some point in time. And so that's why I get worried about joining forces too closely with the AI safety people because I actually Hazeep was making the case that they're not very powerful, but I think they are incredibly powerful. Not just like, not the leazier types. I'm not talking about them. I'm talking about the AI censorship people. I think they are incredibly."
    },
    {
        "speaker": "B",
        "text": "They become the AI government people. And, like, why are they powerful? Cause they're the government."
    },
    {
        "speaker": "A",
        "text": "Yeah. So that's why I couldn't quite align fully with what he said. And I'm probably more on the Tournenberg side of things. I'm not full Beth JSOs, like, IAC, you know, my thought coming out of our Beth JSOs conversation was like, I appreciate and am interested in that whole philosophy, but for me, it kind of lacks. It's just like missing something. It's missing this humanistic quality. It's just like, it was almost too. Almost too machine oriented."
    },
    {
        "speaker": "B",
        "text": "It's just like, well, when you are thinking about 1000 years into the future, 1000 plus years into the future, it gets pretty machine. Yeah, gets pretty cool."
    },
    {
        "speaker": "A",
        "text": "When it's all about just energy harvesting things, I'm just like, I don't view myself like that. Or like, the relationships in my life where, like, why are humans here? To harvest energy? Like, what that sounds all right."
    },
    {
        "speaker": "B",
        "text": "Wake up, kids. You gotta go to school because eventually society needs to harvest the sun's energy. Like, it's just not what you think."
    },
    {
        "speaker": "A",
        "text": "It's not what I think. It's not my value system. And I think, like, 99% of the world probably, it's not their value system either. And it's cool in like, a Sci-Fi way of, like, how much energy are we harvesting as a species? But, like, beyond that, there's some other weights, I think, that are very important to me and for most people, right?"
    },
    {
        "speaker": "B",
        "text": "Jeff Bezos is like, excuse me, Beth JSOs, the meme guy, not the actual one. He's zooming line, driving himself towards the logical conclusion and staying totally focused on that logical conclusion. But in reality, like, society just, like, swirls on its way there. And he's saying, like, guys, this is where we're going, so let's go there. But then what actually happens is society, like, you know, somebody gets up and mows their lawn first, and, like, that doesn't get us there, and, like, they all, we go out and we, like, have a party, and that doesn't get us there. Like, we do all these things that are, like, soft and cozy and make life worth living. And Jeff is like, let's zoom towards the Dyson sphere, but, like, not realizing that society just needs to, like, have a good time on its way."
    },
    {
        "speaker": "A",
        "text": "Yeah, I think, you know, Marc Andreessen put out that tweet thread about tech, techno optimism, and it was very hyperbolic, very sort of, like, exaggerated. Like, it felt very exaggerated."
    },
    {
        "speaker": "B",
        "text": "Well, he's the cultural leader of his platform, right?"
    },
    {
        "speaker": "A",
        "text": "And I think he felt the need to do that as a. I don't think he actually thinks all of those things. Like, I think he has a much more nuanced, like, mental model for the world than appear in that tweet thread. But he. He's sort of pushed into stating almost like, a more extreme version of what he actually thinks as a counter reaction to the AI ethics type people."
    },
    {
        "speaker": "B",
        "text": "Well, yeah, they. Well, no, they. Not the AI ethics people. The AI doomer people."
    },
    {
        "speaker": "A",
        "text": "The AI doomer people."
    },
    {
        "speaker": "B",
        "text": "This was encountered."
    },
    {
        "speaker": "A",
        "text": "Yeah, because they will."
    },
    {
        "speaker": "B",
        "text": "They were saying, like, hey, like, AI is going to literally cause doom. So, like, he's allowed some, like, room for hyperbole."
    },
    {
        "speaker": "A",
        "text": "But it's also that tech manifesto wasn't just AI. It was also anti tech degrowth, tech deceleration. And it was just making the case for why tech is good. And that's all wrapped around the axle of this conversation. I've been listening to some hidden forces episode with Dmitri Kofinas, and one theme that he's had over the last six months or so has been the changing political order, not just in the US, but around the world. And how we are moving from a period of, like, where neoliberalism, whether it's like, Republicans, Democrat, right, or left, they were all sort of united under this framework of thinking about, like, how their political thought as, like, the neoliberal, you know, world order, right, which was, like, popularized probably by Reagan, but then continued by Clinton and so on and so on. And that was like a departure from FDR's new deal kind of political order. And so the idea is, like, each of these political orders last, you know, maybe 30 to 40 years. And where are we now? Well, neo, like, even on the right, you know. So the Republicans, they decry the neoliberals in their party in the past, right? They all hate Bush and getting into the Iraq war and all of these things. And so they have sort of moved past neoliberalism the same is kind of going to happen on the left, right. And so the question is, what comes? What political order school of thought succeeds this neoliberal order? Because it's going to be something different, it's going to be something new, and it will probably have some populist undertones. But a big question for the tech community, I think, is will it be pro tech or will it be anti tech? And I think there's reason to believe that however it emerges and when it manifests on the right and the left, Republican, Democrat, whatever the dichotomy is in your jurisdiction, it will not be as tech forward, it will not be as tech favorable. It could be even anti tech, it could be slightly luddite, if you will. And I think that Eric was sort of making that case where it's just, that's why we have to sort of shape the conversation and sort of all team up and push back against that because it would really be a step backwards. What happens if the next reigning political order in the US just didn't want to invest in technology, wanted to bring us backwards or just slow everything down and gum up the works? And that could happen. That could totally happen."
    },
    {
        "speaker": "B",
        "text": "I kind of consider that as base case, actually, over the next 20 years or so, especially as this parabola of technology gets more and more aggressive, you're going to see like the long tail of society get really upset because they are not included in the acceleration of technology. Right. Like that. There's like kind of some notion of what's the effect when the central bank prints money and the people local to it get it first. So like, yeah, there's some catilian effects."
    },
    {
        "speaker": "A",
        "text": "Yeah. The frontier people that are on the frontier of tech on the front of it, and the people that are just like, I'm just happy to. I don't have a, you know, I'm not using a laptop, I'm not exploring crypto, I'm not doing using chat GPT. I just like the good old simple things."
    },
    {
        "speaker": "B",
        "text": "My nine to five. Yeah. They lose going. Yeah, yeah, totally. And like, there, there's a reason why that, like, I think Aaron Troinberg brought it up a couple times, but we never really dove into it. Like transhumanism. Why? Jeff Beth, Jesus is a trans humanist. It's because like, we are seeing on the horizon a divergence of literally the human race, whereas like, one gets the chip in their head, one gets their DNA edited so that they can live longer. One set of people, one set of humans does all of the things that technology will produce the fruits of technology will produce over the next 2030 years. And then, literally, our DNA starts to split from the people at the top who can afford it and who milk the benefits of tech versus everyone else who has at the bottom. And this is when, like, who, you all know, Harai writes this about in human Deus. That's literally the title of the book, is humans number two. And so we are watching, like, some of the slow machinations of this process start to boil up and, like, impact society. Right now, we just call it accelerationism versus decelerationism. And, like, later, it'll get even more polarized."
    },
    {
        "speaker": "A",
        "text": "Yeah, I think so. I mean, this train's not stopping, right? And, like, even for somebody who is very tech forward, like myself, and I know you would consider yourself very tech tech forward. Right? Like, we're generally, like, we think technology is a good thing. And, like, let's press into. Of course, there are dangerous technologies out there, but, like, more tech good, right. In general, even some of us, like, I find for myself, I'm like, oh, it's changing so fast. Like, this is happening so fast that, like, even for me, I'm like, well, okay, things are getting weird, and I can feel like I don't have. I don't necessarily think it's good, like, all the stuff that's going on. So one thing, like, for myself personally, I don't think is good. I still spend too much time on my screen, like, on, like, on my phone or something else. And I'm starting to look at that and just being like, oh, that's not. That's not a good thing, right? And, like, of course, there. Once you. Once you've realized this, like, you can kind of ride around it or, like. But then you look at kind of all of society, and you're just like, oh, is it. Is it good for my kids? I have kids. Is it good for my kids to have access to this all the time? Like, you know, should we be cautious about this? Like, again, it's like a conversation of tech, but with safeguards, with limits. Like, you know, like, knowing when to do it and when not. Right. It's like, it seems careless to just accelerate, accelerate, accelerate without any wisdom, without any, like, how does this affect things? How is this affecting me? How is this affecting the people around me? Is it really progress or is it something else? And even for me, I'm just a little bit like that. So imagine the general population, how freaked out they are by this stuff."
    },
    {
        "speaker": "B",
        "text": "Yeah, but there's also some natural immune responses that I think younger generations get, because zoomers and whichever generation comes after zoomers are being born into the Internet where they. They know, like, AI is, like, all over the place and creating fake images. And that just started two years ago, right? And, like, I see, like, an AI image, and it's like, to me, like, very clearly an AI image. Like, maybe I have some benefits. Cause I tinkered around in Photoshop, like, between middle school and high school. Cause I was a photographer. So I understand, like, the dynamics of pictures. But then you go into just like, the regular Internet sphere, and you have, like, everyone above the age of, like, 50 thinking that this very obvious AI image is, like, totally real, and it's the most fake bullshit that I've ever seen. But, like, the zoomers and, like, the, which are, again, the younger generations, totally immune from this because they had, this is the Internet that they're, they're born in. They understand what is AI versus not AI, at least right now. But, like, the whole idea is, like, am I looking at my screens too much? Like, am I being bombarded by Internet signals too much? I actually think that part actually naturally solves itself just because that is just what society, that's just what life is."
    },
    {
        "speaker": "A",
        "text": "I think it could. But there's also, like, I don't know if you've read any snippets of John Jonathan hates new book where he just, like, it's basically a case against teenagers using social media in particular. Right? Basically, the idea of the algorithmic feed is not good for teenagers teenage depression from 2012 up to now."
    },
    {
        "speaker": "B",
        "text": "This sounds like his old book."
    },
    {
        "speaker": "A",
        "text": "What was his name? Yeah, he just wrote a new book and published on it. This is a bit more explicit about all of this. Anyway, one thing he says is that for younger generations, and this is true for, like, us too, millennials, there's also a collective action problem of, like, if you ask teenagers, hey, is this good for you? Like, do you want to be on the phone? Like, many of them will say, no, I just wish no one was on this thing. But they have to be, because their social life's there. All of their friends are there in order to collect clout in order to get a date, in order to interact in sort of the real world, right? You actually have to have a phone and, like, you have to be present. And so it creates, like, this collective action problem, which we would call David, a Moloch trap, right? Of, like, coordination failure, where we're all doing something that is, like, worse for all of us because we just, like, so many people have opted into that system. So I think there can be traps like that. And of course, you're right, there is a societal autoimmune response of like, younger generations get wise to it. We get educated about this, and we're like, huh, maybe this isn't good for us. Like, what you like, we should like. Fast food is actually, you know, bad. You know, we realized this years later, our cigarettes were bad for us. We realized this years later. And we kind of adjust, you know."
    },
    {
        "speaker": "B",
        "text": "In New York, in the dating scene, on the men's side of things, finding like a, like, a love interest that doesn't have an Instagram is like, well known to be like, green flag material."
    },
    {
        "speaker": "A",
        "text": "Really. Finding a love interest doesn't have. So the, like, you know."
    },
    {
        "speaker": "B",
        "text": "Yeah. So if you're like, on a date with a girl and she doesn't have an Instagram, it's like the joke, like, oh, like married material."
    },
    {
        "speaker": "A",
        "text": "Why?"
    },
    {
        "speaker": "B",
        "text": "Yeah, yeah. Cuz, well, because, like, you know that they're not going for the cloud, right? Like, they're. They're not trying to climb this Instagram social media ladder, right."
    },
    {
        "speaker": "A",
        "text": "So that's. They're generally working a little bit."
    },
    {
        "speaker": "B",
        "text": "Yeah, well, yeah, yeah. Reproduce with the girls that are Instagram."
    },
    {
        "speaker": "A",
        "text": "Yeah, well, yeah, so, yeah, I mean, I guess it's things like that. And I guess what I'm saying is it's just. It's not just one thing. It's not. We're like, oh, something new has come out. Now let's figure out, like, before we get addicted to it and, like, have this collective action problem. Is it good for us or bad for us? It's just, like, happening everywhere all at once anyway."
    },
    {
        "speaker": "B",
        "text": "Yeah, there's too many choices to make."
    },
    {
        "speaker": "A",
        "text": "So I do think that these problems, like, kind of exist. What about. Yeah, what's your take on things? So I stated that I skew more towards the IAC side of things despite some misgivings. Right. It's like, not full IAC, but, like, id doom is definitely greater than zero, but I skew more towards Tornberg side. How about you?"
    },
    {
        "speaker": "B",
        "text": "Yeah, no, I think that's the same for me. I've always thought that the only reason why society needs pessimists is because sometimes optimists are wrong. And so, like. But then also, as it continues, in an ideal world, we would actually only have optimists that are correct. And so pessimists are meant to be a counterbalance to optimists who are overly optimistic. Right. And vice versa. And there's a natural harmony between pessimism and optimists. Same thing with liberals and conservatives. At the very base where conservatives and liberals were born was at the primal campfire, and people were cold, and the conservative was like, hey, let's conserve the firewood. Cause we're all cold. And the liberals like, no, I'm gonna go out and venture away from the campfire, and I'm going to go explore to try and find more. I'm gonna take a risk. I'm gonna go and find more fuel, more energy to harvest. Right? And so, like, there's a tension between, what do we do with our resources as a society? And, like, optimists are the entrepreneurs. They're the inventors, they're the creatives. They take risks. They go out and explore. And the conservatives are like, oh, let's. Let's. Let's not do too much exploring. Let's make sure we have some left in the gas tank, right? Like, has Heb said, oh, if you're going to make a gamble, make sure you never actually drop to zero. Right. This is the role of the conservative. And again, the only reason why you need conservatives is because, like, sometimes the people who over experiment get it wrong. But ideally, in an ideal world, you would just be just perfectly optimistic and also perfectly precise. Um, and so, in my eye, that's why always why I lean towards the entrepreneurs. Uh, the optimist. The acceleration is, like, you only need the minimum amount. Amount of, um. You need a marginal amount of brake pressing, but generally, you need gas to go forward. Uh, and so, like, I'm like, mostly gas as a vibe, but then somebody else is going to have to press brake."
    },
    {
        "speaker": "A",
        "text": "Like, this mix, this healthy, uh, balance, this tension."
    },
    {
        "speaker": "B",
        "text": "Yeah, the healthy mix, but with a bias towards."
    },
    {
        "speaker": "A",
        "text": "You're just more biased towards the frontier then towards utopia bias. By the way, do you ever read that Slate Star Codex article about, like, basically, if you assume conservatives see the world as, like, a zombie apocalypse, and, like, progressive people see the world as sort of a utopia, then, like, their assumptions make sense."
    },
    {
        "speaker": "B",
        "text": "Yes. You know, I actually did a podcast episode on my old podcast about this, but I haven't been able to find that."
    },
    {
        "speaker": "A",
        "text": "The idea is, like, if you go through. If you think the world is basically just kind of bad, like, kind of shitty, right? Like, zombie apocalypse. Right? Most extreme case, then, like, you know, small. Small governments or small family, right? Very, very, like, everyone looks out for one another in the community, like, have a gun, you know, like, all of these assumptions make sense, right? If you think the world is a bit more towards, like, utopia and, like, conservatives would say this is a very naive view, then you're more likely to be, like, some of the more progressive assumptions make sense. Anyways. One interesting framing of things that I think you're getting at, the optimist versus the pessimist. So is that what it comes down to? Just, are you optimistic? Are you pessimistic? And that's like, that, that informs your, that informs your outlook on AI safety? Because, like, that doesn't seem very empirical. I feel good about it."
    },
    {
        "speaker": "B",
        "text": "It's very, very vibey. Well, like, sometimes I look at, like, some of the legislation or just like, I, things that Liz Warren says, and they all kind of align with, like, this cynical decelerationist attitude, disposition towards everything, and she just wants to hit every innovation on the head with her, like, hammer of cynicism. It's like, okay, well, you just built this thing. Well, that thing might harm my constituents. And so I'm against it. And it's never taking the optimistic stance. It's always like this cynicism, like, I want to regulate you stance. That's just like the Liz Warren vibe, which is why I put Liz Warren in, like, the deceleration."
    },
    {
        "speaker": "A",
        "text": "That's like, that's definitely a framing. Like, she's just worried. She's a worry wart. She's just worried. She always sees things in negative light, I think another framing of her or that, like, whole feeling, like that whole vibe is like, control. It's just, it's weird. I can't control it. It's outside of government. It's like someone's doing something, and I haven't said it's okay. You know, it's just like, we have to bring that up."
    },
    {
        "speaker": "B",
        "text": "They never asked me."
    },
    {
        "speaker": "A",
        "text": "They're just out of complaint, you know? Yeah. So there's that, that view on it as well. Okay. I don't know. I feel like I, one thing I came to, I guess a conclusion on at the end of this episode is, yeah, I really don't like the AI censorship people."
    },
    {
        "speaker": "B",
        "text": "AI ethics."
    },
    {
        "speaker": "A",
        "text": "Yeah, AI ethics is."
    },
    {
        "speaker": "B",
        "text": "Well, because they're the, yeah, they're the control people. They're the same thing. They're the controllers."
    },
    {
        "speaker": "A",
        "text": "I'm just very much against that. I do think there should be some AI. What do you think of the whole regulatory capture conversation? This is what Abef Jas would say Sam Altman is doing. And Haseeb's defense against that was like, we don't know yet, which I think is a rational kind of defense. And so he's basically, everyone's projecting what they want to see, in Sam Altman, we don't know. We can't see inside his brain. We can't look into his soul and see what his intent is, what he's really trying to do there. And so it just comes down to a feeling of, do you trust Sam Altman or not? And that's very squishy. So let's wait until we see some legislation to see what's actually happening."
    },
    {
        "speaker": "B",
        "text": "I did like, haseeb's characterization of Sam. He put the characterization of Sam into words that I hadn't heard anyone put. And for, like, what was that called? It disrupting reality distortion, or, like, oh, yeah, reality distortion field."
    },
    {
        "speaker": "A",
        "text": "And, like, you know."
    },
    {
        "speaker": "B",
        "text": "Yeah, yeah, yeah. Sam's definitely got that. And so, like, I'm, like, one eye wary about Sam, but I'm also like, sam goes because he has super glasses."
    },
    {
        "speaker": "A",
        "text": "Like, he can use his reality distortion field for good or bad."
    },
    {
        "speaker": "B",
        "text": "Yeah, he's, like, wherever, direction. Like, maybe he's, like, five degrees off from where I would like. Maybe he's ten degrees off from where I would like. But, like, he's where he's going. Like, and I want him to keep on going. Yeah, I think so. Do I trust him about, like, the whole, like, government regulatory arbitrage, government regulatory cash? I. Yeah, that one. I generally think that Sam SPF. He's SPF. He's an entrepreneur."
    },
    {
        "speaker": "A",
        "text": "I don't know yet. You think he's Brian."
    },
    {
        "speaker": "B",
        "text": "He's closer to Brian Armstrong."
    },
    {
        "speaker": "A",
        "text": "Maybe he's a really good SPF because he makes people think he's Brian Armstrong while he's doing SBF things."
    },
    {
        "speaker": "B",
        "text": "I mean, like, it's not gonna. It's not fair to call them, like, if. If SBF. If Sam Altman is like, SBF, he's inventing his own new category of what an SPF could do in a very bad way. Like, SPF doesn't even deserve to be in a category in, like, if he's good. If Sam Altman is the SBF of whatever he is, he's like the God that captured the Internet with AI and the. And by."
    },
    {
        "speaker": "A",
        "text": "Therefore, the world appears. Very good guy, very legitimate, you would say."
    },
    {
        "speaker": "B",
        "text": "Yeah, he's just like, oh, no. Like, I'm actually. I'm actually here for the power, but I have to play this, like, very long game of, like, I need to make AGI first."
    },
    {
        "speaker": "A",
        "text": "And again, this is where I come down on the ex. I'd rather just not have to. Like, I'd rather just not have to trust who Sam Altman is. Like, why is our fate in that guy's hands. Like, it'd be great if we all had open source models where we had some checks on power and we had some ability to just, like, out compete him or he doesn't get too far ahead and, like, build this monopoly. I just don't want to have to trust whether Sam Altman is, like, a good person or not. So what about."
    },
    {
        "speaker": "B",
        "text": "Yeah, I do not enjoy how much focus there is."
    },
    {
        "speaker": "A",
        "text": "The last piece for me was in this conversation. Hasoop is really making the case that, like, the US actually isn't doing too bad with respect to regulation. AI regulation. It was Eric in Haseebs debate, so I didn't want to weigh in too much. But he was making the case that it's just a lot better than China or Europe. And he also made some comparisons, I think, to crypto. It's like, what laws do we have in the US with crypto? We have none. But it feels very much like crypto in the US anyway. Like, the US is really, like, one of not the worst places with respect to crypto regulation or crypto, crypto posture. But just, it's. Yes, it's pretty bad. Like, it's not China, sure, but it's."
    },
    {
        "speaker": "B",
        "text": "Just not officially bad."
    },
    {
        "speaker": "A",
        "text": "And so I don't know."
    },
    {
        "speaker": "B",
        "text": "According to Haseeb."
    },
    {
        "speaker": "A",
        "text": "Yeah, I don't. I don't know if that's good of a job with respect to AI and crypto. Maybe AI a little bit better. I just don't know enough about it. But, like, certainly from."
    },
    {
        "speaker": "B",
        "text": "Yeah, I mean, the difference is that, like, crypto has pre existing organizations that are, like, proximate, like the CFTC and SEC, whereas AI doesn't have, like, there's no correlate to AI. Like, AI is like a first of its kind, whereas crypto is like, well, yeah, I think."
    },
    {
        "speaker": "A",
        "text": "I think the US will be a little better on AI than it is, just that it has been in crypto."
    },
    {
        "speaker": "B",
        "text": "Because AI doesn't have entrenched regulatory agencies that want to bring it into the."
    },
    {
        "speaker": "A",
        "text": "Fold of big government, whereas crypto does really restrictive. I've been surprised at how restrictive it's been with respect to anything that touches finance."
    },
    {
        "speaker": "B",
        "text": "It is draconian because, well, that's what makes the United States the United States. We are what we are because of Wall street."
    },
    {
        "speaker": "A",
        "text": "It's not just Wall street interests, but it's also like Wall street. That whole entrenchment of financial regulation is sort of like a boss, but it's just a mini boss. The two big bosses for me in the US are national defense and very much. The US is like, we want the power to sanction, we want the power to blacklist enemies of the Republic of the United States. Right?"
    },
    {
        "speaker": "B",
        "text": "Yeah. But that's because the power of the dollar and the power of the military is the blanket that covers the earth, that funnels value back into Wall street. And so, like, it forces like, the long tail of the world to reinvest their profits into Wall street. And so, like, it's all. So that's the top of the funnel. Like, we can compete with a lower part of the funnel, the lower part of the stack, which is Wall street, but we can't compete with the highest part of the stack, which is the United States dollars."
    },
    {
        "speaker": "A",
        "text": "The other thing that's kind of like on the final boss level, it's just in the interior of the US operating system that just feels very threatened when you get close to it is taxes as well. And it's like the IR's is the only tax entity that will pursue american citizens no matter where they live. If your permanent residency is India or some other location, as long as you are a us citizen, you're paying us taxes, man. No other country does this, by the way. The US does this. So anytime you get close to the kernel of the US, which is like, you're threatening national defense and sovereignty of the money system, which is all tied up in the same empire type thing, or you're like, threatening our ability to tax you. Ooh, us does not like that. Right."
    },
    {
        "speaker": "B",
        "text": "Anyway, remember when. What's his face. Kyle Davies says he didn't owe United States taxes because he really do that. But yeah, you can. Oh, no, you can't revoke your citizenship."
    },
    {
        "speaker": "A",
        "text": "You still have to pay your taxes. Yeah, you can. You can revoke your citizenship. That's what they do."
    },
    {
        "speaker": "B",
        "text": "That's correct. You can revoke your citizenship."
    },
    {
        "speaker": "A",
        "text": "All right, we'll taxi on the way up. Yeah, you could be a traitor to the United States. And we'll also tax you on the way out. Trader give you a kick. Kick in the butt, right?"
    },
    {
        "speaker": "B",
        "text": "Yeah. You're not formally. Yeah, right. I listened to this. This planet Bunny podcast about this exact subject, which is like, can you just revoke citizenship to get out of taxes? And apparently people have tried this. People try this like once every decade or so, and every single time."
    },
    {
        "speaker": "A",
        "text": "The crime, extradition. Right. The US says, oh, that person hanging out in your country is a tax. Like, we want that person for taxes. So yoink you back. Anyway, yeah, that individual owes us some."
    },
    {
        "speaker": "B",
        "text": "Yield, says the guy."
    },
    {
        "speaker": "A",
        "text": "That's all I have to say. Anything else. All right, guys, this has been the debrief. Thanks a lot."
    }
]