[
    {
        "speaker": "A",
        "text": "The whole Internet of value can be in one place with shared security. Under the hood, there's these modules, but these are integrated modules, and we only buy into one security assumption, which is that Ethereum is secure. And this brings us to trying to grow the economic security of Ethereum. Right now we are at $70 billion, which is extremely good. It's 29 million eth times the price of ETH. But I'm hopeful that we'll get to a trillion dollar of economic security, or even trillions of dollars, at which point, you know, we'll have unquestionable security, even against nation states."
    },
    {
        "speaker": "B",
        "text": "Welcome to bankless, where we explore the frontier of Internet money and Internet finance. This is Ryan. Sean Adams. I'm here with David Hoffman, and we're here to help you become more bankless. Fixing fragmentation Ethereum rollups have a fragmentation problem. All the liquidity is spread out. Each roll up is starting to feel a little bit isolated. That has been the critique of Ethereum the last six months, and I don't think is an unfair critique. The question is, how do we fix it? Can we fix it? There are certainly Ethereum skeptics out there that think Ethereum is destined to always remain fragmented. That is the trade off with going to a roll up centric roadmap. That's what Ethereum is on right now. But we have Justin Drake on the podcast today who takes the other side of that. Not only does he think Ethereum will fix fragmentation, also it will achieve the holy Grail, something that he calls universal synchronous composability. Don't worry, we explain what all of that is as we get into this episode. There are three parts to it. Number one, we talk about the problem, fragmentation. Why is it a problem? Who is impacted by it? Number two, we talk about the solution, that is shared sequencing and what that means. And number three, we talked about based sequencing, why Justin Drake thinks Ethereum layer one will become the de facto shared sequencer. This in itself was an incredible insight for me, something I just uncovered the last two weeks or so, and seems relatively fresh from Ethereum researchers as well."
    },
    {
        "speaker": "C",
        "text": "There are a few core ideas that Justin really brought together in this episode. First is really how shared sequencing provides the platform, not the solution, but the platform, for achieving universal synchronous composability. Really, once we achieve shared sequencing in Ethereum, the game starts. That is not the finish line. The rest of the solution, the solution space for synchronizing all the chains is left up to accessory technologies like intents. Market makers restaking but really shared sequencing unlocks the door for us to therefore walk through. Also another idea why rollups will all inevitably join together via the incentives that shared sequencing brings to the table. And once we have this, how this unites the Ethereum roll up development towards a single unified direction. Once again, in Ethereum, we will have a unified direction for all of the layer twos, because all of the layer twos will start to feel and look and be one global unified system. And then I think lastly, one of the very, very big takeaways I had from this episode, Ryan, is why all of this would result in an increase in scope for Ethereum's layer one validators. That's if we do get to the base sequencing part of this future. If you are a validator, you could, and you might have increased responsibilities and increased yields as well. So these were some of the three big ideas in this very, very big episode that Justin and Drake brought to us today."
    },
    {
        "speaker": "B",
        "text": "Yeah, and I would say as far as content level, this is probably 300 level material."
    },
    {
        "speaker": "C",
        "text": "300 plus."
    },
    {
        "speaker": "B",
        "text": "Yeah, yeah, 300 plus. And so we tried to break it down for you, David. Maybe we'll talk during the debrief in some layman's terms, what this kind of means, but the essential, the hundred level content is Ethereum feels like it's many different chains today, and it won't in the future. That is the bottom line of this episode. And Justin Drake explains exactly how. So this is frontier material, of course, the kind of content you come to know and expect from bankless. We're going to get right to the episode with Justin Drake. But before we do, we want to thank the sponsors that made this possible, including our recommended exchange for 2024. That is Kraken. If you haven't created an account, if you're new to crypto, or if you're in crypto and you don't have a Kraken account, you absolutely should get one. Open it today."
    },
    {
        "speaker": "C",
        "text": "Bankless nation. I'm so excited to bring you Justin Drake, a researcher at the Ethereum foundation. He needs no introduction, but if I were to give him one, I would say he's the guy who brought us moon math, our episode about how Ethereum is scaling with cryptography, ultrasound, money, how Eth is Sci-Fi money, Mev Burn, and how all Mev on Ethereum will ultimately flow into Ethan. Now, today on the show, he comes to us with a new problem and a new solution. Fixing fragmentation is the topic of today's episode. Justin, welcome back to Bankless. It's always a pleasure to have you, my man."
    },
    {
        "speaker": "A",
        "text": "David and Ryan, thanks again for having me."
    },
    {
        "speaker": "C",
        "text": "So, Justin, people are saying Ethereum has a problem. Liquidity, UX wallet chains, all of our infrastructure is fragmented. While one of the beautiful things about the roll up, uh, centric roadmap for Ethereum is that we all get to innovate and experiment in different directions. These different directions are, of course, different from each other. One of the costs is that this breaks the universal composability that we used to enjoy on the Ethereum layer one. It is getting harder to use Ethereum holistically today more than ever. This is the current state of things. Is this where we end up? Is this a future of Ethereum? What say you about this current context, about Ethereum's trajectory?"
    },
    {
        "speaker": "A",
        "text": "Well, first of all, I do want to acknowledge that we do have a problem with fragmentation. And as you said, it boils down to a very large extent around this idea of composability. Each layer two is kind of its own little silo right now. And while we do have bridges, those are asynchronous, they're slow, and they're somewhat brittle and very difficult to use. Now, the good news is that a lot of people have been thinking about how to fix this, and I think we can fundamentally fix it with something called shared sequencing. So the root cause for this fragmentation of composability originates from the fact that we have different entities called sequencers, that are ordering transactions for little clusters of execution. So we have the arbitrum cluster, the Bayes cluster, the optimism cluster. It turns out that shared sequencing in and of itself is not sufficient, but it's a necessary step to get, to try and regain this universal composability. And when I say universal composability, I specifically mean universal synchronous composability. So synchronous means that things happen at the same time things happen atomically. It's as if you have contracts called arbitrary other contracts in other execution domains. So one of the big upsides of having this universal synchronous composability, as you mentioned, is that we get things like unified liquidity, as opposed to the status quo, where we have these fragmented pools of liquidity. But that's just the tip of the iceberg. We get so much more with universal shed composability."
    },
    {
        "speaker": "B",
        "text": "Okay, Justin, so we're setting up the problem a little bit, and we're going to talk about kind of the solution, the holy grail, which is this term that you've been using called universal composability. And that, for the normie crypto user, is a mouthful. Universal composability, what the heck does that mean? Let's just try to break this down into kind of layman's terms when we're talking about the problem of fragmentation today, let's call it. So, in a lot of ways, ethereum is much easier to use than it has been, but in some ways it's more difficult when you tell someone who's new to crypto, yeah, just use the ethereum network. They might be like, oh, I see that one. Is that the one with really expensive fees? I'm not using that. And then you say, no, you can go use optimism, arbitrum, Zksync, Polygon, like on down. And they're like, well, which one should I choose? How do I get started? I remember in the early days of bankless when we were talking to someone about getting on chain for the first time, the answer was pretty easy, like, you had kind of one option, you just go to Ethereum, there's no other network selections inside of metamask. You can kind of live there. You don't have to worry about bridging assets. The only bridge you had to make was going from a centralized exchange, like a kraken or a coinbase on chain on Ethereum. And like that was it. You could kind of live there. Now the l two roadmap has essentially asked Ethereum users, including the newcomers, to go pick a layer two. And that's caused some confusion because what if the app that I want to use isn't on the specific layer two that I'm on, and I don't want to use Ethereum mainnet because it's too expensive. But like, what chain, what chain do I use? And the UX around this, the liquidity around this, it's difficult. So what's happening is, I think we've seen this a lot in the second half of 2023, is competitors. Ethereum competitors, let's call them, or alternative layer ones are seeing this soft underbelly of Ethereum and they're basically saying, look, come to this monolithic chain. We got it all here. You just go on chain, and everything is universally composable. So an app from one place in an alternative layer one, like a Solana, let's say, or an avalanche, it's available to anyone who is on that chain. That's kind of what we're talking about, just to set up. The fragmentation problem is the UX and liquidity issues that exist today in Ethereum in its current form. And I think you're acknowledging that. I'm just like wondering, high level as we get into the rest of the episode, was the move to the layer two roadmap, is it worth this cost? Because we're feeling some pain right now and I just want to acknowledge that and talk about that."
    },
    {
        "speaker": "A",
        "text": "Right. So I'd say that the move to layer twos was absolutely necessary. And the reason is that otherwise we move too slowly. Like the layer one is extremely slow to move forward. It's extremely ossified in some sense. And we have these extremely high standards of quality to ship things at layer one. So we could have roll ups at layer one. Actually, those are called native roll ups, but in order to do so, we would have, for example, to have a ZKVM, but not just one ZKVM, but multiple redundant implementations of a ZKVM that are redundant, that are battle tested over years. And this is just something that we don't have right now. And so in some sense, like this, ethereum accelerationism in the short and medium term comes from these layer twos that permissionlessly can deploy things and move ethereum forward while the layer one gathers what it needs to ship. The good news is that a lot of this fragmentation, as I said, is temporary. And I think there's two fundamental reasons. One of them is that a lot of the details around fragmentation can be abstracted away. When you use the Internet, there's a lot of different brands behind it, there's a lot of different things, but at the end of the day, you can wrap everything up and just present a very simple, shiny user interface to the user that abstracts away a lot of technical details. And then there's something else, which is something much more fundamental, which cannot be papered away and abstracted away, which is the difference between asynchronous composability and synchronous composability. That's a key differentiator. And what synchronous composability means is that if I'm a smart contract, I can go call any other smart contract and things will happen atomically. So if I'm building a very complex application, let's say that I'm building a marketplace. A marketplace needs identity, it needs a reputation system, it needs payments and escrow agents, and it needs insurance providers. Now, if all of these money legos are on execution zones with different sequences, then, now suddenly your application becomes extremely brittle, because every time you want to interact with it, you're interacting with different counterparties, and composability starts to break down in a very meaningful way. Whereas if we have this one shared sequencer which unifies everything, and it's this one entrance door to this very complex world which can be extremely rich and diverse, but it's a real unlock to go from asynchronous composability to synchronous composability. Now, I used to be one of those people who would say, asynchronous composability is fine. And part of the reason is that Ethereum previously had this roadmap with sharding where we had 64 or 1024 shards which were asynchronous. And to be fair, in hindsight, it was kind of cope. I was optimistic that we could paper over with abstraction. Wait, wait, wait."
    },
    {
        "speaker": "B",
        "text": "Researchers get cope, too? Because I know crypto investors get cope. I had no idea that researchers actually get technical cope."
    },
    {
        "speaker": "A",
        "text": "Well, we have various constraints, and then we just do the best that we can with the laws of crypto economics. Dank sharding was a massive unlock, because dank sharding basically says that we can do synchronous data availability. We don't have to break data availability down into these asynchronous shards. Not only can we do synchronous data availability, we can do synchronous composability, and we can do this synchronous sequencing. We can do everything synchronously. And in some sense, we're getting the best of both the modular thesis and the monolithic thesis. We're getting all the efficiency and the user experience of the monolithic thesis. But behind the scene, we have all the richness and diversity and decentralization of the modular thesis."
    },
    {
        "speaker": "C",
        "text": "I really want to parse apart this spectrum that I see between synchronous composability and asynchronous composability. I see a spectrum that is also a binary at one end. Asynchronous composability can be a very large spectrum where we have, like, on an optimistic roll up, we have a seven day withdrawal window. So seven days to perfect finality. And so that's a very, very asynchronous seven days worth of multiple networks not being totally in sync with each other past that seven days, then some of the state can permeate across chains. After seven days, then in ZK rollups, it's much faster. Uh, ZK proofs are just settled onto the main chain much, much faster. But still, they are not synchronous. They're still asynchronous change. Uh, but, you know, they settle inside of like one to three blocks, you know, just a few minutes. So still asynchronous, much shorter amount of time, slower, uh, lower amount of time for these chains to like sync up with each other. You know, uniswap trades will take a, uh, on one Zk roll up, will take less time to affect a uniswap trade on a different, uh, Zk rollup, but it won't be instantaneous. And then you flip over to the binary, which is like perfect, uh, atomic synchronicity. And this is what I think you are saying requires new infrastructure that you're labeling as shared sequencing and probably some additional stuff on top of that as well. Is this the right spectrum to illuminate this conversation moving forward?"
    },
    {
        "speaker": "A",
        "text": "Yes, that's exactly right. On the one hand, we have a continuum of latencies, or the worst case is seven days, and then we can try and bring that down. Actually, one of the requirements for synchronous composability is real time settlement. And it turns out that the only way to get real time settlement, which is the ability to read and withdraw from rollups immediately, is to have a ZK rollup. And not only do we need a ZK rollup, but we need a ZK rollup with real time proving, essentially being that when the CPU runs and executes transactions, there's some sort of coprocessor running behind it that in real time produces a snark that proves that the CPU is doing correct execution. And we are not there yet, but we know how to do it theoretically. And in my opinion, it's just a matter of pushing the engineering. So two things that we need to do is, one, improve the engineering of recursive proofs, so that allows us to parallelize the proving. And two, we need to have hardware acceleration, and in the end game even have snark Asics. So once we have this real time proving, we've basically brought the latency down to zero for settlement. But if you have two chains that each have zero latency of settlement, that's not enough. To actually get synchronous composer, you need the final step, which is you need one single actor who has a monopoly power to do things at the same time synchronously on both sides. Let's say that I want to buy $10 million of some token, and in order to get best execution, I'm going to need to get liquidity from multiple different pools. Well, what I'm going to do is I'm going to talk to the shared sequencer the shared sequencer is going to have a look at all these pools and say yes, in order to fulfill your order, I'm going to go dip in all these pools. And the cool thing is that this one entity, this one counterparty, can give you very high assurances that it will be able to, in one fell swoop, kind of complete your order. And not only that, also give you a pre confirmation. So that's another aspect of shared sequencing, is that you have this one counterparty that can in real time give you promises of future execution, as opposed to having to wait for the twelve second block time or whatever the block time is."
    },
    {
        "speaker": "C",
        "text": "As ive grown in my understanding about the Rollo centric roadmap, I always understood, oh, asynchronous chains going in different directions. We get a diversity of different strategies. This is good for Ethereum because all strategies get to be experimented with. Let the best strategy win. We get multiple different solutions to the same problems then. Also, in response to the lack of the fragmentation critique, my answer has generally been along the lines of, well, latency towards finality will slowly come down over time and it will approach zero. It won't actually get to zero, which zero I would consider to be atomic transactions, atomic execution, universal composability, but it will approach zero. Chains will get faster. Optimistic roll up settlement times will approach zero. ZK roll up settlement times will approach zero. And we will get so close. That kind of what you are saying. A browser on the Internet, back end of a browser, you have many different asynchronous systems that compose the Internet. Fun fact, the Internet is an asynchronous system, and the browser just packages it all up and presents it to the user. And it's so close in terms of finality and settlement and latency that just from the end user it seems good enough. That was my idea about how the role of centric roadmap will come to be composed together. We will just get so close that we can get just like ux tricks, front end ux tricks to take us the rest of the way. But I think, Justin, what you're saying was that, well, that was the cope that you were talking about. That was like the sharding of the Ethereum roadmap. And actually it's true atomic execution, true universal composability. That is what we are that we ought to be striving for and aspiring to in the Ethereum future. And I think you are also saying we can get there."
    },
    {
        "speaker": "A",
        "text": "Yes, absolutely. I mean, I guess an alternative phrasing could be it is possible that very similar to the Internet, we could do everything asynchronously and just wrap it up. But it is a superpower. It is a luxury that we could potentially get synchronous composability. I think that we, as an ecosystem, we can't afford to not pick up the fruits of this luxury. And part of the reason is that we have competition. If we don't do it, the competitor will do it. And in some sense, Solana is forcing us, through better ux, better composability, to just move a little bit faster. So, hat tip to Solana for doing that. But one of the cool outcomes of this accelerationism from Solana is that now we finally realize that we can do incredibly neutral, extremely secure web pre conformations, shared sequencing for all of ethereum, and basically mimic the user experience that Solana has."
    },
    {
        "speaker": "B",
        "text": "Okay, super cool so far. That hat tip to Solana is kind of interesting, because one of my favorite things about the crypto ecosystem is we're all leveling each other up, and one chain's innovation becomes another chain's area of improvement and their level up potential. We've seen that with so many things. And so I just want to establish what we're saying as we're going into this episode. Justin, you are saying there are some advantages with this thing that we're calling here, universal synchronous composability. So USC, and we'll get into those advantages and enumerate them a little bit more in just a second. But I want to make sure that we are definitionally sound on universal synchronous composability because it sounds like techie like words. It sounds like Ethan researchy words. But, like, breaking this down, universal I take to meet across all chains. So, like, everywhere. And not just, you know, like one. Ethereum. It's ethereum. Plus all of the roll ups, all of the layer twos, and all of the layer threes, that's what universal means. And then synchronous means everything stays in sync. So at the same time, okay, that's what synchronous means, I think. And then composability means you can stitch things together. So all of these money legos, they're not across the chasm where you can't stitch one money Lego with another money Lego. All of the money Legos fit together. All of the smart contracts talk to one another, and you can stitch them together inside of another million dollar word here. You can stitch those together in an atomic transaction. That is atomicity. One single transaction can stitch all of these things together. That's what we mean by universal synchronous composability. And we are saying that is good. If we can have that, we want to have that. Now, the Internet gets by without having that. It's an important distinction. You can build something like the Internet with just universal asynchronous composability. But we are saying we like universal synchronous composability. If you can have that, that's the cherry on top, and you get a lot of benefit from that. Is that a good kind of working definition or what would you modify?"
    },
    {
        "speaker": "A",
        "text": "No, I think that's exactly right. So if you want to have a look, a feel for what universal asynchronous composability is, have a look at Cosmos, because that's the whole vision, right? Its own chain. Every chain is its own asynchronous shot. And arguably, things are extremely messy in cosmos land. And cosmos, people will tell you that. And then the other extreme is, of course, Solana, where everything is under one umbrella. But Solana has made a lot of shortcuts, which Ethereum is not willing to make. And what I guess I'm trying to say here today is that we can get the best of Solana without taking shortcuts. So it will take some time, it will take several years. So that is the main trade off. Like, we have slower speed of execution, but the end game, the North Star, is that we can get the exact same user experience, if not better than Solana. Today."
    },
    {
        "speaker": "C",
        "text": "There's a bunch of quirks, idiosyncrasies, I think, that people experience when they use Ethereum and its roll ups. Today, there's one uniswap per chain. Metamask has a dropdown for all these different chains there's doing this bridging. Can you. Maybe you can just tell us a story, Justin, of fast forward five however many years that we need to wait until we have the research and then engineering done on this. What does a universal synchronous ethereum feel like and look like to a user who knows Ethereum as it is today, where there's multiple networks, multiple uniswaps, different tokens with prefixes in front of them, what are some of the big pain points that would be gone in this scenario?"
    },
    {
        "speaker": "A",
        "text": "One of them is that you have shared liquidity across every single roll up. So right now, we have a bit of a cold start problem for rollups. They're starting from scratch, and they can't tap into the half a trillion dollars of liquidity on layer one, they have to start from zero. This is very expensive for several reasons. One of them is that they have to redeploy all these contracts, which start off empty, and then they have to provide incentives for people to move over. You have to pay for liquidity farming, then you have to set up infrastructure like Chainlink. So you have to set up these business deals, and you need to do all sorts of new integrations. And so the barrier to entry for new entrants is extremely high. So in addition to having unified liquidity, we also dramatically lowering the friction for innovation. So one of the consequences, for example, is that we can expect a much richer long tail of virtual machines, because right now the main roll ups are in some sense opinionated. They say, okay, we're going to go with EVM equivalents, but what if you want to innovate a little bit more at the virtual machine layer, have things that are specialized for one thing or another, and also have them compose with the existing ecosystems? In some sense, what I expect fundamentally is just much more richness than we would have otherwise. But today, arguably, the user experience on any given silo, on any given execution zone, is actually pretty good. You have the pre conformations on arbitrum and you have an existing ecosystem, but it would be so much better, there would be much less dead weight loss, more network effects if everyone were to work in the same direction. Now, one very important distinction, I guess, is around whether or not we can tap into the existing half a trillion dollars of liquidity at layer one. Because oftentimes when people talk about shared sequencing, they talk about shared sequencing for the roll ups, for the l two s, so that they have interpreted between them. But what about the l one? Well, it turns out that we can have both. Like, we can be in a position where instead of playing zero sum games with the layer one, we're actually boosting the layer one. And every time a new entrant comes in that grows the pie incrementally and incrementally."
    },
    {
        "speaker": "B",
        "text": "This is every time we have you on Justin. It's kind of like a conversation where. That I love, because you always come to us with good news. It's kind of like, hey, guys, you can have your cake and eat it, too, right? And like, when we did our episode that David alluded to in the intro, you know, about cryptography magic, it was kind of like that. And many of the other episodes, it's been kind of like that as well."
    },
    {
        "speaker": "C",
        "text": "It's just like the theme of all Drake episodes is hey, we can use cryptography to get what we want."
    },
    {
        "speaker": "B",
        "text": "Yeah, exactly. Which is why I love it. And like, one thing I really want right now is what you, what you mentioned, which is shared liquidity, just to wrap a bow around that for the user. That basically means that the user experience would be like one inch or matcha or any kind of Dex aggregator except across all layer twos by default. That would be easy. Right now you can kind of get by a little bit with intents. So like Uniswap's intents platform, if you use one inch today, they're doing some of that with intents. But what you're saying is we would have that by default if we get to this special place of universal shared liquid synchronous composability. But also another thing that's bothering users, I think, is bridges. Are you also saying that in this world, bridges go away? Because there's another set of questions. Every time you want to move your asset from one layer two to another, or from ethereum to a layer two, you're like, what bridge do I trust? And there have been so many famous bridge hacks. Many of these bridges are like nothing more than multisigs. And it's scary out there. Do bridges go away if we achieve this dream here?"
    },
    {
        "speaker": "A",
        "text": "Right? So bridges exist to bridge a gap. And if you remove the gap, as you said, you no longer need the bridge. So you have bridgeless bridging, if you will. Now, as you said, today's bridges are like really suboptimal from a security standpoint for two reasons. One is that they tend to be fairly complex sometimes we're talking about like clients passing messages back and forth and fancy cryptography, but also just from a governance standpoint, they have their own governance token. They have potentially multisigs, even most of them. And we've seen historically that many, many bridges got completely emptied. When we have universal synchronous composability, you just call the other contract without a bridge, just like you're doing today at layer one. So that's definitely a big gain. Another, I guess, improvement is in terms of deduplication and defragmentation. So right now we have lots of different uniswap pools, for example, one per roll up, and it's actually gas inefficient to go dip into each one individually. It would be okay to have one single pool that makes everything more gas efficient. And actually, this is why a uniswap chain actually makes sense. It doesn't make sense to have a uniswap chain, which has its own sequencer, because then it's this big pool of liquidity, but you can't really tap into it. You don't have this composability. But now if we have uniswap as an app chain, which is synchronously composable with all of Ethereum, then it's as if it was a small contract. Arguably it's just an app. So we're moving up one level of abstraction, but we're not really changing things."
    },
    {
        "speaker": "B",
        "text": "Can we talk about just things like Ens, for example? One thing that bothers me about my RSA eth name is I don't have it by default on all of the different layer twos. Does that become available? How about all of the ratings and reputation? Let's say that it seems like base the roll up is trying to accrue. There's fantastic. Each of these roll ups seems to have almost an economic zone of specialization, and I just want to bring that competency from one chain to the other. Anywhere that I go inside of the ethereum ecosystem, do I get things like ens across all of the chains with universal synchronous composability?"
    },
    {
        "speaker": "A",
        "text": "So the current roadmap that we're on is let's create these new l two s and these new roll ups and migrate all the assets from one place to another. Now that has two big problems. Big problem number one is that there's some assets that you just can't move or just realistically won't move. If you take ens, for example, the root of trust, more likely than not, will always be ethereum. Layer one and same for immutable nfts like cryptopunks or whatever immutable application there is on layer one, it's very difficult to move these assets. And then if you think of whales that are extremely conservative and whatever, like funds and treasuries, that is going to stay on L one. And so we're risking a situation where we have a winner take most roll up and then we have the l one and they're both kind of 50 50 or some share of the market. And this is really bad for network effects. And the reason is of Melkaf's law. Melkoff's law, roughly speaking, says that the strength of the network effect is quadratic in the size of the network. And so if we have 50 50, that's actually like a four x loss of potential strengthen of network effects because we've reduced the size by two. And that means the network effect has reduced by a size of four. So that's one problem, is that the mere migration problem is destructive to network effects."
    },
    {
        "speaker": "C",
        "text": "To summarize this section, we've been talking about just a lot of the costs of fragmentation. Where Ethereum is supposed to be a place where we have positive sun games. The roll up centric roadmap hasn't yet fit into that model. Just like you said with Metcalfe's law, Justin adding on another rollup takes away liquidity from other rollups. It's one plus one does not equal two. It's actually 1.1 equals 1.8 or 1.7. There's loss there when new rollups come into the field because we have to share limited finite resources. Whereas I think the future that you are illustrating that we're trying to get to is that if a new roll up comes onto the scene, it's actually additive, it's actually greater. Any sort of new capital or TVL that a new roll up attracts, brings it into the grander superstructure without pulling it from other roll ups. If optimistic, roll up chain number 74 comes in and then, you know, uniswap deployment number 82 comes in and then it attracts a million dollars of TVL. Without universal synchronous composability, it probably attracted TVL from other chains. And so for the holistic system, it wasn't additive. It was just, you know, we just took from one pocket and gave it to another. But I think with universal synchronous composability, this flips where any single new chain that comes on with another version of Uniswap, or even the uni chain, which is the grand centralization of all liquidity. Any new system adds to the throughput of the Ethereum network. It adds to the liquidity of the ethereum network without pulling away. So it goes back into positive sum games where with the technologies needed to produce universal shared composability, one plus one can equal three, which is one of the reasons why we are in crypto in the first place. Would you say that's the outcome we're searching for?"
    },
    {
        "speaker": "A",
        "text": "Yeah, I think that's exactly right. The competition between roll ups that don't have shared sequencing is not just zero sum, it's negative sum, because we're starting to break down these super linear network effects. Then as soon as we reestablish the network effects, we go back to this quadratic superlinear power of the network effects. I think this is part of the way that I think about it, is that Ethereum is going through its you know, puberty phase, things are a little awkward. Like things get hairy and. And, you know, the. Even this also has impacts mimetically, right. The voice of Ethereum, the narrative is changing, right. People feel like, you know, there's insider fighting, you know, people. People feel a little lost, right?"
    },
    {
        "speaker": "B",
        "text": "It's roll up versus roll up a little bit, right? It's all of these kind of sub brands. Like, if I'm on the arbitram, am I on Ethereum? We used to know when you were on Ethereum, it said Ethereum and it was very clear. And then there's all of the layer twos kind of competing against each other. So we've lost some of the shared spirit. Like there's been some fracturing in terms of narrative, in terms of brand, in terms of this feeling of oneness. It's almost like, you know, how so often we use the metaphor of a country like the United States, and one metaphor we've used is ethereum being the United States, let's say, and all of the states being these individual roll ups. It's almost like the states themselves are at war with one another, not in a healthy economic competition, which they should be, but almost not part of the same, I guess, group of states that are forming a union together. And that's where we're kind of left as of today. You think the process of getting the architecture right and universal composability, you think that could heal what we're seeing on the narrative and memetic warfare side?"
    },
    {
        "speaker": "A",
        "text": "Absolutely, yeah. I think this is more than just a technical innovation, as is usually the case with a firm. This is also some sort of social shutting point, a coordination point, something that the whole community can rally around. And I think there is a large amount of risk if we don't find this common ground, this neutral playing field, which is that we have gigantuous ecosystems, we have titans like arbitrum, like optimism that are deca billion projects. These market caps are huge and they have huge amounts of weight behind them, and we don't want to see these titans fighting each other. It's going to be extremely bloody, and there's going to be a lot of unnecessary loss of network effects. And so what I think we should do is kind of try and understand what is a reasonable thing to compete on and what is a reasonable thing to collaborate on. And where I personally draw the line is on shared sequencing. I think kind of for the sake of the industry, if you will, shared sequencing is something that we really want to collaborate on. I think of it as a trillion dollar dance. If we can get this right, we're unlocking a trillion dollars of value. Now you can ask, okay, what are the roll ups really competing on then? Well, there's a whole list of things that they can compete on. They can compete on tooling, they can compete on virtual machines, they can compete on tokenomics and public goods, they can compete on security, they can compete on biz Dev. There's just so many things they can compete on. For the love of God, don't compete on sequencing. And the good news is that, and."
    },
    {
        "speaker": "B",
        "text": "Justin, what are they not competing on? So they're not competing on sequencing and they're not competing on liquidity anymore. Are they still competing in liquidity for liquidity?"
    },
    {
        "speaker": "A",
        "text": "Great question. So this goes down to the incentives at play. How do roll ups make money? And the way that they make money is through execution and not sequencing. And we can go down this whole rabbit hole. And so really what the roll ups want to be doing is maximizing the amount of execution within their execution zone. And one way to do this is, as you said, to compete for users, compete for liquidity, compete for devs, and that's totally fine. But the important thing is that this competition is healthy because it doesn't have break the pie, it grows the pie. So it's this really healthy competition that we want, not the unhealthy one where we have these negative sum games and we're breaking down network effects."
    },
    {
        "speaker": "C",
        "text": "Justin, we've been talking a lot about what could be, what the Ethereum that could be. When we achieve universal synchronous composability, we actually need to technically answer how we actually get there. You've been talking a lot about shared sequencing, and I think that is the first step on perhaps a multiple step long journey of technical advances that Ethereum needs to achieve. The Ethereum rollups need to achieve in order to have this universal shared composability. Is that the right way of thinking it? Shared sequencing is step number one, and that provides the foundation for the following steps. But first we need to get to shared sequencing. Is that correct?"
    },
    {
        "speaker": "A",
        "text": "Right. So there's two necessary ingredients in order to get to the end game. One is shared sequencing, and the other one is real time settlement for both of these fundamental pillars. We're not there yet. The good news is that even if we have shared sequencing, but we don't have a real time settlement, we can still do a lot of stuff. It's just not the end game. For example, if we're dealing with optimistic roll ups, where you have to wait seven days. What you can still do is use liquidity providers that will mimic synchronous composability and will bridge the liquidity gap, as it were, because it takes seven days to get your liquidity out. Imagine that you want to buy $10 million of a token. You get optimal pricing across lots of different pools, all synchronously, but then it takes seven days for you to receive your money. You wouldn't be super happy. Use LP's to bridge this gap. But once we have real time settlement and shared sequencing, we go back to this very luxurious model. Very simple for developers, by the way. It reduces a lot of mental friction. Besides the mental friction aspect, there's also this entrepreneurial risk going on, because right now we're asking application developers to make big bets to put all their eggs in one basket on one provider. And this is somewhat risky. One of the nice things with universal composability is that you can do these graceful migrations and updates from one app to another. So maybe the best example is Uniswap. Uniswap has no governance. It's a fully immutable, smart contract, and it's been able to seamlessly upgrade from V one to v two to v three precisely because all of these versions of Uniswap are under the same sequencer. So from the point of view of a user going on the website, the Uniswap website, whenever I click buy behind the scenes, it's just buying from all these pools at the same time, and it just feels seamless. But the reason why Uniswap doesn't have a similar buy buttons for all the roll ups is because it's just so much more complicated and messy and brittle. And so for developers now we've reduced the entrepreneurial risk, we've reduced the cognitive friction, and we're going to be able to move so much faster, just really."
    },
    {
        "speaker": "B",
        "text": "Quick, reduce the entrepreneurial risk because the developer doesn't have to pick a winner. I imagine if you're a developer today, you're like, what chain do I deploy on? What chain do I focus on first? And that's like, there's a lot of questions, and that you're saying it removes that risk."
    },
    {
        "speaker": "A",
        "text": "Yes. And not only are we asking, it."
    },
    {
        "speaker": "C",
        "text": "Goes back to just choosing ethereum, rather than choosing optimism or choosing arbitrum or choosing polygon, it goes back to just like, oh, I choose to build on ethereum. Correct?"
    },
    {
        "speaker": "A",
        "text": "Yes. At least for this one layer of the stack, which is the sequencer, which is some sort of very important public good layer that we should all coordinate on."
    },
    {
        "speaker": "C",
        "text": "Okay? Real time settlement and shared sequencing, these are the two big upgrades that we need to bring to Ethereum. And these aren't upgrades like proof of stake or EIP 1559, we're not talking about an EIP here. These are actually more extra protocol upgrades and real time settlement. That's not even just a specific innovation. That has got to be a collaboration between faster roll up settlement times. So maybe the transitioning to ZK rollups, it's also faster intent fulfillment orders, better market makers. And so there's a semblance of extra protocol things contained in that real time settlement. But then the first one, I think, I think that really is where a lot of the magic happens, is shared sequencing. Can we just go back to the 101 justin of what is sequencing? How does sequencing look today on Ethereum's roll ups? And then we'll get into what does it mean to share that process."
    },
    {
        "speaker": "A",
        "text": "So the way that chains, traditional chains, are designed is that at any given point in time, at any given so called slot, you have a well defined entity, the sequencer, who has monopoly power to include a block in that slot. So in l one, we have this rotation of the sequencer, and it's the proposer, the layer one proposer at the roll up level. What we have today is centralized sequencer so that at every single slot it's the same entity. And more often than not, it's just the labs or the team behind this specific roll up that are running the, the sequencer. Now, one of the desires of these teams is to move to a decentralized sequencer. So, you know, sooner rather than later, we're going to be in a position where we're also going to have this rotation of the, of the sequencer at any given slot. But the important property is that at any given point in time, you have this one actor who has monopoly power for a short period of time, and then that they can give you promises on future execution, which is basically a pre confirmation. So a lot of the time people complain about ethereum's lock times being quite long, 12 seconds. It's an eternity. Well, we're going to move to a future where whoever the sequencer is will be able to give you a preconfirmation on the order of 100 milliseconds, because 100 milliseconds is roughly the amount of time it takes for information to travel on the Internet. And not only are we going to have preconfirmations like we do right now on the roll ups. But we're also going to have layer one pre confirmations. So one of the great things about everyone working on the same sequencer, if that happens to be the r one, is that the various pieces of infrastructure for users, the wallets, the searchers, the builders, all of that whole pipeline around going from a transaction to a user will be upgraded. And one way to think about it is just to add the prefix super to every single actor. So we're going to go from transactions to super transactions. We're going to go to builders, to super builders, searchers, to super builders, super searchers, PBS to super PBS. And what super means is that we're touching multiple execution zones at the same time. So a super transaction is a transaction that touches multiple zones. So there needs to be some upgrading of the wallets from transactions to super transactions. But this is much, much easier than shared sequencing, which is more of a social coordination game. It's this dance that we have to play and real time settlement, which is this really hardcore engineering problem."
    },
    {
        "speaker": "B",
        "text": "Okay, so just setting up the landscape and maybe repeating some things back to you. So every roll up today has a sequencer. And the sequencer's role is basically to determine what transactions go inside of the block and then to order that. And this sequencing in all of the rollups, I think basically all of the rollups today is managed by a centralized team. So if you're on arbitrum, it's kind of like the arbitrum people, arbitrum labs, or some sort of entity that is operating the sequencer. And the reason that's fine in the roll up architecture today is as a user with funds inside of arbitrum, you always have the option to withdraw your funds back to the Ethereum layer one. So you can't have that form of rug risk, but you do have some risk with respect to, I suppose, censorship. The centralized sequencer can censor your transactions and then you have liveness risks, which we've seen. So when the centralized sequencer goes down, then the chain stops working. You can't get transactions through. So you have these risks. That's the current state today. And I think there's been some social notion that we want to make our roll ups more decentralized over time. That would be, I think, congruent with crypto values, with Ethereum values. And so we're maybe on the path to do that. But I want to ask a question on this, Justin, because there could be a trap here, and that might be an incentive trap that might slow us down or stop us and that's like, I'm aware of many decentralized sequencing, shared sequencing solutions out there, right? There's one called espresso. There are many others. But there is a profit incentive thing at play where the sequencer not only sequences the blocks, they don't do it for free. In exchange they get mev. So they get basically blockchain fees, and that goes back to the entity operating the sequencer. So in effect, by inviting a shared sequencing solution inside of your chain, you are foregoing some of that profit. You're giving it to someone else. I'm wondering if you could kind of address that. Has that been a reason we haven't seen more shared sequencing propagation thus far? And if so, how does that impact kind of the social layer that you're talking about and our ability to get shared sequencing done right?"
    },
    {
        "speaker": "A",
        "text": "That is a fantastic question, because as everything we do in our space is driven by incentives. So it's really important to appreciate the incentives. One of the things that I want to clarify, first of all, is that the sequencer today on the roll ups is a collector of fees. It's not a generator of value. And the reason is that, largely speaking, it collects two different fees. It collects the layer one data fee for data availability. And really the value creation is the layer one. And it collects the layer two execution fee. And here think of it as a fee. Like the EIP 1559 base fee, it's native to the execution engine. It's non negotiable. The sequencer basically is collecting these two fees and then forwarding them as expenses to the sequencer. And so the sequencer is not really making much profit. Now you're right that fundamentally the sequencer can charge fees, but it's not really fees, it's actually MeV. It's a fantastic question to ask. Okay, the existence of MeV, is that an impediment to everyone playing this trillion dollar dance? Because we're all incentivized to kind of not play it. And I have several answers to that. One is that the roll ups today are not extracting meV. Right? They don't want to extract MeV. And part of the reason is that MeV is kind of extractive to users. One of the really cool things about a centralized sequencer is that it provides MEV protection. It's this super easy encrypted mempool. For example, there's no sandwiches on arbitrum and on optimism and on base, because you send your transaction privately to the centralized sequencer, no one else can see it. And so no one else can go sandwich you in trying to extract MeV. Now, suddenly there's a real trade off. The user experience just becomes so much worse. And I think in our ecosystem we want to try and go to the up and up and up. And users have become addicted to pre confirmations, and I think users will also become addicted to MEV protection. They're not going to want to go back. But let's assume that we do go back just because the incentives are so large that we do want to go back. Well, let's try and quantify the things. And maybe the best place to look at is the l one, because we have a very robust fee market. And here what we're seeing is that on l one we have 800 eth per day of MeV and 3200 eth per day of base fees. So on layer one, the ratio, I guess, of execution fees to MEV is four to one, or 80%, 20% really. MEV is a small part today on l one. Then I guess the third point that I want to make is that I believe that MeV is going to go down by at least an order of magnitude, maybe two orders of magnitude. Today the breakdown is 80 20, but in the future I believe it will be more like 99% 1%. The reason is that today there's two main sources of MEV. One is sandwiching, and I think that will just go out or go away completely with things like encrypted mempools. And then the other source of MEV is arbitrage between decentralized exchanges and centralized exchanges. And again here, with better application design, we're going to be able to remove the leakage of movie to the sequencer. So the basic idea in one sentence is that these new V four decentralized exchanges are going to be able to auction off the right to arbitrage, and then with the proceeds of the auction, rebate the liquidity providers. If you didn't understand that, it's not a big deal. But the point that I'm trying to make here is that the MEV will no longer flow to the sequencer. And so really, the way that I think about it is that the best move for the roll ups is what I call the MEV gambit. They're going to be giving away, let's say, 1% of their revenue, because almost all their revenue will be execution fees. 99% and 1% will be MEV. And in exchange, they get to tap into this wonderful, wonderful ecosystem of composability."
    },
    {
        "speaker": "B",
        "text": "Just to recap where we are right now. Again, we're on this quest to solve fragmentation, and the way we solve that is getting universal synchronous composability and shared sequencing can help us get there. And Justin, you think that there is a positive incentive for all rollups to add shared sequencing to their stack? Because while they might lose some MeV, MeV is not a sustainable revenue source for them anyway, given market forces. And the trade off will be worth it because they want to make their revenue on their value proposition, which is execution. And they get so much more execution if they get the liquidity and composability and bootstrapping effect and Metcalfe's law and everything we've talked about of the entire force of the Ethereum economy. So they're all going to add a shared sequencing to their roll ups. You think, you think the path is clear for that? Let me ask you, why haven't they already? Is the shared sequencing tech not here yet? And for those that aren't aware, there are like a handful, I would say, of shared sequencing providers. Espresso is one that kind of comes to mind. But to my knowledge, that's not in production in any chain yet. We don't have shared sequencing across the chains. But again, once we get that, we get universal synchronous composability, at least I believe so. Why don't you think we've gotten there yet, Justin? What's stopping us?"
    },
    {
        "speaker": "A",
        "text": "There's so many reasons why we haven't got there yet. One of them has to do that with just the sheer simplicity of centralized sequencing. It's the easiest way to just get a foot out of the door. And we've seen how important it is to be a first mover. Optimism. They just wanted to be a first mover. For example. They just went with the simplest approach possible, which is let's just have a shed sequencer. They've even made the trade off of not having thought proofs, and that's fine. It's a business strategy, and it worked out really well for them. Another aspect of the shared sequencer, which is fully controlled by the team, is that it's actually a security training wheel, and very few people appreciate that. Here's the problem. A lot of the verifiers, whether it's a snark verifier or fraud proof verifier, they're extremely nascent and they're going to have bugs. And if an attacker wants to go exploit, for example, a snark verifier bug, well, what they would have to do is kind of craft this invalid block and make it look like it's invalid to the verifier, and then they get to steal money. And so if we have a centrally controlled sequencer that acts like security in depth, because the shared sequencer that's controlled by the team will make sure that no invalid and crafty blocks ever make it on chain. And so in order to exploit a bug, you need to do two things. One is you need to take over the shared sequencer, and two is you need to exploit the verifier. And then another reason, which I've already mentioned, is that these shared sequences act like an encrypted mempool. They provided mev protection. And then another kind of aspect of this is that we need to build a lot of infrastructure. I was talking about all these super things we need to build super builders, super searchers, all of these things. And the great news here is that the market will build this through proposal builder separation. The sophisticated set of builders will go ahead and do that, but we still need wallet integrations and things like that, then we also have the incentive point. People don't really understand the incentives of shared sequencing today. To be fair, some people are very skeptical of shared sequencing precisely because of meV. And today, MEV is a sizable share. It's an extra 20%. Who would want to give up 20%? I think we need to see more maturity. We need to prove to the market that MEV is indeed going down by an order or two orders of magnitude, and then at which point it will kind of become a no brainer. And so I think the roll up teams are keeping optionality right now. And then the other thing worth saying is that the roll up teams just have so much on their plate, right, going back to the cold start. They have to incentivize liquidity within their pools. They have to do all the chain integrations, they have to do the metamask integrations and all of that stuff. And it's really, really complicated. And so a lot of that actually goes away, ironically, once we do have synchronous composability. So let's take Chainlink, for example. Chainlink today, what they're doing, basically, is trying to get a business deal with every single roll up, because you need chain link oracles for Defi. In some sense, they have a monopoly, but this is really at the expense of rollups. My understanding, talking to various roll up teams, is that what's happening in practice is that there's these backroom deals that are protected by NDAs. And it's like we're talking about very large amounts of money that in some sense, Chainlink is able to extract from these roll up teams. But if we had oracle updates on l one and everyone had synchronous composability with l one, then Tada. You just get chainlink oracles for free. No need to pay this additional chaining tax as an l two."
    },
    {
        "speaker": "C",
        "text": "Yeah, and problems like that are rampant across the layer two space. Etherscan, for example, charges a fee for every single roll up. And what if we could get more synchronicity, more universality, with a lot of these different vendor providers that are able to copy and paste their business model across every single chain when it all kind of coheres down into one single chain, at least from the Ux perspective? Justin, we've gone pretty far in this conversation, and I don't think we've actually yet done a pretty thorough walkthrough of a shared sequence. So maybe we can talk about what happens in a shared sequence or paradigm when a uniswap transaction on optimism collides with a uniswap transaction on arbitrum. Right now, these two transactions do not talk to each other. One only impacts the other. Once some liquidity provider arbitrage bot settles and rebalances the pools across these two different chains. Can you just walk us through a shared sequence? What is it we're talking about the sequencers, the orderings of transactions on arbitrum, the orderings of transactions on optimism. But when we get to a place where these things are sharing their sequencer, what does that look like, and what does that get us? Because I think we really need to define this foundation for how these roll ups can compose together after we have a shared sequencer. So maybe we can start from the beginning of defining shared sequencing. And what does that look like across rollups?"
    },
    {
        "speaker": "A",
        "text": "When we have a shared sequencer, there's one well defined entity, the shared sequencer, who has monopoly power to build blocks for all the roll ups and all the l two s simultaneously."
    },
    {
        "speaker": "C",
        "text": "At least those that have updated, that integrate with it."
    },
    {
        "speaker": "A",
        "text": "That integrate with it, yes. So, on that note, universal is maybe overselling it because it's not completely universal. It's whoever opts in to this shared sequencer. But what I think will happen is that there will be a de facto default. And so by default, you have universal composability. But if, for whatever reason, you want to have your own application specific sequencing, then that's fine. You can go ahead and do that. The shared sequencer is not forced on anyone. Now, let's say that we have n roll ups that have opted in. Well, this one entity can build blocks for these n roll ups at the same time. And not only can they build n blocks, but they actually have the ability to build interleaving blocks. So you could imagine calling roll up a and then roll up b, and then roll up a again, and then roll up b again and then c, etcetera. Basically, you can think of it like threading the needle between all these virtual machines and having an interleaved interaction. Just like you can have contract a that calls contract b that calls contract c and then goes back to contract a, for example. Now, in the case of a uniswap trade, what will happen is that the uniswap front end would be monitoring the liquidity on the various executions, and then it would craft for you something that maximizes the efficiency of your execution. And it will turn out that in order to maximize efficiency, you need to touch follow up a, b and c. And so what it will create is a super transaction, which is made out of three constituent transactions, and you have very nice properties. Property number one is that all three of the constituent transactions will all happen at the same time, or none of them will happen. So you have atomicity, and then you have this other really cool property is pre confirmations, which is that you know immediately whether or not your transaction will go through. You don't have to wait 12 seconds. And also, you know. So not only do you know immediately your execution price, but you also know how much you're paying for gas in every single roll up. So we're going back to this web two user experience, but using web three tools."
    },
    {
        "speaker": "C",
        "text": "Okay, so there's got to be some amount of computation going on here. So say I make a decently large uniswap trade on optimism on the ETH USDC pair, and it is so large because my size is size, that it also disturbs the arbitrum Uniswap pool as well, because of some arbitrage mechanism, and there's some computation going on there. I would imagine that if we are living in a shared sequencer paradigm, that computation is happening atomically and that is improving my execution price. But also a market maker or an MEV bot or an arbitrageur is also coming in and helping me rebalance that pool to optimize for efficiency. And their transaction is also coming in. Is that happening as well? Or is that the role of the sequencer who's doing that job."
    },
    {
        "speaker": "A",
        "text": "This is like, slightly of a different problem, but it's basically some sort of order flow auction. I, as a user, I want best execution. What I will do in the future is not what's happening today, but in the short term future, what will happen is that you're going to talk to various searchers, and the searchers will be competing with each other to give you the best quote. And then you just pick the best quote. This is what's happening with uniswap x. You have the searchers competing to give you the best quote. And the amazing thing here is that it's the market that's doing all the computational combinatorial searching, because there's an exponential blow up of different combinations of pools and liquidity. And all of that is handled by the sophisticated searchers and builders. So that is part of the beauty of proposal builder separation. The sequencer who's given the right to sequence doesn't have to do the heavy lifting. Computationally, they can delegate that right to entities that will do the heavy lifting. And the amazing thing is that even though the builders and searchers will be very sophisticated, it might be some sort of army of PhDs with a very large cluster of computers. That sophisticated entity is totally trustless."
    },
    {
        "speaker": "C",
        "text": "Okay, so with this process of. You talked about how this is, like, in the world of intents and Uniswap X. That's how I understand it as well. And all of these intent transactions that are being made by the user and then being filled by fillers, they all collapse down into the centralized sequencer and become atomic because of the centralized sequencer. Correct."
    },
    {
        "speaker": "A",
        "text": "Right. The searchers are able to give the user a deal, which can be signed off by this one counterparty, which is the sequencer. If you have 16 different sequences, then now it becomes extremely messy, because now you need to try and gather some sort of pre conformation from each one of them. But some subset of those 16 might. Might not respond or be faulty in some way."
    },
    {
        "speaker": "B",
        "text": "So all we need to get to this state of super transactions and super bundles. Again, this prefix super, which I love, that's kind of a transaction or a bundle that touches multiple execution environments or effectively, multiple chains in this world. Do we also get the layer one as part of this? Because. So my understanding is all of these layer twos, all of these roll ups will need to adopt the shared sequencer, kind of the same shared sequencer. It's not truly universal because they all have to opt in, but let's assume they all opt into this one shared sequencing solution, then we get a universal synchronous composability across all of the roll ups. We also get that with the Ethereum main chain. Or is something else needed there?"
    },
    {
        "speaker": "A",
        "text": "Right, fantastic question. So the nice thing about the rollups is that they have the ability to opt in because they have a governance and they can basically choose which sequencer they opt into. The l one, unfortunately, is what it is. It can't opt into something other than what it currently is. It happens to be that the sequences of the r1 are the layer one proposers. So if you want to be synchronously composable with the l one, you have no choice. You have to hire in some way the l one proposers."
    },
    {
        "speaker": "B",
        "text": "By proposers, just to translate validators, stakers, like we're talking about the people who run clients, eth clients."
    },
    {
        "speaker": "A",
        "text": "Yes, that's correct. There is a proposed upgrade which is called execution tickets, where the proposers are a different entity. But let's put that aside for now. Let's say that it's just validators that are currently sequencing the l one. If you want synchronous composability between rollups and the l one, the roll ups kind of need to buy into the sequencing of the l one. And this is what's called based sequencing. And if you opt into base sequencing, you become a based roll up. There's all sorts of advantages to being a base roll up that opts into base sequencing. One of them is that you inherit the censorship resistance and the liveness of Ethereum. So not only do you have the settlement guarantees of Ethereum, but you also have the censorship resistance, the real time censorship resistance, not the delayed one with the escape patch, but the real time one that has various consequences. For example, it means that you have longevity of your chain. Let's say that as a roll up your sequencer gets taken over 51% attack and the sequencer can't be changed then now all the users have to use the exit hatch and move out. That's one advantage of base sequencing is security. The other one is credible neutrality. And you might say, do we really care about credible neutrality? Well, if you're one single Rolex ecosystem, not really. But if you want your competitor to also opt in, it needs to be incredibly neutral. You can't have the optimism ecosystem say, hey, we've created our own sequencer, it's credibly neutral, please arbitrum, come use it and vice versa. There needs to be some amount of credible neutrality, some sort of common ground that we can all agree to adopt. And the nice thing is that in some sense ethereum is maximizing for these two properties, security and credible neutrality. It's almost the definition of a roll up, right? What is a roll up? A roll up is one that has already bought into the security assumption of Ethereum. You're not adding a new security assumption, you're not falling to a weakest link, you're just reusing the existing security assumption. And two is you've already accepted Ethereum as a credibly neutral platform. Otherwise you would have chosen another chain. And now you can go ask yourself, why isn't everyone just using the layer one sequencing? And I think there's a couple answers to that. Number one is that first of all, it's not obvious that the ethereum layer one can be used as a shared sequencer. And this is actually a very similar story to data availability. Spent the better half of half a decade to not realizing that database was just there, that it could be used for rollups. It was this discovery of a new resource. I think the ecosystem right now with base sequencing is realizing that there's this new resource that's been there all along and that we can start to tap into. First of all there's this lack of awareness. But the second big problem is around pre confirmations. It used to be the case that if you were to opt in to base sequencing, you inherit the twelve second block times and there's no preconfirmations. But it turns out that we can get pre confirmations and this is a very recent discovery. Basically what you can do is you can ask the next layer one proposer to be your preconfirmer. And because they have monopoly power to sequence things, they also have the power to provide you a preconfirmation. So that ties in with restaking. For example, basically you have the layer one proposer put forward collateral and opt into these new stashing conditions which say if ever I give a promise of a preconfirmation to a user and I renege this promise, I never honor this promise, then I'd stand to lose my collateral. So we're starting to slowly understand and get all the pieces required for the l one itself to have pre confirmations. And then now suddenly you have this amazing shared sequencer which has the pre conformations which everyone wants, but also has maximal security and maximal credible neutrality."
    },
    {
        "speaker": "B",
        "text": "Okay, I just want to chart that we've, I think starting to enter the third part of this, this conversation. So in the first part we were talking about the problem fragmentation and the benefit from getting universal synchronous composability. The second part we were talking about, the way we achieve that is through shared sequencing. And at first we were talking about the private market solutioning for shared sequencing. By private market, I mean non Ethereum layer one, just the natural innovation. There was a problem. What is the, the problem? We have centralized sequencing. We want to decentralize that so that users get stronger safety, security, decentralization guarantees, and also to enable more composability and shared liquidity. And there are a bunch of private market solutions that are spinning up to solve this problem. And Justin, you gave the case for why. Naturally, the incentives align to kind of adopt these solutions. I just want to get a timeline on that section. Do you think private market shared sequencing, do you think that will start to happen this year? When do we get that? Is that in the next six months? Is that in the next two years? How long will that part take?"
    },
    {
        "speaker": "A",
        "text": "Right. It's happening this year. I've been having daily conversations now with Ben Fish, who's the founder of Espresso, and he's really one of the thought leaders on shared sequencing. And over the last week or so, we've been trying to share ideas and align on vision. And I don't want to put words in his mouth, but I think he's now convinced that base sequencing is the way forward. So I think what we're going to start seeing is these market participants that were looking to provide shared sequencing kind of change their roadmap a little bit of to just make it compatible with the l one, just because the benefits are so huge."
    },
    {
        "speaker": "B",
        "text": "I see, I see. Okay. So I was teeing up kind of a private market solution with the espresso type shared sequencers. And then I was thinking that base roll ups and essentially hiring the proposers, the validators and stakers of ETH layer one, maybe that is almost like the public solution, which is basically like the Ethereum protocol saying, hey, use us as a shared sequence. But these things tie together because the shared sequencer market can just not only provide shared sequencing across the roll ups, they can also provide a based roll up type of solution where they're actually, and this, I think, is the thing I didn't realize until probably two weeks ago. You did an AMA, Justin, and the entire Ethereum research team did an AMA. And someone asked this very question, the question that, like on Reddit, the question that this entire conversation is based on, which is how do we solve fragmentation? And your big reveal here was that we could actually use Ethereum like Ethereum made. Net as a shared sequencer. You said that's like hiding in plain sight. And now you're saying that the shared sequencing solutions that are emerging in the market, they are starting to see that too. And now they can opt into using Ethereum itself, Ethereum mainnet, as a shared sequencer. So that's where we've gotten to in this conversation, am I correct?"
    },
    {
        "speaker": "A",
        "text": "Yes, that's correct. And in addition to espresso, I've been talking to three different team of entrepreneurs that are interested in shared sequencing. And for a period of time there was frustration because people realized that shared sequencing with preconfirmations on l one was theoretically possible. But we used to think that a hard fork was required. Specifically, we used to think that inclusion lists were required, which is a potential upgrade to Ethereum. But in the last few days there was this kind of mental unlock where we realized, hold on, Ethereum l one can provide pre conformations today, no hard fork required. And so now these three teams of entrepreneurs, in addition to espresso are excited to go build it out. And so what I think will happen is there's going to be a bit of a rush, a race to try and build this shared Ethereum sequencer. And it's a little bit, I guess, like restaking Eigen layer is not building, it's building the Ethereum restaking platform. It's not building some proprietary thing. It's trying to tap into Ethereum. I think what we're going to see is different protocols like Espresso tap into the Ethereum shed sequencer and enhance it in some way. Espresso specifically is proposing two really, really cool ways to enhance it. Way number one is that in addition to providing the economic security for pre confirmations from one single entity like this layer one proposer, we can actually also get the Ethereum attesters to just double on in terms of economic security. So if you have a layer one proposal that puts forward let's say 1000 eth of collateral, that's a very good start. But what if you could have a million eth of economic security for the pre confirmation specifically? So for this twelve second window, that would be certainly an improvement. And then the other thing that Espresso is innovating on is the redistribution of fees. So let's assume that my thesis around MeV is just completely wrong and that the roll ups will want to tap into the MEV. Well, espresso is building a system whereby you can identify where the MEV creation came from, which roll up within the shared sequencer and then rebate and kick back this value. So there's no loss for the constituent rollups to plug into a shared sequencer, because whatever value they create goes back to them."
    },
    {
        "speaker": "C",
        "text": "Justin, you said that the shared sequencer teams that are building in this space all more or less have had this, call it a eureka moment, discovering that perhaps the best way to achieve their goals is to go all the way down to the bottom of the stack and tap into Ethereum itself to achieve some of their goals. And it sounds like that's kind of consensus. You're nodding your head. And then you also invoked Eigen layer and restaking, because I think what this is doing is this is increasing the scope of the role of layer one validators. So no longer are Ethereum stakers doing the dumb staking and just proposing blocks. They are now also taking on additional computational requirements, additional responsibilities. How does this impact the role of a layer one staker, a layer one validator? We're increasing its duties by a lot, by a little bit. What else is being layered onto the responsibilities of a validator in order to achieve this?"
    },
    {
        "speaker": "B",
        "text": "Sounds like they become super validators."
    },
    {
        "speaker": "C",
        "text": "Yeah, well, to what degree? Like mini supervalidators or big super validators, I think, is the big question."
    },
    {
        "speaker": "A",
        "text": "Right? Fantastic question, but I just want to close off a previous topic around this roadmap and this intermediate step that Ryan put forward of decentralized sequences. So I used to think that the sequencing started with base sequencing at l one, and then we moved to centralized sequencing, and then we incrementally decentralized. So we go from centralized to Federated and then federated to decentralized. And then eventually we all do this little dance and we go back to base sequencing and go full circle. But what I think will happen, more likely than not now, is that we don't need this penultimate step. We don't need the decentralized sequencer. We can go directly to the base sequencer, which happens to also be decentralized sequencer. That's faster."
    },
    {
        "speaker": "B",
        "text": "Yeah, faster progress."
    },
    {
        "speaker": "A",
        "text": "Yeah, we're going faster. We're accelerating. Now, to answer your question around the requirements of a shared sequencer and of a preconfirmer, first of all, yes, I want to acknowledge the fact that you need to be sophisticated in order to provide shared sequencing and pre confirmations. At the very least, you need to have enough bandwidth to cover all the roll ups simultaneously. You need to have low latency, you need to have high uptime, you need to have high amounts of capital to provide a thousand eth of liquidity. You also need to protect yourself against Denali service attacks. So you need to shield your IP address and do whatever it takes for high uptime. Long story short, you need to be sophisticated. But the good news is going back to proposal builder separation. Like we have designs out there where we can have the best of both worlds. We can have validator running on the raspberry PI, delegate to some sophisticated sequencer, the heavy lifting so that we get the maximum efficiency of the market in terms of optimal sequencing, while retaining the decentralization of, of the validators. Now this goes back a little bit to what I was saying about execution tickets, this future upgrade. Right now, as a layer one proposer, you're doing two things. First of all, you're ensuring censorship resistance. You're making sure that transactions go on chain. And secondly, you're doing the sequencing part. And what execution tickets is all about is basically saying, hold on. It would actually be cleaner if the validators were only responsible for censorship resistance and didn't do the sequencing part. Instead, you just sell off, you auction off these sequencing slots to the broader market so that you don't even need to delegate. You have a direct access to the sequencing slot so that the validators don't have to touch it, and it's a much cleaner segregation of concerns."
    },
    {
        "speaker": "C",
        "text": "So, understanding the pattern of how Ethereum has developed, if this vision that you have for the future of Ethereum, the based shared sequencing, shared sequencing using the validators, happens, it's not going to happen all at once. There's going to be first one roll up starts to use, and then two roll ups, and then three roll ups over time. I think one of the reasons why I really like this idea is that it very much fits with mine and Ryan's very old idea of the protocol sync thesis, which is instead of building on proprietary private systems and solutions, we just find the most credibly neutral, most balanced, most decentralized solution and foundation to build on. And that really sounds like why so many of these shared sequencer teams have all kind of discovered to use like, oh, let's go use Ethereum, because that is the foundation, right? That's just skipping down to the bottom of the stack, the most decentralized part of the stack. So that makes sense to me. And over time, slowly more and more and more roll ups will start to tap into this power because of there are incentives. Maybe we can talk for a moment about what those incentives actually are. You talked about why rollups don't want to have a shared sequencer, mev protection. It's easier to bootstrap a layer two. It's just security training wheels. It's simple. I think that makes sense. In the beginning of all chains, all chains start centralized, end up decentralized. This is just what we've seen throughout all of the growth of chains in the crypto space. As roll ups get their multiprovers up and running, the super chain has multiple chains up and running. The conversation will start to turn. It's like, oh, now it's time to start to turn towards the decentralization of the sequencer. Talk about the incentives and why it makes more and more sense over time for many, many roll ups to start to use a decentralized sequencer. As time goes on, why do the benefits grow?"
    },
    {
        "speaker": "A",
        "text": "As you said, there's going to be this maturation process. We need the multiprovers, we need the encrypted mempools, we need the super transactions, super builder, super searcher, super wallet infrastructure to build out. We also need the MEV situation to be solved either with way better applications that reduce the MEV by an order of magnitude, or with this espresso idea of rebating back the MEV to the players at play. But once the timer is right, there's going to be a tipping point, as you said. And really the economic incentive goes back to what are the l two s selling? The l one is selling data availability. The l two s are selling execution, and they want to maximize the amount of execution that they sell. And in order to maximize that, you want to be tapping into a shared sequencer. Now here's the reason why. Let's say that for whatever reason, some roll up, roll up a arbitrum, because it starts with a, decides that they don't want to tap into the shared sequencer. But now what will happen is on Uniswap, Uniswap board, pick whatever sequencer can give you the best deal, and it will more likely than not happen to be this shared sequencer. When the user presses the buy button, there's going to be execution for all the roll ups that, number one, are part of the shared sequencer, and number two can provide some competitively priced liquidity. Even if arbitrum has reasonably competitive liquidity, it just won't get tapped into because it's not part of the synchronous zone. It's missing out on execution fees. The way that you maximize execution fees will be to tap into this sequencer."
    },
    {
        "speaker": "C",
        "text": "Also, just using my intuition to understand how these things have grown in Ethereum. I'm going to guess that the first chain or first handful of chains that adopt a shared sequencer paradigm, a shared sequencer platform, they will be giving up the most and capturing the least, because the incentives to join in the shared sequencer structure will be the smallest at the very beginning. But as more and more chains do grow into. I've used this metaphor to discuss the optimism super chain. For example, the peloton. What is the peloton? It's the very long line of bicyclists who are all racing together and joining in the peloton. You get to draft on others, you contribute to the draft. The peloton moves very quickly, and if you are a bicyclist, not in the peloton, you are just taking the headwinds by yourself. You don't get to draft on anyone. It's all up to you. The idea for the growth of the optimism super chain is that the optimism collective takes a 15% fee for being a part of the super chain. And really, the bull or bear case for optimism is that the value of being inside of the super chain is worth the trade off, worth the cost of the 15%. It sounds like we're actually applying that same sort of model to all of the roll ups using the same shared sequencer, where at the very beginning there are some high costs because the peloton's small, there's only a few chains that are drafting on each other. But as more and more chains all start to use the same shared sequencer, they all start to make trades with each other. The liquidity between each other grows. All of a sudden, something is going to invert, right where standing alone, standing up your own centralized chain that doesn't talk to the other chains, is going to be an insane thing to do. Why would you do that when you can just join in the peloton, join in the network effects, join in the open source growth of the layer two network effects. This is my intuition for how this grows. Will you check that understanding for me? Is that correct?"
    },
    {
        "speaker": "A",
        "text": "Yeah, I think so. Now, in terms of specific teams that are looking to do this, the most obvious one is taiko, where, like, from day one, they want to launch as a base roll up, and that's likely going to happen in 2024. Now, in the last few days, I've been trying to talk to various roll up teams, and I did manage to talk to scroll and arbitrum. Now scroll. I don't want to put words again in their mouth, but at least some significant subset of the researchers seem to be appreciating the value of base roll up, and this is something that they're seriously considering. Arbitrum is also very interesting because they're partnering with Espresso, and Espresso itself is very much interested in base sequencing. Now, one of the interesting dynamics that might happen is that there might be a coalition between the ZK rollups, because what we're seeing right now is that the ZK rollups are losing. In terms of TVL, you have arbitrum and optimism that are winning. Really, you need to ask yourself, what is the superpower? What is the value proposition of ZK rollup? Really, it's all about fast settlement, because you can have a snark come in extremely quickly as opposed to having to wait the seven days. Now, if we go back to the middle of our conversation, where we're talking about the ingredients required for universal synchronous composability, we need two of them. We need the shared sequencer, but we also need the instance settlement. And the very first roll ups that will achieve this instance settlements are going to be the ZK rollups. By necessity, you can't have an optimistic roll up. So what I think might happen is that the ZK roll ups all come together and say, hey, we're going to do a coalition because we're losing right now on TVL, and this is our only way to win out. And it's possible that the optimistic roll ups will come in from day one. It's possible that they'll be forced because of market pressures to join. And eventually, I don't really know how the future will play out. There's also a possible future where the layer one just doesn't win out as a shared sequence. So I do want to acknowledge that. But I think even if that's the case, there will be some sort of winner take most shared sequencer. That happens at layer two, and it's going to be a very fascinating space to see evolve. One of the really promising things is that the major roll up ecosystems to date don't seem to indicate that they want to compete on sequencing. So let's take arbitrum orbit, for example. Arbitrum orbit is like a 10% fee that you have to pay to use the code. It's a licensing fee. Right. And that has nothing to do with sequencing. It's a code fee. If you look at optimism, base is paying, I believe, a 15% fee to join the law of chains. And what is the law of chains? It's basically plugging into their governance. And again, governance has nothing to do with sequencing. So that's very, very promising. And then if you look at the all the other Rolex ecosystems, I havent seen one of them yet that has really strongly suggested that they want to charge a fee, maybe to have people join their shared sequencer. I think were moving in the right direction. Theres a lot of education to be done and I think market forces will play out. My role in 2024 will be to explore the design space as thoroughly as I can and provide some amount of guidance, I guess, and research material for whoever wants to go build shared sequences."
    },
    {
        "speaker": "B",
        "text": "In that I heard Justin Drake just giving a call out to all of the roll up communities, anybody who's interested in this space, to reach out to him for ideas and for coordination there. As we start to draw this to a close, just some questions. One is with respect to the timeline and roadmap, you talked about shared sequencing, that's going to happen this year. I want to be clear about the next level of shared sequencing, which you've called based sequencing, which is just using the Ethereum layer one and the validator set from Ethereum layer one to basically provide the shared sequencing as well. You said that that second part does not require an Ethereum hard fork, which is fantastic news. But also it seems that it would increase the requirements on validators. And I know you mentioned proposer builder separation like PBS, and that hasn't been deployed yet. So are there still things that are required in order to fully realize the based roll up dream here? What is the timeline or rough roadmap for that?"
    },
    {
        "speaker": "A",
        "text": "If so, right today on Mainnet we do have a form of off chain PBS called Mavboost. It's not a fully trustless PBS because you have to trust the relays, but it is a form of pes nonetheless. So as a validator, I don't have to trust the builder, I only have to trust the relay. Now this is an interesting point. The relays can actually start playing an accelerationist role for preconfirmations. One of the major technical change that needs to happen is for whoever's doing the preconfirmations to communicate to the builders the pre confirmations that have happened so far, that the builders can go build blocks that respect those preconfirmations. So the way that you can think of preconfirmations is putting a constraint on the top of block or the top of blobs. Right. So roll ups consume blobs and then the very first transactions go at the top of the blob and if you're synchronously composing with the l one, you're going to be consuming the top of the l one block. Really what we want to be doing is for the shared sequencer and preconfirmer to communicate all these constraints to the builders and for the builders to create the best block. Now one of the interesting economic points here is, you might ask, hold on, if I have all these constraints on block building, the builders are going to be building a suboptimal block, one that doesn't extract the most amount of value. The validators will be disincentivized to provide pre confirmations because it reduces the amount of MEV. But actually what we can do is we can price preconfirmations appropriately. So when a user asks for a preconfirmation, there's a corresponding preconfirmation tip. You can think of it like the inclusion tip. It's a value that gets paid to the validator. Now economically speaking, what is a preconfirmation? It's a future on block space execution. It's a future on execution. And so if, for example, a uniswap trade were to decrease the expected amount of MEV at the end of the slot for the validator, then that needs to be compensated for via the pre confirmation tip and vice versa. If a user is making a transaction which increases the arbitrage opportunity because they're buying against the market, then ironically the user can expect to be paid. It can expect a negative pre confirmation tip from the validator because now the validator is incentivized to pre confirm because they have more mev at the end of their slot. So one of the other interesting things is that the pre confirmer needs to be savvy from a market perspective. They need to be aware of the various defi markets and they need to be able to price these futures properly. And this is where again, the relays can come in because they're sophisticated, or the builders can come in, or some sophisticated entity can help out."
    },
    {
        "speaker": "B",
        "text": "Justin, one thing I want to clarify is you said somewhere in the last few minutes of conversation that it could be the case that based roll ups, that is using Ethereum, shared sequencing doesn't actually take off. That's not the market equilibrium. The market goes and just does regular non based rollups, or non using Ethereum as a shared sequencer and solves it that way. But from the articulation, I know that you're more hopeful of the base roll up type of future, but to me it doesn't make sense why that wouldn't happen. But what are some reasons why base roll ups might not work out? Maybe we just stop before we start using Ethereum l one for shared sequencing. Why would that happen?"
    },
    {
        "speaker": "A",
        "text": "I would say that I have something like 80% confidence that base sequencing will win out, but I do want to leave the possibility that I'm wrong, especially that it's so early days. One of the very interesting points that was brought up by the arbitrum team on their call was that they have very fancy strategies to compress data. And one of the things that they do, which I didn't realize is that they have this machine learning algorithm which watches the change of base fee. And then whenever the machine learning algorithm believes that the base fee is very, very high, it will just forego, it will just wait. It just won't settle immediately. It will wait a few slots for the gas price to go back down, and that allows users to enjoy lower fees on arbitrum. It turns out that this little technical detail is somewhat incompatible with base sequencing. I want to go talk to all these teams, and I want to collect all these little nitty gritty technical details and try and see what we can do and try and understand them better. But, you know, macro picture like, I am very bullish. I mean, one of the things that's surprising is that we can, we always find improvements. Like if you had asked me, you know, two years ago, is the ethereum, you know, roadmap complete? And I would have said, yes, you know, that's the best that we know. But it turns out that we constantly make improvements. Yes, it is. As a snapshot of 2024, this is the best we can even imagine. But who knows over the next half decade, decade, if we're going to find more crazy things. One of the things, for example, that I only realized a few months ago, which completely blew my mind, is this cryptographic primitive called one shot signatures. It's a signature scheme where the private key can only be used once, so you can only sign a message once, and then it destroys itself. And it turns out that this is just impossible with classical cryptography because you can always copy the private key. But if you kind of expand your model a little bit, if you use quantum mechanics, and your private key is a quantum superposition that destroys itself as soon as you observe it, then now suddenly you can have one shot signatures. And it turns out that one shot signatures completely transform the end game of consensus. And that's for completely different episodes. But just to point out that the crazy Sci-Fi crypto economics just keeps on giving, and it's very difficult to know when it will stop."
    },
    {
        "speaker": "C",
        "text": "Ryan asked if this shared sequencing using layer one validators, if that gets us to universal synchronous composability, it doesn't get us all the way there at Genesis. Correct. It provides the foundation for it. And then there's a bunch of private market aftermarket innovations that also needs to develop in order to get us the rest of the way. Shared sequencing gets us the foundation, the clay, for the rest of the market to take it the rest of the way. Is that correct?"
    },
    {
        "speaker": "A",
        "text": "Yes, that's correct. One of the things that we've observed is that sophisticated entities like searchers and builders are very, very good at their job. Actually, their livelihood depends on it. And the reason is that it's this cutthroat market where only the most efficient survive. If you're not squeezing every little drop of mev and value and optimal sequencing, then you lose out. The great thing is that base sequencing is actually the simplest form of sequencing. It's the one where you have to do nothing. You're reusing existing infrastructure and you just let the market do its thing. And it's actually in some sense simpler than centralized sequencing. Because centralized sequencing, first of all, you have to do the DevOps to maintain the centralized sequencer. And these roll up teams, they're not DevOps experts, and their shared sequences accidentally go down and things like that. But also just from a smart contract perspective, the smart contract has to verify the signature coming from, from the centralized sequencer. Whereas base sequencing is literally like anyone can just build a block. It's in some sense a zero line of code sequencing mechanism."
    },
    {
        "speaker": "B",
        "text": "And so if we had these fault lines, this fragmentation, this fracturing that we started the episode with, what you're describing is how ethereum heals itself, and it's kind of a self healing. And I think what you're saying, Justin, is that is starting now, right? That is basically this year that process is starting. I don't know if you can predict how long it will take to have, say, universal synchronous composability across 70% of the super transactions that we're doing. Is that going to play out over a decade? Are we talking about months and years here? Are we talking about one to three year timeline? And we have, for all intents and purposes, pretty much universal synchronous composability for the majority of the Ethereum economy, right?"
    },
    {
        "speaker": "A",
        "text": "I would say not decades, not months, but something like yours, like one, two, three years does sound correct. We do have a lot on our plate. We have to solve security of rollups. We need these multiprovers. We need to solve mev, we need encrypted mempools. We need to solve real time settlements, which means real time proving, which means better proof systems. We even need hardware acceleration of these provers. We need better applications that don't leak so much mev to the sequencer. There's going to be a lot going on. We're talking at least one year, likely two years, three years until we get to this full vision. But the Ethereum community, I think, has several qualities. One of them is that we don't want to take shortcuts. Another one of them is that we're patient. If we can set this North Star and just work towards this as a community, I think is going to be extremely rewarding. And going back to the narratives and the mimetics and the culture, having this shared sense of mission and this shared vision, I think will help heal some of the strifes that we've seen at the social layer."
    },
    {
        "speaker": "C",
        "text": "Well, it sounds like a decently ambitious roadmap, which is nothing that we've ever seen before in Ethereum. We've never seen an ambitious roadmap before. We've never come across anything like this. We don't know how to do that. Justin, you talked about all of the different components that need to come together, both just in the roll up stack. But then even post universal shared composability, a lot of these things are already being built in parallel. There's one question I want to ask you is what accessory technologies will help once we have the shared sequencing base? What accessory technologies comes after to help compose all the layer twos? And these are probably, I'm guessing, technologies like intents restaking from Eigen layer bridges, like across. There's a bunch of projects that already exist, already have some of the solutions, they just never had the base to be built on. And so, even though it seems like a decently ambitious roadmap, again, nothing we've ever not seen before in Ethereum, it also seems a lot of these solutions have already been being built in Ethereum over the last few years. So what are those accessory technologies that will help with universal shared composability? What else is being built in parallel here?"
    },
    {
        "speaker": "A",
        "text": "Right? So a big one, as you said, is intents and account abstraction and order flow auctions. These are all related concepts. These are user facing tools to express yourself. It's possible that actually they won't be completely user facing in the sense that my personal belief is that the user needs to almost not think about the intent. The intent needs to be implicit. And oftentimes there's this kind of disadvantageous master intent, which is just give me the best execution, give me the best deal out there. I think what we're going to start seeing, for example, is wallets, maybe like metamask, that are going to have two buttons. Button number one is do this transaction as requested by the user. Then button number two is get to the same goal, basically try and understand what the intent of the user is with that transaction and give me an extra $100 because the searchers were really good at squeezing the best opportunity and crafting a better transaction than what you could have crafted on your own. And once we have basically wallets integrating with these intents and these order flow auctions, just because of the incentives you'll get paid to transact on ethereum in some sense. Another thing that we need is additional slashing conditions on validators, and that's very much related to, to eigen layer and restaking. Now, for example, espresso. One of the things that they're doing is they want to increase the economic security of the pre conformation to millions of eth. And in order to do that, they use restaking. So they have these. Each 32 e validator can provide individual collateral at stake. One of the things that I do want to highlight is that 32 ETH is probably insufficient for the one layer, one proposer who's acting as the shared sequencer for that 12 seconds. I think we want something closer to 1000. If the reason is that you need to think about the incentive for the sequencer to renege on all their promises. If a sequencer reneges on all their promises, they have the full freedom to build whatever block they want. They're now suddenly unconstrained. And then you can ask yourself, okay, what is the value of building an unconstrained block? And that's basically the amount of MEv that you can grab in any given slot. And historically speaking, we haven't had more than 1000 eth of mev in any given slot. So if you collateralize with 1000 eth, you'll never have an incentive, or only in extreme situations, you'll have the incentive to renege on your preconfirmations. And then I think the last piece of the puzzle is this really hard core engineering around recursive proofs and folding and accelerating algorithms like fast Fourier transforms and msms like multiscatter multiplications, and then programming really advanced hardware like FPGA's and GPU's, and even building your own ASIC in order to get to this real time settlement. And there's a lot of teams out there that are looking to do this. Actually, this is a topic that I was very much interested in. In the ecosystem, there's about ten different companies that are trying to achieve this acceleration. Previously, I used to think that the main value of doing hardware acceleration is that you can have proving at home, so you can have decentralized proving. You don't need a data center in order to become a prover. But now I've changed a little bit. There's actually two value propositions to these ASics. One is decentralization, of course, but the other one is low latency proving."
    },
    {
        "speaker": "B",
        "text": "Justin, this has been a fantastic conversation, and once again, you've kind of given us a world class education. And I gotta say, for folks who haven't listened to previous Justin Drake podcasts, and particularly on bankless, this man's predictions tend to come true and tend to become reality. And his hasn't missed, not yet. And as we've heard throughout this conversation, one phrase I'm reminded of, we got an entire ecosystem working on this solution. Don't bet against Ethereum. I don't think that Bet has ever worked out for anyone who says that Ethereum can't fix its fragmentation because XYZ. All right, I wouldn't bet against that. As we draw this to a close, maybe Justin, my last question is around this. So much of the bankless podcast has been trying to figure out what block space actually is, certainly what crypto assets are, but also what block space itself is. And I've seen this evolution of what Ethereum block space on the layer one actually does and what it contains. And again, this is like when you boil it all down to what is crypto creating? It's creating a new digital commodity called block space. And we've done tons of episodes on this, but now the evolution of Ethereum block space, it sounds like we've certainly talked about it moving to settlement and data availability for chains, and now it's unleashed maybe a new role. What you're talking about here, which is also sequencing for chains, and I suppose that is the function of layer one block space. We could talk about in the full vision of everything you laid out. We've talked about what users get out of it, how builders and searchers evolve, how validators evolve, and how rollups evolve and change. But what about block space? Ethereum block space does it become settlement. And da, does it become sequencing for all of the chains? Is that its role as a commodity?"
    },
    {
        "speaker": "A",
        "text": "Right. So I think what you're pointing out to is that block space is a. Is a complex thing which has multiple constituent components to it. One of them is data availability, another one is settlement, another one is sequencing, and yet another one is execution. And I think one of the nice things about the modular thesis is that we can try and tackle each one of them individually and really optimize for each. Now one of the advantages of the monolithic thesis is that all of these are under one shared umbrella. And the nice thing about Ethereum is that we can start tapping into both of these. And maybe one word that you could say unites both is the integrated thesis. We have modular components, but they're all integrated under one umbrella. Now one of the interesting things is can you start providing shared sequencing without necessarily sharing the data availability layer? And I think the answer is yes, but it's not as clean, necessarily. So, for example, what you can start doing is having validiums and optiniums start plugging in to this shared sequencer. But now you start entering edge cases. What if one chain reverts but not the other? This brings us to the concept of shared security. There's this very nice thing that when you're under one umbrella, you're sharing security. It's not like you have multiple modules. And your net security is the security of the weakest link. I think one of the value propositions of Ethereum is that it gives you the option to minimize your security assumptions. Security assumptions are a bad thing. You don't want to have too many of them. The more you buy into security assumptions, the more brittle your system becomes. And one of the things that I'm hopeful of is that the real bottleneck, fundamentally for scalability, is data availability. I'm hopeful that this will largely go away as a bottleneck. I'm hopeful that eventually Ethereum can be the data availability for the whole world. And the way that I think about it here is in terms of going beyond full dank, sharding fault. Sharding somehow presupposes that we've reached the end game. It's folding sharding. But actually what we're having is we have a law called Nielsen's law, which basically says that the amount of bandwidth grows 50% per year. And there's good reasons to believe that Nielsen's law will continue for a long time, at least a decade, maybe several decades. And part of the reason is that bandwidth is this embarrassingly parallel thing. You can just send more photons through, just have more fiber optic cables. It turns out that a single fiber optic cable can have an insane amount of information pass through it. So you don't even need that. But the point that I'm trying to make here is that with clever engineering, a lot of the bottlenecks that we're suffering today, things like disk IO on geth, things like state bloat, things like verification of execution, all of these things go away. And you're kind of left with the one fundamental bottleneck, which is bandwidth. When you combine dank sharding with Nielsen's law, that compounds. Over ten years, we're in a position. We'll be in a position where we can do 10 million transactions per second on Ethereum. It sounds insane, but this is where we're heading. 10 million transactions per second, and that's enough for every single person on earth to do 100 transactions per day. In my opinion, that's enough. We'll be in a position where I. The whole Internet of value can be in one place with shared security. Under the hood, there's these modules, but these are integrated modules, and we only buy into one security assumption, which is that Ethereum is secure. And this brings us to trying to grow the economic security of Ethereum. Right now, we are at $70 billion, which is extremely good. It's 29 million eth times the price of Ethan. But I'm hopeful that we'll get to a trillion dollar of economic security, or even trillions of dollars, at which point we'll have unquestionable security, even against nation states. And we'll be in a position where the Internet of value is unquestionably secure, and it's just unquestionably the place where everything happens."
    },
    {
        "speaker": "B",
        "text": "Well, what a fantastic vision, Justin. Thank you for guiding us through it. I can tell you, once we have shared sequencing on Ethereum, its base level, I can't wait to start calling it super block space on Ethereum because it will be deserving of its prefix. Justin, thank you so much for superblocks. Thank you so much for guiding us through this conversation today. It's been fantastic."
    },
    {
        "speaker": "A",
        "text": "Thanks, guys."
    },
    {
        "speaker": "B",
        "text": "Thankless nation. We have some Justin Drake episodes from the archives in the show notes. Go check them out if you haven't already. Also got to end with this. Of course. Crypto is risky. You could lose what you put in. But we are headed west. It's the frontier. It's not for everyone. But we're glad you're with us. On the bankless journey. Thanks a lot."
    }
]