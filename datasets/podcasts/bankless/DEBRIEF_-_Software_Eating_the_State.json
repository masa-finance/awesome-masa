[
    {
        "speaker": "A",
        "text": "Hey, guys. Welcome to the debrief. So this is our episode after the episode with Sam Hammond. We're going to try to fit this in 20 minutes or less. We'll see if we can. David, you just got back from a very long trip. You were over in Europe, man. You just flew in."
    },
    {
        "speaker": "B",
        "text": "I got back from a flight and aped into a podcast faster than that."
    },
    {
        "speaker": "A",
        "text": "Yeah. So, basically, like, ten or 15 minutes before we hit record, we started looking at the agenda for the first time and, like, talking about this episode, working."
    },
    {
        "speaker": "B",
        "text": "On their agenda, and reviewing material on the flight. Took a flight from New Jersey to or took a car from New Jersey to Brooklyn. Sat down 13 minutes ahead of recording time. Like, oh, what's up, Brian? How's it going?"
    },
    {
        "speaker": "A",
        "text": "Are you tired, man? Like, how long. How long you been going?"
    },
    {
        "speaker": "B",
        "text": "I mean, I was in Lisbon, so it's only 4 hours ahead, but it's after. It's after being at Solana breakpoint and then Eth Lisbon and then the fabric event, and so it's. Yeah, every time I'm out and about, I'm always, like, holding my breath."
    },
    {
        "speaker": "A",
        "text": "The bankless nation thanks you for doing this podcast. So let's talk about it. So this was one I wanted to set up because I'd been exposed to."
    },
    {
        "speaker": "B",
        "text": "Sam's writing Ryan episode."
    },
    {
        "speaker": "A",
        "text": "I read that three part piece, but actually, it's a Ryan episode. But I was also thinking about David."
    },
    {
        "speaker": "B",
        "text": "Oh, yeah, for sure. It's also David. I mean, because this is, like, Ryan instigated. David enjoyed."
    },
    {
        "speaker": "A",
        "text": "I was like, David. They're talking about the Leviathan. Sam is talking about the Leviathan here."
    },
    {
        "speaker": "B",
        "text": "I'm a big Leviathan guy."
    },
    {
        "speaker": "A",
        "text": "You are a big leviathan guy. Everyone knows that. David's a Leviathan guy. He wrote an episode on. I think you call it the crypto Leviathan."
    },
    {
        "speaker": "B",
        "text": "The crypto Leviathan. I forgot that."
    },
    {
        "speaker": "A",
        "text": "Not an episode. It was a. It was a blog post. Crypto. I'm trying to google this crypto Leviathan. David Hoffman. Let's see what comes up here."
    },
    {
        "speaker": "B",
        "text": "Digital Leviathan. Digital Leviathan. That's a really important article. September 2020."
    },
    {
        "speaker": "A",
        "text": "It was three years ago now. Wow."
    },
    {
        "speaker": "B",
        "text": "Wow."
    },
    {
        "speaker": "A",
        "text": "And that's basically this idea of kind of the network state before Balaji called it a network state. The idea that the Leviathan is this hobbesian idea that we have to give this monster, this kind of creature, the monopoly of violence so that it can help humans better coordinate."
    },
    {
        "speaker": "B",
        "text": "That monster, by the way, is the state."
    },
    {
        "speaker": "A",
        "text": "Yes."
    },
    {
        "speaker": "B",
        "text": "You cede control over the monopoly of violence to a select few to make sure that your neighbor doesn't have violence over you."
    },
    {
        "speaker": "A",
        "text": "Yeah. If I recall, your point in this article is, well, we might need to do less of that if we cede some of this power to protocols that are nonviolent by nature. So maybe we can give some of this power to our money systems like ethereum and bitcoin and property rights systems, and then we won't have to use as much violence. That's the basic idea here."
    },
    {
        "speaker": "B",
        "text": "Yeah. So, Thomas Hobbes, Leviathan. There's this picture of this big man, face of a man, but the body, which is human shaped, but made up of many, many thousands of humans. So humans coalesce, congregate together into governance structure. And then this man is holding this flaming torch, which is supposed to represent governance, and then a sword in the hand, and the sword is the monopoly on violence. And so all the humans come together into this one head, and the head has the sword, this head has the monopoly on violence. And the big claim of the digital leviathan is that bitcoin and ethereum don't need swords. They don't need the carrot. They don't need the stick. They only need the carrot. And so, therefore, if you unbundle certain roles of the nation state, mainly property rights and money, and give them to these digital protocols, then the power of this sword of the old nation states just becomes a lot weaker because some of the forces that come to create the nation state Leviathan are just pulled and unbundled and kind of like stolen by ethereum and bitcoin. And crypto protocols is the thing."
    },
    {
        "speaker": "A",
        "text": "Yeah, exactly. If you think of it as, like, bitcoin and ethereum's military is basically its miners and validators, which is kind of a nonviolent force, and yet it secures how many hundreds of billions of value? That's quite an accomplishment. Not enough getting into the trillions, but that's quite an accomplishment. I mean, there had been previously, to my knowledge, no way of doing that without some sort of monopoly on violence. And yet now we're accomplishing it, so. What a marvel. Anyway, that's why you're a big leviathan guy."
    },
    {
        "speaker": "B",
        "text": "All of that was a big crypto guy. Like, it is actually one of the big motivations, like why we're in this whole crypto thing to begin with."
    },
    {
        "speaker": "A",
        "text": "Yeah, totally. Okay, so now connect that article to this episode, then. So Sam is, I would say, definitely a crypto proponent, but that's not his field."
    },
    {
        "speaker": "B",
        "text": "It's not his shtick."
    },
    {
        "speaker": "A",
        "text": "Yeah, his schtick. His area is political science. He's an economist by training and very much he works at this think tank promoting basically AI AI policy and kind of AI thought so. But the reason I think that's so interesting is because the things that AI is going to with respect to its battles with the nation state, it's a very similar path and track through which crypto is going to. And I just see such similarities. Basically, you have these nation state governments. They don't get it. They're unable to respond. They're all in their seventies and eighties. They don't know what we're like. They don't know what we're talking about. How can they move fast enough? We're entering this exponential age wherever crypto is changing so fast, AI is changing so fast, and they're trying to regulate this thing. And by the way, they're also trying to grasp onto the vestiges of their power and the nation states power itself. And so what happens when these forces collide? I think that that's really the genesis for this conversation, why it was so interesting to me."
    },
    {
        "speaker": "B",
        "text": "Yeah, yeah. I think crypto and AI, I'm saying, just more and more symbiotic with each other, where ethereum, bitcoin, they unbundle money and property rights from the nation state. But Sam was talking about, well, we put cameras out in farms, and we can undo, like, the FDA or whatever organization that was. Right. And so with AI, AI does most of the rest of the unbundling, if not all of it. So you pair these things together, the value side from crypto and the information side with AI, and then all of a sudden, like, you have the tools, the platform for an unbundled nation state. And I'm a big anti state guy in a sense, in which, like, I kind of think that our states are too big, that I kind of think they're misaligned with the humans. I would like to make them smaller, and that's why I'm in crypto. But I will never, I'd never have thought about the concept of going so far that, like, they get deleted. I don't know if I'm that anti state. Like, I do enjoy my roads and my police and people."
    },
    {
        "speaker": "A",
        "text": "I certainly enjoy those things. And I think in a vacuum, what we get is a lot of chaos that is just, you know, undesirable and not kind of world that anybody wants to sort of live in. And maybe that's another topic I want to get to in just a minute. But, yeah, I do think that when he was describing Estonia as kind of like a software stack. And like a post Internet received its post Internet upgrade in kind of the nineties. What I was thinking with is basically with crypto, a nation state gets a banking and money system out of the box. They could issue their digital currency on something like Ethereum, but then they have digital property rights attached to it, and they have all of the value of what we build in the banking system of Defi. That has to be part of an Internet first, a post Internet nations operating system. It's all going to be based on crypto. And what are the AI's going to be using, the AI agents and bots and all of these things. I mean, it seems obvious it's going to be some form of programmable money. Where's that programmable money going to come from? I mean, do you see any nation state building such a system? Because it's got to be open source, it's got to be Internet native, it's got to be permissionless, it's got to be decentralized. The nation's not going to pull that off. So it's obviously going to, crypto is obviously going to be a fundamental part of the stack. But I want to ask you, because I think some people will have listened to that podcast, particularly near the end, and be left with this. Maybe they're not quite a libertarian bent. Be like, oh, that sounds like techno libertarian fantasies. The governments are going to slow it down. You know, it's not going to be peaceful. It's going to be like just violent mobs and roving marauders and mafias and that kind of thing. It's going to be very undesirable and oh great, it's another techno libertarian fantasy. And I hate it. I hate it. Like I listening to it, I hate it. What's your reaction to that? Do you think there's an element to that with what Sam is saying here?"
    },
    {
        "speaker": "B",
        "text": "Yeah, if I think I'm interpreting Sam correctly and also my own interpretations of how this works, is that like, that's what he was talking about in very briefly and what I was trying to get out of him and he didn't take the bait of like the first order and second order consequences of AI and this stuff. First order is like the liaison consequence where it's like AI comes and kills us. So ignoring that they have the second order consequence where if AI doesn't kill us and it is capable and in our hands and functional, well, then society has to adapt to that. And that has costs and frictions and winners and losers and there's this transition period. And I think if I'm putting on my Sam hat, if I'm interpreting him correctly, in the fullness of time, AI unbundling the nation state is great. We get the trustless state that we want, but there's the gap that we have to cross. The chasm that we have to cross, where that's. There's chaos. There are people, like, operating inside of that chaos. Some of these people are highwaymen who will rob you, et cetera, et cetera. But I think it's like a big Winston Churchill, if you find yourself going through hell, keep going kind of thing, which doesn't make me feel good, but nonetheless, that's how I perceive it."
    },
    {
        "speaker": "A",
        "text": "Well, it's kind of interesting when you ask him a question of, does this make you optimistic? And he said something like, wow, this makes me benevolent, but never, I'm ambivalent. Right? Like, I just, like, it's gonna happen anyway."
    },
    {
        "speaker": "B",
        "text": "Yeah, that doesn't make me feel good."
    },
    {
        "speaker": "A",
        "text": "I mean, but is it sensible? I feel like that's a sensible. Like, we can't stop this train, apparently. So we're on this train, so we may as well make the best of it. It's dark, dude."
    },
    {
        "speaker": "B",
        "text": "It's not."
    },
    {
        "speaker": "A",
        "text": "It's dark, but like. But okay, so, you know, the problem is, I think the. The period of chaos, like at post printing press, for example, the problem is that can last a long time. I mean, that can last dark ages, can last generations. Do you know what I mean? It could be decades of chaos before we find this new reset equilibrium. Or the chaos could be particularly bleak and dark before we reset to this better mode and figure it out."
    },
    {
        "speaker": "B",
        "text": "I think it's going to be chaos for some, maybe perhaps larger portion of the population, and then other people who are able to take advantage of that wave position themselves appropriately, which is why we're doing this podcast, because we're trying to further on the opportunity."
    },
    {
        "speaker": "A",
        "text": "Yeah, I think that's true. At least now you know that this is the type of transformation that's coming. This could be happening. What's your take on the timeline?"
    },
    {
        "speaker": "B",
        "text": "So fuck right now, dude. I don't know."
    },
    {
        "speaker": "A",
        "text": "I think it's aggressive."
    },
    {
        "speaker": "B",
        "text": "2040. What year is it? 2023. And he thinks we become a failed state by the 2045. Well, I think it's a statement of just like, AI is going to go really fast. Yeah, I think, like, you get more phenomenons like Uber, where they like, flip taxi to Uber inside of five years. I think he said he thinks that we get like 30 of those things in the next 20 years."
    },
    {
        "speaker": "A",
        "text": "I think there's a world where he's right, but I don't think that is my personal thought. What do I know about it? But there's a world. He's right. I don't think that's the world we live in. That's a world where there's no breaks, right? That's a world where just, just humanity, innovation, just like, goes on a course. Like we're already seeing regulators in nation states slow things down. They're going to have something to say. The value leaves labor and goes back to capitalism. Well, that's going to cause a lot of societal unrest, you know what I mean? And then people are going to have things to say about that. They're not going to look as fondly on the big AI tech entrepreneurs who are the, like, uber wealthy and leaving everyone behind. So I think in a vacuum, it could happen as fast as he says. I just think practically probably won't. But what do I know? Maybe it does actually happen. But there's an element of, I feel like he is so much an AI, he probably very much sees that inevitability and maybe thinks it's kind of like, you know, bitcoin. Bitcoin to a million people from like 2013. And by 2020 it'll be a million. Do you know what I mean? Like they're, they think it'll happen sooner than it'll happen, but it doesn't mean the destiny is wrong. It just means the timeline. Right, me, right."
    },
    {
        "speaker": "B",
        "text": "If he says it's by 2040 and it happens by like 2050, is he really wrong?"
    },
    {
        "speaker": "A",
        "text": "I think it could be like, you know, after our lifetime. I'm just saying I think people have to."
    },
    {
        "speaker": "B",
        "text": "I don't know about that."
    },
    {
        "speaker": "A",
        "text": "I don't know. I think generations will have to die to progress things forward. It's going to be hard."
    },
    {
        "speaker": "B",
        "text": "I think you're underestimating from Sam's perspective how powerful AI will be. I think I have an assumption of super intelligent AI doing the whole thing."
    },
    {
        "speaker": "A",
        "text": "He said by, we have the first version of that that is basically human identical in terms of capacity by 2030. David, that's real soon, man."
    },
    {
        "speaker": "B",
        "text": "Seven years. That's so long."
    },
    {
        "speaker": "A",
        "text": "You think that's long?"
    },
    {
        "speaker": "B",
        "text": "Yeah."
    },
    {
        "speaker": "A",
        "text": "Here's a fact for you. Do you know Chad GPT is less than one year old?"
    },
    {
        "speaker": "B",
        "text": "It came out the phenomenon."
    },
    {
        "speaker": "A",
        "text": "Yeah, but also Chad is super old."
    },
    {
        "speaker": "B",
        "text": "We just got the sticker shock of it from getting introduced into society after it had actually been developed for like multiple generations."
    },
    {
        "speaker": "A",
        "text": "Yeah."
    },
    {
        "speaker": "B",
        "text": "We came in at chat GPT-3 one and two, we never saw. And then we were like, chat. GPT-3 whoa. This is phenomenal."
    },
    {
        "speaker": "A",
        "text": "I know, I know. It's just at the time it's gonna kill us. It feels like it has impacted society so much, and it's been out less than a year at the time of recording, which is absolutely incredible. So, yeah, maybe you guys are right. By the way, where do you sit on the effective accelerationism? Marc Andreessen, techno optimism."
    },
    {
        "speaker": "B",
        "text": "What's the other side? What's the other side of the spectrum?"
    },
    {
        "speaker": "A",
        "text": "I think it's probably Eliezer Yudkowski is be careful. Techno doomerism. I think that would be probably the opposite. It's just slow down. This stuff isn't good. It could go bad. So just slow down. Stop creating so many gpu clusters. Think before you do it. What's your take on this?"
    },
    {
        "speaker": "B",
        "text": "Yeah, I think that question is, if you imagine society as a line of technical progress, Eliezer is like, yo, if you go too fast, if the line moves too fast forward, you blow up. So careful. And then also, the faster that line that moves forward, the better quality of life there is for everyone. Like, better conditions of living, better prosperity and abundance there is. So we do want the line to move fast, but it's like a speeding ticket, right? Like, if you go too fast, you die, you blow up. And then Mark Andreessen and Sam are probably just like, there's never been a case in history in which going faster wasn't better, and so we should go faster. And I'm, I think I resonate with the Mark Andreessen side of things, but also, at the same time, I will take the yo AI itself is an extenuating circumstance, and it's unprecedented."
    },
    {
        "speaker": "A",
        "text": "So, I don't know, special things. That's one of those special things we keep an eye on."
    },
    {
        "speaker": "B",
        "text": "Yeah. So, like, if there's ever going to be a moment to not juice the engine, it might be AI."
    },
    {
        "speaker": "A",
        "text": "Yeah, well, here's the one. A difference, right, when we talked about between AI and crypto, that I, I was thinking while he was talking about it, when we talked about the, the Biden executive order that basically says if you got a data model, come in and register."
    },
    {
        "speaker": "B",
        "text": "Scary words. Executive order."
    },
    {
        "speaker": "A",
        "text": "If you got open source, we need it permissioned. If you've got compute locations, disclose where they are. We need to know where your gpu's are. If you got foreign persons, we need AML Kyc. I hear all of that and I'm like, oh, that's, that's crypto. And yet the difference between AI and crypto is, like, AI could potentially be dangerous, right? Crypto is not dangerous. Like, if crypto is dangerous to your regime, then encryption technology, that means you have an authoritarian regime. That means you are probably cheating your citizens out of their savings and their money. If you are threatened by a encryption technology that delivers power to the people."
    },
    {
        "speaker": "B",
        "text": "Yeah, that's on you."
    },
    {
        "speaker": "A",
        "text": "That's on you. You got the problem. And so that is a total difference between AI and crypto that I, you know, I don't think it makes sense to kind of group them the same. We don't have existential risk with respect to crypto. The us dollar could decline like, it could. But is that going to end all of humanity? Is this power to the people? It's a very, very different technology from that. From a safety perspective."
    },
    {
        "speaker": "B",
        "text": "Yeah, no, I agree with that for sure."
    },
    {
        "speaker": "A",
        "text": "I thought you would. Well, we're coming close on our 20 minutes. David, is there anything else to talk about?"
    },
    {
        "speaker": "B",
        "text": "No, I'm good."
    },
    {
        "speaker": "A",
        "text": "Guys, thanks for joining us. This has been the debrief."
    }
]