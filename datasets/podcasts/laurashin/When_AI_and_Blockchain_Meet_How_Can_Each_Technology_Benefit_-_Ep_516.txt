Speaker A: Hey unchained listeners, as you know, its hard keeping up with the fast paced world of crypto, so weve got just the thing for you. Subscribe to our free unchained daily newsletter at unchainedcrypto dot substack.com. youll get the latest crypto news in original articles from our reporters, as well as summaries of other happenings in bullet points, plus our meme of the day, all curated and written by our amazing team. Its still your no hype resource for all things crypto, just in newsletter form. Sign up at unchainedcrypto dot substack.com. again, the URL is unchainedcrypto dot substack.com dot. Hi everyone, welcome to Unchained, your no hype resource for all things crypto. I'm your host, Laura Shin, author of the Cryptopians. I started covering crypto eight years ago and as the senior editor at Forbes, was the first mainstream media reporter to cover cryptocurrency of all time. This is the July 11, 2023 episode of Unchained. Asia is buzzing, and everyone's going to token 2049 Singapore on September 13 to 14th. Apologies. Renewsen, Mike Novogratz, Arthur Hayes and 200 others will hit the stage, joining over 10,000 attendees. Visit token 20449.com for 65% off with the code unchained link in the description. You know it, we know it, they know it. The system doesn't just need an update, it needs a complete rewrite. Web three offers that rewrite. It allows us to take control back and to truly own what's ours. Visit okex.com rewritethesystem to learn how Arbitrum's leading layer, two scaling solutions, can provide you with lightning fast transactions at a fraction of the cost, all while ensuring security. Rooted on Ethereum, Arbitrum's newest addition, orbit, enables you to build your own tailor made layer three. Visit Arbitrum IO today buy, trade, and spend crypto on the crypto.com app. New users can enjoy zero credit card fees on crypto purchases in the first seven days. Download the crypto.com app and get $25 with the code Lora link in the description today's topic is the intersection of crypto and AI. Here to discuss are Ilya Palasuchin, co founder of Nier, and Jason Warner, founder at Poolside. Welcome, Jason and Elia.
Speaker B: Thanks, Laura. Great to be here.
Speaker C: Thank you.
Speaker A: Let's start with you, Elia. You have an extensive history in AI from before you got into crypto and in a way, it's actually how you got into crypto. So why don't you tell us your background in AI, for sure.
Speaker B: Yeah. So before kind of doing a startup journey, I was for about ten years working in machine learning. And I actually started my career there. And my now claim to fame is I worked at Google Research, where I led a team work on natural language. We've done kind of a lot of work across the spectrum, which has launched actually on Google.com and a few other places, Google Play. And as part of it, I worked on Tensorflow, which is machine learning framework that Google built back in the day. That kind of started a lot of the open source innovation in machine learning as well as I worked on attention is all you need, the transformer model that now powers all of the chat, GPT, mid journey stability and other kind of innovation, language models and image generation. I then left to actually do GitHub copilot style startup in 2017, trying to use transformers kind of in 17 when we just built them as a startup called near AI. And because we did not have Microsoft money, we ended up trying to be smarter and using a lot of students around the world to do crowdsourcing to build a better data set for language, to code descriptions, to kind of functions. And we faced this challenge where we needed to pay people. Right, this was students, and students don't have bank accounts frequently. They were from countries like China, Russia, Ukraine, which have some monetary control. Again, 2017. And like, it's been a challenging to just like, pay them for the work they were doing. And so we started looking at blockchain as a way to facilitate global payments, which what blockchain has been touted as a solution for in 2018. As we were trying to explore this, we realized there's no solution that's really trying to address the simplicity of usage as well as would power it at the scale even that we needed. That's what gave burst a near protocol because we realized we can solve that problem and then hopefully build a bunch of things on top. That started journey since 2018 on blockchain side, but obviously been keeping track on the I side and now involved as advisor and some other efforts on the I side.
Speaker A: Yeah, it's fascinating, actually, because if I feel like it's actually a very similar story to Brian Armstrong's start in crypto, which is that he had been doing payments at Airbnb and he realized, oh, wow, you know, making payments across 200 different countries around the world, especially because, you know, sometimes, like somebody's visiting Bolivia, but they're from Iceland or whatever, he realized it's so challenging. And then he learned about bitcoin. And now obviously he's the founder of Coinbase. So Jason, what about you? What's your background in AI?
Speaker C: I'm mostly growing up through what I'll call building platforms before what I'm doing now, which is co founder at Poolside, I was a venture capitalist. Ignored that little phase of my life for a little while here. And before that I was a CTO at GitHub. Before that heroku. Before that, canonical, people, Linux. So it's basically been devs and platforms. But while at GitHub, inside the office of the CTO, while we were doing a bunch of incubation projects at a small team that incubated copilot, as Ilya mentioned, his first foray into this, they.
Speaker B: Didn'T have Microsoft money, so we had.
Speaker C: Microsoft money at that point. And OpenAI, Microsoft, you guys just.
Speaker A: Can you define Copilot? Cause I don't know what that means.
Speaker C: Sure, GitHub Copilot, which is the AI coding assistant that's pretty popular and also the very first one that came out with the name Copilot. Now that there's a copilot for everything out there, including doing packets or looking at sports scores. And so, you know, that was in 20, I wanna say 2020 is when we started that work, in 2021, when we launched on beta. But I've been trying to build that. When I first got to GitHub, I wanted to build two things. I wanted to build what will become GitHub actions and what will become GitHub copilot. So it's like the ending of a long journey while I get hub. And now I'm doing something called, which we call Poolside, which is the way I describe it, is simply OpenAI, but exclusively focused on software. And that'll go into a couple different directions here. And then Ilya and I got connected. When did we meet, Ilya? Was it 2019 or 2020 as well?
Speaker B: Or something in the end of 2020? Something like that?
Speaker C: Yeah, yeah. And you know, we've been talking about the overlap between the two blockchains and AI as well in recent years as well. So it's been fun with that. But yeah, AI primarily blockchain peripherally.
Speaker A: And when you say that Poolside will be focused on software, you mean it's an AI that's focused on coding as opposed to like giving you all the best tips for, you know, where to go get drinks in New York City on a Friday night or something.
Speaker C: Yeah, we're not going to tune it for any of those sorts of things. And definitely if you know me as a person and what I would actually care about, too, definitely don't care about where I'm getting drinks in New York on a Saturday night, but I definitely will care about how efficient the python or Rlang is running.
Speaker A: All right, so this is not an AI podcast. I am not an AI expert. So I just need to have a set some ground rules for the discussion. How would you guys, or at least for this discussion, how would you define AI? And the reason that I'm asking is just like as kind of a consumer watching this, it feels like all the buzz is around the AI's that are built on these large language models, which is like very languagey. But then in my head, like, blockchain stuff is very numbers based. So then I was like, hmm, yeah. How do those come together? And I obviously have read a little bit about the different things, but to me it didn't seem obvious at first some, some of the stuff around, like daos and whatever, that made sense. But, you know, when you use the term AI in this show, like, what do you mean or what are the different things you could mean?
Speaker B: Yeah, I mean, I think, like, just to set the stage right, the AI, I think people always called AI something that's like, feels magical. And then when they stopped feeling magical, they like, figured out the proper term for it. So machine learning has been like a proper science that, like, for example, I was doing in everything from credit score to when you type things on Google.com, comma, when you type things on your phone to when you slide up and you see suggested apps, everything using machine learning, like, literally every single action you do right now is using machine learning in some shape or form. I'm pretty sure right now with this recording, there's multiple sound processors that are running, there's video processors that are running, there's package optimizers that are running, which are using machine learning. And so AI really has been this thing that's like kind of the next thing that machine learning or whatever cannot do or we want it to do. And so until we get there and then it becomes a proper term. And that's why this large language models now have a term. Large language models is now becoming its own, you know, kind of a field subfield. And so then people, you know, now dreaming about what the next thing about AI will be. But I think AI is just this term that like, whatever is like, magical that computers can do that is getting them closer to how either humans or like superhuman kind of ability, we call that AI, really, and then everything else, like everything we can really explain becomes its own term. Right? There's the information theory. There's all kinds of things actually, that became, that came out of AI over, past, almost like, I think, 60, 70 years of AI from existing.
Speaker C: The joke I use is that if it works right now, it's machine learning, and if you're raising money, it's AI. So everyone in the world already experiences this, as Ilya pointed out, in various ways. But the large language models are something that kind of emerged, as it's called, in recent years. And that is what we, that next wave of AI is kind of riding on. And, you know, we've gone through versions of cycles with AI already in like the 2010 ish era, 2015 1617 ish era, and then this one. And so each one had distinct phases, just like even in crypto, they went through distinct phases. And this one is largely going to be defined by the large language model breakthroughs that particularly OpenAI had pushed with GPT-3 and four. And we saw a scale.
Speaker A: All right. Yeah, I was going to ask you something, but I think you answered it, because I have a friend who actually was a writer for Siri. And so I was going to ask you if you thought of Siri as an AI. However, I know Apple's secretive, so I feel like, even weird just talking about the fact that this friend of mine worked there, and I won't name the gender of the person. They started in 2011. So maybe, like, when I was going to ask you, do you think of Sirius and AI? You're talking about like an earlier iteration where there was a human, or many humans, you know, kind of feeding the AI, but, yeah. Would you consider that an AI?
Speaker B: I mean, it's definitely a machine learning system.
Speaker C: Yeah.
Speaker B: And to be clear, like, there was, in nineties, there was expert systems, which were also, like language based expert systems that back then were called AI, which now nobody would have touch with AI stick, but they were actually powering medical systems for decision making and things like that. And actually their failure led to the big AI winter where nobody was funding AI because everybody was too excited about it and it didn't live up to expectations. So very similar to crypto waves and been running way longer, too. It started in sixties.
Speaker A: All right, so if you're just being as broad as defining it as machine learning, then that means you can apply so many different types of machine learning to crypto. So of all the different types, which ones are you most excited about when it comes to the intersection of AI and crypto?
Speaker B: So I think like worst kind of stopping on the large language models because they are the kind of this recent innovation. And the interesting thing is it's for the first time that computers went from needing a human to interpret what they output to being able to communicate directly. It went from somebody needed to be professionally trained to understand the output to anybody can talk to. That's why it's really exciting and really powerful is because you have this transition now going back to web three. Broadly speaking, there's a number of areas where this intersects. So I would start with generic marketplaces of resources I mentioned. We started because we wanted to use blockchain to pay people for our data crowdsourcing task. This example, there's data, there's compute, and there's kind of model architectures and ways to train things. Those are, quote unquote, resources that are used in machine learning, that blockchain is a really good marketplace kind of facilitator that can open up and really create better liquidity. To just give you an example right now, if you want to get a gpu cluster, you need to commit $10 million at least to one of the cloud service, and you need to negotiate with some representative. It's not a very efficient market. And let's say you did get this, but you're not using it. There's no way to facilitate renting it out for someone for an hour. Things like that is where blockchain can already become a really easy facilitator to really provide these resources across data model, like mobile architectures and compute.
Speaker A: And I'm sorry, you were saying, like, paying people, but also it felt like you were saying crowdsourcing as well.
Speaker B: To do crowdsourcing, you need to pay people, right? So crowdsourcing is a way to kind of facilitate, like, I need this work to be done, and I need to find somebody who is like, skilled and willing to do this, and I'll pay them for doing this work.
Speaker A: And, Jason, what about you?
Speaker C: Well, I think, like, going back to some of the central premise of, I'm going to say blockchain here, too. So let's say it's like, you know, it's permissionless and trustless. Like, let's go back to those two things there. So theoretically, as everyone has pointed out on the Internet, whenever you talk about a blockchain, someone say, well, this could have just been a database at some point, too, and et cetera, et cetera. Yes, like, technically, I guess that's true in many situations, but that doesn't adhere to those two principles of permissionless and trustless, plus some other central things. Now, I think when we're talking about AI in particular, particularly this wave of AI, there's a lot of things where those two elements could play a really interesting role. So Ilya's talking about marketplaces, but there's provenance of data and there's ability to get information in and out of these things where the permissionless and trustless is important, because otherwise we're talking about how these things have to be essentially administered. So if you're talking about data as an example, somebody somewhere always has access to these things, can manipulate and whatnot. So it depends on your views on what those things could, the potential challenges with those, those sorts of things. So right now, as an example, we don't have any idea provenance of any of the sort of things that are going into any of the OpenAI language models. We have no idea what type of data went into this. Now, that's an important aspect of what we want as a society for how we're going to evolve in the future. How do we do that in such a way that it's auditable and traceable and we can understand how these things evolve again. We can go back to like, okay, well, we can show you the books and all that sort of stuff, but it turns out that we already have a system in place where we can say, if you just put it here, we can all look at it in some sort of way. But that's just one example of the way in which these things can work. So it could be embeddings, it could be weights, it could be all these different things that we talk about along the way. Then, as Ilya was talking about, you know, resource management, which is a particular issue right now, because I'm literally going to the most central of all central authorities trying to get GPU access at the moment, because it's the most precious commodity in AI, is how this compute is going. So I'm going to the Nvidia's and the Googles and the Amazons, and there's 30 people in the world that have access to the type of compute that I need at the moment to go build these things. And what does that really look like in a world that's a much more efficient. And you could basically have GPU spot marketplaces where we can just kind of come in and use it if we need to, and then rent it out if you bought access to it. Or whatnot. And it's a very different world. And if you build these things around that now, again, people talk about, well, that could just be a database. It can, but then you're putting a lot of trust into people and a central authority and depending on your views on that, what does that mean?
Speaker A: And so where you were going with it sounded like you were saying transparency is something that blockchain tech could help bring to AI. What came to my mind was, you've seen those news articles where the AI reflects the biases and prejudices in our society. Is that what you're talking about? Like helping to.
Speaker C: I'm going to use an artist's example here because I think when we talk about provenance of data and what the training data is, it can get into a really nuanced area really quickly. But right now, the simplest way to think about this might be just mid journey style image generations and what could have gone into that. And it's a gray area right now. A lot of this stuff will be tested and legal arena here, and I.
Speaker A: Don'T know what that means. Mid journey style generations, what is that?
Speaker C: A mid journey is an image generation like, generative AI image generation model that will, if you tell it, hey, make me a pirate sitting on the moon holding a banana, literally, it will understand that and generate several versions of this image that you can manipulate and say, okay, now make it more of like sixties retro style. And it knows how to do that sort of thing, but only knows how to do that because of how much data is ingested, other images and things of that nature. So in some ways, when we talk about attribution, like, how does it know that from that particular image? What inspiration is it drawing from? Because it is drawing from other images. Some of those might even be copyrighted, some of those might be whatever. It would be interesting to understand how it knows which one of those things are. And no one's doing this at the moment because it's actually a pain in the ass to go do. But if that's important in the future, there's an easy way for us to go achieve that as well.
Speaker B: I would turn that around on the other side as well. Right now. OpenAI and mid journey, all these companies, they also need to decide what are things that are good and bad. They are actually making decisions for things that this model should not do. And so we're getting into a single company, pretty much deciding for 100 million of people what's good and bad. And we know how that went before with social networks, for example, and so this is kind of extension of this problem. And this is going back to what we've been building in blockchain space with Daos governance and really trying to figure out how to create an open, inclusive way of deciding on things. We can actually have this daos to be driving kind of training data collection that specifically tries to debias and find the consensus on what is communities things kind of good and bad or safe or not safe, aligned with humanitarian values or not right, and use un principles as well for that. And like do that in an open and transparent way so everybody sees exactly what are the rules versus right now we don't even know where like the edges of these models are.
Speaker C: I was going to say this is actually something that I've felt for a long time because I've worked in the open source community for going on 20 years at this point, but professionally probably the last 15. And one of the things that you do when you open source your code but not your decision making process is people can look at your code and they can say, okay, x, I understand that, I understand why, et cetera, but they might not understand how you made decisions to come to these things. So in an interesting roundabout way, open sourcing your code actually can lead to a lot more scrutiny because people will then start questioning the decision making process or who made the decisions and when and why and all that sort of stuff. And five years on working on Ubuntu with the Debian and Linux community, it was a constant thing. There's a world in which you could then take some of those things as Ilya was pointing out and put them in a system and it's open for everyone to go inspect those sorts of things like hey, this is the rationale or this is how we're going to do this, or this is the rule system that's going to be in place for this. And again, like, you know, no one's actually done this fully to an extent, but I do think that there's a world in which somebody somewhere is going to see that opportunity and say, hey, I don't want to have to be in a position where I'm going to go defend each one of these things. Just find a way to go put that in there and let people inspect and understand what that looks like just.
Speaker A: To draw this out for me because my question was like what areas are you most excited about where crypto and AI come together? So what you're seeing is if you have a self funded open source project, like you can fund it with crypto and then that will allow all these decisions to be transparent.
Speaker C: Is that, that's not specifically what I'm talking about, although that would exist. I think that where I would be most excited about it is being able to show more provenance. I think at the moment. Like I would like to be able to show where some of the data came from so you can attribute it back to folks in the future.
Speaker A: Oh, and somehow you would use the blockchain to do that?
Speaker C: Yeah, you can. Yeah, you can. You can say, hey, these are, stick all the data there and you're gonna say, this is in the series of data blocks that allowed me to, that were using this generation as an example, like saying like or inspired this or helped on this. And you know, at the end of the day, it's all just data.
Speaker A: Oh no, I got it. Okay, well, so I wanted to now ask probably this is a more poll side question, but I'm sure Ilya has ideas because I was reading that AI's help coders do their work, but I didn't know, like is that just, you know, like JavaScript or something? Or could they even do like solidity smart contracts or any kind of smart contracts? What are you seeing in terms of like how well AI's can do the types of coding needed to run blockchains?
Speaker C: Yeah, all those are. Anything is available. Any type of code is available in most of these systems. I haven't specifically checked on solidity, but I'm assuming it is.
Speaker B: I've seen two. So I've been to a lot of hackathons recently. Two of the winners of two different hackathons were using OpenAI's API to do solidity auditing. So they were finding solidity code like using the API, pretty much conditioning it with specific things, as well as feeding it with some other static analyzers, but also describing what kind of vulnerabilities this would generate. On our side, I've seen people actually using it to write rust smart contracts for near as well, at least like somewhat common set of problems.
Speaker A: So when, when it's doing that, when it's auditing and it's catching bugs, that is just based on what's already known, right? Or if it's machine learning, could it ever, like with the chess thing or the go game, like, could it go beyond what humans have already figured out, or will it only ever because it's only like being fed? You know, what people have already figured out? What's the limit?
Speaker C: Yes, it knows about those things, but from the past. But the idea here is, and this is where I think everyone's kind of racing to, is that it will go beyond what people have known now. Like how we're ever going to be able to achieve that, you know, depends on your views. I think we're going to be able to do that and go beyond. But, you know, I do think that what Ilya is describing here at the moment is most of what we're seeing today is generation, like functional generation. And in reality, what it does is it knows more about the broad swath of like all the solidity code that has ever been done and the docs, so it can catch these things. And at some point it is going to be able to test this and say, hey, this is where, this is specific to what we're trying to do at poolside because we're focused on code and software in general, but we'll be able to test the outputs. We'll be able to say, this is good code, or this is runnable, or this is insecure, and it's a future version of a thing. So we've not seen it before, but we know that it's insecure because it breaks down on these rules. Or the testing environment that we have shows that it's probably vulnerable to these things.
Speaker A: I also wanted to ask, because some of the news articles that I was reading just made me wonder. We've often heard about, for instance, crypto trading bots. And then I was just like, wait, so is AI, is that just a new word for what people have already been doing? Or is this somehow like, I didn't really know, what's the difference between a crypto trading bot and then using AI for crypto trading? Because, like, suddenly there's all these articles on using AI's for crypto trading. I'm like, is that different from before? Or are they just using a different word now?
Speaker B: So I think, I mean, machine learning being used for trading, probably like, as soon as somebody did machine learning, it.
Speaker C: Actually was one of the first real applications because you can make money super quick on this. Like, hey, awesome, and we can make money.
Speaker B: So, yeah, machine learning always there. I think what people are doing now is being able to ingest more signals from language. So, for example, you can read news articles or analyze transcript of this podcast and realize, like, you know, catch some of the project names or whatever and potentially make some decisions based on that. All of that has been done. Like, Wall street has been doing all of this just with less sophisticated models. I've been doing natural language from 2010. This was early years of natural language. So generally speaking, it's just more sophisticated models. They understand better the language you can kind of inquire. And the other thing is bringing that use case as well up because this is the first time you can talk to computer. Right. In a way, this allows to have two things. One is, you know, blockchain is a lot of code and numbers in a way, and trading as well is just a lot of, you know, numbers and things. And so what it allows to do is it lowers the barrier for kind of people being able to come up with more sophisticated models without needing to really build all the code or strategies or structures and actually have this conversation with kind of the bot, for example, to describe the strategy.
Speaker C: Right.
Speaker B: So imagine we're like discussing, you know, it would make sense to buy low when, you know, some bigger whales are buying like this. Sounds simple, but like implementing that and making that actionable, you know, before would require like building out a team of ten high frequency traders. Right now you actually can have this conversation with, for example, like one of the systems and potentially it will build a strategy and start executing for you. And so expanding that now to DeFi, DeFi right now is pretty complicated for a lot of things beyond just simple swaps. Imagine you can describe like, hey, I want take a position in whatever the latest high yield pools is and it can iterate over all of them. Find whatever the high yield, take the position and stuff like this. It kind of provides a more natural interface to this somewhat complex still ecosystem. And I think that barrier will actually, like, AI will actually help, like language models specifically will help to lower barrier to access some of these things, both not just on trading side, but also on using side and kind of interfacing with blockchain applications.
Speaker A: Yeah, I just, I do want to insert a caveat, which is nothing we say here is financial advice. I don't want people to like whip these up and be like, I'm going to make a killing, and then they like lose a bunch of money or anything anyway.
Speaker C: Jason, no, no, you're going to lose more money than you're going to make in some of these cases. But for what it's worth, whenever I hear a bot, I always think that there's machine learning behind it. I just assume at this point when someone says bot, there's some sort of intelligence and automation that makes it that way. As an example, there's bots emerge in all these different systems and really what they're doing is they're picking past data sets or blah, blah, blah to try to understand what they're supposed to do in the moment. So trading bots are not anything dissimilar, but as Ilya mentioned, large language models are going to change those again, but also in the crypto space, what do they have? Is that they have access to open access to the data sets as well as the other systems where a good example here is if you want to use non crypto systems and do trading, go to trading view as an example, purely as an example here, by the way, obviously. But you could use GPT four or chat GPT to say, hey, I know nothing about Pinescript I think is what they use. But I do want to create some sort of trading algorithms, help me write these one, it can write them and you can put them into Tradingview as an example. But then what you can then do is extend that out and start to do this. Now the difference between that and crypto, which is like you're using this on the stock market stuff, is you don't have the same access to all the underlying data sets, but someone could do the entirety of this in the crypto space, and then you could also find a niche much easier too, because you could be off on some far phone platform that doesn't have a lot of xyzs, and you could really make it killing if you understand how to wedge yourself into a certain system.
Speaker A: All right, so in a moment we're going to talk about the intersection between misinformation and AI's and crypto. But first, a quick word from the sponsors who make this show possible. Join over 80 million people using crypto.com comma, one of the easiest places to buy, trade, and spend over 250 cryptocurrencies. With the crypto.com Visa card, you can spend your crypto anywhere and get rewarded at every step, up to 5% cash back instantly, plus 100% rebates for your Netflix and Spotify subscriptions and zero annual fees. New users enjoy zero credit card fees on crypto purchases in their first seven days. Download the crypto.com app and get $25 with the code Lora link in the description. Arbitrum stands at the forefront of innovation as the premier suite of layer two scaling solutions, bringing you lightning fast transactions at a fraction of the cost, all with security rooted on Ethereum. From Defi to gaming, Arbitrum one plus Nova is home to over 500 projects, and with the recent launch of orbit, Arbitrum welcomes you to build your very own tailor made layer three. Or, as the Arbitrum ecosystem calls it, an orbit chain directly on the Arbitrum tech stack. Designed with you in mind, Arbitrum empowers you to explore and build without compromise. Propel your project and community forward by visiting Arbitrum IO today. Weve said it once and will say it again. The system doesnt just need an update, it needs a complete rewrite. Web three offers that complete rewrite because it extends beyond just money staking nfts Defi earn, web three has become a world of its own. But who has time to juggle between five different crypto apps? Okex Wallet is one of the best apps for everything web three. It allows you to store, trade, earn and manage your crypto and your nfts across 60 plus blockchains all in one place. And now it's one of the only self custody wallets that doesn't have require a seed phrase. There's just no other wallet that says powerful yet so simple. Give it a try@okex.com. web three Join over 10,000 attendees for this year's biggest crypto event at Token 2049 Singapore on September 13 to 14th. Sandeep from Polygon, Eric Wahl, Chris Berniske and over 200 others will hit the stage, joining the industry's most influential for an unforgettable experience ahead of the Formula one Grand Prix race weekend, Singapore will transform into a crypto hub for a week from September 11 to 17th, with over 300 side events that will make for unparalleled networking opportunities. Builders and investors at the bleeding edge of innovation will drive an agenda that covers the ever evolving regulatory landscape, the convergence of crypto and AI, web three gaming nfts in the Metaverse, defi scalability, interoperability, and many more. Visit token 2049.com for 65% of regular tickets with the code unchained link in the description. Back to my conversation with Jason and Ilya. So I have seen a lot of thoughts about how blockchain technology can be used to address misinformation from AI's. But I'm curious. Yeah, for your thoughts on like how exactly that would work.
Speaker B: Yeah, so I would start with that. Misinformation is not even AI problem, right? This thing has been existing, you know, even the basis of crypto, right? The byzantine fault tolerance is based on the misinformation. So the byzantine general's problem, right? And so like generally speaking, like this is a human problem, not AI problem. That AI is just becoming a tool to really kind of efficiently create a lot of either misinformation or like very pointed content or create, you know, generated content that looks very real but has, for example, wrong facts.
Speaker A: Yeah. And in case anybody doesn't know the byzantine generals problem, it's basically when there's different people, they don't necessarily all trust each other. And it's something about, like, you want them to act together in concert even though they don't trust each other. Is that.
Speaker B: Yeah, like, there's potentially, like, up to one third of them that are malicious and trying to, like, propagate some information that's not true, and you still want, you know, your army to kind of execute correct orders. The consensus of blockchain is based on that, where, like, up to one third of validators may be malicious, trying to, like, maliciously attack the system, and you still want the whole blockchain to come up to a consensus, like, on, you know, order of transactions and money spent on kind of decisions made on chain. I'm just saying, like, the source of the misinformation is, you know, spanning, like, thousands of years. It's like, as, as soon as people started talking, they started spreading misinformation. And so I think, like, the, you know, even with generated, like, images now, the reality is the photoshop, you know, photoshopped image existed before and was, like, cases when it was presented in court, like, a yemenite, altered images. So I just, like, want to set up the case because a lot of people say, like, oh, AI is, like, you know, creating misinformation. It's like, that's not true. Like, humans creating misinformation. They're using this language models and image, and, like, generative AI as a tool to create misinformation. And so the question is, like, how do we address this challenge with our, I call it society operating system. Now, our society operating system runs on language. We communicate with language. We have, like, all the government kind of systems run on language. And so this is where Web three comes in. Web three has cryptography, has reputation, has all these things that kind of tie together, and they provide the tooling for us to actually authenticate the content, link it to its creator or authorizers, or kind of create reputation around the content source. Right? So, for example, let's say this podcast was completely a generated. How do you know that? How would the listener know that it was AI generated or real people? We three actually said, yes, we actually participated. And so the way to do that is for us all three, after it's recorded, to sign the hash of the whole podcast and say, like, yes, we participate in this. And this is indeed content that we've been members of. And potentially it can be actually edited with AI to make it sound nicer, to have better images, et cetera. That doesn't matter. What matters is that I say, yes, I authorize this content and I put my reputation in this. And so to do that, we need cryptographic signatures. We need kind of an identity that ties all of the things that I signed with. So you can see, like, what I've signed. And we need a set of tooling that when you do listen it on, for example, podcasts or Spotify or whatever, it says, yes, it's verified and indeed signed by the right people. So that is kind of the system that needs to exist. And like, not just, you know, for podcasts is good example, but, you know, this needs to exist on a government level because there will be like artificially generated filings, companies that don't exist, that are run by AI. You can have politicians that are completely artificially created that are talking to people through instant messenger and describing their policy exactly adjusted to that person, and they would not even know that. And that's all possible now just to scale the level and create it a lot more personalized. And so using cryptography and reputation, kind of all those pieces that blockchain is powering, would allow us to really kind of create a more trusted environment and reputation based environment that we don't have right now.
Speaker A: This is so fascinating to me, and obviously, because I'm a journalist and I really care about facts and just really hate misinformation and think it's corroding democracy and all things like that, I couldn't help but think, okay, so let's say that this system comes into place and then really reputable publications like the New York Times, the Wall Street Journal, the Washington Post, LA Times, whatever, they start entering things in the blockchain, they're using their reputation. I mean, I just thought of these really famous incidents where reporters were making stuff up. Like there's a famous case of a guy named Jason Blair. There's another one, Stephen Glass. And there was also the case of the New York Times reporter who got the weapons of mass destruction in Iraq. Wrong. Judith Miller. So then what do you do when like, a reputable source is stamping misinformation? Or I guess misinformation, I feel like is more intentional. And then, well, so in some of those cases, yes, the reporter was doing intentionally, but in some of them it was just a mistake. So then how does that work? What do you do in that kind of situation?
Speaker B: So important part now that it's on chain, right? You can inspect, right? So you can go back and see for this reporter, for example, have they said something already that was marked as incorrect? Or you cannot get out of this and say, like, oh, I didn't say it, or whatever, go and edit it post factum. So you have now reputation attached to each kind of source. The reality is everything's subjective, right? And so although, like, yes, we want facts, but like, at the end it's subjective. And so reputation is subjective to some extent. But you can study, like now there's objective facts that you can inspect that cannot be retroactively changed. Then the other thing is, let's say as a reporter, you probably have sources. And so now if you have this cryptographic reputation system, you can actually have a zero knowledge proof of your sources without revealing who they are. Let's say you have a White House. You can prove that, hey, you actually had somebody in White House that told you this without revealing who they are, but revealing some fact about them and things like that, right? Like now you can have kind of a lot more information being plugged in into this reputation. And then at the end, it still would be a subjective, like, you know, some people watching fox, it doesn't matter for them if it's not true all the time. I mean, I don't know, just as an example. And like, they kind of continue watching Fox. Right. That's what I'm saying. In some ways, reputation is subjective. But like, at least you can have the facts and you can study them and you can observe them and you can have systems and browsers and apps that actually show you. This kind of summary about reputation is like, hey, this journalist, you know, like out of last three articles, two of them were flagged with some not correct facts, for example, by the community that you're following. Let's say you follow one of the communities of fact checkers and they're like, hey, you know, we flagged, like multiple facts are not correct and stuff like this, right? Like, you can have this composability now of different pieces and communities kind of coming together and informing things.
Speaker A: Oh, wow, I love so much about this. And I think you kind of addressed a question that I had because I'm sure you're very well aware. And we see this. It's not just news organizations, but for instance, presidential candidates. Even when one source, like, tends to be repeating misinformation more frequently than another one, people still, they just believe whatever they want to believe and they kind of don't care if one is like proven over and over again to be spouting misinformation. So a couple of things. First of all, my thought was, oh, but what if the people who just want to believe whatever they want to believe are start attacking the reputation of the factual ones? Is there a resolution for that? Or is it simply that because you have the sourcing, you can see, like, okay, actually, all of this does check out. Where's the other? Like, it doesn't have as many things that check out or, or what?
Speaker C: I mean, I don't know if we would be able to fully answer the question, but I would say this. Think of it as a hierarchy at the bottom. What blockchains would be incredibly good for, useful for, is facts. Straight up. Identity is a good example. Is Ilya a human or not? Can he prove himself to be a human? Et cetera, et cetera. Then going all the way to the top would be things that require some amount of interpretation. As an example, does that make sense? Hey, you've got to be able to juggle a couple of different things together and whatnot. You're not going to be able to do as much with that. You have to actually build some other systems on top of the base level systems to be able to do some of those things. But the point being that you could build those systems on top of each other. And again, going back to, even as Ilya said, some of the start with the byzantine general problem and thinking about this, going back all the way to when everyone first started talking about blockchains with bitcoin and others, what it was is trying to take trust from a central authority and swap it out to a publicly transparent something or other. And if you think about just that one motion going back to identity here is, I'm a us citizen, so how do you verify that I'm a us citizen? You have to go ask a central governmental authority. But what if that was instead, over here in a publicly verifiable, transparent system? That's an interesting, amazing ability to go do. And you could do that for other things as well. Verify that Jason was the CTO at GitHub. You have to go look at my LinkedIn, then you have to go call GitHub. But what if that was not the way in which we had to do this? Now just think this through for a second. We think, why is Sam Altman looking at Worldcoin and getting this off the ground for? What does that mean? What is that supposed to be about? All that sort of stuff? And I guess playing these things through this is why I think that there's interesting overlap between these two types of technological movements, let's call them. But each of them has become shrouded in their own weird. I don't know what to call them, but idiocy might be the best way, which is AI is going to be used to generate all this bad spam on the Internet and this terrible content, all that sort of stuff. But let's just be honest. Like a lot of the stuff that's going on in crypto for the last, or web three for the last three years is just like straight up idiocy scams and whatevers of the world. And it was not what the, obviously the base of the system was supposed to be intended for. And we're throwing out baby with the bathwater in a lot of that situation there.
Speaker A: Do you see there being some kind of remedy once misinformation does get. I feel like so much will need to be built out for this vision to happen. Like, I almost feel like what we're talking about is minimum 20 years from now, if not like 30.
Speaker B: So a few things. One is so we've been building, we call blockchain operating system, which is a fully cryptographically kind of reputation based everything from blockchain itself and using all the blockchains in the web three ecosystem to front ends to kind of authenticate it. The content you see, not just us Lans and others who are building decentralized social, we are all building the substrate for all of this. It's not that far away. I think it's more about how do we bootstrap the adoption. And I think this is where we just need to show more examples where if it's not used, it's going to be not great, right?
Speaker A: I mean, I think getting it used on a society wide scale, that's what I'm talking about.
Speaker B: 20 years and that's what I'm saying. I think actually it will happen faster because of like people will start using AI for misinformation, for creating spam and kind of generated content that is like malicious and intent like this will become a motivator to actually start using. Like we already see, right. Twitter is doing rate limiting because the kind of scrapers are running wild. This is already beginning of this thing. If you search for I'm in AI language model on Twitter, you'll see all of the bots pretty much that are posting that hit the rules that are not allowed. But this is just things that we see that are pretty much errors of the bot. But all of the other rest of the Twitter is being generated already. That's a reality. The content explosion is just starting. But like, as more gpu's become available, as more of this open source language models become powerful, this is just going to escalate, right? Again, like the podcasts fully generated, this is like next year.
Speaker C: This is one where I think about this quite a bit, which is Ilya and I have this conversation in private, a bunch, but part of this conversation, which is how weird the future is going to get, how fast things will happen, how weird it will be, how many things will be generated. Even if it's 10% real, 90% generated, or 50% real, 50% generated, there's going to be a lot of things that just get generated, positive and negative. Then going back to what we just experienced in the last wave of the crypto, now that we're particularly in the winter here, I feel like the focus now particularly. This is one of the reasons why I like what Ilia is building with Pagoda and NIR, which is blocking chain operating system, because it's a focus on the fundamental problems and solutions that would go back to the original premise of the technologies, as opposed to going into the very speculative nature, effectively, financial manipulations and stuff, like with all these different systems, that felt like a really weird side path where a whole bunch of people can make a whole bunch of money. But it wasn't focused on what this is going to do for society. And this is, again, what Ilya is focusing on, is how this could be useful for society and how we could build applications on top of it. And that focus now with what is going to happen should emerge out with some really entrepreneurial people saying like, well, this is a real problem, this is a real solution. Let's figure out how they overlap together. It'll get interesting. And my hope is that coming out of this crypto winter, people are using these technologies for these reasons, as opposed to just, again, speculating with VC money so that everyone can walk away and buy a boat and we're building something.
Speaker A: Real and name it much. Wow. I had to ask also, we talked about how you can use these right now to audit solidity code and things like that. Obviously, we've seen so many hacks in DeFi. I think for 2022 it's more than $3 billion worth. I just released an episode where someone had proposed circuit breakers for DeFi to help prevent. But I wondered, could you create an AI that would in real time do something to either help prevent these attacks or whatever, and it's not even just the act of withdrawing money, but even like, the economic attacks where they're manipulating prices and stuff like that.
Speaker B: So, I mean, like, folks like Gauntlet and others, they're using machine learning to do this stuff, right? I mean, it's not always like language models per se, because a lot of it is not based on language. A lot of it is like understanding time series of prices, understanding the movement of money. Like, a lot of folks are actually using what's happening on Testnet to detect if there's a hack gonna happen on Mainnet. Like, so all of this is like predictive analytics type things already happening. There's a lot of smart people doing this kind of work. It's just maybe not as hyped up as whatever new plugin to chat GPT that can be explained in seven ways. Right?
Speaker C: If you want to think about every time you hear a word bot, just think that it is actually already using some of this technology, just maybe not the specific large language model portion of the technology, you're directionally correct. You may not be in specifics, but this is why people are doing these things already. There are going to be, again, going back to. It's going to get weird. You're going to see people start building these things out quicker. I think, though, too, you're going to start seeing people who are manipulating systems more, and you're going to see both protective measures, but also adversarial measures emerge more as well. So one of the things that I do think about on a regular basis is what happens when all of these systems are available to anybody and any random person could generate a bot army. And right now, we know that what's happened on the Internet with a lot of that has been nation state level for manipulations for various reasons, but it's also gone down to lower levels where it's like, well funded organization has created bot armies to go do and manipulate, et cetera, and then, you know, spam creation, et cetera. So it's still funding, but imagine when one person could theoretically create these things on the fly super fast. So this has nothing to do with specifically the overlap between the two, but the point being that, like, it's going to be possible for the barrier to entry for a singular person to do these things is going to drop towards zero on a infinite timeline, but sooner rather than later, in my opinion, which means there's going to be negative things from that. Not nearly just positive things, but very negative things that we're going to all have to kind of watch out for and hopefully build protections in place for.
Speaker B: Yeah, maybe to bring back to the DeFi example. So that bot you can use using OpenAI API to find vulnerabilities in solidic code, you can use it now to find a lot of the common vulnerabilities that do exist in existing DeFi deployed projects. So what this means is the challenge being that the circuit breakers, and I've been talking about having circuit breakers in DeFi as well for over a year. The reality is this needs to be deployed first before we deploy DeFi. Those circuit breakers also needs to be, ideally economically guaranteed where somebody is underwriting and actually monitoring this. For example, some of the audit firms need to actually take kind of some of the risk and become an insurers of these protocols. And like, that all needs to happen. That's adoption part to kind of really start preventing some of the bad things happening. As Jason mentioning that it's becoming, you don't actually need to even know solidity potentially to start generating attacks on smart contracts soon. Imagine that it will soon be happening. To your question how fast this adoption will happen? I mean, we're getting to the level where we have all the tooling. It's now more about whoever launches things need to be thinking long term and creating the right structures to protect things versus throwing things out. And this is true about content, this big publications need to start thinking about it as well, and protecting, signing and protecting the content they're producing in such a way that you can build things around that and build these reputation systems around that.
Speaker A: All right, so this actually brings us full circle back to what we were sort of discussing kind of at the beginning, but we didn't go into depth. And this is like, when I was doing my research, I felt like this is where I was kind of finding the most interesting stuff. But I feel like Daos and AI are sort of the place, at least where I thought like, oh, there's a lot of potential here. So, Ellie, I feel like that's where you were going initially when you were talking about the crowdsourcing and crowdfunding. Yeah, but I feel like there's other things, too. So I don't know, why don't you guys just talk a little bit about all the different ways that you think Daos and AI's could work together?
Speaker B: So I think a really interesting part is, and also intellectually, it's interesting to think about, and I think we'll see this very soon is, let's imagine we have an organization that's run by AI. So instead of a CEO being a human, you have a CEO being an AI. And they have a mission. They have a set of KPI's and goals that they set out to do. And they actually allocating work to people to do within that company. Legally wise, we cannot do that right now in the physical world. But on blockchain, this is actually pretty easy to do. We set up a Dao. The DaO coordinator is an AI model that produces tasks and pays for them to people. And you have shareholders, token holders, whatever the interest holders in this Dao who actually are setting up KPI's making sure that AI is on, on point and kind of doing the things it should do. That structure is like very possible, you know, very soon, like I'm expecting, you know, somebody. I mean, there's like few technical things that needs to be built. And I know a few companies that are doing this right now. And we'll see some of this happening where you can have a project that's like kind of coordinated by AI based on the KPI's that a community has set out. And it's kind of, you know, splitting the work and you know, analyzing the results and kind of deciding what to do next. And you know, it will make mistakes, but so as humans, and at the same time it will be way more kind of cold hearted in a way with some of the decisions and not biased with some of the things. I think it's interesting to think, you know, expanding that, you know, a few years forward. And beyond that we talk a lot about, you know, AI is taking over the world. Like people love this like Terminator story, but the reality I think will be economical, not kind of existential. It will be because AI is actually better at coordinating humans that humans are, because they're not biased, because they're kind of can observe everything and can process all of this data. At the same time. We economically will want to work for AI's pretty much as better boss makes us more economically successful than this existential AI becoming evil and wanting to take over the world. So I think that's an interesting concept for me.
Speaker A: Just help me for a second, because, you know, as we mentioned earlier, there have been like prominent AI scientists who come in and said, oh, these models are being trained in a way that they're reinforcing a lot of societal prejudices. So you're saying that it's an AI where they're only gonna.
Speaker B: Yeah, the community is becoming, it's pretty much like governance body, right? Like, you know, they can decide if it's doing the wrong thing. It can decide if it's like, should be, you know, fine tuned to for a different thing. They can literally say like, hey, we need to source these types of data to fine tune, to adjust the AI model to be better at that, or not do this, or be less biased about that. They can commission pretty much crowdsourcing data using again, blockchain to actually get more training data for this model to become better at specific tasks.
Speaker A: Yeah, but also I felt like where you were going to is that since the AI will have a certain set of kind of goals or parameters that are more numbers based, then it's just a simple thing, almost like a check of did the DAO manage to do this or did it not? Or like which DAO members did it versus which ones didn't. That kind of thing.
Speaker B: Exactly. It's like it's way less about, you know, any, any kind of observable parameters and a lot more about like, work has been done and kind of, you know, just very transparent, very like kind of egalitarian or meritocratic approach. Then, you know, as humans, we strive to be that, but like, we always fail. Right. That's just inevitable.
Speaker A: One other thing that I wanted to ask about is that I was also reading you could do the reverse where you could have daos that manage AI's. And I think we had kind of touched on some of these issues before, you know, when Jason was talking about like the transparency and different things like that. But do you see anybody working on that already or. Because we have robust DAO infrastructure, I'm.
Speaker C: Not as close to anything going on in the Dao arena, so I don't know if anyone is actually using this at the moment. So maybe Ilya in his hackathons has seen more of these things than I have. Ilya, have you seen anything?
Speaker B: I mean, people are definitely trying. I think the missing piece right now on the infrastructure side is right now there's two types of models. There's either fully centralized models run by OpenAI, Google, or fully open source model that just runs on edge. And so there's no kind of way to run some of these models in a. I call it under consensus, right? So in a way that like, you can prove on chain that it's correct. Right. So some people are trying, you know, there's for example, a way to convert some of the machine learning models into ZK circuits, but it only works for kind of smaller models.
Speaker A: And ZK circuits is what, a zero knowledge circuit.
Speaker B: So like, you can, you can run a model and then prove that the output is indeed the output of this model.
Speaker A: Oh, okay.
Speaker B: Yeah. So people are working on infrastructure for that. And this is kind of precondition of any of the, like, Dao and machine learning interacting in a actually, like, trustless way outside of this. Like what you can expect is more like a Dao commissioning pretty much somebody to do something with a model and then getting results back. Right. So this is more like, hey, you know, similar how Dao has commissioned somebody to go do something in physical world, right. And validate the results later. But I think the interesting parts for sure are more like around either augmenting humans kind of in their day to day work, right, and kind of interfaces and creating a better interface or in this, like, making AI now become more of a coordinator role or kind of a pilot versus a copilot role.
Speaker A: Yeah, I feel like what that combination could do dow managing an AI would address. Like, I'm sure you guys have heard, you know, people will say things like, you know, I mean, it's like with the FTX stuff, you know, they were always trying to mitigate against. AI is doing something really potentially adverse to humanity. And I feel like that's what a lot of the fears are around the more closed sourced AI's and even things like world coin, like people just get nervous about certain things that aren't well known, and it's only like a small number of people that know them getting too much control. So I feel like if it's something where it's more public and the community feels that it has control of it, then it could mitigate some of those fears. So one other thing that I want to ask about was both of these are super emerging areas of technology, and they're definitely not well understood by regulators and lawmakers. And, Elia, I know that you have some thoughts about how you see parallels and how they're being regulated. And you mentioned to me an interesting idea about how they could be used to kind of regulate each other. So what are your thoughts on that?
Speaker B: Yeah, so, I mean, I think the similarity here indeed, that like this is emerging technologies that like, literally changing every, every year, you see like a completely complete shift from what it was before. You know, regulations don't move on that speed. And at the same time, like, what we're really trying to do is to protect consumer, protect the markets, protect kind of the people. And like that, that is the core part. And then around that a, we already have a lot of the regulations around products and around Internet and around just people doing wrong stuff, right? So, like, that all exists and it's just kind of, you know, the point about blockchain always been like, hey, on the edges, you already have all of the regulations that are happening, people doing the wrong things, they already fall under the existing everything from money laundering. It doesn't matter which tool they use to do that. And same on the I side, when people doing malicious things like creating misinformation, there's already laws against that. It's not a new thing. Same as doctored images to present at cases and so, or misusing copyright information or whatever. And so on the other side, like, what do we want to protect? Well, so I mentioned, right, using blockchain for reputation and identity and same actually, even for blockchain space itself. Like, we're not using blockchain to actually have the identity of people who are building blockchain. Right? Like, we're not using, like, the tokens launched are not kind of cryptographically signed by people who launch them. There's no, like, security reports that, you know, produced by auditors are not cryptographically signed and put on blockchain. So, like, all of this body of information organized properly can be the way to really regulate it. And for that, regulators should be just using this technology because it's actually designed for a lot of this use case of like, keeping track of, you know, records, making sure that everything is authenticated, allowing community to inspect it very easily, allowing other external tools. Like imagine you opening a wallet, and if you want to transact with an address that is on some list, it automatically shows it, because that list is on blockchain. And to add to that list, you need a community vote of the interested part of the parties that are involved in these decisions. Same if you're trying to transact with a contract, if it doesn't have an audit, your wallet right away shows you that this contract does not have an audit. And are you sure you want to transact?
Speaker C: Going back to some of our earlier points already, the core basis for what blockchains would be good at would be a remarkable boon for society if we could use them that way. So think about even just phishing attacks and emails that come in or text messages or whatnot. We haven't really fully used them. This is, again, going back to one of the reasons why I like hanging out with Ilya is he's focused on making these things possible as opposed to just trading monkey pictures on the Internet, which, yes, people are going to go do and stuff, but ultimately it's solving a real societal level problem. And if we use them that way, we can actually advance real needed things that are going to benefit everybody in the world to a degree. But we got to focus on them, build them, and we have to actually understand how they're going to be used. So going back to the regulator point on this, which is on both sides of the fence, no one who's going to make up any of the rules or regulations fully understands these technologies and they don't understand the implications of the technologies. Not the core of the line, but what's positive or negative can happen with these things. And so they rely on experts to come in and talk about them and all that sort of stuff. But this goes to age old problems of, like, incentive structures. And so somebody going in front of Congress and saying, hey, we need to put all these things in place for large language run models at the moment. Well, let's just be honest, that's a very selfish view of the world for that one particular person. We need people who understand these things. I'm going to go into like a slightly different tangent to Ilya here and just say I think we need showcases for the technology that will help folks understand these things. So right now, in like, what Ilya described is there's a lot of practical that exists on the crypto side of the world, but then some theoretical for some of the, the things in place. And I think we have to understand, like, that technology needs to get showcased, the capabilities need to get showcased so that people can fully understand that, because Ilya is smart enough and everyone who's listening to this is likely smart enough to understand and extrapolate out what Ilya just said, that it goes, oh, yeah, I can see how that would be useful. But people who are not immersed aren't going to be able to see that. So they're only going to see the moment. If we can move what is possible in the moment, we can showcase that sort of thing. So again, I hope people listening to this start to focus on those problems because those are real things that will advance the state of the art and society forward.
Speaker A: I mean, for sure, speculation is just a huge part of the cryptic community, at least for now. So I don't think it's the majority of my listeners, but.
Speaker C: No, but this is actually something that I get. I get really bugged by because, because obviously it was encouraged for quite some time because you can make so much money. But imagine this, too. Half of these VC firms, just to show that they were, quote unquote in the community, hired people with anonymous identities on the Internet. And one of them was famous for saying, we don't even know who this person is. Well, that was absurdly reckless. Absurdly because the technology that they're supposed to be investing in is one of those things that should show them that they could actually prove who that person was, et cetera. And they didn't even go through that process. They just hired a random avatar from Twitter. And it's silly in the moment now retrospect to talk about that, but they should have been showcasing what is possible with this technology too, in my opinion.
Speaker B: Yeah. I mean, to mention another example is using this technology will allow to ensure that all the money are staying in the right place. They are said they're staying, not being reused in different places by editing some code and moving them around accounts. Like this is, this is like, that's the part. It's like it's been encouraged to build stuff on top that are not really using the technology and kind of allowing to speculate versus actually using technology. And like we, you know, there's actually projects like orderly, which are, you know, all of the custody is on chain and you can inspect everything while all of the trick, like for example, execution and order book is off chain for performance and for, so like, stuff like this is possible. It's not like it's impossible to build performing things. It's just like it's been encouraged indeed to do a more, I mean, I guess reckless ways of doing things. But again, like, I think to point to bring back to the regulations, what's important here is instead of saying like, hey, we're going to regulate with more, I call it language, right? Hey, we're going to come in and say, like, there will be, you know, you need to come to us and register for this and that and the other. And this is true about web three and AI. They say for AI right now, if you're using more than this much teraflops for your training of your model, you need to register. And it's like, well, that makes no sense. First of all, the capabilities that will emerge from lower than that, nobody knows what they're going to be in a year. This technology is evolving. Somebody will open source, the weights will leak. None of this makes sense versus saying, hey, we ensuring that even if there's super powerful model, it cannot actually affect us in any way because we have this cryptographic identity and reputation. And then on the other side, we're registering the right things automatically through a blockchain and augmenting it with more and more information from external sources because it's transparent which data is being used, et cetera. That's the way to go again, both for web three and four AI, and for web three side, you can use AI to explain to everyone else, like what is actually happening, to actually interpret the source code of the smart contract in natural language, to explain what transactions have been happening. Right. Now, when you open a metamask and you see a bunch of bytes that you're signing, that cannot be the real world, right? Like, we should actually explain exactly what you're signing in transaction, and we can use for that again, like fine tuned models to explain it. So, like all those things just like coming together, really, like reinforcing each other, but they need to be used in the right way and really focus on that versus focus on some of the other things.
Speaker C: And I think to even go further on this, too, with what Ilya is saying, what we're talking about now, particularly, I'm obviously closer to the AI regulations side of the fence, but I am close enough to the crypto side to talk about this. It's all this weird kind of performative regulatory stuff. So going to the teraflops example here, it's like, sure, whatever, you can do that and have someone audit you, but we don't know what the capability that's going to be in a year, let alone 18 months or two years, etcetera. And so it's all this performative, classic nonsense from a regulatory perspective, when in fact, all someone has to go do is understand and go build some of the systems that can showcase what would be possible to go do and have these conversations publicly, in a way, from a transparency perspective. So again, going to where the data comes from, provenance and all that sort of stuff. Well, the system existed for us to register data sets into and say, this is what our training data sets look like, and go ahead and order them, or the weights or whatever, blah, blah. We understand that.
Speaker A: But, yeah, I mean, I see what you guys are saying. I just think some of, because at different points, it seemed like you were kind of referencing what happened with FTX or whatever. And I do feel that some of the problems that you cited, I don't know really how you would use blockchain technology to resolve some of those things, because there would just be the sheer number of things you would have to build to make that possible. Just seems so.
Speaker C: That's what I'm saying.
Speaker B: It's built. We have a project that's literally a as performant and as easy to use as centralized exchange.
Speaker A: But it does. It does.
Speaker B: Settlement and assets are all on chain.
Speaker A: And it does not only proof of reserves, but also, like liabilities going out.
Speaker B: Everything is literally on chain, like it's in smart contract. It's like the Defi Dex, but with the speed and execution of centralized exchange.
Speaker A: You should do a partnership with Coinbase or something to show how this works. Or binance might be up for it since they're in regulatory hot water.
Speaker C: Yeah, I think you're assuming Binance wants that in this case here.
Speaker A: Well, I mean, yeah, assuming they want to keep their business, they probably need to give an apple to the teacher. Anyway. We've spent plenty of time on regulation and we're running long. I do want to ask you one last question, though, which is obviously we've now seen a flurry of activity around the application of AI and blockchain or crypto. So kind of in the next year, what are different things that you're kind of keeping your eye on? Like developments that you are interested in following?
Speaker B: I mean, from my side, I do think the AI coordinated daos are really interesting, and I'm expecting some first results, like, you know, to come out. Everything from, you know, simple AI based treasure management to more maybe like coordinating people to do some activity in real world. I think that would be really exciting to see. And they will be governed by the DAO members, to your point. DAO members will be ensuring that this AI is operating within its mandate and potentially be biased. I think that we'll see probably this in next year, first examples of that working, and I'm pretty excited about that.
Speaker C: I'm focused on obviously getting my first model to market for poolside and making sure that it's already beating state of the art, which is what our expectations are based upon. Some more early model runs. But also, if I'm particularly paying attention to anything, it's going to be how the regulatory conversation is coming down and who is particularly, who is in it and how to help push that to a good spot from the AI side of the fence.
Speaker A: All right, well, this has been a very fascinating discussion. Thank you both so much. Where can people learn more about you and your work?
Speaker B: Twitter ilblackdragon or check out near.org for.
Speaker C: Blockchain operating system and Twitter. Jason C. Warner at Twitter and then a landing page at the moment. But Poolside AI will be there soon.
Speaker A: Perfect. It's been a pleasure having you both on unchained.
Speaker C: Thanks.
Speaker B: Thank you.
Speaker A: Thanks so much for joining us today to learn more about Jason and Ilya. And the intersection of crypto and AI. Check out the show notes for this episode. Unchained is produced by me Me, Laura Shin, with help from Kevin Fuchs, Matt Pilchard, Zach Seward, Juan Aranovich, Sam Sriram, Ginny Hogan, Leandra Camino Shashank, and Margaret Correa. Thanks for listening.
