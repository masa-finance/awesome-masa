[
    {
        "speaker": "A",
        "text": "Hi everyone. Welcome to Unchained, your no hype resource for all things crypto. I'm your host, Laura Shin, author of the Cryptopians. I started covering Crypto seven years ago and, as a senior editor at Forbes, was the first mainstream media reporter to cover cryptocurrency full time. This is the April 18, 2023 episode of Unchained. Unchained comes out twice a week, but crypto news breaks constantly. For up to the minute news stories, please check out our new website, unchainedcrypto.com, or subscribe to our mailing list. Buy, earn, and spend Crypto on the Crypto.com app. New users can enjoy zero credit card fees on crypto purchases in the first seven days. Download the Crypto.com app and get $25 with the code Lora link in the description web three projects lost nearly $4 billion of crypto assets in 2022, but nothing is more expensive than losing trust. Secure your company with Holborn's best in class security advisory solutions. Visit hallborn.com for more. Hey unchained listeners, as you know, its hard keeping up with the fast paced world of crypto, so weve got just the thing for you. Subscribe to our free unchained daily newsletter at unchainedcrypto dot substack.com. youll get the latest crypto news and original articles from our reporters, as well as summaries of other happenings and bullet points. Plus our meme of the day, all curated and written by our amazing team. Its still your no hype resource for all things crypto, just in newsletter form. Sign up at unchainedcrypto dot substack.com. again, the URL is unchainedcrypto dot substack.com. todays topic is MeV or maximal extractable value and the distribution of it. Here to discuss are Uri Klarman, CEO of Blockstrout, and Justin Drake, researcher at the Ethereum foundation. Welcome, Uri and Justin hey, good to be here."
    },
    {
        "speaker": "B",
        "text": "Thanks for having us."
    },
    {
        "speaker": "A",
        "text": "So before we dive into all the details on MEV distribution, let's first get some background out of the way, just so all the listeners understand the full context of this situation. So, Uri, we'll start with you. Can you just explain what MeV is?"
    },
    {
        "speaker": "C",
        "text": "Sure, MEV maximal extractable value is basically all the value validators can extract by ordering transactions, seeing trades, trading ahead of them, etcetera. In reality, what it really, really means is if somebody is trading is buying on uniswap a large amount of ETH let's say that is going to change the price. So there is value in trading just ahead of it, right. If you see a giant trade about to happen, you're better off buying ETH just before it happens, and then maybe selling that ETH immediately after it happens and you capture value. So this is sandwiching, it's a front running and back running. That's part of it. Also, if that trades happens on Uniswap, and now the price of ETH increased on Uniswap, but it's different, let's say on balancer or a different decentralized exchange, then there is arbitrage to be made, right? Buy cheap, sell high until prices balance back. Let's say two years ago or something. This was something done mostly by the traders themselves. So people participating in DeFi, starting with the deFi summer kind of starting these games started to run, try to execute their trades before other trades pay higher fees and et cetera, and identify where value could be captured. Then with the evolution of the MEV ecosystem validators, you could imagine that people could go and strike a deal with a single validator back then. Mining pools, I will pay you money, you put my transaction the way I want them, etcetera. It is really whoever produced the block, whether that's mining pools, whether that's validators, who has the power, and therefore they extract the value. With evolution of the MEP ecosystem, the current setup is that validators kind of like allow everybody to bid. If you produce this block, you will get one eth. If you'll produce that block, which has other transaction or engravement order, get 1.1 or two, or three, and whoever pays them the most, the validator would produce that block. So it maximizes the value. They extract that mostly go to their stakers, the e folders, and that's, I think, the TLDR on Mev. Justin, you want to add to that?"
    },
    {
        "speaker": "A",
        "text": "Well, Justin, yeah, so you can go ahead and add, but also I'd ask like, so Ori started to go into the different entities, like the searchers, builders, relays, validators. But if you could just like walk us a little bit through that process, just so people know those terms, right?"
    },
    {
        "speaker": "B",
        "text": "Sure. So I have a slightly more abstract definition of MeV, and I kind of think of it as the value that is generated by the economic activity on top of some economic system that can be extracted by some set of participants. And often in the context of blockchains, it could be the validators. But I really, we want to look beyond the validators. We want to look, for example, at the protocol itself. One very good example here is EIP 1559. EIP 1559 is a way for this extractable value that derives from the connectivity to actually go to some place other than the validators to the protocol. I think for the purpose of this discussion, we also want to be looking at the users. The users themselves create extractable value from the activity, and this MEV can go to the user as well. And actually, I kind of have this notion of a MEV precedence list. From a design perspective, what is the ideal outcome in terms of where the MEV goes? In my opinion, any MEV that's generated by the user should go back to the user, and then all the rest should go to the protocol. And basically nothing, or almost nothing, should go to the validators, because that's this toxic waste almost, that distorts the incentives that we have on the chain. Now, in terms of recapping the MEV pipeline, what we have basically is users who have some sort of intent in terms of generating economic activity, and then they will interface with some sort of wallet that will generate a transaction. This transaction usually is broadcast to a mempool. It could be the public mempool, but we're seeing the emergence of all sorts of other mempools, private mempools or encrypted mempools. And these transactions are observed in the mempools by searchers. Searchers take these transactions and they package them with other transactions. It could be their own transactions into bundles. Bundles are basically like mini blocks. And then these mini blocks get given to builders who make normal ethereum blocks. These ethereum blocks then get passed to relays. Relays are these temporary intermediaries for technical reasons, but eventually they will go away. And then the relays relay the block, ultimately to the proposer who signs it off, includes it on chain. And then there's a next level to the MEV pipeline, which is the attesters. So the attesters kind of really finalize the inclusion of the block in the chain."
    },
    {
        "speaker": "A",
        "text": "I love how succinctly you describe that, because it is otherwise sometimes seemingly a complicated process. And yes, this is definitely kind of a longer or not longer, but there's more entities involved than there used to be. I'm sure listeners are aware that MEV has been controversial. Haseep has talked about it frequently on the chopping blog, how there was a time when it was sort of really taboo for miners to extract this value, and then now it's become just part of how things are done, mainly because the way that what was happening was that people were doing it secretly, and it was causing all kinds of havoc for processing transactions. So still, people, I think, don't like the idea that oftentimes their transactions get front run, and so they get worse execution. And recently we saw that there was a group of various MEV entities that formed a group called MeV Blocker. And it's exactly what it sounds like. They're trying to block MEV from being exploited. They are saying that MEV exploiters have profited by $1.38 billion from everyday users so far. And I was wondering what your opinion was of MEV blocker, whether you thought this effort would succeed or if you thought it was the wave of the future."
    },
    {
        "speaker": "C",
        "text": "First of all, the MEV is still there. There is value to be extracted. The question is, does it go back to whoever generated the user, or is it being extracted to the validator and from that to the state? So it's kind of like, where does the value go? It doesn't disappear. It just might stay with the original holder of it, maybe the user who generated the transaction. And so, from the way I'm saying, it's not, well, you know, some time, people are upset that their transactions are being. Yes. If I send a transaction, somebody sees that and does something, so I get a worse price, and he expects value. That's a bad, unfair thing. If you don't see that, like, people, people aren't. There's a great discussion, like, well, what's fair ordering and what's fair and what's not fair. And for me, it's very simple. If somebody else made another transaction was faster than me, and he got there and not me, sure. Like, he was faster, that's totally fine. If somebody else saw me, what I'm doing, my transaction, my trade, and then did something in order to take advantage of what I'm about to do, that's unfair. It's very simple to me. There isn't like some great question there. And so what me, the blocker, does, actually, we might have been the first one to come up with this back then with, like, background me. Basically, the idea is that there are two forces here. Users trying to keep the value that they generate and validators trying to extract it. I think shout out to Thogard from Fastlane, I think six months ago, he wrote, like a good thread, like, these are the two forces, these are the two models. Both users and validator have power. It's not like neither of them is powerless. Validators cannot extract the value if the user won't give him the transaction. The user can't get their transaction confirmed if the validator don't get it. So there is a struggle of forces between the two, and the outcome isn't necessarily clear. I'm not sure where the value is going, and maybe we'll have to live through it. And to see where it goes, I would add, like, I think that's a great step forward. So, like, I think we definitely should be building systems where less value is extracted from users and go, whether that's for the protocol and whether that's to validators, no matter what the end result is, from my perspective, I always think of like, well, it's getting clubbed in the head you sent to get front run, maybe, oh, you know what? MeV Blocker actually doesn't do front running, only capture value behind. So I'm going to change. Like, I'm going to ignore that piece. So that's my general take. Like, it's a good thing, it's a step forward, but it isn't clear what's going to happen between these two forces."
    },
    {
        "speaker": "B",
        "text": "So I have a very strong opinion, which is that users have sovereignty over their data. And I don't just say this from an idealistic standpoint in terms of what I want to see the world. I actually believe that from a fundamental standpoint, they have the power, if they are sophisticated enough to get as a rebate, the MEV that they create. The problem right now is that we just don't have the tools. And MeV Blocker is one of these tools that makes it extremely easy for a user to be able to enjoy the sovereignty that they natively have over the MEV. Going back to this idea of MeV precedence, the way that I see this space evolving is that any MeV which is generated by a very well defined user. So, for example, a user making a transaction on Uniswap, almost all the MEV, let's say 99%, will go back to the user and the second tier player, which could be the validator, or in the case of MeV burn, it could be the protocol itself. They collect the so called excess MeV, or the so called latent MEV, which is just there from markets and efficiencies like arbitrage, and it's not clearly assignable to a very specific user from which the MEV originates. Now, in terms of MeV blocker, I'm still warming up to the name, but for me, blocker is about blocking something. And I think the big thing that it's blocking is front running. And a year ago, if you had asked me what is one of the big problems to solve for MeV is preventing the front running. But actually I realized maybe six months ago, but that there's an equally important problem, which is to actually enable back running, which is basically to facilitate the extraction of MEV from that transaction so that it can be specifically rebated back to the user. And so really there's two sides to the coin. You want to prevent the front running, but enable the back running. The reason why I say backrunning, and the reason also why backrun me by blocksroute was called that way, is because if you are a naive user, and for example, you make a transaction on Uniswap and you only hit uniswap then, now what's going to happen is that the price on Uniswap is going to be slightly different than the price on all the other Dexs. And so really if you were fully sophisticated user, you would use some sort of aggregator, maybe like, like matcha or one inch and the back running. It basically fills the gap between the unsophistication of the user and the optimal execution that you could have had if you were fully sophisticated. And it does that in a fully automated way, which abstracts away all the details. And just as a thought experiment, just to give you some intuition as to how this works, imagine that you had a mempool for transactions where the transactions didn't have signatures. You could only see the content of the transaction, but not the signature itself. And so what that mempool would allow, it would allow the searchers to create these kind of bundle templates that could potentially be included on chain if they had access to the signature, but they don't have access to the signature, and so they can't actually go ahead and extract the DMEV. And now the user who does know the signature, they can kind of selectively opt in to being part of this one bundle which is favorable to them, and disclose the signature for that transaction, thereby making it executable on chain. And I see this whole idea of rebating MeV as one of the big mega trends in MeV. And we've seen Mev share by flashbots, we've seen ideas like wallet boost by block native, OpenMev by manifold, and all of this is part of the same MEV rebating theme."
    },
    {
        "speaker": "C",
        "text": "Can I push back against at least three different things you said? Justin?"
    },
    {
        "speaker": "B",
        "text": "Sure, for sure."
    },
    {
        "speaker": "C",
        "text": "So first of all, so I feel strongly regarding MeV I'm actually like, oh, I don't think we should have an MEV auction. Like, rebate is not enough, but for a second, I'll take the hat off the other side and want to counter argue, yes, users have all the power. They want something to happen and capture or not. Validators also have power that you cannot ignore. There is, at least under the current consensus mechanism, there is one proposer, he is the one to include the transaction or not include it in the next block. A proposal could say, any transaction that doesn't pay me at least $1, I'm not including in the next block. It isn't worth it for me. And so validators do have the power to delay transactions. And if you're, if we are building, you know, the open global financial system of the world, then delaying transaction actually matters a lot. If you trade now at the current price or trade later at a different price, it changes a lot. So I'm not sure I completely agree with you. Well, you know, users can extract 99% or keep to themselves 99% of the value and value that will only get 1%. Validators might have a problem coordinate. A lot of it is about coordination. But you could imagine especially, and I don't think this would happen, but in theory, a large validator pool, or staking pool, who controls 10% of the stake. So, you know, like, okay, in these lots, your trade won't go through unless you pay x amount, and it is completely, you're the user might be better off paying a dollar per transaction because you're paying, let's say, $50. But it's a big trade. You're paying 50 to uniswap LP's one more dollar is very much worth it for you. So I'm not sure I agree with that piece about 99%, 1%. A different thing I disagree with you about. And I'm not sure I'll remember all three things I thought while you were talking. The other thing is that I'm not sure I agree regarding the rebate being a big thing. Okay. Rebates are nice. Like, you made a transaction, there is some inefficiencies, like, you know, you might, you traded on Uniswap, so there is somewhere else to be traded. But the actual price of every asset actually changes in real time. Outside of Uniswap, outside of the blockchain, the price of ETh constantly fluctuates in real time. A transaction in second one is different from that same transaction in, what, 10 seconds later? We just had like, a major bull run, right, 10% over like, like 12 hours or 24 hours. I'm not even keeping track of what's, what prices look like. It very much matters for the user. A user making a trade should, again, if we're building a good world, global, or a useful global financial system, it should get the correct price. I'm sending a trade now. Maybe that trade is trading against the correct price right now, but that price on Uniswap is no longer true 5 seconds later, etcetera. So getting a rebate is, you know, it's a step forward. Instead of user getting completely wrecked, they're taking some of the money back. It's by definition inefficient. You're making another action on chain to pay it back. Ideally, we want to build a system that the user send a transaction trade at the current correct price, and that's it. So by definition, rebating is inefficient, right? Like, maybe it's better than again, just reacting users, but it's not the future of France. From where I'm standing, this is not, okay, we'll get that. Maybe the third thing, because I really don't remember what was the third thing that I wanted to object to. Yes. Front running is the bad thing that affect users and actually get the worst execution, price, etcetera. Back running happens later. And you said, like, listen, maybe back running is as important. Again, going back to this idea of real price actually fluctuates and changes in real time. It should be the validator from my perspective, if somebody made a trade, he said like, okay, here's the price. You should get the correct price. But any price changes that happen afterwards, it's okay for that to go to the validator or wherever, not to go to the user. The user didn't get a worse execution. He saw the correct price, the current price, he got it. And if afterwards price actually changed or increased or decreased, it's okay for the validator or a different entity to capture any value left behind. It, it didn't hurt the user. It does hurt the user. If you frontrun the transaction, he gets a worse price. And so I don't necessarily agree that, well, we have these two equal problems. One of them hurts the user, the other don't hurt the user."
    },
    {
        "speaker": "B",
        "text": "No, I think I agree with this. This is second order details. And I agree with Yuri on pretty much all of it. Yes. So there is some potential delaying or price gouging that is possible by the validators, and maybe that is an optimal strategy. But basically what we have today is these minimal tips. If you have a one way tip, then most of the time you'll go in. But maybe some validators will enforce a hundred way tip. And in expectation, this might be a profitable move, because even if you have ten times less people willing to pay that tip, you're still ten times better in expectation. There are possible solutions here, including inclusion list and Mev Burn, but that becomes quite a quite technical, I guess, on the rebate. I think one of the points you're making is that it's not about the rebate per se, it's about optimal execution at the time of execution. And I totally agree with you. And then the other point that you made is that the technical mechanics of rebating with another transaction is suboptimal. And the reason is that you have these gas inefficiencies when you're dealing at the transaction level and trying to, to fix the transaction that was suboptimal. Really what we need to do, as you said, is we need to go back to the intent layer, because ultimately, users generate intent, they don't generate transactions. And then from that intent, submit one single transaction, which is optimal. And actually, I'd go even further than that. What you want to do is you want to take the intent of all the users that are willing to transact and then create one master transaction that optimally executes the intent of all the users simultaneously. This is a little bit what Cal swap is doing for a very specific application where they basically aggregating the intent of chain so that you have better execution on chain."
    },
    {
        "speaker": "A",
        "text": "All right, so one question, you guys. When I asked you about Mev blocker, first, I initially thought it only blocked the front running, but it does. Does it do rebates? I didn't read anything that talked about the rebates."
    },
    {
        "speaker": "C",
        "text": "So basically what it does is it takes transaction or an intent and prevent front running it, but also go and says, who's willing to pay how much to be just behind this transaction? And so if there is money to be made there, there's $100 to be made there. Then somebody would offer, I'll pay 90, I'll pay 91, I'll pay 92. Most of that value would go in rebate to the validator they're taking. There's a bid to pay, and that amount goes 90% to the user, 10% to the validator. And that is where going slightly to the previous point, I don't think validators would come and say, oh, I'm starting to extract value from where I'm standing and require 100 g wave transactions. But if all the value extracted back to the user, if it's fully protected, they're not extracting any of the MeV, then they might. At that, we say, why should I include all these transactions which are fully protected and etcetera, if I could potentially make more money? Somebody. Price of uniswap. If ETH is $1,000, price of ETH on binance just increased by 3%. Whoever gets to fix this and capture this arbitrage will make a lot of money. Instead of serving everybody who are keeping all their money to themselves. I won't. I would require high. So it's kind of like, it's. It's the collision of. Of these two forces. At that point, something like this may happen. If they get no value, but they have some power, then they would use that power. From my perspective, like, there should be some split. There's some split, or we're having a conflict. Desires, I guess."
    },
    {
        "speaker": "A",
        "text": "Okay. All right. So, like, I asked you a question specifically about that, and I had a separate question about all the other distribution things, because I thought that they were different in nature. So, I mean, we've mentioned some of these during the show, but, you know, back in February, flashbots, which does Mev boost, they proposed something called Mev share blocks route, as you guys mentioned, has background. Me block native has wallet boost manifold, has openmev. So literally all of those, including Mev blocker, they're all doing the same thing, but in different ways, is that there."
    },
    {
        "speaker": "C",
        "text": "Are currently, I think, twelve teams building these kind of projects."
    },
    {
        "speaker": "A",
        "text": "Okay, so what are kind of, like, the main differences between them? And, like, I mean, maybe you guys previewed some of that with, you know, your little debate there, but what would you say are kind of the main things that they're all trying to hash outd? Like, in terms of standards or what's the most common way to do things?"
    },
    {
        "speaker": "B",
        "text": "I can answer the question about similarities. So, they're all basically order flow auctions. Basically, the user is auctioning its order flow to the searchers, and all the searchers are competing against each other to rebate the most to the user, and the user will ultimately sign off on the searcher that rebates the most to them. And from a user experience perspective, you could imagine on metamask, two separate buttons. There's the traditional sign and option one, and then option two is sign and get $100 extra. I think what will happen is that most people will click on the second button. I think people don't necessarily realize that they're getting front run all the time. And so it's kind of this pernicious problem because it's happening behind the scenes, but people will notice the plus $100 button. And I think that is what will cause a sea change from a user experience perspective, because it's very, very obvious to the user that there is a benefit for them. Adopting wallets that give them rebates, maybe."
    },
    {
        "speaker": "C",
        "text": "Covering a bit of the differences. I think the main differences are whether these transactions, when they're auctioned, do they get sandwich front run and back run, or just being back run? I would argue, and I'm not sure Justin would agree with here, I think the flashbots teams see Mev as okay and fair, and therefore take a transaction sandwich, extract as much value of it, but try to distribute it. Mev blocker takes a slightly different approach. Prevent front running and just do the back running. These are the two main, I think, approaches done there. I do wonder. So, for the, I don't like the flashbot, as I started saying it earlier, I don't like the flashbots front sandwiching idea, because it's, okay, let's club the user in the head, but okay, I will club you and give you $50. He would club you and give you like $60, by definition. Like, doing that isn't a good execution. It's better than just clubbing in the head. But clubbing in the head and payment might not be really the outcome we should be aiming for. For the front running, just do back running. I actually don't know how MeV blocker, when he takes, let's say they offer it, and they include some transactions. Just back running transaction. I assume they take it, create a bundle from it, which is what the MeV ecosystem used to go and give it to a blockbuilder to try to produce a block front running that bundle sounds reasonable. So I'm not sure how they actually take it from there. They probably have. I'm not sure about the details, so maybe Justin knows what. How do they prevent taking that bundle and making a transaction happen before that? So somebody who do agree with the flashbot idea would say it would still happen. It just, that searcher won't front run the transaction. Somebody else would front run the transaction. Not sure how that's being technically handled."
    },
    {
        "speaker": "B",
        "text": "One very important design flavor of these mempools that give you rebates is whether or not it's a public mempool, and one which is permissionless. Anyone can join in, or if it's a centralized gated a mempool. Now, the easy way to build it is just the centralized way. And I think long term we really want to have these open permissionless mempools, just like the current mempool is open and permissionless and transparent. But unfortunately we need to do a bit more engineering in order to get simultaneously the private aspect and the rebating combined with the open permissionless. There's these two flavors, these two routes that you can take. You can either take the SGX route, basically, where you're trusting secure enclaves, for example SGX from Intel, or you can go the fancy cryptography route and you can use what's called homomorphic encryption, and you can use delay encryption and threshold encryption. The way that I see the progression basically is that we're going to start with these centralized proof of concepts that get us out of the door in terms of changing the user experience. And then hopefully we will upgrade to something which is SGX based, which is more permissionless open, and then eventually we'll reach the end game of having a fully trustless system using cryptography."
    },
    {
        "speaker": "A",
        "text": "All right, so in a moment we're going to talk about how all of this is going to affect the general ecosystem around staking, or I guess, validation. But first, a quick word from the sponsors who make this show possible. $3.8 billion of value was stolen from crypto projects last year due to compromised private keys, exit scams, flash loan exploits and other preventable causes. Holborn offers preventative security solutions for every stage of your software development lifecycle, from smart contracts, layer one and DevOps audits to advanced penetration tests, risk assessments, and incident response. With over 150 industry partners, including Animoca Brands, Solana foundation, and Ava Labs, Holborn's best in class security advisory solutions ensure the safety of company assets and user trust. Visit holborn.com for more. Join over 50 million people using crypto.com comma one of the easiest places to buy, earn, and spend over 250 cryptocurrencies new users enjoy zero credit card fees on crypto purchases in their first seven days with crypto.com earn get industry leading interest rates of up to 14.5% on over 30 coins, including bitcoin. Earn up to 8.5% on stablecoins. With the crypto.com Visa card, you can spend your crypto anywhere, enjoy up to 5% cash back instantly, plus 100% percent rebates for your Netflix and Spotify subscriptions and zero annual fees. Download the crypto.com app and get $25 with the code Laura, link in the description back to my conversation with Uri and Justin. So from what I'm hearing you guys describing, it kind of feels like the end game of this will just be that a bunch of services will compete on how much they can return back to the user. Well, that plus, I guess, better execution. So in the end, right now, most of the MEV is going to the validators, but do you think that the end game is that most of it will end up going back to the users, or where do you see this going?"
    },
    {
        "speaker": "B",
        "text": "The way that I see it is, roughly speaking, and this is just rough orders of magnitude, half of the MEV is generated by the user. I think half of it will basically go back to the user instead of going to the validator. Then the other half, which is this excess latent MEV, I think will actually go to the protocol. And this brings us to a whole new topic, which is MEV burn, which is the exact same thing that EIP 1559 did to congestion fees. But this time for what I call contention. Contention is this externality that comes from the fact that blockchains fundamentally have to order transactions when there is competition for this ordering. You have contention because various transactions are contending to be, for example, the first one that executes and collects the arbitrage and congestion is the fundamental externality that comes from inclusion as a service. So block space can be used in two different ways. You can either use it to include and confirm transactions, or you can use them to specifically order the transactions. And 99% of users only care about inclusion. But then there's this very sophisticated class of players like arbitrages, that don't care about inclusion. The only thing that they care about is ordering. And just like EIP 1559 kind of was this really beautiful design which allowed for kunta gesture fees to go to the protocol, as opposed to going to the validators. Mev Burn does it for contention fees. And the reason why this is important is because it provides us various security upgrades, and we could spend a whole podcast talking about those. But one of the things, for example, it improves chain stability. If you have a very big spike of MeV right now, the validators are actually incentivized to compete with each other and reorg the chain, and double spend and double sign and do all sorts of nasty stuff like denial of service attacks at the networking level in order to grab this bounty. But if you were to burn it, you remove this incentive. There's also this very interesting edge case with decentralized pools, whereby you have operators in a decentralized staking pool that are actually incentivized to rug the pool. So I call it rug pooling. So, just to give you a concrete example, rocket pool will soon have four EtH minipools, meaning that as an operator of this minipool, you have this four eth as collateral, plus a little bit of RPL collateral. Now, if you have a spike of mev, which is greater than the collateral, for example, if you have a. A ten eth spike or 100 eth spike, now, the operator is actually incentivized to forward the mev to themselves instead of giving it to the smoothing pool and forego the collateral to the staking pool. And so me v burn, for example, fixes this edge case, and there's like a whole slew of other edge cases that it fixes. And the other really exciting thing about me v burn is that in addition to these microeconomic game theory security improvements, it also has huge macro implications, just like EIP 1559 did with the burn. It improves scarcity, for example. But it has all the other advantages that EIP 1559 provides from a macro standpoint. For example, not overpaying for security. It's also a tax optimization, because when the rewards are paid, almost like a dividend, you need to pay income tax. But when you burn the rewards, you actually effectively have to pay capital gains tax. And so you kind of have this roughly 2.5. X tax optimization. But I'm going to be spending more time on podcasts, specifically trying to educate about the benefits of MEV burnt."
    },
    {
        "speaker": "A",
        "text": "And one other thing that I wanted to ask you, because you're also supportive of MEV smoothing. So are they essentially, is that just part of MeV burn, or is that like a totally separate thing, or can you explain that?"
    },
    {
        "speaker": "B",
        "text": "Yeah, that is exactly it. So the smoothing is one aspect of MEV burn. There's two aspects of me burn. Number one is the smoothing. And this is where all the security benefits come from, because you're smoothing out the spikes. The second big benefit of MeV burn is the redistribution. Instead of giving the MEV to the validators, you're giving it to the ETH holders. And that changes the macroeconomics of Ethereum as an economic system."
    },
    {
        "speaker": "C",
        "text": "I like some parts of Justin's vision, but I disagree with him on your first question. So where are things going from where we're standing right now? Yes, currently validators, or this is. We're starting to see that end. Like the bonanza of the validators is about to end. So MeV used to be captured by the traders competing on that, and then they got a lot of competition, started to pay higher and higher gas. So it was mining pools back then who used to, who started to capture that value. Now it is strongly the validators who capture that value. And as we said earlier, the user is starting to pull from their end. And there is this contention between whether the value go to the validators or to the users. However, the point I disagree with Justin is that Mev has indeed two halves. He said like, okay, one of them is like externalities and one for the users. Mev is a fancy word, okay? One half of all that value, roughly is front running transaction. People make a transaction, other people getting ahead of them. We see some people argue that, well, that's that whoever get front running background and sandwich just didn't do a good enough job to create the transaction right. Set the slippage just right, you'll be just fine. Like, this shouldn't happen if you know what you're doing. And that is not actually correct, okay? If you're making a large trade or trading a less liquid asset, or more than anything else, you make a trade, that trade is perfect, okay?"
    },
    {
        "speaker": "B",
        "text": "Exactly."
    },
    {
        "speaker": "C",
        "text": "The slippage, as it should be. But because price actually moves in real time, price just increased on a percent somewhere else, and all of a sudden, your transaction is actually willing to pay way too much for it. Okay, your transaction, which was created just perfectly, is now somebody should come, oh, this guy is willing to buy at this price? Sure, let's let him buy at this price and then push the price. So sandwiching that transaction, pushing, then back running and pushing the price back because, let's say price dropped by a percent. So even if you created that transaction at that time, in a perfectly the perfect setup, you still have to allow slippage because price would change. Not even talking about, well, what if some transaction just got ahead of you? Your transaction would fail because price moved by 0.001 basis point. So you allow for some slippage, the current ecosystem ensures you'll get the worst execution no matter what. So if price moved elsewhere, you know you're about to buy an asset and it went up, you're not going to benefit from it. Okay. No matter what, you'll get to the worst execution. So half of MeV is that the other half of MEV is c five defi arbitrage. There isn't as much insight into it. Stefan, who used to be at flashbots and now at Frontier, wrote a good blog post around it a month ago or so. Really? There are a few large actors with a lot of capital, both on DeFI and on CFI. And whenever the price moves between them, they capture that arbitrage. And that is really, that's around half of the other half of MeV. Yes, there's liquidation, yes, there's long tail MeV. Yes, there are other things. But these are the core two things that MeV is constructed of. Back to your original question. Where do I see it going from here? I see defi. The way it's working right now is not good enough. Okay. If we want to build the future of France, the next global financial ecosystem, open to everybody, always on online. 365 24 7365. But really, all of it is arbitrary. All the trading happened on c five, and the arbitrary isn't being captured and sniped on the defi side. So if we actually want to take DeFi and make it valuable and actually be an alternative, and competing with DeFi, not just arbitrage, battleground, I think the direction is completely different from the stuff that we're working on right now. Although I'm not against, like me burn, et cetera. I see. How can we have users get the correct price in real time? When I send a transaction, I should buy whatever is the price out there, and validators should provide this service. Whoever is the current value should be able to capture value from providing it. So I think of validators as service providers. They have the power to include transaction and ordering them. And if they would make more money providing this service and enabling real time defi, as an example, they could be making more money this way than front running and taking advantage of users. And so the future, as I see it, is moving from the predatory setup that we're trying to kind of like get out of right now and build something that is more useful, better for the users, who will get more, like correct, etcetera, and better for the validators. So kind of like this win win win situation. That's how I see the MEV landscape moving forward with a lot of big changes."
    },
    {
        "speaker": "B",
        "text": "Yeah, I mean, I would try and highlight some of the things that Yuri said. Like, one is that the MEV is not restricted to Ethereum. It's really, Ethereum bathes in this broader context of the real world. Really what we have is this multi domain setup, whereby if you want optimal execution on your transaction, more likely than not, you won't find it on chain. More likely than not, you might get a better price if you trade on Kraken or on binance or whatever it is. What I think will happen is that we are going to have entities that are going to very sophisticated ones that have very low trading fees because they have extremely large volumes. They're going to be on all the main exchanges and they are going to be giving users this optimal execution. Now the thing is that we don't want validators to provide that service. And the reason is that the barrier to entry to providing this optimal execution for users is extremely high. This is why in Ethereum we have this notion called PBS proposer builder separation. So we actually are in this amazing situation where the builders that need to be sophisticated are segregated away from the validators. The validators have to do almost no work. They basically have to pick the highest bid or do something like that. The heavy lifting is actually done by separate entities, the builders that are themselves relying on other sophisticated entities like the searches. Now another point that Yuri brought up is this idea of real time execution. And here we have this notion called pre confirmations. So if you look in roll ups like optimism or arbitrum, they have this service whereby the sequencer right now, which is just the centralized sequencer, gives the user some sort of soften commitment that they will be included in the next block. And this soft commitment comes within on the order of 100 milliseconds. So from a UX perspective, it's really, really good. Yuri is right that validators could be, or the whole MEV pipeline could be extracting more value by providing the service as opposed to not providing it. Now one of the questions that we can ask ourselves is how do we provide this service? And the answer is a little unclear. We could, for example, have the builders provide the service pre confirmation, whereby the builders promise to include these pre confirmed transactions in that next block. But we could also do it at the proposal level. Now, one question that we have from a research standpoint is how do we do this? This is where maybe Eigen layer comes in. Eigen layer is this restaking platform where the proposers can opt in to providing pre confirmation services. And if they don't provide adequate pre confirmation services, they stand to lose some of their stake. Thief. Now, thinking in terms of the future and what's next for MeV, I actually think there's going to be a whole new class of MeV. So right now, so far we've explored execution MeV, what is the value that can be extracted from execution and the two services that execution provides? Just to recap again, is inclusion and ordering. And this is where congestion and contention fees come in. But then there's this other kind of type of MeV. And that might be a bit of an abuse of the way the term is used today, is what I call consensus MeV, right? So the validators have stake, and they can restake to provide services like pre confirmation. And this pre confirmation service value is extractable value, right? That's the definition. It's value that can be extracted, but it's provided through restaking the stake within consensus, and it doesn't really involve so much the inclusion or the ordering of transactions. Well, maybe pre confirmations is a bad example, because it does involve the inclusion and ordering of transactions, but I think there will be all sorts of other services within the restaking framework which don't touch, which are purely orthogonal with inclusion and ordering."
    },
    {
        "speaker": "A",
        "text": "So, I mean, this is super interesting, but I do want to touch on a few things that we haven't yet discussed, which are, as far as I understand, I think wallets, especially dexs, a little bit, they are places where a lot of these transactions originate, but they haven't been huge revenue generators. And I wondered if anything about how MEV is changing would affect them or allow them to generate more revenue."
    },
    {
        "speaker": "C",
        "text": "I think recently people are talking a lot about the MEV pipeline or supply chain, which I think is a bad model, because when you think about the supply chain, you start with producer of a very small piece, and he give it to the next, who can build a bigger one and build a bigger one for the small one. And eventually you have an iPhone that's going to. However, the way MEV actually is, is like a mesh network. It's like user can interact, send a transaction directly to the builder or to the mempool to reach searcher. Or there is the Dex, there is a wallet, right? User use the wallet. Maybe the wallet speaks directly with the proposer, or with the builder, or with the searcher, or with both of them. So there are like all these connections between them. It's not like a single line that's kind of really is straightforward, where user validator, and everything in the middle is kind of like super thin straight line. And so I definitely think that anybody that creates value will have a way to capture some of that value. Definitely, you could imagine, and there's going to be competition. But large wallets, if the future ends up being like, let's say rebate to users, which isn't my favorite future, but let's say this is the case, you could imagine that one wallet will pass 90% and the other one will provide like 91% or 92%, or some percentage of that and as an aggregator of users, and it's not like competition, there's a problem. We want competition, but we actually also want good products, and we want them to make money to invest and build it. I think wallets that will do a really good job building the wallet. The users really won't care if the rebate is 85% or 90% or something. So that's like one future from the perspective of the wallet. Dexs could do something similar, but also whichever infrastructure or team or group of searchers that has access, let's say, who can run these transactions, maybe the Dex route is there, so maybe they charge them, or the users, or both. So you have this value flowing around, touching users, touching wallets, touching Dexs, touching proposers, searchers, builders, validators, stakers, everybody. And we should assume that everybody are going to try to take a cut. And that's not necessarily a bad thing. So if a wallet is really good and provide the user experience, and they're taking somehow some portion of the rebate, maybe it's a good thing, maybe it's a bad thing, I'm not sure. Like maybe people have strong opinions on it, but they definitely see, I'm already seeing all these actors tried to figure out how they could take a portion of these numbers, because as an aggregator, you're big, so it's okay to take a small portion from each one, and that's a decent size revenue."
    },
    {
        "speaker": "B",
        "text": "So, yeah, in terms of wallets getting involved, I think there will be this shift in the market where people will be incentivized to connect to things other than the default mempool. One of the things that I want to highlight as a risk moving into this new direction is that there's this notion of exclusive order flow. So right now, if you use metamask, there's this inherent fairness in a way, whereby your transaction goes through metamask and it gets broadcast to the whole world on an equal and fair footing. But what if metamask, instead of doing so, kind of send the order flow to preferred partners, preferred searchers or preferred builders? Then you're potentially in the scenario where you are effectively enshrining or king making some specific searcher or builder. And that is dangerous because there are some network effects to searching and building. The more all the flow you have, the better packing, for example, you can do, the better aggregation. And if we have decentralization at the search and the builder level, then now you make it easier to do censorship, for example. So it's possible that metamask will not give you all these nice services if you're interacting with tornado cache or something like that. Now the good news here is that we have technology that can give us all the advantages of rebates and front running protection with SGX and fancy cryptography. I think the other kind of tool that we have at our disposal is this notion of social norms, whereby it's frowned upon for wallets to be creating this exclusive order flow, just like it's frowned upon for a mining pool to have more than 51% of the hashrate, or it's frowned upon for a very large staking operator to only use one consensus client and one execution client. We want diversity, we want decentralization. So I'm very optimistic that in the medium and long term, we will have the technology that gives wallet operators the option to use credibly neutral, credibly fair and transparent mempools that don't kind of king make a very specific searcher or builder, and that the adoption of this technology will happen through social norms at the social level."
    },
    {
        "speaker": "C",
        "text": "So I enjoy strongly disagreeing with Justin today, although I like it a lot. And so I disagree with four things with this argument. If social norms were enough, then we wouldn't have be having this discussion. It was clear to everybody that mining pools are not allowed to order transaction or whatever they can't do over the counter or under the table deals with anybody. And everybody knew, like mine, like you speak with mining pools operator, like they knew way ahead that they could be making money like Mev, and they weren't doing it because everybody knew you're not supposed to do it. Until flashbot came out and said, well, this kind of happened, let's remove all the red tape around it. This isn't good enough. Of course it's fine. So like within six months, the entire social consensus changed. And nowadays, really, this was like 2020. Nowadays, of course it's fine that all the value, they try to extract the most value. So, social isn't like a good tool for this. Second one is we have some network effect in the searching ecosystem. Is an I Uber understatement. If somebody is a big block builder, all the searchers have to send him their bundles. Okay, so searchers find opportunities, they create a bundle, give it to the blockbuilder who tried to create a block out of it. If somebody is creating 1020 percent of the blocks, Zero X 69 is doing like 30% right now or something. Everybody have to give them their bundles. If you're a searcher, you don't send it to him, you're losing out 30% of opportunities. You really have to send it to them. Now, notice that block builders can take advantage of searchers. In theory, it's a trust relationship. I give you the bundle, but I trust you not to unbundle it and take advantage of my transactions. It's not trust, I don't trust them, I just have to give him my bundle. So there is strong network effect, that whoever has momentum, everybody else have to work with them. If some relay get a lot of the percentage off the proposers, and have some proposals that connect only to that, the blockbuilders need to work with that relay again, relay could do whatever it wants, it could unbundle everything, it could cheat everybody, etcetera. So there are very strong network effects there to the tech side. Okay, like we could solve it with tech, either SGX or I fancy threshold encryption and other things. SGX is being hacked roughly once a year, and there's a question I just asked literally yesterday, or the day, I think yesterday. How much would it cost to hack a single SGX chip? Like really, like if it cost a million dollars, then you can't have it secure more than a million. Like, does it cost a million? 10,000,100? I really don't know how much it costs, but it's kind of like it's the hacker's setup. I get to choose a setup, I just need one to crack one SGX, and then I could do something like sandwich the reaper, who kind of like, okay, take all the bundles, unbundle it, take advantage of the searchers, or threshold encryption, which solves it, but makes it even slower. Right? We talked about real time Defi, and whether it's valuable or not. You do threshold encryption. Yes, there is a, you could spam it, statistical, mev, whatever, etcetera. Maybe there's a solution to that. But whatever you do, it becomes even slower, making Defi even less suited to compete with c five. So I think that's a big problem. And we don't have like, oh, here are like, here are three solutions. There are a fourth thing, which I don't remember even at this point. No, this is a problem, and we don't have a good, like, solution for them right now. We are searching for possibilities, but this is a major issue that we don't really have a solution for."
    },
    {
        "speaker": "B",
        "text": "So, Yuri, I agree with all your points, just to emphasize my agreement on the strong builder network effects, I agree that not only do we want the mempool to be decentralized, but we also want potentially the builder itself to be decentralized, because if there's going to be strong network effects and logical centralization, then the best thing that we can do is have decentralization in the operation of the builder. So there is a possible future where there's one builder, just like there's one blockchain, but that the operations of the builder is itself decentralized. And that would be a future."
    },
    {
        "speaker": "C",
        "text": "Isn't that full circle for PBS? We separated the validator from the proposal, from the builder, and then we sent, and then we end up having to validate, like a decentralized setup with staked entities. We just went full circle to having the validators together build blocks. Like isn't this."
    },
    {
        "speaker": "B",
        "text": "The operators don't have to be the validators. The operators could be something else. It could be a separate chain. It could be based on fancy, a cryptography that doesn't necessarily require an honest majority, because the thing is that consensus requires honest majority. But maybe things like mempools and block building don't require honest majority. I guess you're right. If ultimately we end up with both systems being operated by the exact same set of validators, then we might as well remove PBS. But I don't think that's going to be the endgame. Yeah, I guess another very interesting point that you brought up is on the cryptography being high latency. And I agree with you that there's all these latency games, and really what we need is low latency cryptography. So not only does it have to be fancy, but it has to be low latency. And I'm optimistic that we can get that through things like hardware acceleration and whatnot. One of the good news here is that the latency has diminishing returns in terms of impact for the user. If we go from 100 milliseconds to ten milliseconds of latency, well, that might only be fractions of a cent in terms of improvements for the user. We just need to get the cryptography low enough latency to be practical, but we don't necessarily need it to compete with the decentralized block builders."
    },
    {
        "speaker": "A",
        "text": "We did touch on proposer builder separation, but I really want to ask about this directly. Justin, you brought this up a couple of times. So Ethereum does plan to incorporate proposer builder separation into the protocol itself. Once that happens, how do you expect that that would change mev and this trend we're seeing around distribution?"
    },
    {
        "speaker": "B",
        "text": "I don't think it would change much. It would basically just remove this semi trusted entity, which is the relay operator from the equation, and we'd have a more trustless and more robust ecosystem. But from the user standpoint, they're kind of higher up the supply chain. They interact with the interfaces and the searchers, whereas the relays, which is the focus of entry pps, they interact with between the proposer and the builders. So these are fairly separate ecosystems, and I don't think it will dramatically change the functionality of the supply chain. It will merely be a security improvement."
    },
    {
        "speaker": "A",
        "text": "And I also saw that Vitalik tweeted a roadmap that indicates that he's in favor of application level mev minimization and also eventually instituting this mev burn. So because he said it, do you think that that's where things will eventually head, or how does this all get decided?"
    },
    {
        "speaker": "B",
        "text": "So, one of Vitalik's kind of big strengths is that he's able to have a finger on the poles of the community and try and distill what makes sense and distill the rough consensus. So he's not trying to put forward an opinionated take on what he thinks the roadmap should be. He's really trying to reflect to the maximum possible extent what he thinks the community thinks the roadmap should be, and he's trying to minimize for possible disagreements with what he's suggesting in the roadmap. Now, I agree with him that there's these two things that need to be done. On the one hand, we need to either minimize or return the mev back to the user, and that could be done with better mev design at the application level. It could be done with better infrastructure off chain, with the wallets and the searchers. And I also agree with him that in terms of the so called excess mev, which doesn't get minimized or rebated, that it should ideally be burnt. And that's the topic for another episode."
    },
    {
        "speaker": "C",
        "text": "I would argue that everybody believes that Mev should be minimized at application. Like it's better, right? Like even thinking uniswap v two versus uniswap v three. Uniswap v two was put, it was creating a lot of arbitrage, opportunity, unity units of v three creates less. So because, like, the way the liquidity works, etcetera, you won't find a single person, I think, out there that say, oh, no, no, applications shouldn't try to minimize it. However, some MeV can't be minimized by the application there. As the example from earlier, okay, somebody made a trade, that's perfectly fine, et cetera. But then some 3 seconds later that trade is already out to date. And then there's mev, because the price elsewhere changed."
    },
    {
        "speaker": "B",
        "text": "Okay."
    },
    {
        "speaker": "C",
        "text": "Asset price change in real time and it changed. So you can't remove all of it by the application, but everybody wants it. I think Vitalik is awesome and a good person, which in crypto isn't necessarily is both smart and good, etcetera. I think, and Justin would probably disagree with me here, I think PBS is wrong. I think this is not the direction I lately started to have strong lightning network vibes with. Will we separate the validator to proposer and builder? And now we have a decentralized builders, and we have searchers and block builders, and we have another MEV focused layer, one which they participate in. Yes. Or, you know, validators used to build blocks. Can that have. So I just strongly disagree on that. Totally fine. I am in the opinion of the PBS isn't necessarily should already be on the roadmap. And of course we're doing it. The merge was just like what, September 9 months ago? Ten months less so, right. This is just like shaping out. I think we'll see a lot of more shaping out, like coming out of there. Okay, to be wrong here, but I actually don't think PBS is the direction and the thing we should solve for. I think validators should require little resources and run open source and provide services which create more value than taking advantage of users. Taking advantage of users actually require a lot of resources. That's like validators can't just do the front running themselves and everything, right? You need a lot of expertise, a lot of resources, simulation, etcetera. I think there are ways not to need PBS to create a better defi and crypto world. But that's just my opinion."
    },
    {
        "speaker": "B",
        "text": "Excellent, Yuri. I'm really looking forward to this amazing local block building that validators on the Raspberry PI could do. If you can build this, that would be absolutely amazing."
    },
    {
        "speaker": "C",
        "text": "Not sure about raspberry PI, but sure. I'll keep you in the hoop."
    },
    {
        "speaker": "A",
        "text": "I think I detect some sarcasm from Justin, but anyway, a tiny bit, so. But Justin, did you want to respond more like fully than that?"
    },
    {
        "speaker": "B",
        "text": "No, I agree with you. There is a possible future where proposal builder separation is not required. But like, intuitively, in order to be, you know, a good builder, you need to be extremely sophisticated, you need to have a lot of computational resources because you have this complex packing problem that you need to solve. You need to be extremely well connected to exchanges. You basically need to be a legal entity that crosses multiple jurisdictions. You need to have professional trading accounts on all the big exchanges. You need to have extremely low fees with these exchanges, so you need to trade extremely high volumes. Your average validator is not going to be trading trillions of dollars. And so they basically need help from other entities, which could be searchers or builders. And I don't see validators being able to single handedly build these optimal blocks. But maybe there is some system out there which can do that. So, for example, arbitrum is a proponent of this first come, first serve, which is this very simple model where a transaction comes first, then you just include it as it comes. And it is possible that you only need a raspberry PI to build blocks with a very, very simple strategy. Now, it is a possible future that these kinds of systems can be built, and they are incentive compatible. But the problem with first come, first serve is that at least our current understanding is that it creates externalities which are not great. It creates latency games, for example, and it potentially even creates incentives to completely bypass this whole system and recreate PBS. Really what I think will happen over time is that the incentives will shape the ecosystem, and then we should just see what this final shape is. And then depending on what it is, either have enshrined pbfs. If it makes sense, or if it doesn't make sense, because block building can be done fully locally very, very easily, then we might as well just remove enshrined PBS."
    },
    {
        "speaker": "A",
        "text": "All right, well, this has been a very, very fascinating discussion. We, I think, went pretty in depth on all of this stuff, and it's clearly not something where, yeah, just everybody is converging on one opinion, and I'm so glad that we were able to get a range of them for Justin and Uri. Where can people learn more about each of you and your work?"
    },
    {
        "speaker": "B",
        "text": "People can find me on Twitter. I mean, I don't tweet much nowadays, but at the very least, I have open DM's there. I'm also easy to reach on telegram and on Discord."
    },
    {
        "speaker": "C",
        "text": "Similarly, Twitter is a place to find me most of the time. I think. I think I stopped using my email because I have no idea what's going on there. But it's the coolest thing about the crypto ecosystem, basically, if you want to speak with somebody, you can find them on Twitter. Twitter. And they'll respond to you, and it doesn't matter who they are and who you are. So I think that's a very cool thing about our community. So find us on Twitter. Super easy."
    },
    {
        "speaker": "A",
        "text": "Yeah, let's hope that doesn't change in the future, given some of the things that are going on in that platform. But anyway. All right, well, it's been a pleasure having you both on unchained. Thank you so much."
    },
    {
        "speaker": "B",
        "text": "Thank you."
    },
    {
        "speaker": "A",
        "text": "Thanks so much for joining us today. To learn more about Uri, Justin and Mev distribution, check out the show notes for this episode. If you enjoyed this episode of Unchained, please share it with a friend. Unchained is produced by me, Laura Shin, with help from Anthony Yoon, Mark Murdoch, Kevin Fuchs, Matt Pilchard, Zach Seward, Juana Ranovich, Sam Sriram, Ginny Hogan, Ben Munster, Jeff Benson, Leandra Camino, Pama Jimdar, Shashank, and CLK transcription. Thanks for listening."
    }
]