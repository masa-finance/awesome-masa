[
    {
        "speaker": "A",
        "text": "Hey unchained listeners, as you know its hard keeping up with the fast paced world of crypto, so weve got just."
    },
    {
        "speaker": "B",
        "text": "The thing for you."
    },
    {
        "speaker": "A",
        "text": "Subscribe to our free unchained daily newsletter at unchainedcrypto dot substack.com."
    },
    {
        "speaker": "B",
        "text": "Youll get the latest crypto news in."
    },
    {
        "speaker": "A",
        "text": "Original articles from our reporters, as well as summaries of other happenings in bullet points. Plus our meme of the day, all curated and written by our amazing team. Its still your no hype resource for all things crypto, just in newsletter form. Sign up at unchainedcrypto dot substack.com dot. Again, the URL is unchainedcrypto dot substack.com dot."
    },
    {
        "speaker": "C",
        "text": "Not a dividend, its a tale of Tuqwan."
    },
    {
        "speaker": "A",
        "text": "Now your losses are on someone elses balance sheet."
    },
    {
        "speaker": "B",
        "text": "Generally speaking, airdrops are kind of pointless anyways."
    },
    {
        "speaker": "A",
        "text": "I manage trading firms who are very involved."
    },
    {
        "speaker": "C",
        "text": "Pollock Eth is the ultimate defi protocols."
    },
    {
        "speaker": "A",
        "text": "Are the antidote to this problem. Hello everybody. Welcome to the chopping block. Every couple of weeks, the four of us get together and give the industry insiders perspective on the crypto topics of the day. So quick intros. First, we've got Tom, the defi maven and master of memes. Next we've got Tarun, the giga brain and grand poo bod gauntlet. Today we've got a special guest with us, Ilya, who is the founder of Nier. So I actually, for today, because we're going to be talking about AI, I got GPT four to write some intros for Ilya, and you tell me which one you like. First one is Ilya, the near network's noble navigator. Ilya, the brilliant blockchain builder behind near introducing Ilya, Nier Protocol's pioneering pilot. Ilya, the founder and fearless frontiersman of Nier. That one doesn't rhyme with Nier, but that's fine. And then, Ilya, the Nier protocol pioneer with a visionary vibe. Welcome to the show, Ilya. Chad GPT welcomes you as well. And then you've got myself, I'm haseed, head hype man of Dragonfly. So we are early stage investors in crypto, but I want to caveat that nothing we say here is investment advice, legal advice, or even life advice. Please see chopping block XYZ for more disclosures. I should also mention, before we're kicking off the show, Dragonfly, we are investors into nier protocol. Tarun, are you also an investor engineer? We are. Okay, cool. So just so that, just so that we're all fully disclosed. Ilya and us go way back, and so he's a good friend and we're excited to have them on the show because in addition to all the crazy news that's been going on, there's been a lot of hype around AI and all the advances in machine learning, large language models, and we wanted to finally get a show to cut through some of the noise with somebody who knows about this more than almost anybody, especially in the crypto industry. But we are going to get to that. First, I want to get through some news because the last couple of weeks have been all about this banking crisis been going on in the US. Things are now winding down. And so we're going to take the first half of the show roughly, just talk about the news, and then we'll jump into a deep dive on AI. So let's update what's happened over the last week that's significant on the crypto side. So the first thing was that signature bank was one of the banks that was wound down. And there was this broad discussion within crypto about is signature being headshot because of its proximity to crypto and its crypto banking activities. So there was a report that FDIC went after it took over the auction process for signature, was requiring bidders to wind down the crypto business. So this was reported widely and then crypto was like, oh my God, it's happening. Operation Choke. .2.0 it's really true. And then FDIC official denied in a public report that this was the case. They said, look, thats not true. This is a bank. We want to get the best value for the bank. So any activities that are revenue producing, feel free to take them over. Then yesterday, which was Sunday, it was announced that signature was in a purchase agreement with New York Community Bank. New York Community bank was announced is going to be the buyer for signature, although the deal is not fully closed yet and New York Community bank is winding down the crypto business. So now was this off instruction of FDIC, not only winding down the crypto business, meaning probably signet, which is the time settlement system for signature, but also they are going to be debanking the crypto clients. So they're going to be asking the crypto clients, take your money, buzz off, go somewhere else, we don't want you here. So this again begs the question, was this FDIC kind of nudge nudge saying, hey, if you want this bank, get rid of this crypto stuff? Or was this just in your community bank just not liking this thing and saying, look, after Silvergate, I don't want crypto deposit money. It's not worth a headache. And it seems to invite more trouble than it's worth one way or another. This seems to be an indication that whether it was FDIC directly or whether it was indirectly through the treatment of all the crypto banks and the fact that all the stuff is in the news now, and you can't help but notice that banks, that bank crypto clients get a lot more attention from the regulators than they otherwise would like to, that this is causing this kind of stigma around banking crypto clients that's likely going to continue in the US. What were you guys perspective on this story about signature and the debanking of signature crypto clients?"
    },
    {
        "speaker": "B",
        "text": "Yeah, I think part of it is definitely a narrative that is being propagated in a lot of press outlets with respect to, oh, crypto caused these bank runs and crypto caused this banking crisis. And I think there's not a lot of truth to that. But obviously, it's a great narrative to tell, I think what happens, see what happens with SDB. Obviously, SVB is still looking for a buyer. They weren't a big crypto bank. Crypto is a very small percentage of their business. But if whoever buys SDB also winds down their crypto business, there might be more to the story. But this feels maybe a bit sort of isolated in some ways."
    },
    {
        "speaker": "D",
        "text": "So I know there's actually some other big banks that started debanking crypto companies even before SVB's kind of case started. So it's not like that message was already there, and banking regulators, I think, were already propagating that message. So I don't know if it's FDIC itself, but I like, I think it's already word on the street that crypto banking kind of is risky and people should stay away from it. On the banking side."
    },
    {
        "speaker": "A",
        "text": "Yeah. So Nick Carter made this point when he was, he wrote this blog post that's gotten, at the time, it got some attention. Now the attention on this blog post has exploded, where he describes this operation, choke, .2.0 which is basically this kind of full court press from the executive branch to try to put pressure onto anybody who touches crypto, the banking side. And it's now really manifesting that we're seeing bank failures. This is a perfect time to paint crypto as a scapegoat, as you said, Tom, what I'm curious about, so, one, obviously, there are banks that are starting to position themselves as being crypto friendly. Obviously, these are mostly smaller banks because they can afford to take more risk. Obviously, as a small bank, you're more like a startup and you're more willing to try to do something risky in order to win a big business. So cross river is effectively a startup bank that is doing this. And there are a few others that have positioned themselves as crypto friendly. A lot of the banks in Europe are taking the opposite tack. Europe doesnt seem to be quite as aggressive. Ilya, I know youre based in Europe at the moment. What is the vibe youre seeing from the european side with respect to crypto banking? Is this purely a us thing or is this spreading to Europe as well? Because obviously with Credit Suisse and all this stuff, obviously Credit Suisse has nothing to do with crypto. But there is a broader banking crisis going on in Europe now as well."
    },
    {
        "speaker": "D",
        "text": "Yeah, I mean, I haven't seen anything on the european side, per se. I mean, Switzerland has been always very welcoming. I think they're even more welcoming right now as this is kind of unfolding. UK is also trying to set up kind of better rules around crypto. They actually, as far as I saw, adding crypto on tax returns explicitly so that, you know, I don't know if."
    },
    {
        "speaker": "A",
        "text": "That'S being friendly to crypto. Wanting your pound of flesh from crypto."
    },
    {
        "speaker": "D",
        "text": "As soon as you put like, you know, if you say, hey, you should be paying taxes from this, like that means, like everywhere else, like this is, you know, now is an accounting software. It's in all of the systems. So like, now what rates are going to be taxing on? That's, that's the other thing. But I actually think it's like a."
    },
    {
        "speaker": "C",
        "text": "Way to, you're saying that, you know, weed in many us states is the same as crypto in the UK, basically."
    },
    {
        "speaker": "D",
        "text": "Is there tax returns on weed? No."
    },
    {
        "speaker": "C",
        "text": "Now they ask you directly and a lot of state filings where it's legal."
    },
    {
        "speaker": "B",
        "text": "Yeah, I think the UK is finally up to like 2019 IR's rules, which is like when, when it changed."
    },
    {
        "speaker": "C",
        "text": "Do you think Switzerland's going to continue to actually be positive after this current stuff they have?"
    },
    {
        "speaker": "D",
        "text": "Yeah, why not? I mean, like, for them, what's the difference?"
    },
    {
        "speaker": "C",
        "text": "Well, I just feel like they're banking sectors. Probably consolidating is probably like, means that the smaller banks don't survive. And, like, the smaller banks were the ones just like here that gave a lot of the crypto companies stuff like what was that bank, Seba, SCBA or whatever that did, like a lot of the 2017 layer one ICO stuff I'm just curious if you think they'll survive."
    },
    {
        "speaker": "D",
        "text": "Because so in Switzerland, they have an weird system where like there's Canton banks, which are actually can just like have all their deposits and not lend them. And camtons really want business. They really want people to come. When we were looking for foundation Camton governments were emailing me, cold emailing me, which was like, I'm like, what government does that?"
    },
    {
        "speaker": "A",
        "text": "Fascinating. Well, okay, so amidst this broader banking crisis, there's been one story that's been dominating Twitter. Basically. Twitter just can't stop talking about this, which is a good friend of the show, Balaji, who was on the show I think, a little while back. So he has made a bet, and his bet is basically a million dollar bet or a million dollar in USD terms. Hes basically betting a million dollars to one bitcoin, that essentially he believes that one bitcoin is going to go to a million dollars within 90 days, essentially because he believes that the us dollar is going to hyperinflate. Hes claiming very loudly and very aggressively on Twitter that the banks are insolvent, that the bank term funding program, which is the sort of liquidity injection that the Fed is providing to banks that need liquidity on some of their hold to maturity treasuries and mortgage backed securities, this program is pure quantitative easing. And that in this banking crisis, which is going to extend everywhere in the world, all the banks, or the majority of the banks are insolvent already. The Fed knew it all along. They're going to hyperinflate the currency in order to prop up the dollar system. And that bitcoin is going to go to basically infinity or a million dollars. And so, curiously, he's making two of these bets. So he's made one already. I think he's going to make another one. Or has he already made it? I don't know, but. So he's betting, I guess, 2 million USD that he's putting up against people's sort of bitcoin in return. And this is, it seems a little bit crazy. I've gotten a lot of people hitting me up and being like, hey, what do you think about this Balaji thing? Do you think hes right? Should I be worried? Should I take my money out of the USD? Whats your guys take on this balaji end of the world bet?"
    },
    {
        "speaker": "C",
        "text": "Maybe many observers have made the same point, but its a great marketing spend. At the very least, bitcoins already moved up ten plus percent."
    },
    {
        "speaker": "A",
        "text": "Its a great marketing space."
    },
    {
        "speaker": "C",
        "text": "He already owns more than 10 million worth of BTC, which is very likely he's already ev positive. I think the other thing is that this is the type of thing where it's directionally correct. Yes, there is going to be. Just look at the overnight banking operations changes over the weekend for all the central banks coordinating to provide a liquidity that's a little bit. That's very 2008. And I think directionally this is correct. There is just like a ton of operation. There are a ton of operations that are basically quantitative easing, 2.03.0, whatever. I don't know. It depends on how you want to index it. There's a sense in which such a bet will cause if enough people glom onto it will cause things to move in that direction, even if it's negative ev. And right now, all he's doing is basically recouping costs. But as long as bitcoin still goes up ten to 20%, he's fine."
    },
    {
        "speaker": "A",
        "text": "Preston. Okay, so you take a cynical view that you think that he doesn't actually think bitcoins going to a million, but he owns enough bitcoin that if he can meme a price, rally in bitcoin, which obviously bitcoin is rallying outperforming everything else. Right now that it pays."
    },
    {
        "speaker": "C",
        "text": "It's not just that it pays for itself, it's also that it's directionally correct. So even if it doesn't hit a million, he's always going to be able to be like, look, banks did hyperinflate. Even if I made the wrong bet, I got the right direction, and I just didn't hyperinflate enough. It has a little bit of, like, I can fall back on that. It's not just like, oh, I got it wrong. Yeah, I got the magnitude wrong. I got the direction right."
    },
    {
        "speaker": "B",
        "text": "All right, yeah, I agree with that. I think it's one of those things where, you know, even if you're off by, like, a fewfold, you can still sort of claim victory. It's kind of like people who thought, you know, there's gonna be a million people dead in the Us from COVID in, like, early 2020. I was like, okay, well, like, you got the timeframe wrong and, like, the numbers wrong, but, like, you were sort of right in, like, ringing the alarm bell. I think that's kind of what he's going for. But, yeah, I think I kind of disagree with his interpretation of what's happening with, like, bTFP. And, yeah, it seems more like, I mean, we're talking about on the show, everybody's talking about it. It's actually very difficult to get that, to get that kind of earned media for like a million dollars."
    },
    {
        "speaker": "A",
        "text": "That is very true. Super bowl ads are a lot more expensive than that, and I don't think they have the reach of this as."
    },
    {
        "speaker": "C",
        "text": "Much as I think Gabriel Layden, who founded Limit Break, is a marketing genius on the Internet. I'm not sure I would call the five to $7 million whatever spent on the Digidaigaku ad on the Super bowl very good. Whereas this is, like the most persistent marketing for a million bucks. If you compare it, it's unreal how good marketing this has been."
    },
    {
        "speaker": "A",
        "text": "Yeah, very fair point, I guess. Yeah. The issue that I take with it is that a million dollars is a 60 x increase in the bitcoin price. Right. This is not a direction. Oh, bitcoin went up and now it's worth 35 instead of 20. It's like, oh, you're still off."
    },
    {
        "speaker": "C",
        "text": "How many claims and marketing nine X are like, we're going to improve your life by 1.5% if you buy this product? No, they're all like, we're going to improve your life by five x if you buy this product. And this is just the same type of."
    },
    {
        "speaker": "A",
        "text": "Again, but GTX is like a. It's just a big hurdle, you know?"
    },
    {
        "speaker": "D",
        "text": "But anything else would not make people pay attention, right? Even if it was actually 100k, if it was 100k, people were like, yeah, it's kind of plausible. You know, the bitcoin Twitter would be like, super excited. You know, crypto Twitter would be like, that's interesting. And it would kind of die away."
    },
    {
        "speaker": "C",
        "text": "999,999 would not have memed."
    },
    {
        "speaker": "B",
        "text": "Right?"
    },
    {
        "speaker": "C",
        "text": "Like, you would not have got the attention and you would not have got the articles. Like, like, there's also this fact about choosing the number. It's like astrology, like choosing the right number."
    },
    {
        "speaker": "A",
        "text": "Somehow I guess I resist the Justin sun kind of energy that you guys are ascribing to Balaji here."
    },
    {
        "speaker": "D",
        "text": "But I think, again, it's a directional bet. It's not 90 days, it's two, five years. But if the system doesn't fix itself, there's something going to break."
    },
    {
        "speaker": "C",
        "text": "It's a little more like microstrategy meets Justin's son."
    },
    {
        "speaker": "B",
        "text": "Yeah, I think it was Matt Levino saying, if you really think bitcoin is going to a million dollars, you should probably just spend that million dollars and buy bitcoin instead of buying bitcoin for a million dollars today. But it sort of misses the reflexivity of bitcoin as a market and almost manifesting the price increase by putting this idea into people's heads. There's a core reason why you would see that kind of inflows, but you sort of create this meme around it, and that can sort of self manifest."
    },
    {
        "speaker": "A",
        "text": "Yeah. I mean, look, it's hard to know if it is. Like, okay, the counterfactual is hard to tell. Right. Obviously, at a time when the expectation of interest rates are cratering and banks are failing, like, okay, yeah, that's good for bitcoin. So that meme was already happening before Balaji made this bad. So it's hard to tell how much of a lift was Balaji's bet. And the earned press, as you guys put it. I mean, it does seem like it's having some impact because so many people are messaging me about it that I have to assume this is drilled itself into people's brains, that, hey, maybe you should be worried about this. The interesting thing is that unlike most of the rallies, altcoins are not following. So it's really just bitcoin breaking way ahead of everything else, which maybe lends some credence, because most of the rallies we've seen in crypto, especially around interest rates, have been pretty broad. Everything followed together. Now bitcoin is really breaking away in the market, and that maybe, again, it's hard to ascribe something that, oh, well, this is because of this thing. And who knows? Markets are crazy. Okay, let's take this showmanship of the bet aside. What about the claims in the bet? One of the things that Balaji and a lot of people on Twitter are arguing about right now is whether or not the bank term funding program, which is the credit line that the Fed is offering to banks on their treasuries. Is it Qe? And if it is QE, how stimulative is it? And should we be thinking about this as, hey, the Fed is totally about face. Now they're doing QE again, and we're basically going back to the kind of profligate, stimulative monetary policy that we had for the last ten ish years."
    },
    {
        "speaker": "C",
        "text": "If you asked someone in 2008 if this was the last failure, every time there was a failure, they would have said yes. Right? There's sort of this, like you're living in the fog of war. You don't really know what's going to happen. Central banks seem to be incompetent at communication right now. I only say that because of, like, this weekend stuff. I mean, did anyone watch the Credit Suisse press conference? That was a little embarrassing for the swiss government, I'm not going to lie. That was like, that did not sound good. Like, the media had some pretty hardball questions. And like, the banking officials, whether they were from UBS, credit suites or the swiss government, were just like, yeah, we don't know. It's fine. We'll figure it out. Like, in a very non polluted way that did not give anyone any confidence. For instance, one of the biggest things people fought about in the us bailout last time was like, oh, do people get paid bonuses or do they get clawed back? And there was a reporter who asked, hey, it seems like you're not culling pay of any executives. Is that planning on changing it? They're like, no, no, no. We just agreed on it, were like, never going to change this. And like, then there was this huge uproar, and then they were just like, oh, well, maybe we'll change it. And it's like, well, I guess they're making their decisions live at the press conference. It just like, it didn't really inspire confidence. And so I think this fog of war thing is also really true. So it's kind of hard to make such strong claims. That's what I'd say."
    },
    {
        "speaker": "A",
        "text": "I mean, so with this, with this bank term funding program, I think a lot of the assumptions people are making around it, claiming that it's QE and it's kind of this broad paradigm shift and how central banks are approaching the situation, almost all the assumptions I'm seeing about it. Arthur Hayes had a piece we just had on recently where he talked, I think it was called Kaiseki, where he talked about, hey, this is actually kind of disguised QE, and QE is back on and central banks start printing again. And I think almost every crypto take that I've seen about this, that basically calls it QE, is assuming that this program is going to keep rolling over. The reality is that the difference generally between QE quantitative easing and this bank term funding program is that in normal QE, you buy assets from the market. You generally buy toxic assets, and you often buy them at a premium, and you just hold them on your balance sheet for some uncertain period of time. You might hold them to maturity, or if theyre other assets like mortgages or whatever, you might just hold them for a while and then eventually sell them back when the market stabilizes. But basically, you're providing a lot of liquidity to the market and absorbing toxic assets for an uncertain period of time. That is not what the bank term funding program is doing. Ostensibly in this case, the program is explicitly for one year. It may be rolls over for two years, but in this program, instead of buying the assets outright, what they're doing is they're allowing you to borrow against it. They're basically saying, look, Im going to be a pawn shop for you, youve got these toxic assets, ill let you borrow a lot against it, ill let you borrow it at par, even though the market value of these mortgage backed securities or these treasuries is down and Im going to charge you 5%, basically Im going to charge you the prevailing interest rate. So this is not cheap, this is not cheap borrowing, but you can borrow from the Fed. Basically you have a year to tide over your liquidity needs. And if at the end of a year you cant figure out how to make money or satisfy your depository base, you're done. You're not going to make it. It's okay. You can argue like, well, are they really going to let the banks fail a year from now? If they didn't let them fail today, what's really the difference? I mean I would argue a lot of what the Fed wants is no shocks. They don't want shocks, they don't want sudden things to happen. But if these regional banks are just fucked, if they're just horribly mismanaged and they took a lot of risk and they can't get recapitalized and they need to get bought, then okay, you've got a year to figure that shit out, right? The thing that markets hate is uncertainty and volatility. If you can smooth that volatility, that's the purpose of a central bank, is to smooth that volatility and basically say, hey, let's give people a year to buy each other, acquire each other, reorganize their assets, make sure that we don't have sudden collapses. But if these banks are not viable, they're not viable. And I don't think the US is fundamentally committed to never letting another bank fail. Banks do fail. It's not that uncommon for banks to fail. The problem is banks failing at the same time. That's the thing that the Fed doesn't want."
    },
    {
        "speaker": "B",
        "text": "Yeah, I agree with your points with respect to the difference between QE and PTFB in terms of banks don't actually want to use PTFB unless they have an immediate liquidity constraint. And the nature and the scope of it is pretty limited. I think something that is somewhat different about Balaji's argument too, is that unlike zero eight, or maybe even 100 years ago, is the proliferation of social media and basically the ability of that to instigate bank runs in a way that is an order of magnitude or two faster and greater than it was back then, which you saw with SDB, with all these group chats and all these people dming each other and busy within 48 hours, everyone trying to withdraw their cash from the bank and that basically creating a credible strain and a need for liquidity, and thus tapping into BTFP, pushing more dollars into the system. And that's where he imagines the, uh, hyperinflation coming from. But I also think the hyperinflation thing is a little, um, maybe, maybe melodramatic. Like, I see a lot of crypto people, um, getting excited about the million dollar bet and oh yeah, you know, fuck the banks, fuck USD. I don't think anyone actually wants to live in a world where the US is undergoing hyperinflation. It would be extremely bad. Everything would go to shit. Even if you. Bitcoin."
    },
    {
        "speaker": "C",
        "text": "Someone needs to buy enough bitcoin to make Balaji's ev greater than zero on this bet, right?"
    },
    {
        "speaker": "D",
        "text": "I."
    },
    {
        "speaker": "C",
        "text": "And those are the people who are buying it."
    },
    {
        "speaker": "A",
        "text": "Look, I do think that bitcoin is going to do well, and I think it's plausible that this has. I mean, I think obviously this program is not, it's definitely stimulative to some degree, right. Obviously it's providing more liquidity, but it's not pure stimulus in the way that QE is. It's more subtle than that. But I think it is going to be good for bitcoin. And I do take Balaji's point that probably there's going to be more inflation. Obviously the Fed has to back off now, and interest rates are pricing in. The Fed is not going to raise rates all the way to five and a half or whatever it was originally. Theyre probably going to back off before the end of the year, and thats going to make it harder to tamp down on inflation. So probably, yeah, inflation is going to be elevated in the US for some time now. For those of you who dont know, hyperinflation is when you basically get into a reflexive inflationary loop where inflation just increases, increases and increases, and theres no psychological way to stop the expectation that the money is just going to get debased further and further. So tomorrow it's going to inflate more, and the day after that it's going to inflate more. And so you just want to get your money out as fast as you can, and nobody wants to hold dollars anymore. That kind of event has happened before, you know, it happened in Zimbabwe, it happened in Weimar Germany, happened in Ukraine."
    },
    {
        "speaker": "D",
        "text": "In the beginning of 19."
    },
    {
        "speaker": "A",
        "text": "That's right."
    },
    {
        "speaker": "D",
        "text": "I remember buying bread for 10,000. 10,0000 in a million was in like span of a year."
    },
    {
        "speaker": "A",
        "text": "Oh, wow."
    },
    {
        "speaker": "C",
        "text": "Nothing like logarithmic scales."
    },
    {
        "speaker": "A",
        "text": "It does happen, but it happens mostly in failed states and it happens maybe once a decade or so. There's a hyperinflationary event. The US dollar hyperinflating would be absolutely just batshit crazy. This is not a prediction you should take lightly as like, oh, the central bank is going to lower interest rates too fast, so it's going to hyperinflate."
    },
    {
        "speaker": "C",
        "text": "This is also why it's very clearly a trade, not a, a real philosophical bet."
    },
    {
        "speaker": "D",
        "text": "I think there's an interesting question of confidence of dollar. There's maybe nobody's counting this, but there's a global confidence in dollar latent score that outside of us countries are putting confidence. This is how much indexing their reserves into this, how much of the economy is transacting in ithood is like, is the events that have been happening going to help with this confidence? No. Right. So, like, it's definitely going to reduce index, which means this assets like the central banks, the kind of economy the companies need to go somewhere. And given what we see with other countries, like, a lot of them have similar problems. Right. And so there's an interesting question of like, yeah, what is the confidence? You know, where like, let's just say it's not a zero sum, but, you know, that confidence needs to go somewhere. And so that's, I think what at least, like, if I was Balaji, that's what I would be banking on. It's like, hey, like, here's an asset where you can put confidence in. The rules are known, the supply is known. Like, you know, a bunch of people already have it. Like, it's, you know, so far still easy to come and go in it. And, you know, if, if a lot of people even put a fraction of their kind of value into it, it's going to actually be like, then hits this reflexive state where people see it going up and they're like, oh, actually we need to go because Balaji said it's going up. Right? And so, like, I mean, there's like a huge reflexivity in crypto in general, right. And obviously, I mean, bitcoin has like less efficacy just being bigger, but, you know, just kind of kick started by like world events. And so the amount of attention right now on this is huge, you know."
    },
    {
        "speaker": "C",
        "text": "Actually, the reason I was laughing about this is my friend who's at OpenAI, and like, maybe it's a good segue for our AI segment. And, you know, he's been in AI stuff for like, maybe a decade. Okay, so my friends in the SF scene, especially EA, people are actually getting freaked out by the Balaji tweets. I literally got that while Ilya was talking. So all I have to say is, amazing marketing, right? There's no way you get a million. For a million dollars, you get anywhere near this level of dispersion."
    },
    {
        "speaker": "A",
        "text": "That is very true."
    },
    {
        "speaker": "D",
        "text": "Yeah. Somebody on Twitter said it's like balaji paid $2 million to be the main character for next 90 days on the Bluebird app."
    },
    {
        "speaker": "C",
        "text": "It's. And it seems to be working. I mean, like, I just think people who aren't even paying attention to crypto are suddenly like, oh, my God, what is this guy saying?"
    },
    {
        "speaker": "A",
        "text": "Okay, well, as long as we are kind of taking sides, let me just register that I don't think the us dollar is going to hyperinflate, but I do think bitcoin is going to do well over the next 90 days. But let's take that segue and transition over to second part of this conversation, which is about crypto and AI. So obviously, AI has been on the rise. Chat, GPT, large language models, diffusion models, everybody is going nuts now over this idea that AI is just the next massive technology wave. It's a platform, it's deflationary. It's going to change everything. Ilya, the reason why we brought you on the show is that you are the natural person to talk about the intersection of crypto and AI. So just a quick way of background, Ilya, you were originally at Google. You were actually working on Tensorflow, and you also were right before you left Google, you were one of the co authors on a very famous paper in AI called attention is all you need, which is the paper that introduced the transformer model, which is the model that is now used to train almost every large model in AI. It's basically revolutionized, basically machine learning at a scale that we've never seen before. Originally, before starting Nier protocol, you were starting a company called Nir AI, which was an AI company where you were trying to build a sort of GitHub copilot type thing back in the day. Obviously, you didn't have the resources that GitHub has."
    },
    {
        "speaker": "C",
        "text": "They still own the domain."
    },
    {
        "speaker": "D",
        "text": "And pun was very much intended."
    },
    {
        "speaker": "A",
        "text": "I'm sure it's going to go for a lot more today than it did back in 18, and then 18, you pivot into blockchain. And I remember the coffee shop where we initially met, and you pitched us on the very, very V zero version of Nier protocol, which was totally broken and made zero sense. But you guys were. You and your co founder Alex, were some of the most brilliant guys that wed met working in the blockchain space. So id love if you could talk us through what have you seen? So you were at Google basically at the seat of this when we were just starting to turn the corner on a lot of the problems that were, seemed to be insuperable back in 2018, 2017. People were excited about, oh, hey, we've got things that kind of sound vaguely like humans, or we had all these back in 2018. Every single problem in AI, whether it's syntax parsing or understanding natural language or machine translation, they were all these individual models that people were training and fine tuning on individual problems. And basically that is gone. It's not completely gone, but a lot of it has just been blown away by the generality of these large language models. Talk us through. What was it like for you seeing that evolution in your time at Google and beyond since you came into the blockchain space?"
    },
    {
        "speaker": "D",
        "text": "Sure. Yeah. So my journey in kind of neural networks, deep learning started, actually. So I was playing with this stuff when I was in high school, and I always thought it was interesting, but it didn't work. Like the kind of the neural networks back then were basically just the basic classifiers that you could not use for much. And then I remember reading a paper, which was Andrew Ng and Jeff Dean training using a large, at the time gpu cluster inside Google. And they were pre training model to look at the image and output image back and create a representation inside. And they found later inspecting it, that it had the neuron that would recognize cats. And so it kind of called cat neuron back then. And that was, for me, was the signal that I need to go into this. So that's when I applied to Google research and joined the team, because this was kind of the first time, we did not teach machine to recognize anything specific. It wasn't a classifier, it was just for training, and it found something that, like, relates to human concepts. At the same time, I always believe language is like images. There is thousands of species in the world that can actually navigate world, look at things, they have eyes, etcetera. There's only one species in the world that speaks language. And so I always thought that language is a way to kind of actually train these models and get them to actually understand and reason and make logical conclusions and answer questions with all this. And so that's what I worked on. Now, back then, state of the art was recurrent models. And recurrent models means you kind of one word at a time, pretty much read the sentence, and you kind of process it. And so, first of all, it's highly inefficient, right? Second, because of kind of the way these models are trained, it's actually very unstable model. And so called gradients explode when you try to train it. And so it was really hard to train them and even harder to put them in production. There's no recurrent models ever put in production at Google scale because it would take seconds to actually query out of it. And Google optimizes for millisecond response time. What it would do is we would then take and dumb down these models to just independent words without order and kind of train the dumbed down model that does not know anything about order in a sentence to then output the same prediction and then try to launch that. And we've launched a bunch of stuff like that. And so then there's a concept of attention came in. And so that actually helped a lot with kind of training these models, because it allowed to bypass this recurrence, right. This kind of step by step evaluation, and kind of look back into a sense, like, let's say if you're doing translation, look back into words in the sentence you were translating, kind of when you outputting the answer. And so that was the concept of attention. And then there's, like, few papers that, like, tried self attention as well. And so combining all this, right. We knew that kind of bag of word models were actually kind of okay without order, self attent kind of attention. And then self attention was an interesting concept, and we needed something that's way more efficient to train. This all kind of came in, and Jakob, kind of our manager lead at the time, came this idea that's like, why don't we try just not putting them in sequence, but just processing altogether, but then attending back into the whole sequence and using that to output. So for machine translation, for example, task outputting that. And so that's kind of how transformers started. And the idea was, I like to describe it for people who watched movie arrival. Instead of, like, we usually say one word at a time. The aliens were outputting the whole sentence at the same time. That's what that model learns to do. It's way more efficient, effective, which means you can train it longer, more, and at the same time, kind of the gradients, like, the actual training methodology is more robust. And so that's what we had first prototype, and that's where I left. And the team continued and got amazing results and published that. But the interesting thing is that model architecture started to work for everything else. They started applying it for images, they started applying it for other tasks, and it just worked without changes. And that's where I think people started experimenting more and more. And why it's now, I think, over 60,000 citations, because now everybody's just leveraging that kind of as a basic building block."
    },
    {
        "speaker": "C",
        "text": "I was only going to make one comment, which is, you said there's only one species that has language, but they're dolphins."
    },
    {
        "speaker": "A",
        "text": "Thank you, Taru. That was very useful interjection. Sorry, Ilya, go on."
    },
    {
        "speaker": "D",
        "text": "Yeah, next time we're going to do a dolphin to human language translation model."
    },
    {
        "speaker": "B",
        "text": "There you go."
    },
    {
        "speaker": "A",
        "text": "Coming up next. Powered by near."
    },
    {
        "speaker": "D",
        "text": "But, yeah, I think. And then the big change that happened is this idea of pre training, which I mean, which existed like, we all pre trained a lot of models before, but they kind of applied at like a huge scale, pretty much just feeding the whole Internet to this model, saying, like, I just predict the next word using this model and then we can condition you and sample from it, like, and kind of try to output. What would you, if you had this scene, this prefix would produce. That's what this GPT retraining team started to explode, really, because at a reasonable scale, that model started to actually create representations similar to that cat neuron example, started creating representations of world knowledge and being able to make reasoning, because it's seen so many times how people reason about things."
    },
    {
        "speaker": "A",
        "text": "So I remember I was following opening eyes work from the very, very early days when they first with GPT-2 and then eventually, of course, GPT-3 which is the one that took the world by storm. And I remember being absolutely fucking amazed that with unsupervised learning, just, basically, just feeding lots and lots of text into a model, that it could figure out such a wide variety of tasks that seemed to be incredibly idiosyncratic. Right. And so I think a lot of people internalize. There's this great essay by Rich Sutton called the bitter lesson, where he describes basically the history of machine learning was lots of people trying to solve these individual problems and thinking that the way you solve these individual problems is as a human being, as the architect of the AI, you have to encode into that particular AI idiosyncratic features of this problem to understand a face, well, there's a nose and there's two eyes, and there's some symmetry, and there's all this other stuff that the model needs to know that we know about the world. And only if we encode that into model is it going to get anywhere near the right answer. And that's what a lot of old school machine learning approaches would like, embed human known features of the problem into the problem. And what we've learned over time, especially within the last three to four years, is that that just doesn't scale. The thing that scales and gets to like the real state of the art for most problems that we have today, obviously there's like some extra zhuja fine tuning that we do for most of these things. But most of the way that you get to these world scale today is just throw fuckloads of training at it. Just like lots and lots of data, lots and lots of training, lots and lots of money. And if you just do that enough for almost every category of problem that we can think of, the machine figures it out way better than we can. And in a way like the human, you know, the human kind of symbolic craftsmanship just ends up being actually worse than just raw data input, which seems to belie an anxiety that a lot of people have now about AI, which is that, okay, now it seems more and more that the AI's just kind of need us to sort of like shovel it oil, which is data, right? Like, yeah, there's some fine tuning, there's some extra, okay, maybe we tweak the fucking training algorithm or whatever, but for the most part, we just need to generate lots and lots of training data. And the more training data we generate, especially, you know, with tragedy and reinforcement learning, with human feedback, a lot of it is just like the way that these models are getting better and better is like they already have huge corpuses, they already have all the writing on the Internet that we're feeding to it. The big thing is that we just need to train it to not lie to us, to be kind of friendly, to follow instructions. We have these gigantic eleven dimensional monsters, and we're trying to use just raw hours of human training to make it nice and be friendly. More and more, I'm seeing this nervousness from people about this new state because it was beautiful before this idea that like, oh, we teach it about the nose and we teach it the eyes, and then the machine figures it out and it's like, no, no, no, don't tell me anything, just give me lots and lots of pictures and I'll figure it out. I don't really need you. I don't know what your perspective is on that."
    },
    {
        "speaker": "D",
        "text": "Yeah, I mean, I think that transition was happening for the past ten years. Again, that paper was in 2013 that like, hey, you don't need to, like, handcraft things. Just throw. Just like, it's a basic model, right? Back then, it was just a convolutional network. Now it's just transformer, and it will build representations that it needs to solve its task. And then this representation is actually extremely useful across many, many, many tasks. And so there was this thing, embeddings, which still exists actually inside GBD models and everything else, which represents pretty much meaning of the word. It's like 100, 200 numbers. And these numbers represent meaning of the word. And people were training the model to get this embedding. So then using the symbetics and a bunch of other tasks, that was like, we were doing that in 1516, and it was extremely useful because it would capture lots and lots of different dimensionality of our world without, like, even, you know, us teaching it anything. And then we could use that dimensionality to then decide, oh, this is a city, or the person. It can be like, you know, is this some words that mean similar things, et cetera, et cetera. And I think this is just kind of continue expanding. But we should remember this is still tools. This is not a thing that has, like a, you know, I want to do this. This is like a tool we give instruction to, and it does things for us. And so I think it's important to kind of understand, like, at the base of it, it's a thing that, like, it ingested all the world knowledge. It has the common sense. Now, it has some resemblance of logical reasoning, although not always correct, but it's a tool that we kind of feed the input to produce output. Now, it's a really powerful tool. And I kind of the way people will start using this can be extremely dangerous. Right? That's why, like, you know, teaching it not to do bad things is good, but, like, people keep finding ways to kind of go around the teaching, right? And, like, you know, they close the one level. Now people, like, pretend you're someone who is. Who is pretending that you're someone that doing something, right. And like, that. That now jailbreaks kind of the system. So, like, it's a tool that, you know, people will be using for things. And so we should look back again at people and how this can be used and what things that people usually do with tools, good or bad and just magnify that by kind of the abilities of the systems."
    },
    {
        "speaker": "C",
        "text": "So actually you brought up Sutton before as he, Sutton sort of a famous author, in that he sort of coined the term to some extent, reinforcement learning, which in the eighties. But one of the reasons I think people miss the sort of like, hey, we can throw more parameters and we don't. It will eventually figure itself out, is that it's not just the idea that we were encoding like, hey, we need these features that are human interpretable, like a nose. But it's also that statistical theory still to this day doesn't justify over determined systems like this, where it's like, hey, we have way more models than even data points by orders of magnitude. And there's really no way to know if you can ever have something that's stable. Like, if I throw in one new data point, it doesn't completely destroy the model. But the last ten years have been a resounding set of examples of, hey, these models are sort of robust in a way that basically none of the existing literature could ever describe correctly. And I think to some extent, maybe the limits of such models that are overdetermined is that you can't really stop them in the sense of you can't really figure out what types of constraints to put to avoid these types of jailbreak scenarios precisely because you're like, okay, well, we're willing to just have way more directions to search in the model space than there are actual possible queries. And so there's always sort of some way of getting to whatever outcome state you want. And sort of the opposite philosophy of crypto, which is like, how do we restrict the number of output states quite dramatically?"
    },
    {
        "speaker": "A",
        "text": "I mean, what I've seen from OpenAI is that they seem confident that if you just do more, more and more, more, more reinforcement learning. Like eventually you will get it to sort of enclose that output space more and more, such that you kind of find these nooks and crannies that people are exploring by trying to jailbreak the system or get it to tell you how to hotwire a car or tell it how to hack a bank or whatever. All these things that people have managed to get chat, GBT and Bing, and Bing's real name is Sydney. Get Sydney to tell you how to do. And the reality is that we're at the very infancy of this stuff, and it's only going to get better, right? It's gonna get better. It's already gotten better insanely fast, and no doubt that is going to accelerate as people realize the economic value that is going to be unleashed with all these large language models."
    },
    {
        "speaker": "D",
        "text": "I think this is where it's interesting to think about. So OpenAI went from, hey, we're gonna build it and open source it and everybody can use it to like, hey, we gonna control it because we're afraid of what, how people will use it."
    },
    {
        "speaker": "A",
        "text": "Right."
    },
    {
        "speaker": "D",
        "text": "That's really kind of transition. And Ilya Subskever actually mentioned that, like, hey, I was wrong. Like, if you have such a powerful tool, would you really give it out to everyone to leverage? And this is where I think coming from a crypto blockchain, that three perspective and honestly, open source, like, I've always been doing open source in my life. Like, open source always wins. Like, there is no so far, like products that in long enough term open source did not take over. I think the only one so far is search. And this may change actually because of these models. And so the reality here is, yes, open source will be lagging maybe like one model, like one year of modeling behind. But for anyone who is following OpenAI footsteps right now, it totally makes sense to open source it because they get so much street cred for doing that. And they don't lose anything because, well, OpenAI has kind of theirs not. And we already see like a bunch of them are open sourced. Like some of the models you can run on your laptop that like, reasonably powerful, like this, obviously not, not near GPT four or GPT 3.5. But they started to get there and the reality is like, it doesn't matter what you, what OpenAI does to train it. Like, there will be models that will be used in all kinds of ways."
    },
    {
        "speaker": "C",
        "text": "Did Facebook get street cred? That's my question for you."
    },
    {
        "speaker": "A",
        "text": "Yeah, that was a very. I was about to bring that up as well. So Facebook, they invented this model called llama, which is much smaller than in terms of the number of weights than GPT four. We actually don't know now opening, I won't even tell us how big the model is, but GPT-3 we know is I think, 175 billion parameters. And Lama, they release these models that are significantly smaller. The smallest one, I believe is 7 billion, which is enough that you can run on your laptop."
    },
    {
        "speaker": "C",
        "text": "And they show mobile phone even."
    },
    {
        "speaker": "A",
        "text": "Oh, wow, I didn't realize that."
    },
    {
        "speaker": "B",
        "text": "Yeah, someone has a run on pixel."
    },
    {
        "speaker": "C",
        "text": "Yeah."
    },
    {
        "speaker": "A",
        "text": "Oh, wow. Well, they demonstrated that actually if you, instead of blowing up the size of the model, if you just train the model for longer, actually you can get significant increase in performance that approximate a lot of what you get from something like a GPT-3 but not only that, there was a more recent paper that came out from Stanford called Alpaca that showed that if you basically use in conjunction the outputs from a bigger, more robust, better trained language model, you can actually approximate that model really, really well as long as you have a big enough model that you're training on. And so you can imagine the gigantic blob, big brother, GPT four training this little llama model running on your mobile phone, actually can get your mobile phone to really closely approximate the big monster, which is surprisingly cheap, I think they said roughly on the order of 100,000 input output examples, which is crazy, which basically means that the edge of having a gigantic model that's hidden behind a wall and that nobody can access and the weights are secret and the size is secret, that actually, that moat just might melt away. If in fact this a co optive training can be done at scale, because you never know when you're talking to somebody. Is this person training another model to try to steal my internal knowledge? And that might really change the economics for how these large language models end up interacting with each other."
    },
    {
        "speaker": "D",
        "text": "Yeah, so this is actually exactly what we were doing to launch stuff at Google where we would take expensive model and then we would train a way cheaper, like bag of words or whatever model, just by feeding the input to the bigger model and kind of training the smaller model and output. So like, this is like distilling or, you know, there's a few different terms how to call in that. And that's part, part of the reason. The other part, yeah. That you just can query out kind of information out of this bigger models, even if they're closed source. So that's why I'm like, open source will win, right? It's like, we'll get this out. And smaller models can approximate very closely indeed this. So I think the mode there is, again, it's just like it's people multiplied by compute, multiplied by data. But I think the most interesting mode is actually product. It always was at the end. If everybody believes chat, GPD is the main thing where you find the best state of the art, everybody goes there, everybody talks to it, everybody feeds data to it. That data then improves the models that becomes still ahead of everything else because they just don't get this flow. And that's what Google bin. Google bin, not compared to bing and other search engines, because it became kind of like state of the art. People kept feeding it queries and clicks and these queries and clicks. Then fed back into improving the model. And so there was no way to kind of turn that around again unless you completely change how this thing is kind of interacting. And so I think the interesting mode OpenAI has is in product land, not in the model architecture or purely data. It's in this feedback loop that they now built."
    },
    {
        "speaker": "A",
        "text": "Okay, so I think this is a good place for us to bring it back to crypto. So obviously, AI is huge. Everybody's thinking about it. And so, naturally, given how hype driven crypto is, there's a lot of people who are now trying to take the two and mash them together and see what. Is there something that we can do with crypto or blockchains to enable AI?"
    },
    {
        "speaker": "C",
        "text": "To be fair, to be fair, every cycle has had a lot of, oh, yes, non reputable scam versions of this. But I think our goal in this conversation is to focus on the actual real ones, not the marketing. Just as a disclaimer to anyone who is listening, who is like, oh, you missed AI coin, and it's like, well, AI coins, git repo is nullified."
    },
    {
        "speaker": "A",
        "text": "Okay, well, so there are a few threads that I think we keep coming back to. And to be clear, this isn't just with the advent of chat, CPT, and these large language models. I remember when I first started getting into crypto investing in the 2017 2018 cycle. They were also a bunch of AI hype driven, blah blah blah type blockchain projects. But I think we keep coming back to a few core ideas. And Ilya, I want to get your take on what you think about the intersection of crypto and machine learning. So three years in particular, I think, that get the most attention. The first one is private machine learning, whether it's using zero knowledge or fully encryption or multiparty computation one way or another, finding a way to make machine learning training happen in a way that is privacy preserving. The second is decentralized training. So obviously you've got all these companies spending huge amounts of money on training these models. Is there a way to decentralize that and do a kind of peer to peer, you know, folding at home kind of thing? Uh, and then the third is, what if you just put the fucking model on chain and you do inference on chain, which obviously is, you know, you, you want, you wouldn't want to do training on chain because training is super expensive, but inference is so much cheaper. So does it make sense to just put models on chain and, you know, query them that way? Which of these approaches do you think are the most interesting and why walk us. Walk us through them if you can."
    },
    {
        "speaker": "D",
        "text": "So let's start maybe with the current state, right? So the current state is these models are trained on supercomputers which are built out of a purpose built hardware which is called Nvidia A 100. And there's a new version which is h 100 or tpus at Google. Or there's like few other, like tranium and few others in other organizations. But kind of generally speaking, this is like when it says Nvidia GPU, it's not the gpu you have in your play game box to render graphics. It's especially designed for four AI training gpu's. They cost $30,000. So you usually use about like for GPT-3 ish model, you would use 1000 of them for three months. So this is about a million dollars worth of kind of cost to train a model like that. So there's not that many, like, kind of companies right now that can afford this. And so this gpu's a thousand. Them are interlinked with kind of very high speed connectivity. And when I say very high speed, this is like 6700gb/second this is faster than connectivity between the GPU itself and the local Ramirez, like the memory on the computer itself by like almost order of magnitude. So it's literally easier to send data to another GPU than to say and like, recompute something later than to save things and load it back. So that's the current state of how this models are trained. And so when somebody says, like, hey, let's do decentralized training on like, a network that, you know, barely maybe can push like 1 perennae second, and we're talking about, you know, 7800 gigabyte per second. We're way, way more, you know, orders of magnitude away from this actually happening. Right? And plus, like, people generally don't have this kind of hardware. People have, you know, let's say people have leftovers from the GPU mining that we're doing for Ethereum. Well, that's like, you know, or orders again, of magnitude far away from what usually these chips are used right now. So can you do decentralized training with the current setup, with the current training dancers? Nothing closely to what you need to train any of these models, like, for real. Right? And again, we're talking about, let's say again, gbd three because we know the parameters, 175 billion parameters, right? You need, you know, I think like 20, 2030 GPU's, 32 gigs of Ramdhenne each to just store that model on this thing and then being able to pass through it. So that's just coordinating that making that is just so not effective. And so anybody who is doing this really right now will not be using anything. They don't even want to use custom hardware that doesn't work with either XLA or Nvidia right now. Because if you're betting on custom hardware or custom setup, that's not kind of in the common. It's just something that nobody who's right now rushing to build better models and kind of out compete each other will be doing because they're willing to spend more money, even if it's to just be in the same kind of setup that is reproducible and doesn't have risks. So I think that's probably the main when everybody's like, hey, let's do decentralized training, let's do private training similarly, right? Well, private training is done either on secure enclaves which don't have any accelerator, accelerators, MPC possible. But like, you know, you adding a huge kind of overhead on just like, you know, computing parts aggregating, like it's going to be probably ten to 100 times lower and you still need the same level of compute, right? You'll still need. And synchronizing between different clouds, for example, would be huge. I think at the end where I think if we call decentralized training, what does make sense right now is this marketplace of hardware itself, of the supercomputers is completely closed. If I want to train something, and I do have a million dollars, I need to call up Amazon, I need to call up Microsoft, and I need to call up Google, maybe a few other organizations and negotiate with them a rate. And so I think what blockchain is really good at is opening up marketplaces. And so what we can do is opening up marketplaces of supercomputers so you can kind of have a better price discovery on where is the supercomputer and having better resource allocation. Like kind of auctioning off this compute around the world where people are building these clusters."
    },
    {
        "speaker": "A",
        "text": "But like you said, the kinds of GpU's, GPU's in name only. The kind of GPU's that you use to train these models are not consumer GPU's. These are not things that people running a node at home are going to."
    },
    {
        "speaker": "D",
        "text": "Have, and you cannot actually buy them. So you need to be a large bulk buyer. I think you need to like, I don't actually know what's the minimum buy, but like Nvidia will not sell you like can I buy a couple?"
    },
    {
        "speaker": "C",
        "text": "We can back estimate this based on the fundraise sizes of, like, adept and traffic, right? Like, so I don't think they actually."
    },
    {
        "speaker": "D",
        "text": "Bought their own hardware, though. So I."
    },
    {
        "speaker": "C",
        "text": "They will know."
    },
    {
        "speaker": "D",
        "text": "One startup that has access to this like everybody else is like, literally you need to be a cloud, like a billion dollar cloud level to buy this. I know only Lambda, which is able to buy them from Nvidia, and they've been, they've been doing this like, I've known them doing this, buying GPU's for past, like almost ten years. That's why they probably have the access."
    },
    {
        "speaker": "C",
        "text": "I will say that having seen a bunch of these fundraising decks between stable diffusion and adept, 90% of their fundraising decks said 80% of our funding is going to build our own clusters. And they actually are really trying to convince people right now. What I'm saying is Nvidia is not going to be like, oh, yeah, this billion dollars of money raised, we can't sell to that. I think they're just going to probably charge them more and it's pretty clear they're going to charge them a lot more. But my guess is the minimum order size is 100 million, roughly, based on the."
    },
    {
        "speaker": "D",
        "text": "Probably. Yeah. And remember that it's like you buy GPU's and you need to buy all the other stuff. Like, there's networking stacks for sure. Yeah."
    },
    {
        "speaker": "C",
        "text": "I agree. I mean, the Sli infiniband stuff itself is probably as much as the GPU's."
    },
    {
        "speaker": "D",
        "text": "But any engineers who then can maintain all that."
    },
    {
        "speaker": "A",
        "text": "Okay. All right, so TLDR anything that's going to be an impediment to training either one, you don't have the money, or two, even the kind of machines you would need to train in a decentralized way are so expensive, very few people have access to them. So I think blockchains work well when you're coordinating resources that lots and lots of people have, and the distribution of these resources are very decentralized. This is not the case for a 100s from Nvidia. Very few people have them. And so you don't need to blockchain to coordinate them. Just go call up the three big cloud guys and they're the ones who have all these."
    },
    {
        "speaker": "C",
        "text": "It won't stay that way, though. There's no doubt that someone will actually try to break the monopoly here. And obviously, AmD has tried and has failed so far, but I think there's going to be a day that some of these other accelerators are good enough and they're cheaper."
    },
    {
        "speaker": "A",
        "text": "Right? But it's hard to imagine that it's not going to be the case that the most cost effective, right, like the most kind of energy efficient and cost efficient approaches to training are going to be basically gatekept by the people who have the economies of scale, but maybe."
    },
    {
        "speaker": "C",
        "text": "Not for these distilled models, right? If you're bootstrapping off of just like training a smaller model off the open AI API."
    },
    {
        "speaker": "A",
        "text": "True, true, true."
    },
    {
        "speaker": "D",
        "text": "Yeah. So if we're talking about smaller models here, it's totally different story. Right? And I mean, you can potentially get a server with few GPU's consumer grade and train it and people doing that, like researchers."
    },
    {
        "speaker": "A",
        "text": "Yeah. So the day that you have a model on your phone that approximates one of these large language models fairly well, and you can do fine tuning of that model through some cloud GPU's that maybe are not quite sort of state of the art grade. Is that a case where you think that, okay, in this kind of situation, you can imagine having some kind of GPU marketplace and maybe there's enough demand there for this consumer level fine tuning of these miniature models that the economics can work. What's your take?"
    },
    {
        "speaker": "D",
        "text": "I think the question is if it's enough to have few GPU's, getting them off the cloud is actually pretty easy. Or buying a server with four GPU's plugged in, like kind of, what's the reasoning? Right. It's not that you need it, generally speaking, to be decentralized. And so if it's a rentable resource and there'll be ton of demand and clouds are not able to satisfy the demand, that's when it can start spilling over. And like people buying this, you know, maybe servers can offer it for rent. That means like, you know, clouds need to really like not satisfy the demand or start censoring someone from using it. That's the only reasons why this moment would start."
    },
    {
        "speaker": "A",
        "text": "Sure."
    },
    {
        "speaker": "B",
        "text": "I was going to say I think you have a compute marketplaces and obviously decentralized compute, verifiable compute has been, it's been a meme in crypto for a long time. But the other meme has been owning your own data and data permissioning in data marketplaces. I feel like that's been the other point of contention or debate with these LLMs is they're ingesting images and text from the Internet, training these models on them, and specifically for diffusion models and image output. Artists feel maybe deceived or hurt that their work is then being used to train these models that they don't really see any benefit from, I believe Getty Images is actually suing open air stable diffusion for basically training their models on Getty Images, even though they're not necessarily licensed to do that. I'm curious to get your thoughts on this crypto meme of owning your own data, making people pay you, or advertisers pay you to actually access your data and train on it. Is there a new life to this idea with the rise of LLMs, or is it still just impossible to actually do this in practice?"
    },
    {
        "speaker": "D",
        "text": "Obviously, being on the crypto side, I want this to work, but practically speaking, we still don't have tooling to do that. And so I also think, I think it was stability that took out whatever that content was, trained models, and they were pretty much kind of same quality. And so generally speaking, it's like, unless we actually flip the script and actually start creating provenance for all the content we create, that is cryptographic, that is potentially also enforced by law, that you need to kind of have include provenance as you kind of process this content further. Like, we will not be able to, just like by the current systems will not be able to use this data. And if data belongs to users with this limited, I would say law, kind of regulatory enforcement. So I think this goes back into like, what we need to start doing is that the content that we produce, and I mean AI as well, but especially humans produced, needs to be cryptographically authenticated. It needs to have provenance and needs to be leveraged. And I think this actually will become even bigger problem because these models are kind of effective tools to create insane amount of content, right? And so one of the kind of core issues is that all of the kind of societal systems actually run on language. They run on language. You file things with language, you read news, you look at what candidate their platform is or video of that. All of these systems are highly susceptible already to manipulation. You don't need AI to manipulate them. People manipulate them all the time. AI just gives you this extreme leverage to create this. And so you can be reading a book which literally has all the same characters and all the same kind of overall story and complete a different narrative, and you will not even know that, right? You can be going to this website and seeing the same titles, the same author, the same everything, and completely different narrative that's already possible to do now, to create this deceptive content. So we need authentication path for everything. Otherwise we're going to actually live in this. Like, everybody will see its own version of reality. That's completely different from what you think you're putting out."
    },
    {
        "speaker": "A",
        "text": "So, interestingly, I remember when GPT-3 first came out, and certainly chat GPT, people started really worrying like, oh my God, how will we ever know that a human being wrote something? And then with stable diffusion, it's like, oh, how will we ever trust an image ever again? And obviously this is going to, when we have good video models as well, people are going to say this about videos. How do I know that's Barack Obama making out with Mitt Romney or whatever? How do I know that's real? And I think a lot of these things are a little bit of an overreaction. We've had Photoshop now for 20 years and things are fine. Obviously, Photoshop does affect things. Fake media does end up going viral sometimes, but for the most part human. It's not like civilization has collapsed because Photoshop exists. We find ways to figure out chains of provenance and authentication of what's real and what's not. And I think we're going to adapt because that's what society does. Society adapts to technology, period, every time it does. That being said, I do agree with you that we do need to have better authentication of raw inputs that come into society. So one of the things that, one of the most obvious things is how will we know that an image that comes from a camera is actually a raw image from a camera and has not been manipulated? If you have some kind of physically unforgeable signature from the camera itself that verifies that this image was taken from a camera. And maybe there's a small number of transformations that were applied to this that are not manipulative as the color was tuned or it was cropped in such and such way already. I think we're starting to see hardware that can, I'm sure that we're going to see this with video as well as just cameras and audio as well, you can verify this thing came from the real world and it was physically produced, and we can have some certainty of that. And maybe someday your browser, when you right click on something, it'll show you like, ah yes, this thing came from a Nikon D seven, blah, blah, blah, whatever on such and such date. That, I think is the path that this stuff has to go in order to co evolve with the speed at which generated content is going to compete with real content. And I think it's plausible that blockchain crypto is going to have some role to play in how that information gets authenticated, stored, tracked, et cetera. Or maybe it'd be way simpler than that. Maybe you just hit the Nikon API and your browser just knows the Nikon keys or, I don't know, something like that. What's your take on this question of physically verifiable data?"
    },
    {
        "speaker": "D",
        "text": "Yeah, so I think some cameras already do that. Like there's a secure enclave that signs photos on some cameras. I think like Sony added that and like few others. And there's like, actually it's, you know, metadata on Nikon and everything I think similarly needs to happen for, you know, let's say, you know, we record this video like we should all co sign on it. That indeed this is a video that we produced and we talked about. Right. So things like that, we kind of need to make this almost like a new normal, a new habit. But I totally agree. Like, we will adapt. This is not like we have all the tools. It's not like an unsolvable problem. We just need to do it. And I think the more things that will be breaking, the more we'll be fixing, the faster we'll be fixing them. So I'm kind of introducing new habits around us where again, like our identities are, you know, have cryptographic information and so you can like co sign directly on the YouTube that like, hey, yeah, you know, yes, I recorded this video or like I participated in this video or this quote is mine on inside a newspaper article. Right. And so that kind of creates this like prominences that then browsers show robustly. I think that the important part though that some people were like, oh, you know, we should enforce fingerprinting in the output of the AI models. I think that part is like just not going to happen. People will always go and remove that fingerprint in the code and just do it without. And so I think authenticating content as a source is the right way to do it."
    },
    {
        "speaker": "A",
        "text": "Okay, so we've talked about the things at the intersection of crypto and AI that maybe don't work or are not likely to work anytime soon. What are you bullish on at the intersection of crypto and AI? What do you think is going to work?"
    },
    {
        "speaker": "D",
        "text": "I can say one thing that's been working is data collection. So data collection in general is how to get a lot of people to contribute data for some income, some reward. And this is literally what blockchains are really good at coordinating. A bunch of people doing some work. 1 may call it proof of work, actually. On nier there's been near crowd a community built project which has been running for past two years where one to 2000 people every day has been working and labeling data like various tasks and creating a massive data set from that. So that part is, I think, very straightforward. It's like fits micropayments and coordinating people, kind of a marketplace of tasks and people. And so that works really well. I think that kind of continues scale and used in more different ways because you can introduce that as part of some experience you can introduce because as Tom mentioned, data has value. And so as people do something, they can receive reward for that data then flowing back into the model. But then it does need to be fully authenticated and unchained for that to happen. So I think that works. I think there's interesting examples of this model that can run on your device. So like more on edge computing that are applied to your data. And so that will be interesting again, more in the conceptual web three, not specifically, crypto world is starting to have a personalized model that fine tuned on your stuff without leaving this. And for that you don't actually need that much compute. You probably don't have millions of data points anyway. So you just kind of run a few back props on that. I think there's interesting question. I'm always been excited and that's why we're doing Neo AI is on coding. There's an interesting intersection of decentralized data that belongs to users. Decentralized services, meaning they're open, accessible, they're not going to disappear. And coding, which if we think of this end user coding, where they're not going to probably build complex stuff, but they can mix by describing what they want, they can mix existing services and existing data. It's really hard to do that in web two, because the services are closed, APIs are not always known, the source code is closed. All these things here in web three, we actually have everything open saying, hey, can you build me a front end that combines Aave compound and Uniswap and creates me a ten x leverage? That's actually possible now to do, because the smart contracts are public and also services to pull data public. And so it can create that front end for the user at the moment pretty much in a custom way. And I'm really excited about that. That is a vision of what we were trying to do originally. And I think that's going to attract a lot more attention as well to how people interact with services, because now there's UI problems may disappear or may be reduced as well."
    },
    {
        "speaker": "A",
        "text": "So I really like that. And it augments a lot of the way that I view the intersection of crypto and AI, which is that they may not like the way that crypto and AI intersect, in my view, is probably not going to be that there are going to be large tokens that you can invest in that are going to make a lot of money, that are the AI tokens. And those are going to pump, right. Obviously, right now there are a lot of AI tokens that are pumping as the AI trend is getting more and more exciting. But I think the two are interlinked in more subtle ways. One of the examples you mentioned is just the fact that obviously, as code generation and AI has become better at writing code and building front ends, that's obviously going to be good for crypto, because crypto will have better front ends and the programming will become more efficient and cheaper. And eventually you're going to have. Already, there have been examples of chat, GPT, sort of, quote, unquote, auditing code and finding, you know, common vulnerabilities. So I think all these things are accretive, right? They sort of make human beings better, and making human beings better makes blockchains better because blockchains are made today by human beings. I do think. I wrote a tweet store about this a little while ago. One of my theses about the intersection of crypto and AI is, I think, a little bit more forward looking, which is that, you know, today. I think you mentioned this earlier, Ilya, is that most of these models, almost all of them that we're interacting with, like the large language models, we sort of make them kind of look and feel like people, but it's a bit of a sleight of hand, right? These are not actually agents. They don't have any kind of persistent preferences or desires or anything like that. We sort of make them pretend to because that's what human beings like. But eventually we are going to have more agentic models that have long term memory, that are going to be goal directed and are going to try to be doing things in the world world. And when we have those kinds of AI's and they're so far away, I think to have them realistically beyond just like video game environments, when we have those kinds of AI's, I think those AI's are going to want to solve problems that involve shared resources. And we know how to solve problems that involve shared resources. We use money. Money is the way that we negotiate access to shared resources. Whether it's a, you know, whether it's a message bus, whether it's a, you know, whether it's, you know, turning into a lane, whether it's asking somebody to do something for you that's easier for them than it is for you. The way we solve all those problems, a huge category of problems, is with money. And so AI's are going to want to use money, but they're not going to be able to use fiat money because chase is not going to open a bank account for an AI. They won't even open a bank account for a crypto startup, so they're definitely not going to do one for an AI. But the fastest way to get onboard onto money is just by owning a private key. If you can manipulate a private key, which pretty much any AI can figure out how to rent a. If you can rent a cloud gpu and stick the key in an enclave and then give it instructions, boom. Now all of a sudden, you can use money just like everybody else, and you can coordinate with other AI's, you can get an AI to work for you. You can end up employing somebody else to work for an AI or an AI driven organization. And so I think the ways in which these two things are going to intersect, I think, is not that, okay, there's some big, maybe there are going to be some applications, certainly, that are going to be blockchain accelerated, potentially decentralized labeling, and maybe generating training sets. But the biggest thing is going to be that AI's are going to want to use money and they're going to use crypto because it's just faster, it's easier, it's digitally native. That I think is going to be an accelerant, maybe, in a scary way, for how these AI suddenly start interacting with us in the world. And so you can imagine someday, instead of balaji making this crazy bet, it's going to be like some very poorly calibrated AI that's making bets on Twitter."
    },
    {
        "speaker": "C",
        "text": "There's a very famous crypto investor who, I won't say who it is, but one of the first times I met them, I remember they told me their vision of the future in 2016 or 2017, which was the world's richest entity in 50 years, will be a broken Tesla, because a Tesla that's broken and can't be used to be a cab will have to train itself, because it'll have all these GPU's on board to basically become an investor because it can't do its normal function as a Tesla, and then it becomes the world's greatest investor on its own. Trust me. I was like, I did not."
    },
    {
        "speaker": "A",
        "text": "What? What? This was an investor who told you."
    },
    {
        "speaker": "C",
        "text": "This is their thesis of a famous crypto investor that you ever. Everyone in this call knows."
    },
    {
        "speaker": "D",
        "text": "Tesla."
    },
    {
        "speaker": "A",
        "text": "Wait, is this Kyle? Tell me. This is Kyle."
    },
    {
        "speaker": "B",
        "text": "I don't think we should disclose on the call."
    },
    {
        "speaker": "C",
        "text": "Yeah, okay. But it was that sort of matches what you just said for the record, a little bit."
    },
    {
        "speaker": "A",
        "text": "I don't know if I'd say that matches. I wouldn't endorse that particular thesis that we're all going to get beaten in our investing prowess. Bye. Broken Tesla. But I've been proven wrong before."
    },
    {
        "speaker": "D",
        "text": "But I think the general idea that blockchain is a place for autonomous agents to pretty much interact with each other and the world in general is true. And we actually actively building more and more ways for them to do that. And, I mean, there's already agents interacting, right? They're just very basic. Like, maybe they don't. They use basic machine learning to predict prices for arbitrage and do a few other things. But as there's more and more externalities for the blockchain, and there's more and more ways to do this. Imagine a very simple system where the model indeed is trying to beat the market by investing. You give it $1,000, and you give it access to also ask people to do stuff again on chain, which exists. You know, there's, like, job markets on chain. And so now it can, like, decide, you know, buy. Buy a crypto coin, you know, sell a crypto coin, or ask a, you know, humans to do something. And so it may start, like, invest and may start to actually suggest people to start its own project that it's gonna pump, you know, by posting stuff on decentralized social media. That's. That's actually possible now."
    },
    {
        "speaker": "A",
        "text": "No, what'll actually happen is broken Tesla starts doing NFT scams. That is absolutely how this broken Tesla is going to end up making all this money."
    },
    {
        "speaker": "D",
        "text": "Yeah. Generated generates nfts with mid journey and then."
    },
    {
        "speaker": "A",
        "text": "Yeah, exactly."
    },
    {
        "speaker": "D",
        "text": "But anyway, but this is totally possible now. This is like, this is not science fiction. This is possible now."
    },
    {
        "speaker": "A",
        "text": "Yeah, interesting."
    },
    {
        "speaker": "D",
        "text": "But the question is, like, who put it together to do that? Right? Like, at the end, it still was a will of someone."
    },
    {
        "speaker": "C",
        "text": "I'm waiting for someone to make broken TeslA capital, which is their entire thesis. Their entire thesis is we're investing in the future of the broken Tesla that eventually becomes the world's greatest investor."
    },
    {
        "speaker": "A",
        "text": "I feel like now, next bridge hack I see, I'm going to be like, shit. Was this a broken Tesla that hacked this bridge? All right, I think we're at time, so we have to wrap. Ilya, thank you so much for sharing your font of wisdom with us. I hope that next time we're having this conversation, we can just generate you. And we don't have to bother you out of your day. But for now, we appreciate you showing up in person. That's it, everybody. Thanks, everyone."
    },
    {
        "speaker": "C",
        "text": "See ya."
    }
]