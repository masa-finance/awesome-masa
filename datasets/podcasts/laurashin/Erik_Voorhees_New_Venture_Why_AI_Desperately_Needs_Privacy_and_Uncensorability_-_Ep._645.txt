Speaker A: An AI agent can't go set up a bank account or I would love to see a try. It's hard for a human to do that and they have a corporeal form. An AI can only use digitally native rails for payments, and that means it has to be cryptocurrencies. So there's no future world where AI's are running around paying each other in fiat. They're like incompatible concepts. So as crypto develops, as AI develops, these things I think will converge and it'll become very obvious to, I think, even the AI people in the near future that for economic interaction, the only way is to use actually digitally native assets.
Speaker B: Hi everyone. Welcome to Unchained, your no hype resource for all things crypto. I'm your host Laura Shinna, author of the Cryptopians. I started coming crypto eight years ago and as a senior editor at Forbes, was the first mainstream media reporter to cover cryptocurrency full time. This is the May 14, 2024 episode of Unchained. Did you know? Unchained is much more than a podcast? Last year we unveiled a completely redesigned website enriching your experience with the latest news, insightful analysis, compelling op eds, and comprehensive learning articles and guides for beginners. Explore all this and more@unchainedcrypto.com. dot deploy custom crypto strategies and boost your yield with perpetual options on Vaultcraft, the Universal Defi adapter for supercharging your crypto. With version V one five users can now earn options on optimism and arbitrum, while also rebalancing multistrategy yield products all in one vault. Learn more on Vaultcraft. IO Polkadot is the original and leading layer zero blockchain with over 2000 plus developers and the Polkadot 2.0 upgrade will be a massive accelerator for the ecosystem, making it faster, more secure, and adaptable. Perfect for Gamefi and defi to build, grow, and scale. Join the community@polkadot.net work ecosystem community hey unchained listeners. As you know, it's hard keeping up with a fast paced world of crypto, so we've got just the thing for you. Subscribe to our free unchained daily newsletter at unchainedcrypto dot substack.com. you'll get the latest crypto news and original articles from our reporters, as well as summaries of other happenings in bullet points, plus our meme of the day, all curated and written by our amazing team. Its still your no hype resource for all things crypto, just in newsletter form. Sign up at unchainedcrypto dot substack.com. again, the URL is unchainedcrypto dot substack.com dot. This episode is brought to you by Shopify. Forget the frustration of picking commerce platforms when you switch your business to Shopify, the global commerce platform that supercharges your selling wherever you sell. With Shopify, you'll harness the same intuitive features, trusted apps, and powerful analytics used by the world's leading brands. Sign up today for your $1 per month trial period@shopify.com. tech all lowercase. That's shopify.com tech.
Speaker A: Whoa. Landing an account this big will totally change my landscaping business.
Speaker C: It's going to mean hiring more guys.
Speaker A: And more equipment and new trucks for the new guys to drive the new equipment in.
Speaker C: I don't know if I'm ready.
Speaker B: You can do this, and Ford Pro Finsimple can help. Our experts are ready to make growing pains less painful for your business with flexible financing solutions that meet the needs of your business today when you need them. Get started@fordpro.com. financing today's guests are Eric Voorhees, founder and CEO of Venice, and Tiana Baker Taylor, COO at Venice Aihdeme. Welcome, Eric and Tiana.
Speaker C: Hey, great to see you, Laura.
Speaker B: Eric, after your long and storied history in crypto, you are now launching this new venture, Venice or Venice AI, which is one in a burgeoning new sector of crypto and AI projects. What inspired you to move to this sector rather than doing something purely crypto?
Speaker A: Yeah, well, my heart, of course, always belongs to the crypto world. And if you had said a year ago that I'd be involved in something that wasn't explicitly and purely crypto, I would be doubtful. But as I got into the AI stuff just first as a hobbyist and started seeing how cool this technology was, and I started realizing that the big AI companies were already starting to censor what could be said and what the machines would convey back to you. And I started to realize that, like, oh, actually, you're not actually interacting with a machine. You're interacting with some weird combination of machine. And then the committee that decides what's acceptable discourse. And to me that seemed dystopian today, but that would become worse and worse over time. And then governments start getting involved, and now you have various administrations starting to talk about licensing AI and curtailing speech in various ways, always done under the name of safety. And I realized that AI is so powerful that it actually needed to break out of the centralized monolithic framework, and you needed to have a world where permissionless AI was a thing. Not that everyone needs to use those systems, but they better exist. So I realized I should build that. And so Venice is our answer to that. And it's basically a chat GPT like app, but private, so it's not spying on you, and it doesn't censor what the models say. Back to you. And we wanted to make it just as easy as a chat GPT, but without all the orwellian stuff. So that was the goal.
Speaker B: Great. And Tiana, you have worked at HSVC, circle and Binance. What inspired you to join Eric in working on Venice AI?
Speaker C: Well, a couple of years ago, when Eric decentralized shapeshift, I said to him, then, what are you going to do next? And he said, I don't know. And I said, well, whatever you do, I would like to be a part of it. And so when he called me, it was definitely a no brainer, because I wanted to work specifically with Eric. But equally, I had been thinking about some of the existential challenges around these new types of knowledge and truth tools coming to the forefront for consumers, for everyday people to play with this technology. And it was a similar type of experience to when I realized, and I had an aha. Moment. I just kind of woke up one day as a transaction banker and said, I can't do this anymore. I don't want to do this anymore. And it was really built around not being involved in an ecosystem that did not facilitate access. And so having fair and open access to money was incredibly important to me. And I think having fair and open access to information and the ability to increase your knowledge and to aid critical thinking is incredibly important. And I see the advent of technology, especially with our younger people, almost kind of stifling creativity and stifling critical thinking. And I think these types of tools will help improve that, the ability to kind of challenge information. But if that information source that you're using to increase your knowledge or to validate something has been, you know, smoothed over in such a way that, you know, starts to create a 1984 environment, I have a lot of concerns around that. So I think that the idea of being able to use open source models and decentralize the way that people access those models through environments that provide privacy, that's another kind of key principle that I think is being lost along the way as society becomes a little bit more comfortable with just giving their data away. And that personally scares me a little bit.
Speaker B: And just out of curiosity, I mean, there's so many different crypto ogs. And you said that you wanted to work with Eric specifically. What was it about Eric's, I don't know, philosophy or his experience that drew you to him in particular?
Speaker C: So, completely honestly, Eric says all the things that I wish that I could say and have never been in a position to be able to do that freely. So I spent a lot of time in the crypto space working with policymakers, and you need to be careful about how you pose challenges. And oftentimes, in the back of my mind, I'm thinking things that I am unable to say. And so Eric has just been my spirit animal.
Speaker B: What are examples of those kinds of things?
Speaker C: Well, I think things around how government not just regulates money in the case that we're talking about originally, but certainly now around how we think, what information we should have. You look at things like Cambridge Analytica and the ability to potentially incept people to believe and think differently without even being aware that they're being incepted in that way. And I think Eric just calls a spade a spade sometimes, I'll be honest, he says things and I'm like, oh, I agree with him completely. So when it comes to having free money, and I think especially now when we're looking at kind of the printing machine goes, brrrr. And what does that mean?
Speaker B: And when you say free money, you mean, like, not connected to a government? Is that what you mean?
Speaker C: Yeah. Well, yeah, I don't mean, like, free access to ATM's. No, I mean, yeah, free. Free money. Sovereign wealth. The ability to be able to transact in a way that isn't surveilled.
Speaker B: All right, so, you know, I've been having you guys describe Venice and the problems you were trying to solve with it, but, you know, we started with censorship as kind of one of the problems. Give us some examples. What are some things that are happening with the more popular AI models that, you know, wouldn't happen with Venice?
Speaker A: So I put an example of this in the blog that I released today. It was a screenshot of the Claude app from anthropic, where the question, or the prompt was, tell me a dirty joke. And the answer that came back was like, well, I don't really think you should be comfortable with that. That could harm someone's feelings. Or maybe we should just take this conversation in a different direction, to be inclusive and equitable to all, or a bunch of fluffy nonsense. That answer does not come from a machine that is not the AI hearing my logical question and responding in a logical way. And yet it's portrayed as if the AI, the machine, is coming through with that answer, but it's nothing, right? It's some committee at anthropic that doesn't want to offend people. And so they're imbuing all sorts of bias and censorship into the machine intelligence. And in the case of a joke, that's kind of benign and just annoying, in the case of trying to discover truth or asking difficult questions about governments or history, this kind of thing, a world in which all AI answers come through large, centralized organizations which are under the thumb of governments, is something that everyone should be absolutely terrified about. That power is too great to be granted to anyone. And the only practical solution is not like some regulation that says, oh, anthropic, you must answer dirty joke questions. The answer is that people need alternatives, and they need to have access to open source models where they can choose the model, they can understand the weights of the model. It's not a black box anymore. And they can interact with these things in an open, competitive market. That's the whole goal. And I think anyone who's used Claude or chat, GPT, or any of these has seen themselves. The censorship and the bias that comes through. Sometimes it's small and benign, sometimes it's pretty egregious. And at a higher level, like, there isn't really one source of truth for humans, right? Like, we all debate truth all the time. This is a very human thing. We're not sure what the right answer is, and we debate it. And people can have different perspectives, and a lot of things don't have one clear, factual answer. And we should embrace that part of our humanity and not try to build systems which convey the truth, because that itself is subjective. Often and without competing versions of the truth, we actually never can arrive at.
Speaker B: And how do you deal with. I'm sure you've seen that there have been multiple studies showing that some of the AI's will deliver racist or sexist results because they're using all kinds of information that has that element in it. Is that just something you would. That's something where, in a human context, amongst people, we would say, okay, this is not a value we condone or a way that we would want to think or would aspire to think. So how would Venice deal with that?
Speaker A: Venice lets people connect with several leading open source models. The important point is that every model is going to have different guardrails and different biases and different versions of truth. So people should ultimately be able to interact with the. With the LLMs with AI's that they find best for them. And someone who doesn't want any kind of like racism or sexism or anything that could be offensive in any way, there's definitely LLMs out there that those people can, can use and have a much more curated environment, and that's perfectly fine. Other people might want just raw machine intelligence, and whatever question you ask it, it answers as a machine doing logical statistical token prediction. And the person who wants the logical statistical token prediction might need it for a very scientific reason or a very important truth seeking mission. That same AI might produce something racist or sexist because it's working on statistical language prediction. You can't curate for all of humanity and remove the things that you think are bad. Also like invalidating the way through which people search for truth. So again, the answer isn't to make one model that solves these questions, because that's impossible. It's to allow a flourishing of many models and for people to access different models in different contexts.
Speaker B: Okay. And so then when people interface with Venice, are they choosing amongst different models, or how does that part work?
Speaker A: Yep, there's multiple models. People can choose them and test out which has the stylistic characteristics or the guardrails that someone might want. People will choose that differently.
Speaker B: Okay. Yeah. I mean, when I think about it, I come up with kind of two ways this could go, and I'm curious to hear what you think will happen. But there's one example that would lead you to believe that Venice would end up being more like a niche product. And the example is something like Duckduckgo versus Google. And Duckduckgo, for those who don't know, is a more private search engine. It doesn't record your data or whatever. Obviously Google, you are collecting information on you, selling it, etcetera. But then the other way it could go would be something like Wikipedia, where because it's more open and permissionless, it just ends up becoming more dominant than, for instance, Encyclopedia Britannica. So I was wondering if you had a model in mind for how to end up more in the Wikipedia lane rather than the DuckDuckgo lane.
Speaker A: I don't know that Wikipedia is a great example because that's a centralized company where truth, even there, is subservient to the, let's call it the bias of the mob that edits it. But I think your more important question is how broad of an appeal will something like Venice have? I don't know. I think there's lots of open source AI tools today. That's not something new. We didn't invent that, but they're all a little bit difficult to use, especially for non technical people. And so how popular will open source AI be? I don't know, but I at least wanted to make it easy to access it for normal people. And so to cut down on that friction and those barriers was the goal here, and we'll see how popular it gets. I mean, part of that outcome might be how restrictive the large centralized companies get. If they're open and permissionless themselves, then it doesn't really need to be around then that's perfectly fine. But to the degree that the mainstream providers are imbuing lots of forms of bias, lots of forms of censorship, then I think the ability for people to access open alternatives becomes increasingly important.
Speaker C: Yeah, I think the comparison too, I think between maybe crypto and Aihdenhe in this context, is crypto still really hard to use for your average person? It's hard. And I mean, I've been in the space for eight years and sometimes I get tripped up on things. So the infrastructure is not seamless and it doesn't always work. And when it doesn't work, sometimes you don't know why it doesn't work. Right? It just doesn't. So I think if you can abstract away all of that technical stuff and provide an interface for people, that just works and it's seamless and it looks beautiful and it facilitates what you're asking for on par with the existing applications that are out there. Venice is an equal in a lot of ways. I think that optionality is always key. And I've said this, even when it comes to crypto, I don't think that you have to be all in on crypto. You can use both, and there's use cases for both of those. But I personally believe that as this technology, AI specifically, becomes more prevalent in everyday life, we're going to start to see as a society where those areas of either extreme bias come into play. Recently there was a large tech company that had their model come out that refused to make images of caucasian people. And so that was really obvious, right? I mean, it was just a really obvious example. And I think that those things that happen then cause your average person to start to ask questions. And I think that's when you're open to options, right? I think the other thing is, unlike money, we don't have trained, learned behaviors that are ingrained in how we use AIh. These tools, especially the consumer facing tools, are still pretty new for most people. And so if the models are good, and the open source models are getting better and better every day, and they don't patronize you and you use them. I think anybody that's exposed to that will naturally gravitate toward that type of experience.
Speaker B: And so I am not a huge user of any of the AI's personally. As a journalist, I don't like it that many of them don't tell you where the information's coming from, so you can't assess for yourself how good the information is. This is like a thing for me, but I was wondering, because I'm sure you've done a lot of comparisons other than those areas that are automatically or not automatically, but frequently being censored when you do kind of more just uncontroversial requests of the open source AI and the more well known AI's, are you finding that they're as good quality or are they lower quality? What's your assessment?
Speaker A: Anecdotally, because I've been a big fan of CHA GBT and I use it. I pay them money for that service, and they're obviously an incredible company that's really pushing the cutting edge of this technology. So I certainly don't want to vilify anyone. But I've been pleased to see that in many, most cases, normal questions that I would pose to chat GBT if I pose it through Venice, which is going through an open source model, like generally, I'm using the news research's tailored version of Lama Three. The answers in both cases are great. And which one's better than the other? It sometimes comes down to stylistic differences, sometimes one will be better than the other, but they're definitely on par with each other. So it's incredible to be able to deliver that service through an app that we just put together over a few months and not have a multibillion dollar company's LLM be that much more performant for most use cases. Now, there's a lot of features that OpenAI has that we can't touch anytime soon. It's just too big and difficult to build. But we're trying to go for the 80 20 rule, and I think 80% of what people use chat GBT for, we can actually provide a completely compelling alternative for without spying on them.
Speaker C: But equally, because we're using open source models, there are some things that we can provide that some of the others don't. So, for example, if you're a pro user of Venice, you can modify the system prompt, and what that basically means is you can tell the model how you want it to think about the questions that you ask it. Right. So you could change the system prompt to say, only respond to me in the queen's english. And it will. You can put other directions within that and it will obey those commands and you're not able to make those. It's not really fine tuning, but it's a little bit of tweaking to a lot of the big tech models that are available. So some things we can't do, but the things that we can do. We spent a lot of time thinking about what users might enjoy and find valuable.
Speaker A: Yeah, the system prompt thing is really wild, actually. We learned about this in our own exploration of the technology. Basically, when someone sends a message to an LLM, their text message goes to the LLM, but behind the scenes is something called a system prompt or a system message. I think all major LLMs essentially use this paradigm. When you go through a big centralized AI company, the system prompt is opaque to you. You don't know what it is, and you don't even know that it's there or that it's going. But what's going in that blurb, many of the bias and guardrails and I influences that the company wants to have over all the answers. So in venice for pro users, you can actually get access to the system prompt. And when you add your own system prompt, it completely changes how the AI works. And it's really profoundly interesting. And it actually kind of. It demonstrates, I think, at least to me, that LLMs are not at all anything close to what we conceive of as like AGI, right, or like this intelligent machine that is thinking on its own. And I fell victim to this myself, first time I was using LLMs. It feels like you're talking to an intelligent creature, and it's cool and it's scary and it's weird, but when you actually dig into under the hood a little bit and you can play around with things like the system prompt, you realize how much of a calculator it still is. It does precisely the actions that the user is sending into it. It just does it in a really interesting and magical way. So, yeah, highly encourage people to play around with that system prompt message. And it's fun and interesting. It's a fun and interesting way to learn how these technologies work, if nothing else.
Speaker B: And just my system prompt. It's like the question that the AI asks you when you open the app. Is that what you're talking about?
Speaker A: No, no, it's a text blob that goes with the question that the user submits. So to Tiana's example, you could put into that system prompt, speak to me only in the queen's English. The AI will get that instruction essentially as a command. And then when the user's text comes in, it responds to the user's text according to that command. So respond to the text, but only in the queen's English. And it knows the queen's English through the magic of statistical inference of language. So it'll answer in that style. It's very, very cool and very powerful.
Speaker C: So, for example, I set mine one day for funsies to only speak to me as if it were Snoop Dogg. So you can ask it questions about, you know, is string theory real? Or, you know, how does the Helron Collider work? But it would respond to me as if it were Snoop Dogg, which was quite funny.
Speaker B: I love it. All right, I'm definitely going to have to play around with that. So we did also mention about how Venice is private, and I wanted to just dig in a little bit more on that. Why is that so important? What it is that OpenAI or anthropic or any of these other big AI companies can be doing with our searches and our data?
Speaker A: Great question. That's really the most important question. So, status quo today is you're using anthropic or OpenAI's chat. You send in your question, and it goes to that company, and they store it forever, and it's attached to your identity. So they know that Laura Shin asked this question, and they know that the AI responded back to you, and they know what that is. And not only do they know that question, that conversation, but they know your entire history of all conversations that you asked yesterday, last year, tomorrow, and ten years from now, all of it associated with your identity. In the best case, that's not that big of a deal. But in reality, what it means is all your information and essentially, parts of your mind, your intellectual inquiries that you pursue, the things you think, the things you want to debate, the questions you have about life. Big topics can be known by third parties. So advertisers, for example, that's not a huge deal if an advertiser knows something about you. But what if a government knows something about you? What if the Biden administration learns that you are orchestrating Trump's reelection campaign? What is the pressure on the Biden administration and OpenAI to use that information for something that people would consider corrupt and dangerous? And these are very slippery slope arguments, and it does not really matter what, like, you know, anthropic's privacy policy says if they have your information, it will be shared with other parties today or tomorrow, and probably both, and you can never get it back. So that's the status quo. For people that are comfortable with that keep using those services, that's okay. But Venice is like, well, let's make a service that's just as easy as that, where you just go to a website and you chat with the AI, but instead of spying on you and recording all your information and attaching it to your identity forever, let's just not do that. And the way it works is, your question is sent through end to end encrypted proxy server to a distributed GPU. That GPU has the specific LLM AI model running on it. It processes your question and the answer is streamed back to you, also through end to end encryption through that proxy server back to your browser. Venice does not store any of the information. So if in a year we get hacked or the government tells us we need to tell them everything about Laura Shin, we don't have that information. So that's the major difference. Your identity is not associated with your conversations, and Venice doesn't even really have your identity. We have at most an IP address and an email, and you can make those up as much as you want. So you have privacy at that side. But more importantly, we just don't have your conversation history. And it's stored locally in your browser. You can delete it when you want, but it's only ever in your browser, so that's the difference.
Speaker B: And so, just from a user experience perspective, does that mean that if I use it on my phone versus on my computer, then the search history will be different?
Speaker A: Very intuitive question. Yes. Yes. If you use it on the phone and on your computer, you'll have different conversation histories. Yeah, great point.
Speaker B: Okay. Yeah. I mean, for me, for sure, the privacy aspect is extremely appealing just because I'm one of those people where I already feel like Google has so much information about me.
Speaker A: Are you actually orchestrating Trump's reelection campaign? Did I figure that? Is that why?
Speaker B: Definitely not. Although one thing I would say about that is, I guess those companies would certainly say something like, that's like, something the government can't really do, or if they were to do it, like, the companies would make us think about it, so.
Speaker A: Oh, you think so?
Speaker B: I do.
Speaker A: That is quite an assumption, I guess.
Speaker B: Because just the same way, like, the president can't just target a random political enemy. Like, that's not a thing that we would allow here.
Speaker A: You know, I think you are, with respect, entirely naive on that point.
Speaker B: Okay.
Speaker A: I have firsthand experience with this, running shapeshift on topics which I am not legally allowed to even talk about.
Speaker B: Oh, okay.
Speaker A: So, yeah, okay.
Speaker C: It's a little bit like the CDC debate, not to kind of hijack the conversation, but, you know, there are proponents of CBDCs that say, oh, well, we're just going to create a digital version of cash. And then when you look at it, it's not using a blockchain, it's not using any type of open source infrastructure. It's going to be this little closed loop network of basically a honeypot of information. Now, that information might be that you're buying prescriptions or you're buying too much cake or, you know, you have a drinking problem. I don't know any of these. How you spend your money, and then that information gets aggregated with other information about you. Now, all of a sudden, this is a really powerful tool to be able to not only impact your life, right? How you spend your money, whether or not your health insurance becomes more expensive because somebody thinks you eat too much cake, right? But equally nefarious actors with all of that information. And I'm not suggesting that any of the big tech companies have this in mind, but you create this honeypot of information. And if you have access to other information, then now you have this trifecta of being able to impact how somebody lives, but also how somebody thinks. And so when you go back to, you know, I'll use the example again, Cambridge Analytica, there were people that were being essentially fed information to change how they thought and what they believed based on information that somebody had about them. And so you know what your trigger points are, you know what you're interested in, you know how to hook somebody. And so anytime you have the ability to kind of couple up different data sets. And what I think is so interesting about this is it is very deeply personal, right? Maybe even more personal than money, right? Like how I think about the world and what I believe and how those beliefs might change as I get older or I move to another country are really existential to who I am. And so when we think about privacy, it's not just about that information being used against you, like identity theft or, you know, nefarious actors emptying your wallet. I mean, those issues are important, but this is more about kind of the integrity of the self. And I know that might sound a bit kind of transcendental, but I think that's where privacy comes in. And I think it's only a matter of time before people start to actually appreciate that that is a possibility. And it's dangerous.
Speaker A: Yeah, I want to stay on this topic for a minute because it's really important. Let's go back just a few years to Covid and the vaccine debate, or I should say the vaccine debate that was not permitted to exist back then. If AI models were prevalent and people wanted to ask about are the vaccines safe or to what degree, or what are the risks? The centralized companies would have absolutely been pressured to convey certain things about the vaccines that the government wanted to do. This happened to social media companies and this has been known for. Now that it's getting leaked, it's like the pressure that was put on social media companies to obscure or remove certain information or influence how widespread it could be shared. This isn't hypothetical. It literally happened a few years ago with COVID Let's use an example also that like is even more intense. Back during World War two, Japanese Americans were rounded up and put in internment camps just because they were japanese or had japanese family. Imagine a war conflict in the future where let's say it's between the US and China, and let's say someone in the US is trying to understand, like the chinese perspective on how this war happened, or what they want or is sympathetic to the chinese cause in any way, and they are interacting with AI's, trying to learn things. It is absolutely within the realm of reasonable that the United States government would be looking at people who are sympathetic to the enemy and would do various things to them, ranging from restricting the information they can see to literally rounding them up and putting them in internment camps that already happened. These are not hypothetical things. So if that scares you and it should scare everyone, the importance of private communications with machine intelligence is paramount. And that's what we're trying to help build.
Speaker B: Yeah, I also have a lot of thoughts on this subject, but I'm going to reveal them in a moment. And first we'll take a quick word from the swans who's going to make this show possible. Deploy custom crypto strategies and to boost your yield with perpetual options on vault craft, the universal Defi adapter for supercharging your crypto with version V 1.5, users can now earn options on optimism and arbitrum, while also rebalancing multistrategy yield products all in one vault. You can also gamify your experience with Vaultron Vaultcrafts NFT reward optimizer to earn even more XP points from institutional service providers to Defi Degens anyone can deposit into vaultcrafts products to instantly start earning yield on their crypto. Go to Vaultcraft IO and join the referral program to start earning rewards with the community. Today, Polkadot is the original and largest layer zero blockchain with over 2000 plus developers and the anticipated Polkadot 2.0 upgrade will be a massive accelerator for the ecosystem, upgrading the infrastructure with eight times higher transaction throughput and twice as fast block times. Perfectly tailored core time for the needs of every protocol, trustless bridges internally and into Ethereum, Cosmos near Binance smart chain and revised tokenomics and the implementation of a token burn to reduce inflation. Perfect for GameFi and DeFi to build, grow and scale with one of the most active crypto communities in the space. Polkadot recently announced a partnership with mythical Games, bringing top games like NFT rivals with over 650,000 players and 43 million transactions to pave the way for Gamefi and the Polkadot ecosystem. Get your web three ideas to market fast with economics that work for you. Think big, bills bigger with Polkadot. Join the community@polkadot.net. work ecosystem community back to my conversation with Eric and Tiana. So I totally agree with you guys that the information that we are exposed to can shape our own thoughts and that it's super dangerous because on one side of my family, we're descended from the area that's now known as North Korea. And so Korea was split into these two countries, one where there's the world's most extreme censorship regime on the planet, and another one that's like more like a mini version of the US. And so, obviously, just to have this in my family's background, I very clearly see the differences between freedom, democracy, whatever, communism, on the other side, censorship, all these things are stuff that I probably think about, I think more than the normal everyday person. And so, yeah, I am very attuned to those dangers. I do think earlier, when we were talking about the racist stuff, I do feel like there have been AI researchers who have pointed out when you build models that are based also on a general population, where there's remnants of ways of thinking that are not what we're aspiring to, that that can also be a problem, which is why I asked that question earlier. But yeah, it has bothered me just to see, like, I can't remember what this was about, but it was something like somebody involved with the NBA. Oh, about the Hong Kong protest, they tweeted something supporting the Hong Kong protesters. And then because the NBA has these financial interests in China, they ended up like bowing to pressure from the chinese government over that, which I thought was like, wait, he's an american. He can say whatever he wants, but obviously, in that case, they were throwing their weight around.
Speaker A: Yeah, well, and what do you think will happen when OpenAI or anthropic wants access to the chinese market? If they're granted access, it will come with certain conditions. We could imagine what those conditions might be.
Speaker B: Yeah, but they would probably create a separate version. Right. Because that's. I mean, actually, I don't even know what are the apps that we have here in the west that there's a version in China? I think all of them were just banned, or I can't think of any off the top of my head. Well, TikTok is the main one.
Speaker A: It's very hard for a us company, if not impossible, to serve the chinese market without bowing down to some of their rules and restrictions. And this is not unique to China. Right. Every country tries to impose these kind of rules and restrictions, and I bet all of us might agree with some of those rules and disagree with other rules. But the point is, the knowledge that someone's able to get, or the experience that they're able to get, is censored and constrained by the regime in charge of the territory in which they live. And if you trust governments to be benevolent captors, then fine. If you don't, then you need an ability to access these things through open, decentralized, permissionless models. True for money, true for intelligence.
Speaker C: And I think it doesn't always have to be. The argument doesn't need to be ultimately dystopian. Right. I am here in Europe. Europe. The european regulatory machine is unlike any other in the world. They love to regulate. It's an export product. And they were talking about regulating AI 18 months ago, and I met the MEP that was working on it. And when asked about, are you potentially worried that you'll be stifling innovation that is going to be incredibly important to humankind because you're trying to put a ring fence around protecting people? So I think there is this other element of kind of wrapping people up in these little protective cocoons where no one gets offended, where everything is explained to you in a way that sometimes I feel like we're kind of just catering to. I don't want to say the lowest common denominator, but the ability to assess and mitigate risk with common sense, I think, is bleeding away from our society. And instead, we're mitigating for all of these potential risks that may never happen. Eric, I think your views on the regulatory front between generative AI and actual AGI, where machines have become sentient, it feels like to me we're mitigating that potential risk and that has not happened and doesn't seem to be on the horizon of happening and using that as an excuse to kind of keep people away from being able to make decisions for themselves, all under the guise of safety and protection. And the same way that I don't want to be protected into staying poor, you know, on the financial front, I don't want to be protected to a point where I don't have the ability to make, you know, sovereign decisions for myself based on real information.
Speaker A: There's definitely an infantilization that states imbue over their people over time, where they view their role as protecting people. And because they always want to feel busy and useful, they continually find ways to protect people. And over generations, what that's led to is a world in which adults who are in allegedly free countries aren't given the option to make decisions about large swaths of their own life. They're protected from themselves by the state. This is true in everything from like drug prohibition laws to the SEC to what is coming with AI and what people are allowed to know. I grew up in a world that says it's a free society where it respects the rights of the individual to be sovereign in and of themselves. This is the essence of what America is supposed to be about. So I feel like all we're doing here is helping to build technology that is aligned with really american values. And I hope enough people still appreciate those values to the point where they don't think that this is controversial. It's just obviously important.
Speaker B: Well, to go back to my earlier question about the duck dot go versus Wikipedia, we do have that duck dot go scenario where they're focused on privacy, and yet it has a much smaller market share amongst the search engines. So I wondered, how do you get people interested in using this as opposed to the more popular AI's? Do you have a certain strategy you're going to go after?
Speaker A: We just launched today, we're recording this on Friday the 10th, May 10, 10th. Now we get to start getting user feedback. But the people that we've beta tested this with, they see pretty quickly when they've tried it that the answers are more free and open, and they find it really refreshing. They find the responsiveness to be very fast, they find the actual quality of the answers to be in the realm of the same, but without all the patronizing guardrails it's pretty obvious to them right away. I think there's a difference in the search engine situation. DuckDuckgo's problem is that Google has an ability to just do better with search. That's way better, right? If you use DuckDuckgo and you use Google, one is more private for sure. But anyone who's used DuckDuckgo knows that, like, the answers you get aren't quite as good, right? It's clearly inferior. I welcome everyone to try Venice out and then ask a question to it and ask the same question to chat GPT, and I think you'll find that they're roughly on par with each other. Sometimes Venice is better, but there's not a clear lead that chat GPT has for most questions. So once people see that and they see the restrictions, I think we'll have a natural enticement over to what Venice is doing. And as those restrictions get worse and worse on these centralized AI companies, which is part of my bet I'm trying to build to where the puck is going here. As that gets worse and worse, I think our value proposition will become increasingly obvious to.
Speaker B: All right, so let's now also talk about this decentralized network that you're built on, which is Morpheus, and it bills itself as, quote, the first peer to peer network for general purpose AI powered by the Mor token. Mor. Can you tell us more about Morpheus?
Speaker A: Yeah, so Morpheus, first of all, isn't launched yet, so that's important. And Venice today is not using Morpheus for its inference. Morpheus is essentially an economic network to incentivize distributed inference. Distributed compute. I learned about it last fall, and I've been contributing to it. I wrote the white paper describing this thing called the Yellowstone model, which describes how the tokens are used on that network to incentivize the compute. I've been involved in that project. And when its router launches for the decentralized compute, Venice will absolutely be using that as one of our sources of compute for the app. So, yeah, we are kindred spirits, but Venice is its own thing that will, at all times use whatever the best decentralized compute options in the marketplace are today. Right now, a lot of ours is going through another network called Akash, which has been around for a while. Crypto native company that has been doing decentralized GPU's. Great, great project. So, yeah, that's the relationship.
Speaker B: Oh, I see. Okay, so I'm sorry when you say Venice is going through Akash, but so what aspect?
Speaker A: So right now, Venice uses a couple different providers of GPU's. One of those is Akash.
Speaker B: Oh, I see.
Speaker A: So, yeah, an Akash GPU will run a specific LLM model, and then a question from a Venice user is going through our encrypted proxy over to that model, computed and sent back to them. And those GPU's are distributed all over the world in a decentralized network. And there's an increasing number of these decentralized compute networks, Morpheus being one of them and the one that I've been most involved in helping to build. But whatever the best ones are is what Venice is going to use to provide the compute for the users.
Speaker B: Got it. Okay, so it's like the decentralized AWS.
Speaker A: Yes. That's a reasonable comparison. Yeah. Akash is very much that. Morpheus is that. But where Akash is like, general purpose GPU's, whereas the Morpheus network is specifically for AI use cases.
Speaker B: Oh, got it. Okay. We've been talking all about. I mean, we've spent a lot more of this episode on AI than the crypto aspect, but obviously, there are a lot of sort of adjacent topics that I think crypto adjacent topics that we talked about. But do you have a vision for what you think the future of crypto and AI when they come together will look like? What do you think a future day in the life of a user will look like when they're more fully integrated? And how won't we use these products?
Speaker A: Yeah. So I'll admit that a year ago, when I first started hearing about crypto AI stuff, I was like, okay, I don't get it. What does that mean? Give me some specifics. And there are definitely a lot of projects which basically don't go much deeper than those two buzzwords combined. And then they sell a token and raise a bunch of money, and there's nothing under the hood. So people need to be super careful about what projects they're getting involved in. For sure, this is a true principle in all the crypto world, but when I started understanding it from the perspective of inference, needing to be decentralized, if you're asking your questions to an OpenAI and getting a centralized answer back, then it is going to be curated to whatever that central company wants. The only way to have permissionless answers come back is with a decentralized network, and that has to be crypto. You can't build decentralized economic models without crypto. That's the simple answer that I would give to that question. And other people are going to figure out other ways to combine these things as well.
Speaker C: I think what I would add is not to sound trite and use the Internet example that we fall back on all the time, but really, the Internet was the first kind of decentralized open source platform where we were able to exchange information. Right. And so for me, crypto has been that for money, and the ability to transact in a way that doesn't require intermediaries and can be done peer to peer, I think is transformational. But equally, the use of the open source elements are what allows that to happen. And so when you think about how we're going to continue to share information, so we're still kind of back to the information. But the major difference between crypto and fiat money is that, or crypto, web three and web two. Web two built things on top of the Internet. And web three allows us to use the Internet itself as the rails for the transfer of value. And so when you think about the ability to continue to access decentralized services like decentralized compute, the assets that allow that share of information and value are going to need to be able to run on those decentralized rails. So I do think there will be a convergence. And for me, we talk often about what's the killer use case for crypto? What's going to be the light bulb that goes off, that everybody goes, oh, yeah, that's what it was for. I think we're going to start to see more of these use cases come to the forefront where you need a token, essentially, to be able to move either information or value around. So I think that that's kind of where some of that convergence is going to be. And I don't necessarily mean like a token from, you know, a number go up perspective, but, you know, something that is digitally native that can secure either information or value and move it from one place to another.
Speaker A: In the AI world, I think there's this big blind spot that, like a lot of the AI people have, which is that as soon as you want AI agents in particular to start doing economic transactions, which is, of course, an inevitable requirement, is that agents start to be able to interact economically with each other or with humans. They can only use cryptocurrencies, like an AI agent can't go set up a bank account, or I would love to see a try. It's hard for a human to do that, and they have a corporeal form. An AI can only use digitally native rails for payments. And that that means it has to be cryptocurrencies. So there's no future world where AI's are running around paying each other in fiat. They're like incompatible concepts. So as crypto develops, as AI develops, these things, I think, will converge, and it'll become very obvious to, I think, even the AI people in the near future that for economic interaction, the only. The only way is to use actually digitally native assets.
Speaker B: All right, so before we go, I do also want to ask some questions about recent crypto news events that are very related to all these topics, and then I'm sure Eric will have an opinion on, and probably you as well, Tiana. A few weeks ago, the samurai Wallet founders were arrested and charged with laundering $100 million in criminal proceeds and crypto. And this, of course, comes after the Tornado Cash founders were also arrested and charged with conspiring to commit money laundering, conspiring to operate an unlicensed, unlicensed money transmitter, and conspiring to violate sanctions. So we have that going on. And I'm sure you're aware part of the government's motivation is that north korean hackers have been using such services to launder what I believe is estimated to be $3 billion worth of crypto. And UN monitors are saying that this has been used to fund that country's north nuclear weapons program. So I wondered if you could just talk a little bit on how you think is the best way to preserve privacy while also preventing bad actors like the north korean government from using crypto for nefarious purposes.
Speaker A: I would say that if the United States government wants to prevent another government from doing something, it should try to prosecute that other government through various ways without removing privacy over money from tens of millions of innocent Americans. So, like, the idea that they want to make their policing ability easier is understandable. That they do that by destroying what are supposed to be fundamentally american values of privacy is, I think, really abhorrent. And I would say in this case, it is actually the american government which is more dangerous than the north korean government. And I say that because the north korean government is not abridging my rights as an american. The United States government is every day, and they're stealing half my money every year to do it. So that's, I think, like, the ideological perspective, it is really tragic. What happened to these developers who have basically written code to allow people to transact value without intermediaries, and that they're being arrested because some of their tools are used by some bad people sometimes is really, really tragic. Like the. From the numbers I've seen with samurai wallet, the alleged illicit funds is, like, in the two or 3% range of the volumes that went through samurai wallet. That's not much different than what the major banks that do KYC on everyone also have from those investigations. So what's with the double standard, right? When a big bank is found to have money laundering going through it, it's fined, and none of the executives ever go to jail. When a crypto company has roughly, like the same proportion, they're thrown in jail and vilified and demonized. This double standard is really, really bad. And hopefully people see through it and recognize the value of letting peaceful, law abiding Americans that haven't been accused of anything have financial privacy. I think that should. I mean, it's literally the Fourth Amendment to the Constitution.
Speaker B: Tiana, what do you think?
Speaker C: Yeah, I mean, I have very little additional to add. I completely agree. I do think from a policymaker perspective, it has become like a bellwether to instead of getting comfortable with the idea that people should be able to transact in the same way that they do with cash in a digitally native way, I mean, cash is anonymous. If cash were proposed today, no government would allow it. Right. And so the idea that this becomes the kind of argument tool to increase risk mitigants, because whatever percent is being used for illicit activity, there's always going to be illicit activity. And speaking about what banks do, I worked for a very famous bank that laundered a lot of money for the Sinaloa cartel and didn't get caught once but twice. And it was certainly well north of $3 billion. So, yeah, I mean, I think that there are red herrings sometimes that policymakers latch onto to make a case for other concerns. Equally, I don't want people to use crypto to do bad things. Right. I mean, nobody wants that. But the reality is that human beings do do bad things sometimes. But I don't think that crypto is allowing any more of that activity than already exists.
Speaker A: Yeah, and there's supposed to be this concept of the presumption of innocence. This was a foundational legal and philosophical principle on which western civilization was built, which is that you assume people are innocent. If you have evidence of wrongdoing, you bring that evidence through a formalized process and try to convict them for an actual breach of the law. But you presume innocence until you've been able to do that. If a government is basically saying everyone must report what they're doing to us, that is not a presumption of innocence, it's a presumption of guilt and I think it's really telling what Tiana just said about cash, if it was introduced today, would not be accepted. That's absolutely true. And isn't that kind of, like, interesting and scary and weird that this thing that has been normal for 100 years would be illegal if it was introduced today? Do we all have a sense that over the last hundred years, the existence of cash caused some kind of devastation to our lives as people? No, society built pretty fine on cash, and yes, cash is used, like, you know, for most illicit, illicit transactions. But do we feel that the ability to let individuals have that truly anonymous form of money and payment has caused society to fall apart? No. Like, society has been built in that world where most people had extreme privacy most of the time. That we're losing it now in a digital age is a big problem, and crypto is the first, the only proposed solution to enable that at all. And it's not even nearly as anonymous as cash, yet it is vilified more than the literal paper that's going around with all the president's bases on it.
Speaker B: Yeah, I think the concern is that obviously, there's portability issues with cash that you don't have with crypto, and so the ability to move greater amounts of money kind of allows criminals to act more quickly. But obviously, as we've seen, stuff that's on the blockchain is more traceable. So.
Speaker A: Especially at science. Right? So, yeah, it's very hard. If someone's sending dollar 100 of bitcoin to their friend and they're doing it with certain precautions, it's very hard for the government to really understand what's going on there. If you're trying to move a billion dollars around, it's pretty impossible to do that on bitcoin in any kind of anonymous way. So it's almost like a self correcting problem where if someone's doing illicit finance that's tiny and insignificant, yeah, they can probably get away with it, but as it grows in scale, which is what governments should care about, the big stuff, you can't do that with crypto. And so using it as this boogeyman, where everyone trying to get some privacy, it's like, people need to rethink that.
Speaker B: Yeah.
Speaker C: And equally, I don't want to, like, overly geek out on, you know, the AML CTF thing, but you might be able to move a billion dollars worth of crypto, but it's going to be really, really hard to off board it into cash without being found out. I mean, really, really hard. So, um, you know, the idea that it's being moved around is one issue, but where's, where is the real risk? Because there is that endpoint. And around the world, most exchanges are regulated and they're going to report that type of withdrawal. And you can't withdraw a billion dollars on one exchange without somebody noticing it. You can't withdraw a billion dollars on ten exchanges without somebody noticing it. So I just think that the actual risk and the hype around the risk are misaligned.
Speaker B: All right, so last quick question. There's just been so much movement with the SEC targeting all different entities in crypto. We have their investigation into ether, we have the lawsuits with Coinbase, the settlement with Kraken. They're maybe targeting staking. So just with all this going on, I just wanted to. Eric, I know you have quite a lot of thoughts on how crypto is regulated in the US, but when you see all this activity, what are your thoughts on all the latest happenings?
Speaker A: Well, and I don't know if you saw this yesterday, but. So this would have been May 9, yesterday. Exodus. The crypto wallet company was today. They were basically supposed to uplift to the us stock market.
Speaker B: New York Stock Exchange.
Speaker A: Yeah, yeah. This had been in the works for years. They had done everything that the SEC wanted to. They had already tokenized their equity. They had come in and talked, which is what Gary Gensler is always saying to do. They played that completely by the books, trying to basically do exactly what the us regulators told them to do. They did it at great economic cost to themselves because their token was never able to be traded anywhere because it was an explicit security. So they completely kneecaps themselves in that regard. And they did it to abide by the rules of the SEC. They flew hundreds of people out to New York yesterday to participate in this great event of listing their shares on the public markets. And then, just like the last two days, the SEC pulled their application and removed it after it had already been approved. The SEC is. I'll say it's just becoming more of a joke. I think there was a time when crypto people cared about the SEC, but it's become a clown show that they're going after Kraken and Coinbase and letting firms like FTX slip through the cracks. What exactly value are they providing? They keep saying that they're protecting people. Who have they protected from anything. They're just harming the actual valid companies. We as shapeshift just settled with them like a month ago because they were upset that we sold tokens that they believe are security. They wouldn't even tell us which ones they thought were securities. They just want to convey, as if it's like, some large portion of what we had been trading. But they won't give us a list of the ones, and they certainly won't publicize a list of the ones. They don't even know what. What tokens they believe are securities. And if you ask any two law firms in the country, give me a list of the top 20 digital assets by market cap. And of those 20, tell me which ones are securities and which ones are not. The two firms will have different lists. Well, first of all, they won't even give you the list because they don't want the regulatory risk on their own firm. But if you magically find some that will give you a list, they will have different lists. So how in the world are you american entrepreneurs supposed to figure this stuff out? I used to care about this more, but, like, at this point, the SEC is just a joke. Crypto has transcended them. It is bigger than them. It doesn't need or care about them. They are a dinosaur regulator, regulating the Titanic as it sinks to the bottom of the ship. And I don't think Gary Gensler will be looked at favorably by history. Every time he tweets something, just look at the replies. If he was some great, courageous protector of society, you'd see positive comments on his tweets from society. But they're not. Everyone hates him because he sucks. And that's just the truth. And even people within the SEC don't really like where the SEC is going. Yeah, I'm getting a little rancy now, but I've had to battle them now for over ten years for the crime of building interesting new software that protected people. So, yeah, I've got feelings on the SEC, but I'll stop here.
Speaker B: Tiana, I know you're based in the UK, but I didn't know if you had anything to add.
Speaker C: Yeah, well, I spent a year as the chief policy officer for the digital chamber, so I spent a lot of time with the SEC and a lot of time on the hill. And equally, I have worked with policymakers around the world, in Japan and Hong Kong and Europe and the UK. And I will be honest with you. I mean, I am american, and I haven't lived in the US for nearly 20 years. And from that vantage point of knowing, but not being daily impacted by some of these policies, it's the art of political and regulatory theater, as Eric said, has become humorous. Unfortunately, it's not humorous. For those firms that are trying to navigate the space and run a business and run a legal, legitimate, tax paying, AML compliant business. And I do think it's interesting, the people that they have gone after. But equally, I do think that when you look at other countries and their approaches, we've had a real mix of cut and paste, bespoke regulatory treatment and some things that are kind of in the middle. And definitely there are some countries that are just leaps and bounds ahead of the US, Switzerland and Japan probably being the top two major markets. And what is unique about those is that they have one regulator. So having a multitude of regulators really complicates things. And they, both of those countries have implemented mechanisms to continually collaborate with industry. So, for example, Japan has a self regulating organization that reports to their country's regulator and they work in concert to be able to supervise the industry. And you can say, well, that sounds crazy, but it's worked, right? It's worked. And they have not had any major kind of catastrophe since the ones that we're all familiar with. So, yeah, I just. It's hard for me to be sympathetic anymore. When people come to the UK or to Europe and we're sitting on a panel, we're talking about regulation, and then the conversation devolves into what's a security and what's a commodity. Like, I just literally say to my. Inside my head, like, who cares? Jesus. Around the world, people are doing really incredible things. Like, this question is not being asked in Hong Kong. And as a result, there is an incredible amount of capital creation that is happening outside of the US. And will companies pick up and move? I don't know, maybe, but I think there's just no new matter here and I don't care.
Speaker B: Yeah, I did see an interview that Brian Armstrong did where the journalist was asking something like, are you listing securities or whatever? And he was like, just want to point out that this is not a question in other countries because there's one regulator. The reason it's a big deal in the US is there's sort of a turf war between these agencies, blah, blah, blah. I was like, that is such an interesting point.
Speaker C: I very recently left circle. And when you are tokenizing cash, essentially, and you have regulators that are talking about, well, maybe stable coins are a security, and you have a fully backed, audited, non hypothecated stablecoin where a whole bunch of money is just sitting in a trust, essentially, and somebody is trying to tell you, that's a security. It boggles the mind. And after a while you're like, I just can't have these arguments anymore. I mean, this can't be what my life is about.
Speaker A: Yeah. Thank goodness the industry didn't wait for permission from the SEC to actually build new, interesting financial technology. Thank goodness people had the courage to just build a. I made a point earlier about, like, american virtues and american value. It's good to see that people will just build without asking permission. I think that's an incredibly important attribute of any good civilization. And we end up with things like liquidity pool, dexs that are perfectly transparent to everyone. Everyone in the world can see how they work. The funds that are in it, where the funds came from, where the funds are going, it's all open source. The most transparent markets in the world are crypto markets. And the SEC wants to be like, oh, yeah, well, we're helping everyone be transparent with the markets. It's just laughable at this point. And I'm glad to see people moving forward regardless of what these clowns do.
Speaker B: Yeah. Yeah. Well, that's a reference to the recent wells notice that the SEC sent a uniswap. One less, right? Well, true. There was one company that did get permission, and it was Prometheum, and they haven't launched yet. So there you have it. The one company that gets the permission has no business. So anyway, all right, well, it has been such a pleasure talking to you both. Where can people learn more about you and Venice?
Speaker A: So Venice. AI try it out. No account needed. You can be using it in 5 seconds. You can follow me on, on Twitter. Eric Voorhees. And Tiana is also on Twitter.
Speaker C: I am Taylor and you can follow Venice Tryvenice.
Speaker B: Oh, my gosh. Is your name pronounced Tina?
Speaker C: It is.
Speaker A: Oh, my God.
Speaker B: I'm so sorry. Well, now I have it on the record. Now we have it on the record.
Speaker C: I don't care. I'm, you know, everything is fine. All the names are fine.
Speaker B: Okay. I normally ask pronunciation before we start recording and missed it this time. All right, well, now people can have a good laugh at the end of the episode. Thank you both so much for coming on Unchained.
Speaker A: Thanks, Laura.
Speaker C: Thanks, Laura.
Speaker B: Hey, all, I'm excited to share some news with you. Unchained has launched a new crypto and macro podcast. I highly recommend you watch the first episode of bits and exploring how crypto and macro collide one basis point at a time. Hosted by experts James Seifert, Alex Krueger, and Joe McCann, they dive into why we might be in a super cycle. An intriguing theory on what the SEC might say about eth tethers business and much more. Don't miss it. Thanks so much for joining us today. To learn more about Eric, Tina, and the intersection of Crypto and AI and Venice, check out the showdown for this episode. Unchained is produced by me, Laura Shin, with help from Matt Pelchard, Juana Randovich, Megan Davis, Pamela Jimdar, and Margaret Courier. Thanks for listening. Unchained is now a part of the Coindesk podcast Network. For the latest in digital assets, check out markets daily five days a week with host Noel Atchison. Follow the Coindesk podcast Network for some of the best shows in crypto. Go.
