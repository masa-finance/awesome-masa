Speaker A: This episode is brought to you by Shopify. Forget the frustration of picking commerce platforms when you switch your business to Shopify, the global commerce platform that supercharges your selling wherever you sell. With Shopify, you'll harness the same intuitive features, trusted apps, and powerful analytics used by the world's leading brands. Sign up today for your dollar one per month trial period@shopify.com. tech. All lowercase. That's Shopify.com tech.
Speaker B: Well, I can't wait for this. Ahmad is an old friend of mine, and, as you know from his previous interview, has gone from an incarnation out of being a hedge fund manager to helping the world solve the pandemic crisis to now becoming at the absolute epicentre of the AI revolution. He's incredibly smart, lovely guy, and I think we're going to get some insights to how fucked we really are, but also how augmented we get along that journey and everything in between. If you've been following this AI revolution is beyond anything humanity's ever experienced in terms of technology. And the point being, it's only just bloody started. I mean, it's literally months old in terms of the formats that we're seeing with chat, GPT, and maybe nine months old in the visual elements of stability, diffusion, and some of these other models, Dali stuff like that. So let's dig in and see where we get to. Join me, Raoul Pell, as I go on a journey of discovery through the macro, crypto, and exponential age landscapes. In the journeyman, I talk to the smartest people in the world so we can all become smarter together. So the last time you came on real vision, that was hilarious because it was exactly at the right moment. But when everyone's seen Dali, people have seen what you were doing, and then your interview kind of framed it for a lot of people, and it was like, oh, my God, this is happening. Then chat GPT comes out. You're the busiest man in the world. You're in every single newspaper, every magazine, interviewed, everywhere, and you're at the epicenter of something massive. So, firstly, congratulations. Well done. Let's catch up. Let's find out what the hell is going on now, because it's moving so fast. I read your tweets with interest. I mean, I can't even keep up with this stuff.
Speaker C: It's a bit insane. I think I mentioned last time we created a time machine, not a knowledge concussion machine, but it's a bit of a, you know, like three years ago in February, we did the one of these where I think it was the start of February. We're talking about COVID right?
Speaker B: That's right.
Speaker C: And I think we saved a lot of real vision, people money and made people money that way. Talking about what's coming, this is far bigger than the pandemic. It's far, far bigger. And we're seeing it live in front of our eyes right now. I think one of those things, sorry.
Speaker B: To interrupt, but one of the things I've been framing it as for people to understand at a macroeconomic level is this is a bigger shock than China entering the WTO on so many levels. It's gigantic.
Speaker C: It's huge. I mean, I think fundamentally, people are hard to scale. Expertise is hard to scale. This technology makes it so you can scale people. Like, one of the most difficult things has been always finding a good intern, finding a good analyst. CatGPt is a good analyst or intern with a bad memory. And that can display so many things because now you have knowledge work being scalable, you know? And so the best knowledge work has become more scalable with this technology because we don't get stuck with that blank page problem, you know, and we can take ourselves and put them into these models to then learn about us. And then it extends us. But so much of our world is information based. And this organizes information better. Perfectly, no, but better, yes. So again, it solves that expertise, scalability question still with a human. And as you said, this is a bigger thing than trying to rent in the WTO because what that did, that scaled manufacturing, this scales ideas, it scales information flow. And I think we're just seeing the early stages of that. Even though it's being deployed again at insane scale. There's always this thing, like, technology always starts as a toy. I'm like the toy to deploy cycle. It's become like that. Microsoft is so in the way, and then everyone's following, just like, you know, Twitter somehow is still going despite 75% of the people not being there. Airbnb kind of did that. So people started laying off, like, how many people these big tech companies need? Well, a lot less now. This technology is here. It's kind of, if Microsoft can do it, I can do it. And boom, it's in slack. Boom, it's in notion. Where is it not going to be, Raoul?
Speaker B: So after you really came onto the stage, then suddenly we hit the accelerator button. Everywhere Microsoft ramps up with OpenAI. Google hits the panic button. Amazon, I presume, are hitting the panic button. Where are we now in all of this? Because I'm watching you, Riley, observing all of this on Twitter, as everybody is now hitting. Walk back to ten.
Speaker C: Yeah, I think everything everywhere, all at once is the way it is. And again, it's very reminiscent of the pandemic, right? Like it's February of 2020, where every single person in the world that has a knowledge interacting company needs to have a generative AI strategy. But it's not like a metaverse strategy or web three strategy. It's being demanded now because you can be out competed. You know, like, has Bing had much uptake? No, because Bing is still crap. But it's definitely hit 100 million extra users. Right. It's going to get better. This is the thing. And so you're parallelizing this equation all at the same time with everyone asking the same questions, and they're going to put more and more resources because they've realized this could be existential. You know, 41% of all code on GitHub now is AI generated.
Speaker B: Really? Already.
Speaker C: Just six, seven months after Copilot came out, there was a study shown that coders that use copilot are 58% more effective than coders who don't because it takes away a lot of the drudgery work. You can have the framework to start to kick you off chat. GPT has passed the Google level three programmer test and it's not a specialized model. $478 billion coding industry. What does that look like in a few years? These are the levels that people think, wait a second, this is better than I am. And that's always kind of a question. So this is why emergency teams are kind of being put together. I think the number of instances of AI in analyst earnings calls and announcements. Bloomberg Deer chart are up something like 50% to 70% on the last quarter. This next quarter, every single one, every analyst is going to ask the same.
Speaker B: Question, does this all mean that everybody just does this? So it's just a kind of ramping up in productivity for everybody all at one point. There's no competitive advantage per se unless.
Speaker C: You don't have it. This is the really interesting thing. On an individual basis, everyone suddenly got access all at the same time through OpenAI, but now through new technologies like our version and Anthropic's version, Google's version, that will come in a few months. But there's no organizational advantage yet because it's a very personalized experience right now, or individual, because you've got to go there and then they're just integrating it. Now. How organizations implement this at scale, which share knowledge, will be the most interesting thing because there'll be some organizations, whereby if you're a software as a service company, having the ability to have intelligent code and intelligent knowledge, does so many need you anymore? Your competitor can out compete you by having cost savings internally and then driving you down on pricing pressure. But for a regulated industry like education and healthcare, that's different, right? So, like Google on January 8 released a paper called Medpalm. So Google have a language model that's three times bigger than OpenAI's model, GPT-3 called Palm. When they asked it medical questions, it gets a 50% accuracy despite being a general question. The record previously was 74% accuracy when they trained it on how humans answered questions. And this is a 200 gigabyte file, and that's it. Now it connects to the Internet and it's generalized. It got to 78% accuracy when they trained it on question answer pairs. For clinical diagnostics, it got to 92.8% versus a human expert at 92.9% just from a single file. Again, think about the implications of that for healthcare. Unitedhealth and people like that can save billions and billions and billions, but they maintain pricing power, whereas other areas become hyper competitive.
Speaker B: And your other thesis is, we can also globalize this. So therefore, countries that don't have the level of expertise suddenly have the level of expertise at their hands.
Speaker C: Yes. And think about it. For education. Education is never the same again. You know, if I told you that. So we know we've been doing adaptive learning with imagine worldwide.org for now, years and years, and we've shown it works. 76% of kids in refugee camps get literate and numerate in 13 months on 1 hour a day, compared to nine out of ten kids in Africa. Not being able to read and write a sentence by the age of ten, that's insane. Just with basics, right? But now, when I was having my one week break over Christmas, because I gave the whole team a week off, I said, get some sleep or you're going to die in 2023 because it's going to be so hectic and of course, business side around that as stability. I see. I said, you're going to die in 2023. What are you going to do? I got calls from like five headmasters saying, emad, what's my generative AI strategy? I was like, what? All our kids are using chat GPT to do their essays for homework. Now, this is one of the top private schools, so every single headmaster all around the world at the same time had the same question. So what happens now in Eton? You do your essays live in class the old blue book kind of thing, you handwrite it. Education is never the same. And so this is one of the interesting things. You know, when we always look at markets, sometimes things are never the same. And there's a lot of never the same is coming as a result of this. And how will people adapt? Because you can scale humans again, you can scale expertise. So the global south suddenly can scale, individualize one to one tuition. The blue method is the only thing significant, like one to one tuition. To do that. You can scale healthcare, you can scale all these things, but that means expertise becomes global. So again, China bought manufacturing global with the WTO kind of thing. This reduces the cost of expertise going global, which obviously a far bigger impact.
Speaker B: I mean, how do expertise based companies, if you think about the McKinseys of this world and all, I mean, it's so disruptive to everybody.
Speaker C: I think this is why Bain announced their partnership with OpenAI, with Coca Cola being the first major customer, which is interesting. Do you want to sell sugar, some water with AI? I don't know. I have to come up with some slogan around that or come work with us. They have to move. They have to adapt. I was talking to one of the big four accounting firms. They're putting hundreds of millions into this before the end of the year because they're like, this could end tax and audit. And I was like, you're a big four accounting firm. And they're like, we know, but we tried this. And I can do my report super quickly. So why can I do a tax report super quickly? I was like, okay, but they're going to put billions in, right? So again, information flow gets disrupted by these tiny little files.
Speaker B: How I'm thinking about this? We'll dig into the specifics of where you are and what you're doing, but I just want to frame some of this bigger stuff. How I'm thinking about this is, this is an incredible acceleration moment for productivity, but it does create a change in the job structure. What? That is how it works? Don't know yet. How are you thinking about going out five years from here?
Speaker C: I think about one year later than five years. I thought the chat GPT moment, I think I said to you would happen at the end of this year, not the start of this year. I mean, it's been 14 weeks since chat GPT, and we're recording this five weeks since that year dropped a bomb and made Google dance. Right. And the whole market again. What's the number one question? Is this now? So you're parallelizing capital deployment into this infrastructure, and you have adoption like you've never seen before.
Speaker B: 100 million users in a month or a month and a half. We've never seen anything like that.
Speaker C: Yeah, I know it was a million in five days, 100 million a month and a half. But this is easy. It's usable. You don't have to wait to try it. It's instantly accretive because it solves the blank page problem. But then this is just the first use of it as it gets integrated into flows like meta had a paper called Cicero. Cicero. They took eight language models working together, and it out competes humans at the game of diplomacy, which everyone thought was impossible. So as this gets more and more advanced and used in different ways, again, you're at the iPhone 3G moment. If anything, when we talk last, we're at the iPhone original. You might even have copy and paste. We just got copy and paste. Where's the app store? The app store is coming, and it's coming now, because everyone wants to build the apps, and it's easy to build the apps. Four of the top ten apps on the app Store in December were based on stable diffusion, and that was the entire back end, a two gigabyte file. We got neural engine access on the 1 December, the first AI ever, because these files, again, are entire backends that you can just build on in seconds, minutes, you can even get it to write the code for you. So, again, I don't know where we're in five years, honestly, I just know that, again, this feels like the start of the pandemic, where there's going to be productivity booms and the other side, and I see it as massively deflationary. I can't see how it's not, Raoul.
Speaker B: I can't see how it's not. I don't think people get it. It's incredibly deflationary.
Speaker C: The biggest drivers, the only drivers of inflation have been regulated industry, healthcare, education, some things like that. This completely disrupts those. It'll take time, but again, the profit margins for those guys and any regulated industry with pricing power go insane as they adopt this. Right? The ones where it's competitive, you have massive pricing pressure that comes. And then, obviously, you've got the hardware guys, so there'll be rotation into that side of things, so. But it's going to happen slowly and then all at once. And we've seen this so many times. Right, but we've never seen anything this fast, because if we talked six weeks ago, we'd be having a very different conversation. To three weeks ago to today.
Speaker B: I know. And that's. I think everybody's struggling, and I've been talking about this for a while, that these moments are coming. And it's not just in this. We'll sit in robotics, we'll see it in things. We'll see with so many things where we'll see this moment happening all at the same point. The humanity struggles to catch up with what the hell it is.
Speaker C: Yeah. And I think everyone's trying to get that answer right. But this is unique because we have the infrastructure for rapid deployment at scale. It was in the latest version of Windows, just like stable diffusion. There was a Mac OS update for stable diffusion, and it was like, literally, we now have neural engine access. That's Apple moving that fast. That's Microsoft moving that fast. Google is now a generative AI. First company, trillion dollar companies, robotics, IoT. Other things need to have the deployment cycle, whereas software deploys instantly at scale. And we're talking hundreds of millions of users already, right? Like, if we were having this conversation on teams. Teams now automatically transcribes, summarizes, and adapts your conversations. The next page is automatically do PowerPoint presentations off that if you want. You know, that's here this year.
Speaker B: How is everybody going to re educate themselves on all of these new tools? Because there are literally thousands. I mean, every day there's a new tweet thread with, here's the 20 great AI tools you've never, never heard of. You're like, holy shit.
Speaker C: There's always this question of incumbents versus entrance, right? So the previous AI generation you saw, actually, incumbents benefit from computer vision. Advances benefit from all these other things. I think that's what you're seeing today as well, because you need distribution. Like, there isn't time to build your own distribution from here. Again, chat GPT was very immediate, but now where are we seeing it? We're seeing it in Salesforce, we're seeing in slack. We're seeing it in motion. You know, we're seeing it in freaking instacart. Like it's good enough, fast enough and cheap enough that existing companies can adopt it. And the only question is, can you afford not to adopt it? The actual use is, I think, relatively limited right now because again, it's like a smart intern, but when's it going to get to analyst associate BP level? Pretty quickly, just like that medpar example that we gave. Because you have the generalized model, the model that learns how humans interact with it, specialized domain, and then human in the loop, rapid iteration. We haven't got to that point yet where it learns about Raul or M ad. And this is the thing, you don't need to learn how to use it. It's natural because it's based on the sum of principled analysis of the entire text corpus, or the entire image corpus, or the entire sound corpus. So we're going to have like, it just seamlessly fits into existing architectures, from chat to other things. And in fact, in the future, literally in the next few years, it will automatically build uis for you. We already see that, like, are you a visual output of versus an auditory output versus this or that? Why do you need to have menus anymore? Just tell the damn machine what you want. Language is code. Let's think in code.
Speaker B: Isn't the game going to be about datasets in the end?
Speaker C: Yeah, I think there's a lot of value to datasets. And you know, we've been going and making some very fun deals, but at the same time, these are few shot learners. That's the way it's called. So you have this generalized corpus of the whole Internet, right, or a snapshot of the Internet, and so it learns the principles from all of that. But then you teach it a little bit and then it hones in on that specific area of the Internet. But it doesn't need to have big data for that. You can do that.
Speaker B: The quality of the quality of the datasets that you therefore train it on. So if you've got proprietary data sets, the better the proprietary data set to add into the model, the better it's going to be.
Speaker C: Yeah. So, you know, that's what our model is. Our thing is you create the standard in every model of every modality, and then people can take our base models, these generative engines, and then add their own data to it and have sovereignty over that. So Goldman Sachs city, everyone, they banning chat, GPT, but they can create their own stable chat, as it were, by adapting to that data. But the models, like I said, are very quick learners. So an example of that is the number one app on the app store in December was Lenza. You know this thing where you upload your face like ten pictures and boom, you've got a model that just does your faces, that's just from ten pictures, right? So this is what I said, few shot landing. So if you look as well, what's happening now, there's a bunch of use cases that are based on private data and all this institutional knowledge, like you can pull into Google Slides soon, like all your internal real vision notes on everything and then have OpenAI's API to combine with that and boom, you generate slides based on private and public knowledge. First time it's ever possible. In fact it extends Google mission, organize the world's knowledge and make it accessible, can finally go behind the firewall without our technology in a completely legal and proper way as people have their models and then these general models. But then what's also happening is you can give these things more and more instructions. So until recently you can only use 4000 characters with the prompts, now you can use 32,000. So you can give it a whole instruction set of like a HR policy, and it learns that HR policy dynamically without having to retrain the model. So there is generalized world knowledge, there's specific rule based knowledge, and then there's masses of really unique knowledge, and there's variants for each of these and they're all accessible pretty much now. But again, we can only put tens of millions or maybe 100 million into training this infrastructure. Now there's a revenue component and this is strategic imperative. How much do you really think is going to go into this sector in the next few years?
Speaker B: Trillions. At this rate, literally trillions.
Speaker C: 5G was trillions. This is more important than 5g. So I don't even know where I'm going to end up again.
Speaker B: No, and I don't think, because we don't think very well in exponentials, and this is one of the biggest, well, is the biggest exponential we've ever seen in technology.
Speaker C: It's the extension of human expertise. It's made expertise scalable, like I said. And so that is huge. And like I said, this is infrastructure. Every company needs this infrastructure, every country will need their own versions. And so that's kind of where we position stability. Right. I think we discussed this to be the infrastructure layer for private data.
Speaker B: Yeah, I want to come into this whole comparison thing. I just want to understand one thing before we move on. How you fit into all of this is the one thing that is expensive in this equation is the training of the models and having to use AWS or Azure or everybody else, not really.
Speaker C: You know, we're training cutting edge language models that are GPT-3 level. It's like a couple of million bucks. And then that model can be used everywhere. I mean, even if it cost 100 million now, like GPT four, does it matter?
Speaker B: No, I'm thinking more of the applications layer, not at the foundational layer like you guys are.
Speaker C: Yeah. Once the model is trained, then it becomes about inference or running the model. So stable diffusion from launch to now, we reduce the cost by 100 times. Chat GPT just had a ten times cost reduction as well. Actually, the way to think about it is this way. You remember bitcoin, you started mining on GPU's. Do we use GPU's anymore? No, use asics. So what happens when everyone uses the same model, can have asics?
Speaker B: And so, I mean, a lot of value does accrue to those giant companies because of all the compute power, right, that everybody has to lease?
Speaker C: I don't think so, because I think people are thinking that loads of models will be trained. My take is that 95% of the compute will be ASICs or GPU's for running the models. Maybe 5% will be creating your own custom versions of it, and 1% will be building the foundation layer. Because how can you survive when you compete against OpenAI, Microsoft and DeepMind, Google? We're going to go all in on building proprietary models and have the language feedback loops. It's incredibly difficult, right? And it becomes, again, as you said, bigger and bigger to train the big models. Unless you've got a slightly different strategy like us, there's no competing. How many spacexs are there going to be building infrastructure to go to Mars? Maybe at most two or three, right. How many people are going to be building this space foundation layer model? Maximum two or three. And then you see the market dynamics. What do we see with this type of thing? One entity to be takes like 80% of the market, right, because they become the standard. But you also want to avoid single vendor lock in for your most important kind of thing. So I think that the value does accrue. But then there are questions like Nvidia, Nvidia stocks on a freaking tear. And we love Nvidia because we've got thousands and thousands of GPU's. We're melting a lot of them because we're optimizing the hell out of these things. But again, what happens when you have the move from general purpose to asics? Do you maintain a 70, 80% margin that side? And that's a question mark. You know what happens when there's competitive pressures. You've got Gaudi two from intel, you've got tranium two from Amazon, you have TPUV Five s, and they're trying to undercut your pricing. It's coming now. So it's not quite so straightforward, I think, in terms of the value accrual. And sometimes we don't really know, like ITA software sold for 700 million kayaks or per 2 billion building on top of ITA software. Right. So I think there'll be some value at the foundation layer and these big corporates, but most of the value will be created above that by people that use this correctly, saving money internally or driving better revenue outcomes externally in media and regulated industries, other places. All right. I think semis will be rotated into very aggressively because it's a no brainer play for a simple story, you know, but then other areas, you look across the SaaS thing, you look at all the HR SaaS companies and you're like, I could build your whole stack on a file. You know, it'd probably be just as good.
Speaker B: Hey, everyone, we're going to take a quick pause and hear a word from our partners. We'll be right back. Whoa. Landing an account this big will totally change my landscaping business. It's going to mean hiring more guys and more equipment and new trucks for the new guys to drive the new equipment in. I don't know if I'm ready.
Speaker A: You can do this. And Ford Pro finsimple can help. Our experts are ready to make growing pains less painful for your business with flexible financing solutions that meet the needs of your business today when you need them. Get started@fordpro.com. financing.
Speaker B: The landscape is obviously these mega giants. How did you guys fit into that? So how does the landscape fit together right now as you see it?
Speaker C: So if you're an investment bank, you ban chat GPT, but you're on your internal version. Are you going to hire a bunch of Stanford PhDs and train around models from scratch and take a lot of that risk? Or you're going to use our language models that we're releasing, the ones we've already released have been downloaded 25 million times.
Speaker B: Why are they banning chat GPT?
Speaker C: Because what happens when you upload and type into chat GPT sensitive banking data? You know, can you write precis about the activist takeover of Amazon as an example? Right? You can't do that, can you? So you need your own model. And are you going to train your own model from scratch, or are you going to use all off the shelf model? You're going to use that one, right? Because since we released stable diffusion, we released it open source. Only two companies that we know of created their own version from scratch because training the model is very hard. So we're training the base models in generalized forms. We have sector specific versions of that with commercially licensed data, and we have country versions of that for individual cultures. And then we distribute that through our hyperscaler partners like Amazon and others like Snowflake made 900 million via the Amazon sales channel last year. And our value is in standardizing and making that predictable and stable, shall we say, across all these modalities. So for the base layer, use us, we get our revenue shares, we get our customized things on the back of that as well. And we can be open AI for everyone else, because there's no other company that can guarantee that you can build a model. So we have all the top companies in the world coming to us and saying, can you create custom models for us? And we're like, yeah, how much? How expensive is that? It's very expensive compared to seven weeks ago. So it's a mixture of the standardization and this customization. That's where we fit in for all the private data in the world. If it's public data or if it's generalized stuff, you can use the APIs and you can send your data to Google and Microsoft. There are also going to be private instances of chat, GPT, and others where they guarantee not to look at it. And that's again a great halfway house. The landscape is these private instances, these generalized APIs, and then the private side, the standardization layer is us.
Speaker B: So you talked about the specialist models. Where are you now with all of the suite of products that you've got? Because you've got a lot and more coming.
Speaker C: Yeah, so we've released the image models, and we have the next generation of that coming out. They're cutting edge, full controllability now. So we figured out fingers and figured out text. We have video models training on 11,000 videos.
Speaker B: When is this video shit coming? Because that's, I think another big shock that people don't realize what is about to happen.
Speaker C: I think the first release is in a month or two from us. We've got an amazing team.
Speaker B: And this is text to video.
Speaker C: Text to video, yeah, you type it in and generate videos. You can already kind of just act a video and do style transfer on it, like the corridor, digital videos. And that'll be heading towards real time, where you can turn what we're doing right now into full animation, almost real time, but then you want to be able to create anything just by describing it, which is coming. We've got script writing technology as well, so all write scripts in the style of some famous directors. We're about to announce to help the directors. The whole of media is going to change as a result of this.
Speaker B: Yeah, we're spinning at real vision to try and just figure out where the hell to. Where to play your cards. Because unless you're a big company, you've got budgets and you need to figure out what the hell to do.
Speaker C: Well, I mean, this is the thing. You can auto generate a podcast based on the intents of the person on the other side, right? With a human realistic voice. And then even Raul auto generate entire interviews back and forth between people.
Speaker B: Yeah, because there's enough content of me online that you can train a model.
Speaker C: Yes. And so you can have a customized rowel every morning for every single one of your listeners. I think within a year, definitely too.
Speaker B: Oh my God, how do I keep up? I mean, it's just really hard because you don't want to get. You don't want to get disrupted because somebody's going to do it. That's the terror in all of this. Is there some 24 year old going, well, fuck it, I'm starting from scratch and I'm gonna.
Speaker C: Yeah, like there is an infinite Seinfeld channel. Now some of the jokes are quite funny, you know, there's this thing where they've got the dynamic defects again. There are certain things you have to always think, where is my edge in this new world? Because what happens, this is a regime change, right? It's a regime change in the way that information flows around the world and it's going to restructure the value landscape. And then people find their own areas. Like where is rvalue r value as being the standard for open models? But what do we mean by open? We mean transparent, free range, organic, you know, how they've been fed, you know what's inside it. And there's a whole ecosystem of support around it, right? So transforming the world's private data is our thing. And that's where I'm occupying, because I think that's 100 billion trillion dollar company, you know, that's something I want to IPO ASAP. Other people are finding their edge elsewhere, you know. So like I said, in regulated industries, if you adopt this technology and you can scale the human component, boom, your costs go down dramatically. In media, if you use this, then you can leverage your existing ip and boom, away it kind of goes, you know, you can surface stuff. You've got intelligent interns and analysts and associates and vps coming. You don't want to be computed away. At the same time, stuff is slow. Like people still use lotus notes, right? 1.5 million people are still in AOL. Everyone said that meta was going to disrupt search. Never really happened. Hopefully they'll turn back to being Facebook soon. Yeah, maybe they'll change their ticket to AI.
Speaker B: So we've got text to video, we've got script writing, we've got the next version of your of language modeling, the stable solution. So we've got that's the kind of gorgeous ability, text image. Then you've got language models. Talk us through your version of chat GPT and how you play in that sphere, because that's interesting.
Speaker C: Yeah. So, in our existing language models, from our Eleuther AI community generated 25 million times. So they're basically the standard in language models already. They don't really communicate that much. In fact, we just spun out Alutha into an independent charity, or 501 to do interpretability, evaluation and alignment, because we think it's important to have an independent entity rather than us going, doing it by ourselves. And we're bringing more and more parties to that. So the language model is the first bit, that's the bit that's trained on the corpus of the Internet. And we have our new data set, the power version two, being released in like a week. Right?
Speaker B: And how recent is that versus chat GPT, which is 2021?
Speaker C: It's like a few months ago. But again, these models now we're teaching to be auto updating and things like that, because the other part is we have a code model coming. So we released the first version of that last month, 6 billion parameters. And so when you combine the language model with a code model, you can do dynamic SQL database lookups to fetch recent data. So U.com, neva and Bing do that to make sure they're up to date. So you have this generalized knowledge and then a lookup of recent facts to compare against it. You don't have to have one model to do everything, although eventually you might be able to. So the base thing is first the language model. So our language models are very good, touch wood, like mounting lots of GPU's. But then the next stage of that after that is you instruct it to human preferences. That's reinforcement learning with human feedback. Because you have this generalized thing, it's like putting someone in front of a tv and taping their eyes open and they just watch it. They learn about everything you know. But sometimes the answers are a bit crazy. So you teach it what type of questions and answers via reward function humans usually like, that's the RLHF bit. That takes a few months, right? And then you take sector and domain specific questions and instructions, and you add that, and then you see how people use it in real life, and you iterate and you adjust the outputs that way. So, you know, that'll take like, I don't know, six months or something like that, the whole process. But the language models are the first bit, and then you move forward to that.
Speaker B: And so it's going to be like a stability chat. Is that how you think of it?
Speaker C: Yeah, we've got stable LM first, which is the language models, then we've got stable chat, and then we've got stable code. And so people will use stable code for their internal code repository, stable chat for their internal things, and then they'll pull in Google and Microsoft OpenAI API to create amazing hybrid AI experiences, right?
Speaker B: So you can use both. So you can have your private data, private model on stability, but you can still use the generalized Google one or whatever you want to do.
Speaker C: Yeah, like you could have Google Slides, like I said, and it pulls in your private knowledge, and then it pulls in this really amazing script writer from OpenAI, and boom, you have auto generated slides that are beautifully coded, or you have it in office, etcetera. I think that's the future. You have private models and you've got public models, right? Just like you had on Prem and cloud. So that's why we're building models for every single type of media, because every single type of media will need their own models, and you bring them together, what do you get? Hold worlds created dynamically, movies created dynamically.
Speaker B: And isn't this just the metaverse moment as well? Because everything just goes into that now, because you digitize everything you can create. Raoul can exist in five different places at the same time, talking to different people in my own voice and all of that kind of stuff.
Speaker C: Yeah, this is the breakthrough technology that Facebook should have focused on or meta. They did not, but now they're lucky because they get this. And so what we're doing by building open models that everyone can optimize for and standardize around will drive the acceleration of bringing that multimodality, those digital twins and other things for private data. Because otherwise what happened is you'd have this Microsoft choke point on the Internet just like it had before. Right? Now at least there's another option. And people can own their own models and own their own data and have localized versions of it, customized versions of it, rather than, you know, being beholden to that. So that's where I realized the gap was, and that's where I've gone with stability. I think that's a better place to be as a business. I hope. I know. And also, it's good for society, because, again, we don't want this technology to be controlled by just a few. We want it to be widely available.
Speaker B: So let's get philosophical. There are two outcomes. One is it accrues to some two or three superpower companies, or b, it's given to everybody. And a combination of the two is what's happening. So it becomes kind of ubiquitous. There's no stopping it, right? Your choice of stability, AI as an open source means that it is now essentially viral.
Speaker C: Yeah. I mean, like, you just look at stable diffusion, most popular open source software ever. In three months, it overtook bitcoin and Ethereum cumulatively on GitHub. In terms of popularity, it took them ten years. It's overtaking Linux as an ecosystem, putting this out there. People will take it, extend it and build around it. We've seen 16 year olds to 60 year olds kind of doing that. So our image models are by far the best. Our language models, once they get going, we believe in a year, will be far the best, and they'll be accessible and usable, because otherwise you're going to have this digital divide right on steroids. You'll have super augmented humans who have access to chap GPT and those who don't. Again, I think we mentioned last time, like, I'm usually very supportive of this industry, but I spoke out against OpenAI because they banned Ukrainians in Ukraine from Delhi, too. The image thing, I'm like, how can you do that? Like, I think, I don't say unethical very often, because I think ethics are complicated. But I was like, that's just wrong. You know, they recently changed that in the last few months. But there was a long time when no one in Ukraine could have superpowers for art, you know? And I understand there could be reasons around that, but you can't have a world where you have these restrictions. Like, there was just a study released about chat GPT. Guess what? Chat GPT's ideology is that of Silicon Valley, okay? Like, you might agree that that should be the only ideology. My thing is that the world contains multitudes. And so we need to have, every country will need their own national models to reflect their culture, and we need to distribute this widely as infrastructure. So again, this is why we have imagine worldwide, bring this technology to the kids first and let them be the best of themselves, as it were.
Speaker B: And when in your mind, did these generalized models become smarter than humans? I mean, Mo Gordad, I don't know if you read his book, scary smart. So he was the guy who ran Google X, a really interesting guy. He's just like, end of this decade.
Speaker C: Well, I mean, look, half of people have below average iq right?
Speaker B: Around that by definition.
Speaker C: But 95% of people think they have above average iq, right? The barrier is not high for generality, unfortunately, or fortunately, I'm not sure. So I have no idea. I just know that chat GPT is a better coder than I am in certain instances, right? It's a better paint stable. The future is a better painter than I am. You know, our music models are better musicians than I am. Like, I'm sure that med Palm is a better doctor than I am.
Speaker B: And do these all become just one big, massive model in the end?
Speaker C: I think you need millions of models, because as you have a model that's specialized, it can be highly performance, right? These models are coming stage all of.
Speaker B: The specialized models together. You get generalized aihdeme.
Speaker C: You get. Yeah. So my take on the AGI debate and all that thing is that swarm intelligence augmenting humans, is the only real alternative to an AGI that overtakes everything. And I think this can be used to create swarm intelligence on the way to that. You make people happier and you give people agency, which I think is a great way to do it, because I don't like this idea of just building multi trillion parameter model on billions of dollars, where people talk about alignment to these models with the immersion properties, right? So they're like, we can constrain it.
Speaker B: Alignment discussion, because that's important as well.
Speaker C: Yeah. So alignment is that as we build a model that's generally more capable than any human and can learn to be even more capable, we can align it so it's beneficial for humanity and doesn't wipe us all out, because it's like, man, what's the easiest way to make humans not sad, get rid of them. All right? But for me, that's orthogonal to freedom. So if you have someone more, we've all had people more capable than us, right? Can you constrain them? Yeah, if you restrict their freedom, and that's the only way you can do it, because they're by definition more capable than you. And that terrifies me. So for me, one of the reasons I want to get the technology out there, I want to get it where it's useful in education, healthcare, creativity, is so that we can have dynamic form, intelligence, and then that can coalesce to maybe counterbalance that, which is a crazy thing to say. But again, we see, it's why I'm.
Speaker B: Having these conversations a lot now is like, it is not certain what that path is.
Speaker C: It isn't. And so the common refrain that I get is two things. The only way to beat an AGI is to build another AGI that stops the bad AGI from happening. Like that strikes me as being very bad. Right. The other thing is, if we don't build AGI, the Chinese will build AGI. I'm like, again, that seems like a bit silly. So my thing is, again, get this technology out. Create standards around it. So one of the things we introduced was opt out of our model data training sets. Nobody else has done that. Now is it because they think it's the legal requirement? No moral requirement, not really. Because again, if it's public and open and you're using scraping, I should be able to use for that, but I think it's the right thing to do. And so setting standards around that, pushing back against governments who actually want to be even more permissive about what we can do, I think we need to set standards like that.
Speaker B: How do you stop somebody, Israel or somebody, saying, well, we're not going to adopt any of your standards, therefore we can capture market share and we can do that.
Speaker C: No, I think all you have to do is just have to try and take a lead and make it the defaults. So again, the models that we are training, how many people have released stable diffusion models even though they have the training code? And it's like only a million bucks to trade. Again, compared to the value created? Like, Lenzo was making two and a half million dollars a day on the app store. That's just one app, right, from this technology, but nobody trained them. So being in this open, transparent standard, like, we have quite an important place in setting the standards of what is reasonable, you know? And then if people don't adopt that, as you said, maybe they out compete. I don't think they do. There are elements around that. But it's hideously complicated, unfortunately, and especially at the pace, like, there is no time to breathe, unfortunately.
Speaker B: And it's really interesting listening to Sam Altman speak and seeing his tweets. I mean, he's fucking terrified.
Speaker C: They said that the AGI alignment plan, and it was like, we're going to treat this as existential, even though some people disagree. I think that's incorrect, because if it's existential, you wouldn't build it unless you're terrified of someone else building it. So there's a very unpleasant race dynamic.
Speaker B: The case right there is game theory here.
Speaker C: Yeah. It's kind of a known unknown. I think, you know, it's an incredibly difficult thing. We don't know if it's ten years, 20 years, one year. It's a known unknown, as it were, because again, it's, when do you have generalized intelligence? My take is, stop trying to build generalized intelligence. You don't need it because you can have superhuman, narrow intelligence already. That makes us better, and we should focus on that. And again, getting out there, the hive mind, how people use this and then take it and extend it, especially if you standardize the base, you know, people optimize around that. That's what you've seen with stable diffusion. That's what you're going to see with the language models that can out compete the deepminds and open AI's and others of the world. I think in maybe getting there first in a small manner that is safer.
Speaker B: But I don't know, where are the regulators in this? I mean, they can't even regulate crypto. How the hell are they going to regulate this?
Speaker C: I mean, look, on the section 230 discussions at the Supreme Court, they're basically getting around to the Internet right now, right? I mean, literally, that's in the comments. Like, you have to help them, right? And so I think, again, regulation should be introduced, but you need to help the regulators. You can't introduce it in time. And again, the regulation is actually pro competition now because every single country is looking and looking at the other ones like, holy crap, who's going to adopt this technology faster? It's a very unfortunate race condition. So this is why I said, like, this is one of the biggest economic impacts of all time. I think it's going to be bigger than the financial crisis, bigger than the pandemic. There's a lot of irreversibles, and some key questions will have to be made around this. This is also, you know, like, from my side, I'm like, I need to make stability a public company because we need to be accountable given our place in this. Also because there's going to be a supply demand imbalance like no other if.
Speaker B: I click, because I was about to ask the question. There's basically no way to invest in this right now for the general public. Yeah, you can buy semiconductors and you can buy Microsoft and Google, but that's it.
Speaker C: That's pretty much it. And even with Google, you've got the supernormal margins that are definitely going to come down as a result of this. Right. And they'll get punished for anything. You've got Photoshop and Adobe and things like that, that will get a benefit. But then what happens if a competitor comes in? You've got Nvidia, it's gone high. But what happens when people shift to ASics that are ten times cheaper, you know, so there's no easy place. I'm like, I'm gonna make an easy play. And then that will hopefully allow me to, you know, distribute the governance and have a positive impact on this, even while making it so that we can remake game of Thrones season eight because it was crap and things like that dynamically. So again, there's this terrifying aspect to this, but there's this amazing aspect of this. Educate every child. What if this AI kills us? What if someone gets it before? So it's this duality that I deal with every day.
Speaker B: Yeah, it's like nuclear weapons and nuclear energy.
Speaker C: Yeah, it's like, what if you put the nukes on the bottom of the rocket? You would have got to Mars already, right? We put them on the top.
Speaker B: Yeah, I mean, yeah, it's a very good point. The other thing that is coming down the track, and I know Google have been kind of working hard on it, but also concerned by it, is quantum, because quantum then increases the speed of this thing. Like to Reid's law, it just goes exponential. Exponential.
Speaker C: Well, I mean, so you've had the move. So what happened is that you couldn't, you could with the transformer architecture that paid attention to the important parts of things when learning principles. You could scale it with these a things like that. But after a thousand or so, it tailed off just because of thermodynamics. Actually, like I said, we're literally melting GPU's now and got like 6000 training our language models and things like that. It's like a half a billion dollar computer that's actually been solved now. So that's linear scaling. You can actually emulate quantum qubits on h. You can scale it pretty much out there, which has big implications if you think about it, because people are willing to drop billions on these things now, where people only drop hundreds of millions as quantum computing comes in. The key thing here is you have these models forming one part and then quantum computing is great for optimization equations because one of the things you've seen is you've moved to deep learning as a key thing. Now you're introducing reinforcement learning. And this brings up forward things like Alphago and those AI's that beat humans at Starcraft and stuff like that. And then you bring quantum into that. You can basically optimize complex systems, which is kind of crazy. Um. Yeah.
Speaker B: How the hell are you staying on top of all of this? I know you're at the epicenter of.
Speaker C: It, so I get that it's difficult, man. Like, every day there's not a breakthrough. Seriously. The actual. You look at MLK papers on archive, it's an actual exponential. It had a 26 month doubling. It's now like 13 or something like that. And again, it's parallelizing.
Speaker B: Raoul, a lot of people ask me, where's the financial markets, people with this technology, whether it's renaissance, I don't know what models they had, because they were obviously doing a lot of stuff early on. Where's that coming? How unfair, advantageous. Do the model, the people who can build the models get for a while?
Speaker C: Well, I think they get a big advantage because you can understand how to break down the markets. I think you move to AI based market makers sooner rather than later. There's a whole bunch of stuff. The general sophistication is very low because there aren't many people that understand these technologies. There are only a couple of hedge funds I've seen. They're not even doing properly. Like, if I have this time space, I launch my own hedge fund. So it's going to come. And again, I think there is an unfair advantage from being able to do this even more. So if you have more degrees of freedom, shall we say? Like, what if you could read the stories and create the stories? We're going to see agents like that that understand how things spread based on the variety metrics. So I think markets have already moved highly narrative based, if you look at it more than ever. Where are fundamentals anymore, even compared to narratives? I think that will just continue to be exacerbated by this technology.
Speaker B: Raoul, one of the things you might have seen me talk about this, and we briefed on it before, is how the hell is society going to deal with the deepfakes and the scale and speed with which we can create that going into the US election in two years?
Speaker C: Well, next year, right? Next year basically got perfect deepfakes. They were coming anyway, and it's pretty much real time. And the voices, like the audio dj that just got released in Spotify, that was my sister in law's technology. Perfect voices, right? Dynamic with full emotional range. I think the only way is you have something like content authenticity. You have this kind of immutable trace from a curated source, because then social network becomes even more important with the way that you curate these scenes, because detection is very important. But we're going to do a $200,000 deepfake detection price for open source, then we would like to be a waste condition. So maybe it'll be some sort of blockchain. Maybe it will be something like content authenticity that does a encode meta file. But there needs to be standard sooner rather than later. But I think already people are like, I don't really believe that anymore because I just saw it on TikTok. I'm pretty sure Tom Cruise isn't doing all that stuff, you know.
Speaker B: Yeah, but it's fine in normal, normal life. But when it comes to points like pandemics, things of societal importance, that becomes complicated. I've actually spoken, spent some time speaking to Google, Facebook, Amazon, LinkedIn, all of this about authentication of people as well, because maybe you just authenticate people.
Speaker C: And then this is why Meta is introducing this people authentication. This is why I said, if you look at this variety and spread, it's all about the curation aspect of. Right, and so there's a verification thing and that could be blockchain or it could be content authenticity.org. but then there is, what are these key choke points on information flow and what do they look like?
Speaker B: So you were working and we've chatted about it privately on cool stuff that are going to make people go, oh my God, again, when is some of this cool stuff that you're seeing coming out, or is there any cool stuff that's out already that you think people haven't noticed that, how amazing this is?
Speaker C: Well, we've just hit full controllability on image. So you can take the pose you are now and then you can basically transform yourself into anything, move it to 3d. There are new types of interfaces. So I don't know, how long does.
Speaker B: Something like that take? Talk me through that process. So I put in an image of me or a short video of me, I put it into this model. And then what?
Speaker C: And then you can transform yourself into a transformer in like, I don't know, a minute or something like that. And then once it's trained, it takes a second each time to transform yourself to anything else. But then you can export your 3d model, adjust it with a blender plugin, and then you can just do that. Or you can take a whole movie and then transpose it with coherence probably in the next few months into like an anime. You can make yourself Dragon Ball, whatever. Then you can view that on. I don't think I showed you like one of the companies, I'm on the advisory board of Leia, they just released their glasses free retina quality 3d tablet. So it's 3d without glasses and it's retina quality. I'll send you a tab. And basically we convert two d to three d live as well. And you're like, what is this magic craziness? Especially advanced technology is magic. There's too much magic out there. The question is, you know, is it destructive or creative magic? It's a bit of both, unfortunately.
Speaker B: It is, yeah. We just have to be honest with ourselves. We just don't know. But it's not going away. You can't put the genie back in the bottle. We were always going to. Somebody was always going to build this.
Speaker C: Yeah, someone was always going to build this. And that's kind of what I saw. And that's why, you know, stability is like 16 months old. I accelerated this so, so hard, and now I'm accelerating it again, because like, again, we've got to have options, right? It can't just be like controlled by a few choke points that, okay, they get economic excess, but at the same time, like, are they doing the right thing? I don't know, but there should be options. Am I doing the right thing? I don't know. But at least other people can take the technology and kind of use it hopefully for their own customization. And the ownership structure is different. Is there a good business on that? I think there's an amazing ridiculous business from that as well.
Speaker B: And the whole entertainment industry as well completely changes. Oh, here's a question that somebody asked me the other day, and it's a very valid question. Has the porn industry adopted it yet?
Speaker C: I don't know.
Speaker B: You know what I mean? They've always been very fast with the adoption of technology because then that changes a lot of the equation. You can see these AI models now. So modeling so you can get whatever kind of model you want to wear the clothes that you want. You know, it's like, oh, okay, well.
Speaker C: I mean, like, I'd say my hope is probably that the exploitation, right in that industry decreases if you have digital variants of it. But I'm not sure how it's going to be adopted at the moment. I do know that just like, you know, real life, still life pictures, some of the kind of models that included lots of work, actually have better anatomy and things like that because it learned, again, it learned to from still lifes and nudity and things, which is kind of crazy to think again. I think any information media flow based business gets changed by this. And that is basically western society. Right. Like, I can't think of very many places where this isn't applicable to save money, make money, create new experiences, et cetera. I can't either.
Speaker B: And I can't get my head around it because it's literally every single thing we see do learn. I mean, just. It's everything.
Speaker C: It's everything. And there's this question, like, I am reasonably convinced that in two, maximum five years, you'll have chat GPT on your smartphone without Internet. What does that mean? When you have a very capable, analyst level person on your phone? Bing is no longer stupid. Siri is no longer stupid, and it learns about you.
Speaker B: But it also means that the Internet of things can have the same.
Speaker C: Yes.
Speaker B: And they can be embedded in your fridge.
Speaker C: Yep. And you can go everywhere. I said you'll have it in your toaster. Devil diffusion in your toaster. Why? Because then you have fancy toast, fancy test.
Speaker B: Of course you will. I mean, you know, the Internet, things is headed that way, but once you give it AI, it can do all sorts of stuff.
Speaker C: Well, web three was missing AI, right? I always was very puzzled by that. You have identity, but you don't have AI. So again, like, I think people will adopt this faster than. Well, they are adopting it faster than any technology we have ever seen. And we've been in markets for decades, right? Never ever seen anything like this. Nobody has, because there's an installed base and it just seamlessly fits in because it takes structured, unstructured data back and forth. And then he said, like, eventually it will be on the edge, you know, and it will be available to everyone. And I think that is an incredibly uplifting, agentic thing, or it's the panopticon to end all panopticons. I don't know.
Speaker B: Yeah. I don't know if my fridge is going to take over the world or not, but once it's off the Internet, it's hot. You can't control it.
Speaker C: Yeah. There's a great story by, I think, Cory Dotterer called unauthorized toast, the intelligent toastmaker. You don't pay it, it stops making toastheen. You know, you got hitchhiker's guide to the galaxy with Red Dwarf, with angry toasters and things like that. Oh, my God, it's going to be a crazy future. I don't want toasters giving me attitude. Get enough of that already.
Speaker B: Yeah. Ahmad, listen, amazing. Again to catch up with you. Thank you for giving us your time, and good luck with everything. Let's see what we get. This is crazy. I mean, we only spoke about a month and a half ago.
Speaker C: I don't know, time compression technology. Like, oh, my God, where are we going to be in a year? I don't know. I don't know.
Speaker B: I have no idea. I have no idea. Anyway, my friend, great to see you as ever, and good luck with everything.
Speaker C: Cheers, buddy. We live in interesting times.
Speaker B: We do indeed. There's almost too much to process in this video. I can't get my head around it. It's moving too fast. There is too much happening in too many spaces in every single aspect of everything we do as humans on earth. From creating art, to writing scripts for films, to the medical practices, accounting, lawyers, media, literally everything. Any single absorption of knowledge has changed, but at a rate of which none of us can understand. A how to even catch up, but how to even understand it. And when I ask Emad, who's at the bloody center of it all, where it's all going in five years time, he's like, fuck knows. It's moving so fast in so many unique ways by so many people that we really have no idea. But I think Emad confirmed my view that this is literally the biggest thing that has happened on an economic and societal level in history in the shortest period of time, and the ramifications of this will live with us forever.
