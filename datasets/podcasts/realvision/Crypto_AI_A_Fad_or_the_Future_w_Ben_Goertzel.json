[
    {
        "speaker": "A",
        "text": "Hey there. Before we get started with the show, we just want to let you know today's crypto daily briefing is in partnership with the crypto phenom letter. This is a one of a kind premium investment newsletter service that highlights the next winners coming in. Cryptocurrency tokens and equities get special access today@phenomcrypto.com. realvision that's phenomcrypto.com realvision."
    },
    {
        "speaker": "B",
        "text": "Doctor Ben Gertzel, CEO of singularity net. Welcome to real Vision Crypto Daily Briefing."
    },
    {
        "speaker": "C",
        "text": "Hey, good to be here, Ben."
    },
    {
        "speaker": "B",
        "text": "It's great to have you. Looking forward to this conversation. Excited to talk about AI and crypto and the nexus thereof. But first, we've got a little bit of news flow this morning, and I want to take a look at some price action. First up, bitcoin trading right now, 25,653 one day. That's off about five and a half, we'll call it 5.7%. It's dropping right now on my screen and on some news flow that we're going to talk about in just a second here. But first, I want to talk about ethereum. Ethereum right now trading at $1,789. It's off about nearly 4% in the last hour, off about 6% in the last 24 hours, trailing seven days, off about 5%. All of this happening in the wake of revelations that SEC has sued crypto exchange binance over its violation of us rules and law. This is a breaking story. It's developing here hard and quickly. In the last call at 60 minutes or so. I want to just read this to you right out of the Wall Street Journal so you have a sense of what's going on. The securities and Exchange Commission on Monday sued Binance, the world's largest cryptocurrency exchange, alleging the overseas company operated an illegal exchange in the United States. The SEC also named Chang's pen Zou, better known, of course, as CZ Finance's founder and controlling shareholder, as a defendant. This is personally. The SEC said that Binance and Zao misused customer funds and even diverted them to a trading entity that Zao controlled. The trading firm Sigma chain engaged in fraudulent trading that made binance volume appear larger than it actually was, the SEC said. This is from a Wall Street Journal article literally within the last 30 minutes or so that has just crossed the wire. With that as backdrop, Bentley, an eventful day. It's great to have you here."
    },
    {
        "speaker": "C",
        "text": "Yeah, great to be here. And I mean, the crypto markets have been completely insane in various respects since I got into this space since 2017. So, I mean, you sort of, after a while, get used to, like, let that happen and focus on building amazing, amazing stuff, which is what we've been doing in singularity net, or at least, or at least trying to."
    },
    {
        "speaker": "B",
        "text": "Ben, you are someone who has been in the AI space for a long time. You wear a lot of hats, talk a little bit about your background, how you got to where we are today, and all of the things that you're doing right now in this space that represents the interface between artificial intelligence and blockchain."
    },
    {
        "speaker": "C",
        "text": "Sure. Yeah. I've been doing AI since mid 1980s, really? And got my PhD in math in 89, but already been. I was doing AI prototyping, experimenting and R and D and reading about AI since the early seventies when I was a kid. AI has been around a while. The term artificial intelligence was coined in the late fifties, I guess, and already there had been research like that going on for a couple of decades before. So AI has been building up for quite some time with prototypes and research and ideas and even deployed commercial systems for many decades. But of course, there's never before been such an explosion of AI capability as we've seen in the last couple of years, even the last six months. So it's a super exciting time to be doing AI. What got me into the AI field in the first place was the promise of what I eventually came to call AGI, or artificial general intelligence, meaning AI that could generalize, take imaginative and creative leaps beyond its programming and beyond its training data, and thus, you know, advance itself, much like, much like people at our best are able to do. And I introduced the term AGI in, I guess, 2004 or five, and have been organizing AGI research conferences since then. Of course, when they got into crypto, I used AGI as the. The ticker symbol for singularitynet token. We then changed to Agix as we made it cross chain. But the tension between narrow AI for specific applications and AGI, meaning AI that's broader and can extend to any application, basically beyond its programming or training. This has really been there since the beginning, and it's interesting to think about in the current market, right? Like in the very beginning of the AI field, in the fifties and sixties, people were after AGI, though they didn't have that term. They were after machines that could really think like people. They thought it would be much easier, and they thought it would just be a few years of hacking, right? And then gradually people started to realize how hard it was to make a machine do some of the basic things people take for granted, like recognize pictures or make legs walk down the street. But that it was counter intuitively simple to make an AI do some things that were really hard for people, like solve algebra equations or play checkers or chess at the master level. Right. So then the AI field sort of split into people focused on making AI systems just do practical stuff that seems smart when people do it by hook or by crooked versus short, making machines that can really think in a broad and general sense more like people can, and narrow AI doing specific tasks got a big boost when the Internet came out, obviously, just because there was networks of machines and there was more and more data to feed into the AI's. And AGI R and D on making real thinking machines have been progressing at a smaller scale along the side."
    },
    {
        "speaker": "B",
        "text": "Let me just jump in here, let me just jump in here to frame this up a second so I can get, because I know it's a tremendous amount of information and I want to make sure that we can explain it to people in a way that they can form some kind of categories in their head to break it down. You are really one of the true experts in this space. Pretty extraordinary that you've coined the term AGI, artificial general intelligence. A great debate about where we are with regard to AGI right now. You alluded to something called Morvec's paradox, the notion of some things that appear to be relatively simple, physical motor activities, sensory motor activities, much more complicated for computers to do than basic algebra. You mentioned singularity. There's just a whole lot of concepts here for us to unpack. I'm excited to get to do it. So let's talk a little bit about one of the things that really strikes me, and something that you alluded to initially there in your remarks, is this idea was for a very long period of time, AI was coming, it was coming, it was just around the corner. It seemed like it was just around the corner for decades. And then suddenly there just seems to be this explosion within the last six months. And some of this is probably the degree of popularization that chat GPT has created in the business world and more general news cycles. But talk a little bit about whats happened here in the last, say, six to twelve months thats created this just explosion of new use cases, applications and view."
    },
    {
        "speaker": "C",
        "text": "Yeah, I would say progress on AI has felt a lot more continuous from the inside when you're working on research and development. So I can see from an end user's point of view, it's like, whoa, I wasn't doing anything I could see or understand, and then, boom, suddenly it's making pictures and writing documents for me, right? But from the standpoint of someone in the middle of the research field, AI has been making pictures and writing documents for a long time, just not quite as well. And it took a huge amount of compute power to do so. So, and AI, I mean, it's been proving, proving math theorems and predicting markets to controlling robots, or AI has been doing a lot of things for a long time. There has been a jump and inflection point in the last six months, but it's nothing. Probably not as big as it appears to the retail end user, but I do think from a sort of economic point of view and societal impact point of view, the launch of chat GPT by OpenAI is a sort of black swan event, right? I mean, it's a big deal that changes everything, even though there are very few new ideas inside the chat GPT code base. And it doesn't really work that much better than things that existed before it. But I mean, it was rolled out to the public at large with a very simple interface. Everyone's using it, everyone's thinking about it, everyone's customizing it, right? So certainly in terms of public visibility, public enthusiasm, and just amount of resources going behind developing and deploying it, it's a black swan event, right? And it's quite interesting and important from that standpoint. I mean, I think it's important to clarify that chat GPT, I mean, while it can impersonate human intelligence effectively in some settings, it's certainly not a human level general intelligence. I mean, it doesn't deviate too far from its training data. It's just that its training data is the whole goddamn web, right? So, I mean, it's got a lot of data in its mind, so it doesn't have to deviate too far from its training data to do some, to do some pretty impressive stuff. From an economic standpoint, it may well be that minor variations on GPT four and related systems, because there's a lot of other ones out there now. It may well be that minor variations on this type of transformer neural net could do, who knows, 70, 85% of jobs that people do now. And just because most jobs people do are minor variations on stuff that's been done in the past, you take a big leap beyond experience to do most of what people get paid for. It's like, on the one hand, no, it's not yet a human level thinking machine, and we could talk about what the gap is, which I'm trying to. To fill, to use chat DBT type systems to jump toward human level intelligence. On the other hand, even without being at human level intelligence, well, can be massive disruption to the economy. And a lot of the disruption that one might have thought would happen only after you had human level AGI. A lot of that disruption could happen beforehand. Right. Massive scale, narrow AI systems trained on everything in the web can take over most human jobs. That's going to trigger tremendous disruption and then reorganization economically and societally."
    },
    {
        "speaker": "B",
        "text": "Well, I'm really eager to talk about the jobs component because I think that 80% number that you cited has gotten some buzz, some headlines around you talking about it here in the last couple of weeks. I'm talking about here in mainstream media. This has gotten quite a great deal of pickup. Before we talk about that, I want to ask you about AGI versus the singularity. These are two terms that are floating around out there. Can you define them and compare and contrast those two points in terms of the general?"
    },
    {
        "speaker": "C",
        "text": "I think that's important. So AGI is a very general term, artificial general intelligence. And humans are by no means the most general intelligences that are possible. Right? I mean, we're pretty smart, but we're, in a way, the minimum possible artificial general intelligence, you know, capable of building its successor. So, I mean, humans are an inflection point, not because we're the smartest thing that will ever exist, because, you know, apes and dolphins and chickens cannot engineer their successor. They're just sort of unwitting parts of the evolutionary process. So you can talk about human level AGI, meaning software systems that can do general intelligence at roughly the level of humans, meaning that their stupidest component is at least around the human level. They might be smarter in some things, but then you could talk about superhuman AGIs, general intelligences that are way smarter than people in the same way that we're smarter than chimpanzees, mice, or slugs. What's interesting is when you have a human level general intelligence, if it can program and do engineering, it should be able to improve its infrastructure so as to turn itself into a superhuman general intelligence. Right? So if you look forward from here, I think there's going to be a threshold event, another black swan event, when someone makes a human level general intelligence that's even smarter, that's as smart as people in every significant regard, and a little smarter and a lot smarter in many regards. But then after that, you're going to see another black swan event where that human level AGI has reprogrammed itself to make itself way, way smarter than people, which has been called an ASI, or artificial superintelligence. Right? So once you get that ASI, that artificial superintelligence, then, in a sense, all bets are off, right? I mean, you have something ten or a hundred times more generally intelligent than. Than people on the planet, and, I mean, we can speculate about what that's going to lead to, but it's hard to. Hard to analyze in depth. That's what Ray Kurzweil and Werner Vinji and others have called the singularity thinking at that point, your phone may be making ten Nobel Prize level discoveries every minute. So, in a way, the rate of progress of knowledge and invention becomes effectively infinite from the comparison point of human intelligence. The interesting thing is the timing of these things could be rather soon. I think we could be at human level AGI within, say, three, five or seven years from now, and we could then be at superintelligence within a few years after that. This is the conclusion that rational analysis leads me to, but it's pretty mind blowing from a personal and emotional standpoint. Standpoint. And hard to incorporate that sort of analysis into your everyday life. Right? Like, in. In your everyday life, you're thinking about, like, how do I plan for my kids to go to college and where I'm going to live when I. When I get old and retire? But then, analytically, you're thinking, well, shit, if it's three or five years to a human level thinking machine, and three years after that to a machine a hundred times smarter than people, like, what is that? By the time my five year old gets to college, we may all be, like, floating around in a hundred dimensional space, or just, you know, instead of a foam, we have a molecular assembler that builds anything we describe to it, right? And so it's. It's a quite dislocating time in history to be alive, which I. I find quite fun and many other people seem to find disturbing."
    },
    {
        "speaker": "B",
        "text": "Well, I find it both fun and disturbing. I guess. It. It is really kind of the. The best and worst of times in terms of risks. You talk about this idea of 80% of human jobs being eliminated. This got a lot of buzz and a lot of pickup in the last couple of weeks, mostly from you actually citing that statistic. Talk a little bit about what that would mean in terms of the actual implementation, how those jobs disappear, and what your thoughts are about the impact that it will have on broader society."
    },
    {
        "speaker": "C",
        "text": "Yeah. So, first of all, the 80% figure is definitely back of the envelope. I mean, I may write up a formal paper on this at some point, but, I mean, I just crudely went over the different job categories that are analyzed by us government and sort of tried to think myself through. Which pieces of which job should you be able to do without AGI, but with really smarteen narrow AI? By integrating chat GBT type systems with other tools that we have now. And it comes out with pretty much all of what humans do for a living. You can automate without AGI. I mean, there's a few exceptions. I mean, exceptions would be things like a preschool teacher or a therapist. They're just about people helping other people to be better people and sort of rely on human connection. I mean, very advanced level of science and engineering. I mean, chat GBT can't, can't do that, and probably requires human level general intelligence and then, you know, strategic thinking, where you're trying to go beyond anything that happened in history before, or the sort of high end of the fine arts, where you're inventing a new genre of music or being an incredible virtuoso or something. But this. This is not that high a percentage of what people get paid for, right? So I think most of what people get paid for is, in a way, a minor variation on stuff that's been done an awful lot of times before. And also with the way modern society is organized doesn't require such a deep, like, I vow, connection between one human and another. Actually, society has been organized to minimize the amount of deep and fundamental human human contact that's required during the day in a job setting. So, I mean, I think this is huge. It happens to be less huge than the advent of true human level AGI, which happens to be less huge than super intelligence. But even this earlier thing of most jobs being obsoleted by infra human level AGI is going to be big economically. I mean, I think obviously, for those who are deploying the AGI, there's tremendous business opportunity, which includes both of us, I would suppose. I think in the developed world, it's almost inevitable you're going to have some form of universal basic income getting rolled out, because there's already a lot of talk about it, and I just can't see developed countries letting half their population become homeless and starving. What worries me more is what happens in the developing world, right? Because there just isn't money to give everyone basic income, and we're not very good at sharing wealth between the developed and developing world, you may see very exploitative geopolitical dynamics, where, I mean, superpowers offer developing countries like offers they can't refuse. Give us all your minds and military control of your country in exchange for giving you money not to let your urban poor starve. There's a lot of weird things that could happen. One of the trade offs, which is interesting, is, on the one hand, you could say the best way not to have chaos, mayhem, starvation, and conflict during the rollout of smarter and smarter AI systems will be to accelerate progress even faster, because once, once you have a super AGI, presumably it could create abundance for everyone at minimal effort, including in the developing world. On the other hand, accelerating progress toward a super AGI could be viewed as a higher risk thing to do because you might say you want to be careful and make sure you're building the right sort of super AGI. Right. So on the one hand, there's tremendous humanitarian benefits of accelerating progress if you can do it right. On the other hand, there's tremendous risks to accelerating progress. And then you see in a global competitive context, there's risk to each country in accelerating progress of AI within their borders. If they can do it in a way that fulfills their interests. There's going to be a lot of interesting dynamics going forward, which I don't think we can forecast in detail. So what I've been focusing on is trying to build systems which, which can be ethical and which are hard for any one party to grab hold of and control for their own, their own interests. Right. And I think talk about that. And just for building ethical AGI can't be grabbed control of, at least then you're, you're biasing the odds in favor of a yemenite of a positive outcome in the midst of all this uncertainty and potential confusion."
    },
    {
        "speaker": "B",
        "text": "Ben, let me ask you this, and well talk a little bit about what youre doing in just a second here. But it seems as though the one thing that can be agreed and understood at this point is that the rate of change is going to be simply unprecedented. You talk about the risks in emerging markets. I think its very clear how that risk case can unfold in developed markets. You talk about UBI, universal basic income. I guess one of the questions that I have for you, as someone whos thought about this from not just a technical perspective, but also a social and cultural context, what are the risks of a dramatic shift in the way that work gets done? I think anybody whos ever spent time hanging out with kids, with trust funds knows the risk case that can unfold when you essentially sort of destroy the structure of peoples lives, and they sit home and they just collect a check and play video games or dive deeper into artificial and virtual worlds. What are some of the risks that you see from a radical restructuring of society around universal basic income rather than work that is hopefully fulfilling and meaningful to individuals who participate in it?"
    },
    {
        "speaker": "C",
        "text": "I think thats a fake problem, basically. I think the issue with trust funds kids is that theyre raised believing they have a higher status than everyone else, which is sort of psychologically deforming. I have three adult kids aged like 33, 29, and 26 or something like that, and three little kids age five and two. I would say none of my adult kids nor their friends have any worry about, oh, no, what if I don't have to work for a living and get free money instead? My life will have no meaning. I mean, they've got a lot of ways that their life has meaning that don't require earning money, and they'll be very happy not to have to solve that problem in their lives of finding a, you know, a workable, stable way of earning income. I mean, there's intellectual satisfaction, there's spiritual growth, there's making art and music. There's hanging out with your friends. There's climbing mountains, playing sports. I mean, there's, there's loads of ways to get meaning in life, which exists in our society right now, that are separate from, from working to get, to get paid and get, get resources. So I think for young people, that will be no issue. And there's a lot of young people on the planet. Average age in Africa is four. Is average age in Africa, I think, is 14. Right. So, I mean, it's true for more people getting on in years who've come to define their identity around their work, it's going to be very dislocating. I have a theory people will get over this really, really fast. Similar to, with longevity. Like, if I, if you talk to people, well, should we develop a pill that will let people never die? People will be like, no, but death is what gives life its poignancy and meaning. But if youre like, okay, heres the pill. Do you want to restore your body and mind to its 20 year old condition and leave it there until you decide to stop taking the monthly pill? 99% of people are going to say, oh, yeah, give that to me now. Ill find another way to give life poignancy meaning that doesnt involve becoming, see, now old and rotting in the grave. Right. So, I mean, I think, I think in the end, that will be a positive thing. And what we should worry about is not 50 year old cpas feeling a loss of meaning when they no longer have to work for a living. We should be worried about the people in Africa, Central Asia and Latin America who don't have money to buy prescription medication or, or pay their phone bill during the transition period between when AGI is taking their jobs and when super intelligence can provide abundance to everyone. I mean, there's just, there's just a lot bigger problems than the small segment of middle aged career people feeling uncomfortable because they. Because they can get free money and their status isn't as high as it was before."
    },
    {
        "speaker": "B",
        "text": "But I'm not sure that I agree. I'm not sure that I agree with you. I'm not sure that I agree with you. I'm not sure that I agree with that. I'm not sure that I agree with you. It's just middle aged career people who may potentially be dislocated by this. This notion that it's just going to be people who are over 40 or 50. I think the question about what we do with the structure of our lives remains an open one. I certainly hope that I am wrong and you are right."
    },
    {
        "speaker": "C",
        "text": "I was a bit of slip into that response. But I do think that younger people, on the whole, tend to be more adaptive. Right. And I think we will all need to be adaptive. And that's probably a more key, more serious point to be less flippant about. I mean, as you said, change is going to unfold faster and faster. It's accelerating. Change approaching a singularity. There's going to be more and more different on January 1 each year from January 1 the previous year. Right. So that the primary trait each of us needs to have is to be able to think on our feet and pivot and figure out new ways, both to earn money, while that's still a thing, and also new ways to define meaning in life and new ways to give to others around us. And the ability to adapt will be the. The primary important trait. And, you know, my friend Pei Wang, who's been an AGI researcher as long as I have, he defines intelligence as the ability to adapt to an unpredictable environment under limited resources, which is, I mean, it's one among many sort of equivalent ways to phrasing what is general intelligence. But I think that's a way to think about it that's very pertinent to what's unfolding in the world around us now. We all need really badly to be able to adapt to unpredictable conditions given limited resources."
    },
    {
        "speaker": "B",
        "text": "Speaking of resources, Ben, we've got limited time here today, so I want to give you the opportunity to talk a little bit about what you guys are working on at singularitynet. Talk a little bit about the project, why you spun it up. Obviously, folks who have been watching the token here, Agix, about 500% increase in value here, trailing twelve months, I should say. Talk a little bit about what the goals were for that project and where you think you are on that road right now."
    },
    {
        "speaker": "C",
        "text": "Absolutely. So our goal with SingularityNet project was to build beneficial, decentralized AGI. And the reason I founded Singularitynet in 2017 is it was already clear to me at that point, we were not that long, like maybe 10, 15, 20 years away from machines that are smarter than people. And I'd had the idea since the late nineties when the Internet and the web became a thing. The best way to work toward beneficial AGI would be to deploy the AGI across the Internet in a way that had no central owner or controller. Like AGI has to be like the Internet or like Linux, it has to be all over owned by everyone and no one contributed to by a vast mass of contributors. And if it's not that once you have a threshold event where AGI really starts to be coming, some group of jackasses with selfish urges is going to take control of it and try to use it for their own benefit, which could be a big company, it could be a country in the military intelligence. I mean, no one controls the Internet, no one controls Linux because of the way they're deployed in a decentralized manner. But then an AGI is trickier than the Internet or Linux because it has to be like live running systems on computers. So you really need a decentralized network of live running processes that's running without any central owner or controller. And this is enabled by SingularityNet platform. SingularityNet doesn't enforce any particular architecture for thinking machines, but SingularityNet is a platform that any sort of AI algorithm can be run on across a decentralized network of machines without any central owner or controller. And then there's other pieces to that platform now. So we rolled out something called Nunet last year that with tokenization of the processing power underlying this network, we did a token sell for hypercycle just a month ago, which is a customized layer one blockchain, customized to serve the needs of a decentralized AI network. So it's a ledger less blockchain, which is a quite radical departure from you don't have a replicated ledger anymore, which would be much faster and cheaper, which is really beneficial if you're running a decentralized AI network. We rolled that out in 2017 to 18. We've been making it smarter and smarter. What we're doing now, we have that platform out there for anyone to use, but we're building some very specific AGI systems on there. There's a separate code base called OpenCog Hyperon, which puts together large language models, like the one underlying chat GPT, with other kinds of AI, like logical reasoning engines and evolutionary learning, which is more creative. We're using Singularitynet new. Net and hypercycle as a platform to put together large language models with other AI techniques to try to make the big leap beyond chat GPT. And the notion there is if we make the next big leap beyond chat GPT on singularitynet new. Net hypercycle platform and do it in a decentralized way, then suddenly, instead of everyone in the world using chat GPT."
    },
    {
        "speaker": "B",
        "text": "Ben, let me just ask you a question."
    },
    {
        "speaker": "C",
        "text": "Everyone's using what we rolled out, but it's on decentralized platform."
    },
    {
        "speaker": "B",
        "text": "One of the resources that we're limited by right now is time. So I want to ask you this question about something that you said. Something that you said that I agree with, actually, I think it was in an interview with Coindesk, you talked about the idea of the risks of selfish or malevolent elites taking over the artificial intelligence space and bending it, as you say, to their own will. I guess my question for you is this. When you have selfish and malevolent elites as a potential class, you know, in the current structure of democratic western republics, we have at least the ability that we have accountability, just consent of the governed. In terms of the way that we think about how public policy gets made when elites step out of line, there is a legal process now that we can hold them to account with. What are the risks of having decentralized autonomous networks that effectively can't be controlled by anyone in control of this technology and driving the back end processing of artificial superintelligence?"
    },
    {
        "speaker": "C",
        "text": "I would say, first of all, the ability of current governmental processes to deal with something unfolding as fast as AI is likely to be quite limited. I mean, short of a full on 1984 style fascist surveillance police state, I mean, the legal process and the legislative process are very slow, and technology will be advancing faster and faster. So while regulation of AI is going to happen and is necessary and important at a certain level, I don't think it is likely to be the major factor in guiding the development of AI toward the singularity just because the time scale is. Is so slow. I would also say, until you're at the level of a superhuman AGI, humans are in control. Look at bitcoin. If we really wanted to kill bitcoin, all we got to do is unplug all the nodes the same way with an AGI. If it's running on singularity net, new net hypercycle. If there really was a rogue AGI that was bad for humanity as a whole, running on all these machines, I mean, people can still pull the plug at some point when an AI is much smarter than people, okay, then it's taking control. It sent its robots out. It's physically controlling the environment, right? But that's when you're at a super intelligence level. Until that point, humans are still in control. And I think the difficulty really is that humans are at odds with each other. I think the larger risk is during the transition period when AI's are almost as smart as people, or maybe as smart as people, but not yet super smart. I mean, at that point, people will be using AI to try to oppose other people, like we do with all sorts of other technologies. And to me, that's where. Where the worry lies. I actually, personally, I believe once we get to a super intelligence, it's going to be super benevolent and super compassionate, as well as super intelligence, and things are going to be pretty good. I mean, greater intelligence tends, on the whole, to bring with it, on average, greater wisdom and greater understanding of other people's perspectives. But before you get to that super intelligence, you've got some very powerful, narrow AI, quasi AGI tools in the hands of not just malevolent people, but, you know, short, short sighted and dogmatic people who believe they're doing what's for the best of humanity, but often actually are not, are not right. And there's."
    },
    {
        "speaker": "B",
        "text": "I greatly. I greatly admire your optimism. I greatly admire your optimism on the long term future of this technology. I hope that superintelligence becomes more beneficent as it develops. I guess we just don't know because we've never seen this before."
    },
    {
        "speaker": "C",
        "text": "On a rational level, you sort of can't know, right? I mean, if you're making something ten times as smart as people, it would seem like the confidence interval has got to be very wide if you're doing, like, a pure, like, bayesian calculation about what will happen. So when the conference intervals are that wide, really, you have to go based on your intuition and instinct and sort of spiritual feeling. The calculations don't work, but in the earlier stages, the calculations probably do work. And you can see what will happen if Trump, Putin or Xi Jinping have the first human level AGI and nobody else does, and they think they have an advantage for a year or two, what are they going to do?"
    },
    {
        "speaker": "B",
        "text": "But that's a very different argument. That's a very different argument than saying that carbon based intelligence has the same characteristics as silicon based intelligence. We just don't know. I guess it's always challenging to do that bayesian inference on so little data."
    },
    {
        "speaker": "C",
        "text": "That's right. That's right."
    },
    {
        "speaker": "B",
        "text": "I really enjoyed this. I hope you can come back and do it with us again soon. Really wonderful conversation. Thank you so much for joining us."
    },
    {
        "speaker": "C",
        "text": "Yeah, yeah, thanks. It's a good conversation. And I think that, I think in terms of the intersection of AI with crypto, I think there's a big opportunity, which is why we're talking, because I think if we can roll out something smarter than chat GPT on a decentralized framework, then suddenly you've given crypto its first huge application outside of DeFi, then everyone who needs to use AI is using decentralized networks. And this becomes really quite interesting. A lot of the infrastructure that's been built in the crypto world will come to a whole new purpose. This is what we're doing in singularity. Net, just to take a couple more seconds, we have a project like true AGI rolling out AI for the enterprise, or Zarka, which will be rolling out chat GPT, killer tools for retail. But these are real economy projects, but theyre all rolling out their products on this decentralized infrastructure. And this will create a lot of new economic value in the cryptosphere, as well as creating a lot of just plain old human and business value in different markets. So I think the boost weve seen in the sort of AI altcoin sector in the last six months is very small compared to the boost you'll see in the next few years once we start rolling out something two, three, four times as smart as chat GPT on decentralized networks. Think about the economic impact there for the projects that are doing this."
    },
    {
        "speaker": "B",
        "text": "Well, we're going to have you back in those next couple of years to have that conversation as you roll out more of that technology. Really great conversation. That's it for today, guys. Remember to sign up for real vision crypto. It's free, of course. Go to real vision.com forward slash crypto. That's real vision.com forward slash crypto. We'll be back again tomorrow with Mark Dale from w one curates. See at 09:00 a.m. pacific Noon Eastern 05:00 p.m. london thanks for joining us for this great conversation. See you again tomorrow."
    },
    {
        "speaker": "A",
        "text": "Hey there. Thanks for joining us today. Just a reminder, today's Crypto daily briefing is in partnership with the Crypto Phenom Letter. This one of a kind premium investment newsletter service highlights the next winners coming in. Cryptocurrency tokens and equities get special access Today@phenomcrypto.com. realvision that's phenomcrypto.com."
    }
]