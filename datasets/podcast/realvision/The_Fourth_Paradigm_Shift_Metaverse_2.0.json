[
    {
        "speaker": "A",
        "text": "This episode is brought to you by Shopify. Forget the frustration of picking commerce platforms when you switch your business to Shopify, the global commerce platform that supercharges your selling wherever you sell. With Shopify, you'll harness the same intuitive features, trusted apps, and powerful analytics used by the world's leading brands. Sign up today for your dollar one per month trial period@shopify.com. tech all lowercase. That's Shopify.com tech."
    },
    {
        "speaker": "B",
        "text": "Hey everyone, if you like this podcast, go behind the paywall. To get privileged access to the smartest minds in finance, visit realvision.com rvpod and use the promo code podcast ten to get 10% off our essential membership for the first year, join the real vision community and learn how to become a better investor. And now to today's episode of Ralph Real Vision."
    },
    {
        "speaker": "C",
        "text": "Robert Scobell, I am so excited to bring you to real vision. How are you?"
    },
    {
        "speaker": "D",
        "text": "I'm doing good."
    },
    {
        "speaker": "C",
        "text": "That is great to hear. And as I say, I'm just deeply excited about the conversation that is going to unfold right now. For many out there, you will need no introduction, but you are a legendary tech blogger and strategist writing about technology and this Internet revolution we've been living through at your blog, Scovalizer, since the early two thousands. Ancient history in Internet terms. A true Silicon Valley insider interviewed almost every technology leader I can think of, many of whom you count as friends. I've been reading your work forever. You really are an og of this game of thinking about and writing about the connected revolution, the Internet revolution. You helped inspire me to start to try to do the same. Let's dive in, is all I can say. Let us dive in. Before we start, there's one thing I read that I have to ask about. Is it really true that Siri, the launch of Siri happened at your home studio? Yeah, that is a fact. Is it?"
    },
    {
        "speaker": "D",
        "text": "Yeah."
    },
    {
        "speaker": "C",
        "text": "How did that come to pass?"
    },
    {
        "speaker": "D",
        "text": "It slipped it several months too, because when they first came to show it to me, we found several problems that it wasn't working on. And they opened up the back end. Adam Shire and dad came to my house and they opened up the back end and showed me how it works and tried to fix it right in front of me. And they're like, oh, we gotta come back."
    },
    {
        "speaker": "C",
        "text": "Yeah."
    },
    {
        "speaker": "D",
        "text": "So they actually came to my house twice, right? Second time to do another show like a few months later after they fixed the problems."
    },
    {
        "speaker": "C",
        "text": "And back then, that was pretty much the most advanced sort of consumer facing AI conversational agent out there. Boy, have we moved on since then."
    },
    {
        "speaker": "D",
        "text": "So I actually have an interview up on YouTube with the VC's who funded Siri, because they recognize I was the only one who got it, other than Steve Jobs. And so that's the behind the scenes story of what was going on at the launch of Siri."
    },
    {
        "speaker": "C",
        "text": "Right, right. The breadth of your work on technology, as your readers will know, and your readers on Twitter or X will know, because you're prolific there too. The breadth is vast. So just to put a kind of loose structure on this conversation, I'd love us to just paint a portrait of you, primarily to paint a portrait of what is coming. You believe a massive wave of change is coming. I want to paint a portrait, a brief history of our very near future. And let's start with what strikes me as your overriding thought that the frame thought you put on a lot of your analysis, which is something you call metaverse 2.0. Sometimes you call it the fourth paradigm. Just introduce us all to that."
    },
    {
        "speaker": "D",
        "text": "Or the holodeck."
    },
    {
        "speaker": "C",
        "text": "What's that all about?"
    },
    {
        "speaker": "D",
        "text": "Or the holodeck. We just released a paper this morning on the holodeck, which is metaverse 2.0. We're seeing a range of new 3d technologies being developed and improved. I'm reading all these AI papers, and this week there's a big conference and you saw a bunch of neural radiance field papers or gaussian splat papers. It's like, what are those? These are new 3d scenes that an AI can generate around you, right? So if you're wearing a pair of glasses, augmented reality glasses, or a headset like the Apple vision Pro, in the future, you're gonna be able to talk to an environment, have the environment change, and have a virtual being in that environment that you talk to. And I'm just laying out, if you search on X.com for metaverse 2.0 in quotes, you'll find all these posts that I have been sharing of anything that's moving in 3d technology, basically, and there's a lot coming."
    },
    {
        "speaker": "C",
        "text": "So is this fundamentally about bringing computing into the physical environment? Is this Zuckerberg's Internet that we can step inside? Is that a description you like?"
    },
    {
        "speaker": "D",
        "text": "Yeah. Spatial computing is computing that you, a robot or a virtual being can move through, right. The old way of computing we look at, like right now I'm looking at you on a 2d screen, right? Flat screen. In the future, you might be sitting in the room with me, right, virtually in three D. And soon we're going to be able to, when we move our hand up, a whole user interface could be on our arm, for instance. Right. Particularly if you're wearing a watch that has a sensor that would do that. And so there's a lot coming in this new spatial computing, a ubiquitous computing world or whatever you call it. But, yeah, we're soon gonna be. The computing is gonna happen all around us. The wall could change into Taj Mahal or a material, if I'm a material scientist, a chemical structure could appear on the wall or in 3d space around me. Right."
    },
    {
        "speaker": "C",
        "text": "Yeah."
    },
    {
        "speaker": "D",
        "text": "And that's already happened. I mean, we have apps like Nanome and VR where we could do precisely that. It's just, it hasn't quite gotten to consumer level yet. Because you need a fairly expensive PC and a cord and a fairly ugly big headset to do it. Well, all of that in the next three, four, five years is going to change, and we're going to end up. In five years, we're going to end up with a pair of apple glasses that's very lightweight. Right."
    },
    {
        "speaker": "C",
        "text": "Yeah. And I want to dive in. I mean, let's dive into Apple because it's such a natural progression from that overarching thought of bringing computing into the physical environment, dropping a digital layer over the physical environment. You have been talking about and writing about Apple's incursion into this space for years. You've been saying they're cooking something up at Apple."
    },
    {
        "speaker": "D",
        "text": "You know, wrote two books on a topic, something."
    },
    {
        "speaker": "C",
        "text": "It's coming."
    },
    {
        "speaker": "D",
        "text": "Right?"
    },
    {
        "speaker": "C",
        "text": "You know, and it's like, been a year. And I've been reading it going, yes, maybe this year. Maybe this year. Well, finally something happened. The vision pro, talk to us."
    },
    {
        "speaker": "D",
        "text": "It took a lot longer than I was expecting."
    },
    {
        "speaker": "C",
        "text": "It took a little longer than you thought. But hey, you know, directionally, you were absolutely correct. How do you think that the vision, talk about, for our viewers, talk about what the vision probe does fundamentally, but also what part does it play in Apple's broader strategic vision? Because I know you think there's a much bigger vision at play that Apple."
    },
    {
        "speaker": "D",
        "text": "There's a whole family that's coming. Yeah. I mean, what we're about to see is computing is going to move from 2d screens to 3d environments that you are in. Right. And to do that, you have to wear something on your face. Yes, I know that there's new kinds of 3d monitors. I have one in my family room, right, from looking glass that let me see a 3d object on a 2d screen. But that's not what I'm talking about. I mean, I have a HoloLens right up here. And with the Hololens you can play a game called fragments, for instance. And in fragments, aliens blow holes in the real walls around you. And then you have to shoot them before they get through the holes. Or if they get through the holes, they start flying lying at you, and you have to shoot them in 3d space in the air before they get to you. If they get to you, you're dead. Where are we going with this? The vision pro is that. But unlike the HoloLens, the vision pro has beautiful chips in front of your eyes. Let's just start with that. You can watch a movie on it. You couldn't do that in previous VR headsets that only had two K monitors. They're just not good enough to compete with a four 4K tv you get from Best Buy or something, right? And this new headset has two five k chips in front of your eyes with high dynamic range, high color depth, right? High difference between black and white, which is not true on Zuckerberg's quest two. Now tomorrow he's going to announce a new headset. But even the new headset only has two k displays, not five k. And that's just not good enough to work in. I can't use tweet deck, for instance, inside a quest because it just isn't sharp enough."
    },
    {
        "speaker": "C",
        "text": "It's not high res enough."
    },
    {
        "speaker": "D",
        "text": "Yeah, it's not high. And so that's why for the last seven years, meta has been mostly focused on video games. Cause video games, you don't need the resolution that much, right? If you're playing beat Saber and swatting with your hands and I seeing some fun things, you don't need that high a resolution. But if you're working, like if you're trying to do email or anything modern on a computer, you need a better screen than that. And the screens are just now getting there. The other thing is Apple has a lot of AI inferencing on your head. That's a huge shift from just Vrdez. If you compare to any of my VR headsets, whether it's the vive or the quest or whatever, they have screens, but they don't have AI inferencing. So they can't do this new generative AI that's about to hit. You can't put a large language model in there, so you can't do a real virtual being where you're going to talk with the thing or a non playable character in a video game. These things are about to become human. Like right where you walking down the street, you're going to be talking to AI's who are meeting you in the street soon, right. And talking about some pretty deep things, right? Because it knows all of music and all of art and all of politics. It's crazy, right? Yeah."
    },
    {
        "speaker": "C",
        "text": "And so this is Apple's pitch. I mean, well, my point of view would be this is Apple's pitch to own Metaverse 2.0, to own the fourth paradigm that you talk about. How do you, and I think I'm right in saying, well, you tell me you think Apple are going in a more fruitful direction than meta because the big company many of our viewers will think about immediately when they hear the word metaverse obviously is meta. And Zuckerberg spending billions of dollars to try to own the fourth paradigm too. Why do you think Apple is going in the right direction and not meta?"
    },
    {
        "speaker": "D",
        "text": "Here's one. John, I went down and visited John Carmack, who's a famous video game developer. He worked at Meta back then and I went and visited him in Dallas and he was like, I think Meta is going to need to do a phone. And I'm like, what? You already tried to do a phone, nobody bought it. Why do you say that? Well, because Apple has in the phone a whole bunch of GPU's. They just added, I think six new GPU's in the new phone rewritten semiconductor stack with a lot of new graphical processing, which is also really good for AI. A lot of GPU means you can do AI inferencing there. It also has the radio and a big battery and a big heat sink, so you can heat up the phone pretty warm and it's sitting on the desk in front of you while you're computing in a pair of glasses. Zuckerberg doesn't have that, doesn't have this. He has to develop a lot of custom silicon for the glasses and do a lot of inferencing up in the cloud where he's going to have bank and bank and banks and banks of Nvidia cards in a data center. All the AI inferencing is being done up there, shoving the data straight down to the glasses with custom silicon so that glasses don't heat up and are lightweight and are affordable. Right. And easy ish to manufacture for these people, for these companies, right. And I'm not sure how that's going to go because that brings into play a whole new privacy problem because I was playing VR one night in my quest, two, right, and it has four cameras on it. Now it's not doing a lot of AI inferencing yet because that's an earlier version, but the next version I bet they're going to do, start doing a lot of computer vision and AI inferencing. That's all being done in the cloud. My wife walked into the room naked while I'm playing VR with these cameras blaring, sucking up everything. Right? So if you don't think about where that AI inferencing is being done, you really will soon, because you're soon going to be into these glasses. I mean, it's. Apple and meta are both spending tens of billions of dollars, and this is going to come out with a product someday that excites people because the. The computing around you in a pair of glasses like this is insane compared to looking at a little tiny phone."
    },
    {
        "speaker": "C",
        "text": "Hey, everyone, we're going to take a quick pause and hear a word from our partners. We'll be right back. So Apple have been essentially weaving AI chips through the physical world via billions of devices. And it's almost like, and I. I believe this because I've read it. You've been telling this story for years. It's almost like Apple have planned this all along. They put so much AI capability out there into the world. Now the first iteration headset is in place, dropping this digital layer over the world around us. How long? No one has a crystal ball, but how long until that technology truly can be just a pair of glasses? That is easy to put on?"
    },
    {
        "speaker": "D",
        "text": "Three years."
    },
    {
        "speaker": "C",
        "text": "Okay, what leads you to, for me."
    },
    {
        "speaker": "D",
        "text": "And you, three years, early adopter, five for the normal consumer, ten for the late adopter. Right. So sometime in the next decade, everybody's gonna have a pair of these things on, whether it's apple or snap or meta or Google or Amazon or Tesla or some other company, right? You're gonna have a pair of these glasses on if you want to be part of modern society. And that's sort of scary for people to hear because they don't like hearing that they have to change and adopt a new thing, and they don't like wearing glasses. I hear that over and over, people. I hate wearing glasses. Why do I have to wear glasses now? You and I have to wear glasses just to see. So we're already ahead of those people. But most people don't like to wear. They're going to resist. They resist this idea, right, the second they put it on. And by the way, that's the real goal of the first device. Half of every Apple store in the world is going to be rebuilt to show off the vision pro. It's there to get a demo. You go to the store, you try it out for ten minutes, and you see, holy shit, computing is fucking insane. I'm sorry. It's really insane because now instead of a small little monitor in front of you to watch a movie, you have a wraparound IMAX theater around you right in the headset. And once you see that, then you start going, oh, I want that. Right? And you're then open to, oh, when Apple finally gets a pair of glasses that's lightweight enough and cheap enough that you buy in. Right?"
    },
    {
        "speaker": "C",
        "text": "And when billions of people are wearing this technology, what does that change?"
    },
    {
        "speaker": "D",
        "text": "I mean, everything. Because, I mean, if you're in San Francisco right now, you see an autonomous car goes by, like, every fifth car. It's crazy. And you start thinking about all the data that that thing sees and is sucking in and could use on a digital twin of the real world, right? And then you start thinking about, oh, let's say every fifth person has a pair of glasses on that, walking around that digital twin and adding more data on top of it. So you're going to start seeing this digital twin, this real time copy of the real world, the Mirror world, wired calling it start to really get utility, where you're walking around a shopping mall someday, and it's going to tell you everything about the shopping mall, everything about the products in there, and everything about, you know, hey, how do I get some help over here? You know, robot will come up and start talking to you, or a human will, right? Yeah. Humans aren't going away anytime soon."
    },
    {
        "speaker": "C",
        "text": "This is so, you know, and we're going to get into robots and autonomous vehicles in just a sec because they're a massive part of the portrait, the picture you've been painting for the last."
    },
    {
        "speaker": "D",
        "text": "It's the same technology underneath, right. Nvidia's omniverse, which is their corporate strategy. It's a Hydra that sucks in all data. It runs autonomous cars, it runs augmented reality glasses, it runs virtual beings, and it runs robots, right? One database, one digital twin to rule them all, right? Yeah, yeah. And so your robot that's going to be in your house in 1015 years is going to use the same data structures as your glasses are, and you can interact with them, right?"
    },
    {
        "speaker": "C",
        "text": "Yeah, I mean, let. I mean, okay, before we dive into robots, you know, it seems to me."
    },
    {
        "speaker": "D",
        "text": "And I'm not the one who says that Adrian Kaler actually worked on. He built the computer vision system for Stanford's first autonomous car. Then he worked at magically building augmented reality. Then he built a humanoid robot company, and now he's building a conversational AI, right? So it's all the same. It's all the same."
    },
    {
        "speaker": "C",
        "text": "All into kind of technology, right? Is it the end of reality? Is it the end of a shared reality when we can walk around in the world around us with this layer of data and digital information dropped over it that we can personalize, we can choose as we see fit, we can kind of opt into our own realities then, am I right? I mean, that feels to me part of where we're headed."
    },
    {
        "speaker": "D",
        "text": "Let's go to the best reality. Let's go to Yosemite National park. Go to the top of it's called glacier Point, right? And where you can look down at the valley. Across the way is Yosemite Falls. Over there is half dome. Down the, down to the left is El Capitan. You put on the glasses, and it makes that reality better. Now, the reality, if you're standing there, is beautiful. It's analog. It's a smooth wave. Human beings like it, right? And that's why you go to Yosemite or someplace like it, right? Because it's beautiful and it's fun. It's nice to be there, but you put on the glasses and now you know the scientific names of all the plants around you. Or you can look at the sky and say, hey, Siri replaced the sky with the Hubble telescope view. Now, all of a sudden, you see all the stars, not just a thousand stars, but all of them. And you see them all labeled, right. So you know what you're looking at and you know where Mars is, you know where betelgeuse is right up in the sky, because it's telling you. Right. And it's telling you what the names of all the mountain ranges are around you. So is that reality? It's sort of an enhanced reality."
    },
    {
        "speaker": "C",
        "text": "Right, right. And it feels to me that in the end, the distinction between what we call physical reality, you know, the stuff of atoms and informational reality, the boundaries between those two things will sort of blur and become somewhat irrelevant."
    },
    {
        "speaker": "D",
        "text": "Yep. And we're already seeing this happen. Right. Apple's maps and Google's maps are adding augmented reality. I just used it in San Francisco the other day using my phone to look around. And I was looking around and, oh, man, it changed the side of the building and put the street names and told. And it had an arrow like, this is the right place to go, right on the side of the building. Right."
    },
    {
        "speaker": "C",
        "text": "You've written about Apple and essentially their mirror world, a 3d map of a one to one, essentially simulation of the entire world. Is that still a technology? That's part of the picture here for Apple. Are they still working on that?"
    },
    {
        "speaker": "D",
        "text": "Yeah, yeah. They have a digital twin of the real world. That's how they're doing that. So the phone, when you open up the phone, even you don't have to wait for the glasses to see some of this happening. Right? You go to New York or San Francisco, you open up Google Maps or Apple Maps, you turn on augmented reality piece of that, and then all of a sudden, it knows where it is in 3d space, and it knows what it's looking at. Like, oh, you're looking at the pyramid building right now. Right. I. And then it can change the pyramid building and put a name on it. Or if you're walking around the city, it can tell you, hey, go down this aisle to alley to get to the chinese restaurant you're trying to go to or something."
    },
    {
        "speaker": "C",
        "text": "Right, right. And the key thing is this technology is about to jump from screens. An experience like this, to just an experience like this, an immersive experience. And that's going to change, as you say, you know, I mean, consumerism, learning, our relationship with knowledge and information, just everything. It's an incredible revolution coming. You believe in the next 3510 years, billions of people wearing these devices, and it's partly about solving the hardware challenge of just getting it this easy to put on. We do that every morning. Billions of others can. An incredible wave of change. But let. Let us dive into robots. I mean, there's an incredible video right now circulating on X of Tesla's humanoid robot sorting autonomously, sorting different shaped and colored objects. You know, just something extremely useful autonomously that it's now able to do. I was pretty skeptical when Elon got on a stage, you know, whenever it was, and said, we're going to do this humanoid robot and a man in a suit came out and did a dance."
    },
    {
        "speaker": "D",
        "text": "Yeah."
    },
    {
        "speaker": "C",
        "text": "Look how fast they've gone to something that looks extremely credible and extremely powerful."
    },
    {
        "speaker": "D",
        "text": "Yeah."
    },
    {
        "speaker": "C",
        "text": "How soon?"
    },
    {
        "speaker": "D",
        "text": "They aren't starting from zero, that's why. Because they have the autonomous car. Already talk about that. Well, my car, when I go pick up the kids, it has eight, nine cameras on it. Right. And it's watching the kids playing. You ever think about where that data is going and what it's being used for? Right. It has to know what human beings are doing in an autonomous car, because it has to predict what your next action is before it hits you. Right. It needs to know that, oh, you're riding a bike and you're probably going to keep going in a straight line. Right. But maybe you turn really fast. So we have to be prepared for that. Right. And it's watching you do that. And it has the database of videos, of millions of videos of people doing various things in the street around here. So it can use some of that data to do an end to end neural network. A modern AI now learns from watching videos. They have the videos, they have the simulator, they have the auto tagger. They have a lot of infrastructure at Tesla to deal with the data that's coming off the cars. Well, now the robot comes along and it's a little bit more complex than a car, but not a. Well, it is more complex, but it's not a huge new thing. It's using 26 electric motors with cameras that see the world in three d and microphones that you can talk to and an AI computer in the brain and a bunch of batteries in the arms."
    },
    {
        "speaker": "C",
        "text": "Right. And this is Tesla's unique advantages. They're building this incredible machine vision technology via the cars and they're now going to use that AI technology to make their robot move and to make it understand the world. How soon are humanoid robots coming to people's homes? And talk about why you believe pizza delivery. Because I love this. Why you believe pizza delivery is the first interaction that causes money."
    },
    {
        "speaker": "D",
        "text": "And if we have a robo taxi network where the car actually can drive without a human, and we could argue about what day that's actually going to get finished. GM has cruise driving around San Francisco and Google has Waymo driving around San Francisco. And Zoox is from Amazon driving around San Francisco. Right. And my Tesla is driving around the world pretty well. It still makes a few mistakes, but it's doing pretty well. You can say it's the next two to four years where it's going to be worldwide and it's going to be fairly good. Maybe I'm wrong. Maybe it's another two to four years. So let's see, let's see."
    },
    {
        "speaker": "C",
        "text": "But what's."
    },
    {
        "speaker": "D",
        "text": "The robot is coming sometime in the next eight years. Yeah."
    },
    {
        "speaker": "C",
        "text": "I mean, what's fascinating for me is the business model. You imagine where we essentially, we have a network of autonomous vehicles delivering these humanoid robots to homes. So I, as a consumer, don't have to own it. Right. It's sort of sent to me on demand."
    },
    {
        "speaker": "D",
        "text": "Yeah, it makes a lot of sense. Right. Because if you start having a robo taxi network without humans in the car, out on the street, right. And driving around, well, you're going to want to do things like, can you go to the local home depot and pick up a screwdriver for me? Or can you go to the local chinese restaurant and get me some lunch? Or can you go to the laundromat and pick up my laundry? Well, how would that happen if it's just a car now? You have to have a lot of infrastructure to get somebody to know the car's waiting for your laundry and take it out to the car. No, just put a robot in there. Have the robot go into the store, tell the person, hey, here's the receipt for Robert Scovel's clothes. And I'm picking up the clothes and then drives back home. And when it gets to the curb, it gets out of the car and takes my clothes up to the door and rings my Amazon doorbell. In fact, it probably already rang before it even got there because doorbell has this stuff, but it can go, oh, you have robots here, and that's the business model. Right? Because I'd pay $20 for that. It's a lot better than me driving down to the laundromat and picking up my clothes. That takes 20 minutes each way, and that's 40 minutes of my time. I'd pay $20 to have 40 minutes of my time back and sit here and look at Twitter more."
    },
    {
        "speaker": "C",
        "text": "I cannot wait for that to become a reality. And so I can just pick up my phone or by this time, I'll be immersive computing and probably tap a tile in my environment or something like that, order a robot to my house to do my kind of, to tidy the house and run to the store for me, pick up what I need and bring it back. So here's another way to look at it beyond demand. Economy."
    },
    {
        "speaker": "D",
        "text": "Yeah. The car is hard to make because it's big, and the line to make it is long. The, for instance, I visited Detroit and went and saw how Ford makes f 150 trucks, f 120 trucks, right? And it's a very long line. It's like a snake through this big, huge building, right. With a lot of people doing things, putting an air compressor in or something, where an air conditioner and a lot of robots. Robots are putting the windshield in and gluing them in. Right. Robots, 26 electric motors, brushless motors. So, yeah, those are a little complex to make, but we have chinese companies making those by the boatload. Right. And it's a known thing. And it's one station to make them. And a robot can make all the pieces. It's not a whole lot of pieces there. You know, it's a known thing. We know how to make freshless electric motors. We make those in quantity all over the world. Right. The other part of it is what? Carbon fiber for the arms or something like that. Right? Or aluminum in a casting machine or something. That's not hard to make. I made aluminum casts in junior high school with molten aluminum going into a cast. That's not that hard to make. And the computer is already made, and the batteries, they're good at making a lot of batteries now they're putting them into semi trucks and cars, all sorts of things. So they should be able to make a lot of these robots when they get done. And so that's what people can't get their head around because, yeah, we understand a robot would be useful in a factory putting the same part in a board or something like that every day, every minute. Right. Or every, every few seconds. We can't really understand. Oh, this thing is going to be $5,000 and it's going to be made in quantities like many, many millions. What year? In the next decade?"
    },
    {
        "speaker": "C",
        "text": "Hey, everyone, we're going to take another quick break and hear a word from our partners, and then we'll be right back. Is this. You're such a sort of Silicon Valley insider. Is there skepticism even in the valley, that a humanoid robot that truly can navigate the unstructured environments, that could walk around my kitchen and make me a cup of tea and put the cup back in the dishwasher? Even in the valley. Is there skepticism that in the kind of timeframe you're talking about, that is possible?"
    },
    {
        "speaker": "D",
        "text": "I've had people tell me things are impossible that already happened. I hear this skepticism. I study the skepticism, the resistance to new ideas, because it's always there. Every time there's a new product, new company, new idea, new thing, people are. Oh, it does matter, right? It's like, what?"
    },
    {
        "speaker": "C",
        "text": "You know, even in your world, even in the valley."
    },
    {
        "speaker": "D",
        "text": "Oh, even in the valley. I mean, how many people thought that Elon Musk was an idiot for starting Tesla? Literally everybody. I don't remember one. I mean, Steve Jervidson, who invested in it first, was the first one who, like, I believe in this guy. Everybody else thought he was an idiot. He was going to lose all his money. And that almost came true several times in Tesla's history up to 2018. It almost went bankrupt."
    },
    {
        "speaker": "C",
        "text": "Right, exactly. I mean, like I say, I have to admit, I was skeptical when he got on stage and announced Optimus, you know, humanoid robot and a man in a suit did a dance. And now I look at how fast it's gone. And I reached this conclusion before, but I really am like, that's the last time. I sort of dismiss out of hand something that Elon says, because every time he seems to pull something out of the bank. Ok, we could sidetrack."
    },
    {
        "speaker": "D",
        "text": "What do you think if I go on the Golden Gate bridge and I start counting cars going across the bridge, only Tesla is driving. Every few seconds, a Tesla goes by with cameras and an AI computer on board. Only Tesla has that. So only Tesla has a real time digital twin made by cameras of the Golden Gate bridge. So if there's a truck on fire on the Golden Gate Bridge, only Tesla is going to be able to make a neural radiance field of that, a 3d scene that you can look at in your augmented reality headset. So only Tesla can come out with a pair of glasses that someday is going to show you things on the real world in a new way that nobody else can match."
    },
    {
        "speaker": "C",
        "text": "Yeah, because we face the prospect of an autonomous Tesla delivering a Tesla robot to your home to get stuff done. And that's giving Tesla control over this whole ecosystem of products that the robot uses in the home, like you've said, as well, Tesla building, just all underpinned by this incredible machine vision technology. Do you believe then that Tesla will want to create one of these, a piece of hardware like this, so, like, complete the ecosystem? Have you heard anything about that from insiders?"
    },
    {
        "speaker": "D",
        "text": "I know they've hired a team and they're smart because they're just like Adrian Kaler, who built the computer vision system for the Stanford car and then went on to build augmented reality glasses, then built a humanoid robot company, which is already gone. So they're all smart like him. They're going to get there, even if they're not there today, because they're going to see, oh, Apple has his glasses. We have the digital twin of the real world. Apple doesn't."
    },
    {
        "speaker": "C",
        "text": "Right, right, exactly. I mean, it seems to me their incredible advantage is this is the digital twin, is millions of Teslas driving around learning about the physical environment now, Elon's."
    },
    {
        "speaker": "D",
        "text": "Answer, by the way, because I've poked at him a few times, interesting. Augmented reality. His answer is one word, neural link."
    },
    {
        "speaker": "C",
        "text": "Right, yeah, I can skip. Okay, I want to talk about more, in more detail about AI in a second. Let's skip ahead to Neuralink. Tell our viewers about Neuralink, because they've just launched their first human trial. This is all about putting in the brain to allow us to interface with computing through the power of thought. How far along is that? And does that become a consumer facing technology anytime soon?"
    },
    {
        "speaker": "D",
        "text": "Pretty far, yes. They've gotten FDA approval to bring it to people. Now, it's not for consumers. It's not cheap. Right. To open up your head and put a little hole in your head that costs $150,000. Right. And the surgery is putting wires on your brain. Right. That comes with side effects. You're not going to sign up for that unless you have something like Parkinson's. Now, if you have Parkinson's and your hands shake like this and you can't feed yourself or wipe yourself in the toilet, right. That's a dismal life. So you go to the doctor and go, oh, I can't feed myself. It's not a fun life anymore. Anything you can do for my shaking hands? They said, oh, yeah, we can do a surgery. We put an electrode on your chest or in your brain to affect just a few cells that are misfiring and causing your hands to shake. Right. And on YouTube, you can watch this. There's videos of the patients that have this happen. They have one wire put on their brain. They turn on that wire and their hands steady out. Life changing surgery costs $150,000. Well, a couple months ago, I had dinner with a couple of these surgeons who do this, and they said, well, now we ask the patient, how many wires do you want? You got to have one to fix your problem. Right? We're already going to open up your head and we're already going to spend that $150,000. You've already accepted that there's some side effects to this because we're cutting through brain material and you might have a side effect and might change your personality or something like that. So you're already in, but how many wires you want? Now, neuralink is doing 32,000 wires on your brain. They have a robot that goes and stitches wires all over the place. Your brain is a machine. It's a different kind of machine than a computer, but it still is a machine. And if you can hook a wire up to your brain and know where the wire is or the wire figures it out, it can do things like get you to raise your hand up and down, because that process is being controlled by us as few cells in my brain. And if there's a wire on there, well, all of a sudden it can override that and cause my hand to involuntarily go up or down. I saw a brain surgery where this happened, right? A guy was getting his brain probed by the surgeon, and he raised his hand up, involuntarily because the surgeon touched a certain part of his brain. Right. So if we start mapping out your brain and understanding where everything is and putting little wires on it, now we can talk to your brain directly, and now you can talk to the Internet directly. Right."
    },
    {
        "speaker": "C",
        "text": "Right. And that thing start to be able to interface with the Internet just by thought."
    },
    {
        "speaker": "D",
        "text": "Yeah. Is that a crazy idea?"
    },
    {
        "speaker": "C",
        "text": "It's an absolutely head spinning, scary idea."
    },
    {
        "speaker": "D",
        "text": "Or just, I mean, I have these computer control lights around me, right. Oh, I'd like to make that light red. You know, just think, think it. I make that light red and all of a sudden it does. Right."
    },
    {
        "speaker": "C",
        "text": "But were going to have to get to a place where the intervention to make that possible does not cost $150,000 and is much safer. And that feels a long way off. Is that fair?"
    },
    {
        "speaker": "D",
        "text": "Its a long way off for normal, everyday people who dont have the money or the need, but theyre learning a lot about the brain, and theres a lot you can do from outside your skull. Right. You don't need to put the wires on the brain to do a lot of new things. In fact, over here, I have a, hold on a second. I have a product from a company called Nextmind, which is a comb that goes on the back of your head, and it has, I don't know, seven or eight sensors that's reading the machine on the back of your head. What your brain is processing is spitting out a lot of electrical signals. It picks that up. It has AI running in there to figure out what your brain is doing, and it lets you see things in a new way, unless you control things just by looking at them, because it's picking it up from outside your head. This is non invasive brain computer interface kind of thing. And the neuralink people are learning so much about inside your head that I think they're going to be able to design sensors for outside your head to do a lot of the things that you would only be able to do today with a wire on your brain."
    },
    {
        "speaker": "C",
        "text": "Incredible. And then we're looking at a future where potentially you do have a very lightweight piece of hardware, but you have something very small outside, on the outside of the skull, and you're able to think and manifest things in your physical environment just by thinking about them."
    },
    {
        "speaker": "D",
        "text": "And there's other benefits too, to doing this kind of brain computer interface. The Apple vision Pro actually brings us a little bit into this. It's looking at the back of your eyes with an eye sensor that alone can tell, I don't know, a half dozen kinds of diseases that you might have, right? So you might put on your Apple vision pro and it might tell you, hey, got to go see your ophthalmologist or got to go see your doctor, because we see that you have cataracts or something like that, and all of a sudden you're like, whoa, that's really crazy. And we're going to see a few other things because there's a camera that's looking at your capillaries. It's looking underneath your skin to the blood flowing through your skin, and it can tell all sorts of things. Dad Kitlaus, who started Siri, showed me, he has a system, a system company called Reba Health coming out where you put your finger on the iPhone camera. That's it. No special hardware, just a standard iPhone camera. And it knows your blood pressure just by looking at the color of your blood going through your skin, right?"
    },
    {
        "speaker": "C",
        "text": "Yeah. I mean, incredible. Incredible. So we had, look, we had this portrait we're painting. We have hundreds of millions, billions of people walking around in an immersive computing environment where information, bits and atoms have merged. Computing is all around us. We have robots coming to the home, everything as a service, delivering services to us on demand. Humanoid robots. I suppose we have rich people owning their own humanoid robot, but lots of us will access them that way. AI has underpinned so much of this conversation, but part of your vision, too."
    },
    {
        "speaker": "D",
        "text": "I don't think it's just going to be rich people either, because within a decade, those things are going to be $5,000."
    },
    {
        "speaker": "C",
        "text": "You think they're going to get down to that? Because that amazing that they get into."
    },
    {
        "speaker": "D",
        "text": "It'S 26 brushless motors. Let's go to China and go buy some motors. It doesn't cost that much. Buy 26 brushless electric motors. And then how much is a computer to put in the head? A couple thousand dollars maybe, right?"
    },
    {
        "speaker": "C",
        "text": "So I am torn then, between, because I'm constantly. One of the fun parlor games I'm constantly playing is, look, what is the next piece of consumer facing technology to transform everyday life at the scale of the iPhone? And one answer to that is the humanoid robot that can finally do my dishes. Make me a cup of tea, teach me to dance. Tidy it away, teach me to dance. Hey, all of that."
    },
    {
        "speaker": "D",
        "text": "There's an AI researcher at Stanford who's taught the robots to dance. I love that they already have AI's that do 1600 tasks and hook up to tens of thousands of APIs so you can ask it to do things like, hey, can you book me a flight on United Airlines for next Tuesday to go to Hawaii or something like that."
    },
    {
        "speaker": "C",
        "text": "Yeah. Right. Right. So is it a robot or is it an AI companion that can talk to me and get to know me and become essentially my friend? Are we going to see that? And what role are large language models going to play in that kind? The emergence of that kind of, or whatever comes after?"
    },
    {
        "speaker": "D",
        "text": "Because there's now large math models, there's large vision models being developed. It's not just LLMs. LLMs are important for understanding our language and understanding computer language and being able to translate back and forth. Right. There's other things coming to other components to make this robot really pretty advanced."
    },
    {
        "speaker": "C",
        "text": "And do you think as well as being able to do functional tasks for us, they will become a form of companion? They'll be able to talk to us. Entertainer. Is that in the realm of what's coming?"
    },
    {
        "speaker": "D",
        "text": "Yeah. And it'll know everything about you, everything about your home. It'll be able to buy, you know, it'll be able to do automatic grocery shopping. Right. Because it knows you're out of milk. In fact, it might have even gone through the refrigerator and picked up the milk carton. Go, it's a quarter full right now because it can tell the weight. Right. It has a sensor on it. Something is just like we do. Right. We pick up a milk carton and go, oh, it's about a quarter full. Got to buy some new milk on the, on the grocery run. Right, right."
    },
    {
        "speaker": "C",
        "text": "Yeah, exactly. But can it become my therapist, too? Yes."
    },
    {
        "speaker": "D",
        "text": "In fact, I'm using, I have a psychologist I work with doctor Joanne Munden, and she's using a program from Paula Walto Clinic in her work. And she already has chat GPT, listening to our therapy sessions and writing highly technical notes and tracking us over time. It's caught things that she missed about people, and therefore she thinks it's gonna be, it's soon gonna be malpractice if you don't use this system. She just told me."
    },
    {
        "speaker": "C",
        "text": "That is fascinating."
    },
    {
        "speaker": "D",
        "text": "Right. And this is in 130 minutes conversation. It nailed all of my mental illnesses in notes. Right. And laid out, you know, here's what, here's what I discern from this 30 minutes conversation. So I've been on Twitter spaces thousands of hours. It goes through all of that. What is it going to learn about me? All right, here's the 15 things that make him angry."
    },
    {
        "speaker": "C",
        "text": "I mean, these things can. It feels."
    },
    {
        "speaker": "D",
        "text": "Yeah."
    },
    {
        "speaker": "C",
        "text": "The insight it can deliver to us about ourselves is stupendous. And its ability to crunch through ocean volumes of content and data and bring it back to us in more useful ways is absolutely incredible. And like you said, there's much more coming. If you look at the announcement around chat GTP this week, and you're now going to be able to speak to it, it's going to understand pictures as well as text. I think that ability to speak to it and to hear it speak back just feels to me a crucial next step in this journey, I imagine, towards consumers having a genuine, or feeling they have a genuine relationship with these entities that goes beyond just transaction, because isn't that a huge market and a huge sort of opportunity for innovation? I mean, you're using it, right, in that way as a form of therapy."
    },
    {
        "speaker": "D",
        "text": "It's insane at listening. It's really good at listening. All right, so let's tear apart the chat GPT app on the iPhone, right? If you download it and pay your $20 and you get it, it has a button, so you can type a prompt to it, you can type to it and talk to it, or there's a little icon there. In fact, let's just do it. Hold on a second. We'll do a live demo of this thing."
    },
    {
        "speaker": "C",
        "text": "Mother of all demos of chat GTP."
    },
    {
        "speaker": "D",
        "text": "Yeah, so you got chat GPT, and down here in the prompt window, there's a little icon which when you click it, it starts recording. And it's recording me right now. Hi, chat GPT. We're just doing a demo of how the chat GPT iPhone app can listen and interact with us. Can you tell us a little bit about spatial computing? For instance, what should we think about when it comes to spatial computing? So it writes a transcript. Now, what it just used was the whisper API that OpenAI makes. So, whisper API, you can use this in a rock concert in a nightclub where it's really noisy, where the microphone is a few inches from your mouth, like this, far away, twelve inches from your mouth, and it still hears you this perfectly. And it writes a transcript. Then we send the transcript up to chat GPT and then it answers back and says, hey. Spatial computing is an advanced computing concept where the physical and digital worlds merge, leveraging the space around us as a medium to interact with digital or virtual content. It involves technologies like augmented reality, virtual reality, sensor technologies, and computer vision. When thinking about spatial computing, consider user interaction, as it aims to make digital interaction more natural and intuitive. And it keeps going, right?"
    },
    {
        "speaker": "C",
        "text": "And you just know that. Scobalizer, years of gobalizer, your blog is part of the training data that enables."
    },
    {
        "speaker": "D",
        "text": "Oh, yeah, you can do that. In fact, here, watch this. Watch this. Can you write me a blog post, please, about spatial computing? But could you make it sound like Robert Scoble, tech evangelist, wrote it? Thank you. And it goes, title diving into the infinite possibilities, a glimpse into spatial computing. It's writing a blog post and it's fairly good because it understands my pattern, because it read ten years of my blogs, so it understands how I write on my blog, so it can fake a writing about it, can make it sound like Robert Scoble's talking to you. Now. Apple just had me read to it on this new iPhone and now Apple has my voice. Well, Twitter spaces or x spaces already has 1000 hours, so it already has my voice. And other things like descript had me read to that as well. So now there's several things on the Internet that have my voice. And therefore soon it's going to be able to talk to you as if I talk to you. Right?"
    },
    {
        "speaker": "C",
        "text": "It sounds you're the king of tech rumors. What do you think about these rumors circulating at the moment that OpenAI has even more powerful models?"
    },
    {
        "speaker": "D",
        "text": "Of course they do."
    },
    {
        "speaker": "C",
        "text": "Under the hood that they're not sharing with us."
    },
    {
        "speaker": "D",
        "text": "Of course they do. They have to build a model and then they have to put the church lady in front of them. Right? Do the alignment, technical term, AI guardrail. Right? Because if you ask it. Hey, hey, Chad. Chiefy T, how do I build a pipe bomb, for instance, one question I asked and then the church lady shows up. We're open AI corporation. We don't want you to learn about that here. Go somewhere else."
    },
    {
        "speaker": "C",
        "text": "Do you think that we're, do you think that they're getting somewhere near AGI? However we want to define that, because that's what the rumors are, that they have models under the hood that are approaching true general intelligence on a human, or it's going to, it's going to."
    },
    {
        "speaker": "D",
        "text": "Fool us far before it technically gets there. Yeah, I mean, you see how good it is talking to me back and forth, right? And we could talk about any topic, you know, how many years is it before that thing gets really fricking so good, where it's just interacting with you all day long? Not many. There's a new photonic chips coming probably next year, certainly by 2025, that are going to be many times, many times faster than our current intel or arm chips that are doing this AI, particularly for AI workloads. In the next few years, we're about to get a new chip architecture that's going to bring AI workloads to our glasses and our phones and do it with very little power usage and very little heat generation too. That's some. There's a couple of these new photonic chips companies coming and I've started studying, right. And it's going to bring real big capabilities for developers of these glasses to do all sorts of large language model kinds of things on a pair of glasses or on a phone in the future."
    },
    {
        "speaker": "C",
        "text": "Right. Because we can weave that kind of AI through the immersive spatial computing, through the robots too, so they can talk to us and joke with us and be our companions. I mean, I feel we've painted the picture I wanted us to paint. It's just been an absolutely thrilling, fascinating conversation. Thank you so much for joining us."
    },
    {
        "speaker": "D",
        "text": "We could go for hours."
    },
    {
        "speaker": "C",
        "text": "I need to bring you back to talk more about OpenAI specifically and the journey to AGI and what that means and how we get there. But we need to wrap this one up."
    },
    {
        "speaker": "D",
        "text": "Yeah. The photonics chip just ended. Use biological cells as part of the architecture of the semiconductor, of the chip. And that brings in the real AGI, because now it has the ability to feel right like a human brain does and have emotions. That's when it's really going to start fooling people into thinking, oh my God, this is really smart."
    },
    {
        "speaker": "C",
        "text": "Aih, this is where we get to the next, even beyond the next quantum level of weirdness. Do you think people, let's end on this. Do you think people have any idea what is coming?"
    },
    {
        "speaker": "D",
        "text": "No."
    },
    {
        "speaker": "C",
        "text": "And how should they navigate it? Like, how do you navigate it? Do you ever wish this would slow down or do you just love it so much that you don't, or what?"
    },
    {
        "speaker": "D",
        "text": "For the last year, I've been building lists of all the AI companies. I found 3600 AI companies on X.com dot and I just finished yesterday splitting them all up into lists. I have lists of alpha tools, I have lists of writing tools, I have lists of a whole folder called the holodeck, which is 200 companies that are building this kind of stuff. Right? That's how you follow it. Sign up for my list and start diving in."
    },
    {
        "speaker": "C",
        "text": "Right. And I will second that because I'm a big admirer and a big beneficiary of your incredible Twitter lists. So, Robert Scoble, follow Robert on XDev or formally on Twitter. Check out Scobleizer, his iconic blog. Dive in. There's decades worth of amazing knowledge and analysis there. But Robert, thank you so much for joining us on real vision, and I can't wait to have you back."
    },
    {
        "speaker": "D",
        "text": "Thank you so much."
    },
    {
        "speaker": "B",
        "text": "What's up, revolutionaries? Thanks for tuning in. For more content like this, head over to realvision.com and get unfiltered access to the very best, brightest and biggest names in finance."
    }
]