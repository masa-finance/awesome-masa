[
    {
        "speaker": "A",
        "text": "This episode is brought to you by Shopify. Forget the frustration of picking commerce platforms when you switch your business to Shopify, the global commerce platform that supercharges your selling wherever you sell. With Shopify, you'll harness the same intuitive features, trusted apps, and powerful analytics used by the world's leading brands. Sign up today for your dollar one per month trial period@shopify.com. tech. All lowercase. That's Shopify.com tech."
    },
    {
        "speaker": "B",
        "text": "Hey everyone, if you like this podcast, go behind the paywall. To get privileged access to the smartest minds in finance, visit realvision.com rvpod and use the promo code podcast ten to get 10% off our essential membership for the first year, join the real vision community and learn how to become a better investor. And now to today's episode of Ralph Real Vision."
    },
    {
        "speaker": "C",
        "text": "So I can't wait for this conversation. Dan Desyars Dean is somebody I've known for quite a long time. And magically, through a connection in Little Cayman, I meet a true disruptor and somebody who's literally changing the world in front of our eyes. And it's in a layer that we don't think about. We take computing power for granted, but we don't think how it can be used, who owns it, and how it can be leveraged in different ways. And I'm going to go through this story with Dan, and I think, I'm guessing yet again, he's going to blow our minds. When change comes, opportunity abounds. We're about to enter a period of the fastest pace of technological change in all human history, something we refer to as the exponential age. And real vision is going to be your guide to this incredible future. Dan, fantastic to see you on real vision, finally."
    },
    {
        "speaker": "D",
        "text": "Thank you very much for having me."
    },
    {
        "speaker": "C",
        "text": "You know, amazingly, you and I got introduced by a friend of hours, a mutual friend who lives in little Cayman. And he's like, you need to meet this guy, Dan. He's doing some really cool shame. We've been talking for, I don't know, three years or so, maybe even longer, maybe four years as you've been building this out, and I've been wanting to get you on real vision. And now, now is the time, because I think it's super fascinating. I've had this big thesis around Michael, the exponential age, which is the coming together of all of these technologies of which what you're doing, stuff like distributed compute, is a big part of the future of the world goes. So before we start into what you're up to, give people your background, where you've come from, what do you do, that kind of stuff and how you got here."
    },
    {
        "speaker": "D",
        "text": "And really quickly, I was reminiscing on that as well when we stepped into your office and grand, and you gave me the grand tour. That was what, three years ago? So it's been really interesting to maybe even longer."
    },
    {
        "speaker": "C",
        "text": "Maybe four years."
    },
    {
        "speaker": "D",
        "text": "Maybe four years, yeah. So a lot of water to the bridge and it's an absolute pleasure to be here and maybe summarize some of those. The journey so far, it's been a lot of fun and same congrats to you and real vision. And with the expansion age, this is exciting. Quick background. I have a mixed background in physics and military aviation. And especially on the research side, what passion or what elevates me is answering questions and research and making tomorrow happen today and accelerating innovation and whatnot. And compute from that perspective is a means to an end. It's a tool for innovation and making new medicines and space elevators and aircraft and everything. And I always needed more compute for my research. And if you, if any ever you go into a classroom, you ask students, hey, put your head up. If you've ever used a thousand cores before, nobody puts their hand up, and that's just 1000 cores. Imagine saying, has anyone ever used a million cores? Now the people on the planet would have used a million cores before you could probably count on a couple of."
    },
    {
        "speaker": "C",
        "text": "What is a core, by the way? I'm going to have to ask you many questions."
    },
    {
        "speaker": "D",
        "text": "Yeah, no, it's good. So we can go into slang. So when I say core, I'm referring to CPU cores. But of course, GPU's, which is at least 20 to 100 times more powerful than the cpu core, will give you even more. But typically your laptop will have about between eight or 16 if you got a good one, or even 32 if you've really dropped a lot of dough and graphics card and the gpu. So typically that's what your typical home user or advanced scientists on the lab will use. So going from eight or 16 to 1000 or a million, this is where you can take a sledgehammer to innovation and really light fires. Compute, compute. Compute is the name of the game for the era of innovation, especially with AI."
    },
    {
        "speaker": "C",
        "text": "So give me that journey then. So you're in research and then what happens? How do you get into what you're doing now? Come up with this crazy idea, talk me through that story."
    },
    {
        "speaker": "D",
        "text": "Well, I'll be modest and start by saying that the idea of like putting together computers for accelerating research, that's as old as computing itself. It's an old concept, and nobody should be going around saying, oh, distributed computing is going to save the world. It's been around forever. If we even hearken back to the days of city at home, there are just more clever approaches that can take advantage of technologies. It's a better way of stitching things together, but we'll get back to that. Me personally, it's a rather hopefully relatable story to people who've been doing some modeling, but I was sitting there in my lab on my laptop trying to make my code run, and it would take days to run through some of these simulations. And whether it's physics simulations or financial modeling or risk modeling or what have you, it's the same thing. It's running a bunch of compute scenarios, it's crunching numbers and data, and it spits out an answer eventually. And so it take days on my, my typical computer. Meanwhile, there were a whole bunch of computers in the lab next to me doing absolutely nothing. And the dream was, okay, we could tap into this and of course you could. There was some software that existed at the time, but it was an absolute nightmare to try to configure and keep in mind. So I spent eight years learning physics and then math, and then to code the math. And then by the time I was able to produce results from my own answer about physics questions, now I had to learn how to administer clusters, or learn the cloud, or to manage a data center. I was like, you know what? I spent enough time becoming an expert, I'm not going to now learn how to administer data centers. And so what I did was I manually walked around to each computer and I said, you do compute one to 200, you do 201 to 400. So I sort of manually running around to these computers and making them do this stuff, which is surprisingly more efficient than spending the weeks to months to get up to speed feed on grid toolboxes and other things. So that was my personal frustration. And I can certainly speak on behalf of all of my co researchers, everyone, chemists, biologists, mathematicians, same with them. They spent so long getting good at asking good questions and attacking ways of coming up with the answers. They don't have time to learn all of the new fangled tools that have somehow inserted themselves between researchers and developers and the hardware that spits out the results. We've heard about DevOps and finops and no code as a service or low code, no code. There's all this stuff, this whole cottage industry that is somehow interjected between people asking questions and the hardware that produces the answers. And that's what we wanted to get rid of, or that's what I wanted to get rid of, because I wanted to make my life easier as a researcher. So that's how we got into it. I was tapped on the shoulder at a barbecue party by some friends. This is the rise of bitcoin and crypto. Like, hey, clouds getting big. Crypto is getting big. Why don't we put all this together, do this cryptocurrency, incentivize, distribute cloud kind of thing. And that's how it started. But six years later, we've succeeded in building a compute platform that's no different from typical concepts, but that uniquely uses web technology. So we can walk into any hotel lobby or any audience full of people and say, pull out your phones, for example, open a browser tab, type in this little code, DCP work, and press start and instantaneously out of the compute cluster. So it's secure and ubiquitous, it's fast, it works on every device. And so that's sort of like the dream coming true many years later. How to make spreading questions computational problems resulting from these questions across devices everywhere."
    },
    {
        "speaker": "C",
        "text": "By just using a browser."
    },
    {
        "speaker": "D",
        "text": "Browsers. We have a screensaver version now, so set it home style, really dockerized. It doesn't matter. We've done it on fridges, phones, laptops, everything else. But all this to say it's not about, like, I don't wanna be like, the compute drama. I think everyone knows that compute is sort of the core of what makes innovation happen nowadays, and it's underpinning all of AI and everything else. But I think the next question is, how do you make it more accessible, not just from a cost perspective. And I'm sure you're all over the fact that people are getting sticker shock. Sales volumes with commercial cloud providers are starting to decrease as people are becoming a bit more cost conscious. Right. The promise of cloud is because right."
    },
    {
        "speaker": "C",
        "text": "Now, most people solve this by paying Amazon or Azure for compute in the cloud, I guess."
    },
    {
        "speaker": "D",
        "text": "Yes, absolutely. Some hyup friends at Amazon have said that they're feeling the pinch of chip shortages as much as everyone else is right now. So a lot of the compute is being routed towards their bigger customers, and it's leaving some of the smaller ones with less. Prices are, of course, going up. And in this sort of quasi recession, everyone's looking to reduce costs. I don't think there's a CIO on the planet who doesn't have written into their employment agreements that they have a partial mandate to decrease costs. Where they can, and the cloud bill can be up to or sometimes exceed 50% of a company's technology budget nowadays. And I believe almost 80% of the funds that VC's are investing in these AI startups are basically flowing directly through to the cloud services providers. So when you think about that, only 20% of VC money is being deployed to building new IP and hiring personnel. 80% is going to pay Azure, AWS and what have you."
    },
    {
        "speaker": "C",
        "text": "Yeah, we'll be building some AI tools in real vision. And the cost is the compute. Everything else is relatively straightforward, it's the bloody compute, and you're competing with these giants for the compute. So when it comes gone, I was just gonna say."
    },
    {
        "speaker": "D",
        "text": "And that's why there's been a number of many, many companies that are building these compute platforms, and some have been on your show as well. And we're all, we have that shared objective of reducing the cost of compute, but also making a new set or evolution of tools that get out of the way of the researchers or the developers, or the application developers, because that's the other thing. It's been engineered to be so complex nowadays like that. There's like 50 cycles of this and waterfall that. Again, as a physicist, I just wanted people to get out of the way. I just wanted to express my workload and get my results and move on. Now, when you go to any of these cloud providers, there's like 70 pages of instance types and then different config files that if you screw up the wrong thing, you're now compromised and get locked out, or you have what they call the $50,000 oopsies, you wake up on Monday morning and forgot something on a Friday afternoon. So all of this stuff makes it difficult. I think it puts an upper limit on the pace of innovation."
    },
    {
        "speaker": "C",
        "text": "So talk me through what you've built and how it's being used and what it does for costs."
    },
    {
        "speaker": "D",
        "text": "So from a cost perspective, we've done several deployments in commercial and non commercial locations. So manufacturers, hospitals, airports, on the commercial side, and it's about 8% of the cost of cloud. For example, a machine vision, typical run."
    },
    {
        "speaker": "C",
        "text": "Of the mill machine vision, 8% or 80%?"
    },
    {
        "speaker": "D",
        "text": "8%."
    },
    {
        "speaker": "C",
        "text": "8%."
    },
    {
        "speaker": "D",
        "text": "A 92% reduction in the cost of using, for example, a Microsoft custom vision or AWS recognition solution, which is a machine vision platform. You can spend a formidable amount of money in a hurry when running these intelligent machine vision analytics platforms on a near continuous basis. But if you harness all of the computers, laptop servers that exists at that airport, so what we're doing right now in a couple of locations. It's 92% cheaper and data doesn't leave the building. We're also deployed at a couple of universities and this we do it at no cost. It's free to academic institution true to our initial mandate, which is to accelerate innovation. And we just launched last week a project called the hunt for the Legendre pair of length 117. And for the non mathematicians, basically legendre pairs are kind of like prime numbers in the sense that they satisfy certain rules. Five numbers, they're divisible by solid one legend of pairs have a whole bunch more rules and they're very difficult to find. But when you find them, they're extremely useful in cryptography and for self correcting code and some other things. So these special numbers have special uses that are very useful. And finding them would overcome some conjectures. In one sense, it would have some practical use cases elsewhere, but you would have to search 15 septillion numbers. I've never used that scientific prefix or post or whatever in normal conversation. It's the first time it would take on one laptop something like 200 million years to search that space and find these numbers. To pay the cloud to do this is impossible. But if you have several million cores from all of the idle computers, fridges, phones around the planet, our university campuses, suddenly it unlocks the ability to do some of this discovery without breaking the bank. And so again, it's free. So in this case, we have something like 15,000 cores worth of academic compute alone from campuses. And we've recently been working with the world community grid to bring up SETI at home. They're powered by boink, so that's a very old technology. It basically requests that everyone runs vms on the computers and we're embedding our work inside of that technology, and slowly we're proving things. It gives access to up to 500,000 machines on the planet. So that's more computing power that all of Canada put together, for example, the national research infrastructure. So there's a lot of power in these networks of people who are motivated, incentivized for science or economically or both. And making it easy to tap into that power is one aspect, making it secure is the other big one. So there's a reason why people aren't executing Python, random Python, from all over the web or all over the world on their computers, or random C code. You'd be crazy. That's how you get completely owned. But there is computing programming languages that people execute. In fact, 5 billion people execute every day. On their computer. That's JavaScript. Every time you surf the web, every time you do a Google search and you click on a link, you're fetching code from somewhere on the planet and you're executing it on your computer in order to view the page and fill in forms and everything else. Every time you log into Netflix or your bank, or you search the web, you're executing code from somewhere else on your computer. So that type of security profile is only possible because Google, Microsoft and Amazon have put billions of dollars into making the web secure, fast, and ubiquitous. I mean, name me a device that doesn't run the web stack. Building a compute platform out of this is the new thing that we think we've done. Again, a concept of distributed computing is as old as computing itself, but building it out of the most successful networking technology that everyone has at their fingertips already just makes a whole bunch of sense. And now we can talk about web three."
    },
    {
        "speaker": "C",
        "text": "Hey everyone, we're going to take a quick pause and hear a word from our partners. We'll be right back."
    },
    {
        "speaker": "E",
        "text": "This podcast is sponsored by Ramp. Are you the decision maker in your company? Consider this, for the first time in decades, there's a better option for a corporate card and spend management platform. Meet Ramp, the only corporate card and spend management system designed to help you spend less money so you can make more. With Ramp, you get full visibility into your company's spending and control who spends what. With each vendor. Ramp's software collects and verifies receipts instantly. To save your team valuable time. Ramp automates data entry and routine tasks with automated approvals, expense categorization and bill payments. Time consuming tasks, which means you'll stop wasteful spending and close your books in hours instead of days. Businesses that use Ramp add up to 5% to their bottom line the first year. If you're a decision maker, adding Ramp could be one of the best decisions you've ever made. Get $250 when you join ramp for free. Just go to ramp.com easy ramp.com easy ramp.com easy cards issued by Sutton bank."
    },
    {
        "speaker": "D",
        "text": "And celtic bank members have the IC."
    },
    {
        "speaker": "E",
        "text": "Terms and conditions apply."
    },
    {
        "speaker": "C",
        "text": "Well, come on to use case and something about just want to let people understand a bit more. So now let's say you, university, somebody needs a bunch of compute power, and there's thousands of computers at the university in various formats. As you said, it could be fridge, it could be Internet of things compute, it could be any compute, really. And you can tap into that. So firstly, what's the process of tapping into that compute? And secondly, what's the motivation for me for allowing you to use my compute and setting it up? So talk me through the two sides of that equation."
    },
    {
        "speaker": "D",
        "text": "So I'll talk through some fun different scenarios. So there's three parts, generally speaking in any compute technology. One, it's the mouth or where the jobs come in. So some sort of set of APIs, we call that DCP client. Then you have a scheduler that allocates workload and then you have the worker agents, the workers than do the actual number crunching. So to answer your question, if I'm a student, and I want to set up a compute cluster really quickly in a computer lab, we've packaged the workers in a variety of different ways that can suit enterprise needs or student needs on a budget. A student can walk up to ten computers and open a chrome tab and literally type DCP work slash the name of their cluster. I have one called Dan. So if I type DCP dot work Dan in a browser tab, and I give the password, I press start, that computer is now in the Dan compute group, just like that. So if I open this and it takes 2 seconds to open a browser tab, so I can do this on 20 computers, and those 20 computers, if they each have eight cores, well voila, I have a couple hundred cores and two dozen GPU's just by entering a website and a password like that. And then I can close all the tabs and walk away. So it's kind of like a pop up compute cluster that costs nothing. These are just all computers are sitting there. And then I would use the APIs to push my job at that Dan compute group. And if I want to figure out."
    },
    {
        "speaker": "C",
        "text": "Which computers to allocate it to, and."
    },
    {
        "speaker": "D",
        "text": "Relative load and all of that, that's it. But any modern distributed computing system should be expected to do that. And so ours is no different. All the user has to do is say, this is my data I want to process, this is the code I want executed against that data. Go away and come back with my results. And that's it. There's no environment configuration, there's no docker container, there's no image creation, there's no port forwarding, there's no firewall setting, there's none of that. It's just code data."
    },
    {
        "speaker": "C",
        "text": "Okay, so now that's the student with 20 computers around him in a lab, and he can go around and do each one. That's it. Now let's talk about big project."
    },
    {
        "speaker": "D",
        "text": "So then we can go up a step. Okay, so that's, that's like a really quick, you know, a pop up compute group, if we go one step up to the it level within the university, and they want to get serious, they can, using their existing network installer methodologies, they can deploy screensaver. So we've taken the engine out of the browser that does the compute and we've shoved it into a screen saver. And that screensaver basically can be deployed as in any the same way you deploy Microsoft Word to 2000 computers simultaneously on a campus."
    },
    {
        "speaker": "C",
        "text": "So if the screen saver's on, it means the computer's not being used, so it can be used for compute."
    },
    {
        "speaker": "D",
        "text": "That's it. And so this, everyone here should be saying, well, everyone here should be like, I've seen this movie before, 40 years ago or whatever, SETI at home, that's exactly what we did. That was a very popular model that worked. So we just put the same modern technology into the old concept of, into a screensaver. And so what are you left with? You're left with 2000 computers that when no one's using them, which is always going to be between five and eight in the morning and sometimes throughout the day, that's a lot of compute. And if we say that one virtual cpu core on the cloud is worth about $440 a year, and you have eight vcpus per computer, and you have 2000 computers, and I'm not even talking about graphics cards and GPU's or just the course, if you do eight times 2000, times 440, that's what it would cost the research facility community to buy that same compute power from the cloud on demand. We're talking hundreds of thousands of dollars, and that's not even factoring in GPU's or anything else. And yet it's available free right now. And so now, and that's just one university campus with 2000 computers. 2000, that's probably on the lower end. Your last question was how do I get involved and make some money? We've also created, or we allow anybody in the world to participate in the global compute network. It's the exact same thing as city at home or world community grid. Same, same concept, but just built on secure web technology. The same technology that's used for online banking, everything else that underpinsd the web, same idea. Anybody can participate and get paid, and what they get paid in is cash we've reserved, or we're waiting for market demand to add crypto and other settlement layers. But right now we started with the bread and butter approach, where people are doing real compute, they want to be paid real dollars. And if they choose to be paid in something else in the future. We're certainly happy to include those layers. But when you look at the market demand for compute, that's only exploding. And chip shortages and everything else, there's an argument to be able to sell computing power for about $100 per vCPU year. And if you have eight in your laptop and a GPU and you run it half of the time, these devices should be able to pay for themselves within two to three years or less of their lifetime."
    },
    {
        "speaker": "C",
        "text": "The Uber approach, right? It's basically the Uber of compute."
    },
    {
        "speaker": "D",
        "text": "Absolutely. Except public jobs have to be non sensitive. So your typical hospital at manufacturing airport, where we're also deploying these compute networks, don't want their jobs on open public networks. Correct. And so the ability to warden off workers into their respective groups gives everybody something so big. Gigantic million core networks for science, research and public good jobs. Forced IRA detection, which is very apropos right, nowadays. But then also these small clusters for allowing hospitals to not break the bank as they explore AI tools."
    },
    {
        "speaker": "C",
        "text": "And is having distributed compute safer? Because no computer gets to see the full workings. So if you hack one computer, you're only going to see one set of workings. You're not going to see the whole genome model you're working on or whatever."
    },
    {
        "speaker": "D",
        "text": "I would say it depends on the workload and it depends on the resources of the actor on the other side. If we're talking about a nation state with enough resources, it's never safe to assume that something's 100% safe. But some problems, some workloads require all of the data, the entire training set, to be, be in the same runtime environment. So in these cases that are not data parallel, someone who cracks one of them will get access to almost a totality. So again, it depends on the workload and it depends on the resources available to the other actor. And so the approach we've taken, and until full homophobic encryption becomes actually available and affordable and doesn't sort of like 100,000 times overhead, the easiest approach is just to order off trusted computers for trusted workloads."
    },
    {
        "speaker": "C",
        "text": "So something like the Department of Defense, they'll just run on their internal networks. It never leaves the building. It's no problem. But for others that have less need for secretary, let's say it's us training our AI model, what commercial value is that to somebody else? Relatively limited. So we can use any distributed network."
    },
    {
        "speaker": "D",
        "text": "Exactly. And you have all kinds of national statistics agencies like, I'm thinking national Resources Canada. They want to monitor the presence of forest fires and how they're spreading recession or tree lines or whatnot. So those data sets are already public. They're filed with tax dollars, so they're definitely public. And so running gigantic workloads like dental public networks, it makes a great, make all kinds of sense as smart cities applications that are for the betterment of your municipality. But those should be public jobs because it's benefiting the cities of all. Unless there's sensitive jobs, then, yes, then you do those on secured computers."
    },
    {
        "speaker": "C",
        "text": "Some of these huge models, the global climate change models that are distributed in nature so different people can work on them in different universities or whatever. Makes total sense, I guess."
    },
    {
        "speaker": "D",
        "text": "Absolutely."
    },
    {
        "speaker": "C",
        "text": "Why Enrich Amazon? They make enough money."
    },
    {
        "speaker": "D",
        "text": "They do. They certainly do."
    },
    {
        "speaker": "C",
        "text": "Yeah."
    },
    {
        "speaker": "D",
        "text": "So while we're talking about smart cities and AI, I was recently listening to a panel, there's a couple investors and they're asking what comes after AI? Like, let's put on our futurist hats and let's see what comes next. And everyone unanimously said, I'm more AI. So is that perhaps not a very interesting answer? But I'd like to tackle with that with you. You've seen, like a lot of folks, a lot of their takes on where AI is going. I want to make the case for we're going to see fragmented or personalized customized, decentralized AI. I think that right now, all the AI models are being trained and developed and controlled by massive organizations right now on the planet. But we can see a need for every municipality or every hospital or every locale to have its own AI that's gonna take care of water purification or optimizing bus routes or the train schedules, or maybe regional optimizations for surgeries across hospitals for sort of local efficiencies, but also sharing those efficiencies regionally. And so you could almost see every hospital, every bus station, every city hall having their own large language models, trains on their bylaws, or on their local standing operating procedures and so on and so forth. Each of those models, almost like a village millions of years ago, would take care of a fire. Right? You'd be the caretaker of a fire locally. Well, we're going to become caretakers of our local AI models that are going."
    },
    {
        "speaker": "C",
        "text": "To make sure this conversation, I've gone through this conversation with somebody talking about."
    },
    {
        "speaker": "D",
        "text": "Exactly this, I think it makes sense, right? We've seen this wave in computing as well. Everything was in a room, and then all of a sudden it's on your desk, and now it's at a room, but then it's on your desk, and now it's back in the cloud in a room, and now it's, they're calling it edge, where it's coming back again and back and forth, so on, so forth. Same with AI. It starts big, huge models that are."
    },
    {
        "speaker": "C",
        "text": "Centralized to decentralized, to centralized to decentralized, unbundling, bundling. We're seeing it endlessly, right?"
    },
    {
        "speaker": "D",
        "text": "Endlessly. And so AI is going to go through that phase. And so a lot of people are putting a lot of work into the algorithms and making them more efficient and able to run on smaller and smaller devices at the edge for inferencing. But we also want to build training them or have them constantly learn from data near the sensors that are the ones we interact with, or where we're generating data like our individual municipalities. And so when you're going to have these decentralized AI models that are basically cooperating with society, part of society built into it, you're going to need compute. And I'm not pitching or standing up distribute. This is just going to be true regardless of the compute platform that's employed. Here's a problem that cloud has not yet solved. If we're going to run these cooperative AI models built into society helper models all over the place, they're going to run on compute and data at these different edges. And up until now, cloud is one owner of its infrastructure, and it's scheduling workloads based on hardware that it owns and controls. So it's basically performance based scheduling. What happens when the owners of the infrastructure that come together, the different and the different traffic lights and the different servers and the IoT device that come together to create that data and compute fabric to power the SAI, are not owned by the same owner. Now you have heterogeneous ownership, and not just heterogeneous hardware that you have to overcome. So this becomes interesting. And I was on a panel with Ericsson, and they said the biggest problem that's going to have to be overcome in order to facilitate and true edge decentralized edge computing is going to be remuneration. Which takes me to sort of like a final interesting thought process. When you get your electrical bill at the end of the month, it doesn't say that you bought four toaster hours and six light bulb in its and 17 fridge days. It says you consumed x kilowatts of power. This is your electrical bill. And that's done. It doesn't matter what appliance you are using this, there's a value that's been attributed to the electrical service that you consume. Well, compute we're still stuck in that yesteryear version where we're charging people based on the availability of a particular instance type and instance is just the neighbor the hardware is running on. That's what I meant getting with the 70 pages of these instances. What if instead it's just, look, you have a problem and you launch this workload and your results are worth this, the same way that your electrical bill is just pared down. And we're going to have to do that, neil, in order to deal with heterogeneous ownership and heterogeneous platforms. And by here I'll define heterogeneous, it just means different. So you'll have phones, you'll have fridges, you have computer servers, but you'll also have it. It's owned by the library club, by residents, local households who are part of that municipality. They can get an offset on their electrical bills or whatever if they contribute their idle compute capacity. So measurements without being able to be spoofed or fooled is critical security. The inability for a malicious workload to compromise any of those devices is paramount. And simplifying access to these, making it easy, is the final pillar. Those are the three pillars, I think that not us, but any compute platform that claims it will put a dent in edge computing and AI will have to overcome in order to make that future a reality and get us closer to the singularity, for example."
    },
    {
        "speaker": "C",
        "text": "Hey, everyone, we're going to take another quick break and hear a word from our partners and then we'll be right back. Okay? There's a whole bunch of stuff there. Firstly, when you talk about separating electricity hours by toaster hours and fridge hours and whatever, aircon hours, actually, that whole process could be run by AI. Once you get to that granular level. Because if every Internet of things is giving you that information, then your own household AI can control better than your nest cam, which is a very mild version of this, that you can become hyper lean and effective and you can exactly see what's causing your problems. And I do you need to change that AC unit or whatever it is. That in itself is interesting. When we're talking about localized AI, you can have household level AI already we're very close to having LLMs on our phone that don't need to run on the Internet. So that becomes personalized AI, household AI, municipal AI, online group AI. So real vision is developing Aih and AI. And that's for the community of real vision. So it's a community AI built for the purposes of that community. It becomes super interesting and it links everything. And here's my issue with the singularity in all of this is we don't yet understand, and I don't think we ever will, how large language models learn. We don't know what they know and we don't know how smart they are because we're trying to speak a foreign language to something. And we were, you know, if you go and speak to somebody in Hindi right now, you're not going to assess whether they're smart or not. You're just like trying to somehow, in a broken language, try. And you can speak this much to them. And, you know, if I listen to Sam Altman speak or listen to the guy who runs anthropic or listen to Emad from stability like nobody's got a fucking clue how this stuff works. And what is interesting to me is if you do link everything well, AI can spread everywhere. If it has some ability to think like a virus, which it may well do, we don't know, then it has an ability to use all, compute everywhere, whenever it wants, however it wants, and control everything around our environment. That's kind of an unintended consequence that."
    },
    {
        "speaker": "D",
        "text": "I thought through on this while you're issued now, one cannot avoid thinking about Terminator here and Skynet and everything else right for the next, for the foreseeable immediate future. We think, or at least we think here, that LLMs are excellent stochastic parrots. They happen to be able to spit out things that are."
    },
    {
        "speaker": "C",
        "text": "But you don't know that because when you watch how it won. DeepMind, go right, DeepMind, that was, I don't know if you watched the documentary, but it was, we've all read the story, we all know it. You watch it. It was the first four games or whatever, three games it played, ordinary human games. It then lost a game and never played a human game ever again. And the commentators were like, what the fuck is it doing? This is stupid. This is a dumb move. And it never, ever lost again in a way that we don't understand. So I don't think it's stochastic parroting. I think that's a human protective thing that we suggest because then we can understand it. Like we use narrative and mimetics to understand the world around us."
    },
    {
        "speaker": "D",
        "text": "We kind of say that it's certainly an important conversation to continuously have because the minute we relax our skepticism or our caution around these things, we'll begin to make mistakes. It's the same with Crispr gene editing, in a way. The parallels there for the atomic bomb with Barb and that came out just recently. Right. Like, with great power, we have to be very, very careful, and we obviously are. With some dark, hurts citizen here in the office. We talk about maybe accidentally unleashing something like that. Yeah. We would become in serious trouble if we start too early, letting AI launch more AI jobs and start doing stuff. So I think it's always important to have guardrails. For sure. We have made sure that there's a big red button. Of course, everyone does. I don't."
    },
    {
        "speaker": "C",
        "text": "Yeah, but you might be able to, but the LLMs can't, because if it has infected your fridge and if I can store an LLM on my phone, I can store it on my fridge. And so in which case, the LLM can be anywhere and. No, exactly. Like a virus. It's just something. We're not there yet, obviously, but it's just something I think there is. Like, okay, this is very difficult to stop if it goes certainly too far."
    },
    {
        "speaker": "D",
        "text": "Ex machina. If you've seen the movie, it was such an excellent movie. And the biggest question that wasn't asked explicitly was, are these AI humanoids? Are they simulating emotion with really high fidelity, or are they experiencing it? And it almost becomes a metaphysical question, like, does it matter?"
    },
    {
        "speaker": "C",
        "text": "If that's my point is I was having this discussion about, you know, do they exhibit emotion? It doesn't matter. Just because how we see the world is human emotion, it doesn't mean different things can live. I mean, because if we know the complexity of a bee colony or a yemenite bacteria colony, these are super organisms. They have a collective intelligence of which we don't understand yet. It's fascinating to watch everything."
    },
    {
        "speaker": "D",
        "text": "Yeah."
    },
    {
        "speaker": "C",
        "text": "Because we can only think of in our world."
    },
    {
        "speaker": "D",
        "text": "Yeah. But, yeah, it's fascinating to watch these bee colonies or fungi colonies."
    },
    {
        "speaker": "C",
        "text": "I mean."
    },
    {
        "speaker": "D",
        "text": "Oh, yeah. The ones that actually take over the host's brains and by injecting spores and whatnot, is absolutely fascinating and terrifying. Let's hope AI doesn't start doing that. Then we're really in trouble, right?"
    },
    {
        "speaker": "C",
        "text": "Yeah. Well, you know, is there a flip? You know, are we biological computers? I mean, that's the other question that biologists and physicists are trying to answer, because if we are biological computers, then there's no reason they couldn't."
    },
    {
        "speaker": "D",
        "text": "And, you know, it is always fun to ask the reverse question. You know, like, we keep saying that humankind is domesticated wheat, but someone actually flipped that, that conversation. Wheat domesticated us like dogs."
    },
    {
        "speaker": "C",
        "text": "My dogs domesticated dogs domesticated humans because they now have their food given to them. Yeah. Same with wheat. Wheat is now an endless. It's survived. That's the entire job is to survive."
    },
    {
        "speaker": "D",
        "text": "Making sure it's healthy, it's watered, it's, all the lands are irrigated, it's in these beautiful parts of fertile land, and so on and so forth. I guess at the end of the day, it's important to understand that we're not above or below all the other participants on this planet. We have to be caretakers and be careful. And as long as we're progressing in a way that people are benefiting. All people are benefiting, all people and non people, I guess, then things are sustainable. Why are we inventing AI? Why is there this AI craze in the first place? Do we need it? We've been fine, look, over the last several thousands of years. Millions of years. Well, AI is again like compute. It's a means to an end. AI in itself is useless. What are the use cases that are interesting with AI? Well, it's all about gaining some efficiencies here and there, better scheduling of resources if you can make sure that the right patch of two, so it stops."
    },
    {
        "speaker": "C",
        "text": "Knowledge being a scarce asset. Right."
    },
    {
        "speaker": "D",
        "text": "So your brain, what do you mean by that?"
    },
    {
        "speaker": "C",
        "text": "Yeah. So your brain, what you know and what you've learned is a scarce asset. Right. It's not easily repeatable, but we're seeing that AI can scale knowledge in a way that no single human can. Now, we're not at AGI yet, but we're at levels of knowledge which are frankly making a doctor, an accountant, a lawyer, and a whole bunch of professions questioning what is their economic value versus an AI. Right? Adopted charges. The lawyer charges $1,000 an hour because he's a senior partner. Really? How much is that worth versus the AI?"
    },
    {
        "speaker": "D",
        "text": "Right. It's very interesting. And coming from a bad, everything that."
    },
    {
        "speaker": "C",
        "text": "Gets digitized goes to zero in cost, which, you know, because that's what you're doing."
    },
    {
        "speaker": "D",
        "text": "Well, I used to fly for the military, as a military pilot before, and of course it's hit us too, like we're asking the same questions. AI can land a plane far more accurately. In fact, I think when they were landing drones on the us aircraft carriers, they had to actually build in some stochasticity to its actual touchdown point because it was so perfectly landing in the same place every single time that it was starting to damage. The tarmac that I was landing on was pinpoint precision. So they actually had to build in some variability landing spot. So. Absolutely. And a lot of people are worried about losing jobs AI. It's not that we're going to lose jobs, AI, so we're going to evolve new jobs, more creative ones, more guidance. There'll be a transition and whatnot. And I don't think it's going to happen too quickly. I mean, I think there's a scale right now because there's been a leap, obviously, with chat, GPT and other similar technologies. But there still will be a reasonable transition between our current way we do things because it comes down to trust. And as you said earlier, we don't know exactly what's going on at the end of the day, deep down within these models."
    },
    {
        "speaker": "C",
        "text": "So here's a question about that. And distributed networks is there are two battles going on, which is the same battle we talked about earlier. That is centralized AI. Let's call it OpenAI, let's call it Google, let's call it anthropic. And there's a few others, and China has their own and a few other people. And then there's the open source AI models. How the hell do you stop it? Why can't it? You can't stop atomic energy development or nuclear weapon development, really. It's somewhat easier because control the uranium, but we've seen it with CRISPR gene editing, any of this stuff, it just goes to a different country."
    },
    {
        "speaker": "D",
        "text": "It's the prisoner's dilemma. If you don't do it, someone else will and you're kind of stuck. And therefore you must. I mean, entire doctrines are being rewritten. In fact, they're already rewritten. How, if your enemy or any, any naval or air force fleet that harnesses AI will have air superiority, it's imperative, right, to develop these things because if you don't, your enemy will. So how do you stop that? That's really hard. I mean, I guess you, you cut off. I mean, you can only go after algorithms, data and compute if you want to stop it, and communications, but you've distributed compute."
    },
    {
        "speaker": "C",
        "text": "The algorithms are distributed because they're open source. What, you stop electricity, but that's even, that's distributing now. Right now we've got solar panels and we have, you know, we're moving away from centralized grids to decentralized grids."
    },
    {
        "speaker": "D",
        "text": "It's just so. Is it, it's almost depressing to ask the question, you know, do we, the human species, have we matured? Have we learned anything since, you know, the detonation of several hundreds of nuclear bombs and the devastating effect they've had? Have we learned anything when we're creating potent nerve agents, bio weapons? Have we learned anything about doing anti satellite kill kinetic weapons, where we're creating shrapnel orbits and all at 7 km/second that will basically age us here. I mean, I'm sure you're aware of this. If you look at low Earth orbit, it's littered with dead debris and satellites. And one of the ways you knock out your opponents, now, I've gone in this sort of military slide here, but if you want to knock out communications, take out the satellites and take out the undersea cables. Cutting an undersea cable isn't really going to threaten our civilization, at least not in the long term. But if you start taking out satellites with kinetic weapons, creating again like these gigantic, irreparable shrapnel clouds that travel at speeds that will. You won't even. It would just go right through you and you'd be pulverized. So we're at risk of creating a very physical jail around the planet if we don't let cooler heads prevail. So the question is, can cooler heads prevail?"
    },
    {
        "speaker": "C",
        "text": "Or is it the prisoner's dilemma? It's also interesting to me, at the center of all of this, of all of this conversation we're having is Elon Musk. Because not only has he put up more satellites than all the other governments combined, he's done it as a single person, but he's created an entire network communication, distributed network communication, which is Starlink. Yeah, but then I look at the cars, and they are distributed compute, and they are using AI to drive the robots, because that's what they are."
    },
    {
        "speaker": "D",
        "text": "In the end, they're computers. Oh, yeah. Everything is a computer. I mean, this. I mean, this Airpod case will, I can find it. I can locate this chips in it. It's broadcasting its position, obviously. So is this phone's laptop, this smart tv, that laptop, this everything is basically a computer with chips and a sensor, right? So, Elon Musk, when you take a step back and you look at all the companies from solar power, from battery storage, obviously, launch system, satellite network, and now communications platform. I always wondered why you bought Twitter."
    },
    {
        "speaker": "C",
        "text": "Training the AI, it was, all right."
    },
    {
        "speaker": "D",
        "text": "Well, this train of the AI. But the optimist in me thought when I was looking back and said, okay, I had all the boring company, I thought he was setting up. He might still be. I have no idea. I'm just speculating as my. The curious wannabe astronaut. I mean, I always thought he was building his own space program, but."
    },
    {
        "speaker": "C",
        "text": "Without question."
    },
    {
        "speaker": "D",
        "text": "But if you can deploy these sub saline tunnel diggers to the moon now, you don't have to carry all the materials to build these bases. You can just dig them out. And especially if the."
    },
    {
        "speaker": "C",
        "text": "And also if you want the base on Mars, it has to be on the ground."
    },
    {
        "speaker": "D",
        "text": "That's it. So he's got all the things put together, and maybe at the. At the last second, he noticed, you know, what's missing? The imagination and the will of the public. So if you can influence the media and get people to dream again, as Elon Musk started, and I hope he still is, as an optimistic dreamer, influenced by Jules Verne and all the explorers, and he built all the technology. And the last thing that was missing was maybe the will of the people, that the boldness that the desire to dream biggest, now it becomes almost social commentary. I feel like the human race has been preoccupied with less than exciting topics, I think, these days, and in fact, probably that are damaging to our collective well being. And nobody's talking about, or few people, relatively speaking, are talking about nuclear powered space travel and what's the below the surface of Mars, or how much waters are actually below the poles on the moon, or helium three. If you mine that off the, out of the regular lunar dust, you can create anatrinic fusion fuel. Right? Which power, like a teaspoon of it, would power a city for weeks. No one talks about this. We're more busy contemplating politics and whatnot. So I was sort of hoping that Elon Musk was going after the last piece of his entire space program, his disassembled space program, to actually influence the people, nudge them towards being curious, and."
    },
    {
        "speaker": "C",
        "text": "He'S just going to do it anyway. Now, again, this is not past Judson. Elon Musk is a good person or a bad person, or he does everything to everybody, pisses everybody off and inspires everybody at the same time. And everyone thinks he's a crook as well as a genius. So, that aside, I think what he did was say, okay, I want to go to Mars, the mission statement, and I want to build a colony there. So go back to first principles. What's the hardest thing? Well, we know we could probably get there. The technology was there, he was paying for it. No government could afford to do it. So then if you break it down to the component parts and get each one of those businesses to be cash flow positive, so the car company, let's say the AI training, which is twitter, lets say, obviously, SpaceX, all of this, they all throw cash, and before you know it, theyre all building this end goal, and then it just kind of happens because everything is in place. And thats what, even when I look at the Optimus robot is like, well, you cant send humans to Mars to start with, and if youre going to have to do stuff, youll deal with robots. How do you train robots that are acceptable to humans, that don't freak you out, is train it on humanity so you can, your political views will match with your robots or whatever it is, which is Twitter, which is why he doesn't give a shit about freedom of speech. He just wants an unbiased model so he can train the robots to be."
    },
    {
        "speaker": "D",
        "text": "Like you and I. Yeah, once upon a time, I'm sure he was dreaming of space travel. I'm shrew, stoltas. But it's important not to become too cynical, I think. Right. Otherwise, why are we, why are we trying to go to Mars in the first place? This is another question, like, why? Why go? Are you just going to set up a copy of ourselves over there just to do more of the same? Because in that case, it's not AI, that's the virus. We're the virus. Right?"
    },
    {
        "speaker": "C",
        "text": "Maybe that's true, right? Yeah. I mean, I don't know. But the other question I want to throw at you in all of this is, okay, we've kind of looked at steady state of compute, saying, okay, we're distributing, we can scale it. AI has come. It's a game changer. Requires more compute. Everything's just going to be more compute, more compute. That's endless. Talk me through quantum."
    },
    {
        "speaker": "D",
        "text": "Quantum is going to make a lot of conventional compute obsolete. So it's a guessing game as to when it's going to be ready. And I was having this conversation just recently. Conventional compute computers have come about decades ago, but it's only in the last ten years or 20 years where you starting to see, like, coding really built, deliberately built into even high school curriculum. Right? So from the moment of invention, it took decades. Like, of course it was used immediately, used to go calculate trajectories. But by the time it's actually fully mainstream, like, baked into our educational curriculum, everything else, it took several decades. As a physicist who's taken a quantum mechanics class of two, there are still a lot of principles that we're still working on overcoming to make the first quantum computers more than just cool, but viable for big problems. And I know there's a lot of big efforts that you, again, can count on two hands that are doing some pretty amazing stuff right now. You've seen that wormhole on a chip video that came out by quantum magazine. Is formidable. But there's still a long ways to go before that technology is mature enough to be deployed on many desks, let alone everyone's desk. And that's going to take even longer before it's part of curriculum in school again. As a physicist, I was trying to look around, hey, how do I program a quantum computer? How do I write a quantum algorithm? There are a few. The first, the very first textbooks on this are just starting, right? Like, everybody should know right now what a for loop is, or anyone who's done like a comp sci or computer science degree or, or anything touching the sciences. Everyone knows what a for loop is and how to write one. But if you ask them, hey, how do you write the quantum version of that? Or is there a quantum version of that? Like, I, as a, someone's written a lot of code myself, and who's a physicist, I have no clue how to think about it. What is it, what is it doing."
    },
    {
        "speaker": "C",
        "text": "To everything when you've got kind of. So we talked about knowledge being scalable. We're talking about what you're doing is making compute scalable. But now we've got with quantum, and we're not there yet. So let's talk 30 years in the future, infinite compute, and AI that feels like that is the singularity of all things, because there's no constraints on anything that we understand today."
    },
    {
        "speaker": "D",
        "text": "So in two words, I'm going to say more triangles. And that's an inside joke for people doing finite element analysis. When you design a model, whether it's power or an airplane, and you want to see the impact forces and how it distorts the metals and breaks things, you break that model down into tiny little triangles, 3d versions of triangles, and then you apply the battery conditions and see how forces distribute everything else. But the more you turn up the fidelity, so the smaller you make those triangles, the more triangles you have, the more equations and the bigger the matrices that he computed it upon in order to get your answers. So basically, if you give someone, if you double the amount of compute that they have access to, they're going to more triangles, they're going to turn up the resolution, they're going to push the batteries, they're going to come up with a new AI algorithm. Instead of doing like 10 billion tokens, they'll go to a trillion tokens. If you make more green pasture available to rabbits, well, they're not going to just be sustainable and responsible. They're just going to multiply, and then they'll eat all that grass. Me, the syn assist that if you give somewhat infinite resources, you can find a way to use them is why not. I mean, that's how innovation happens. You're constantly pushing the barriers. If we had a space drive that could go at 90% the speed of light, we're going to look for a way to go at 97% the speed of light so we can go see the more parts of the galaxy. It's just the way we are, I guess. So what does it mean? I think we're going to have someone in the future called Raul Tu and Dan Tu will be having exactly the same conversation about the next thing after quantum computing. Talking about what happens when we truly have infinite compute and find more ways to use it."
    },
    {
        "speaker": "C",
        "text": "Okay, final question. Something you and I have talked about over the years as well is as we're getting towards distributed compute and payment systems, I'm thinking at simplicity level for people to understand. It is the uber of computing. I can get paid by having excess capacity. Like if I wanted to use my car for other stuff, I can do that and I can get paid. We're also seeing that there's machines that doesn't have to have humans. So it could be my fridge in the future state. And you've tested that technology out. Works pretty well. Anything with a screen saver. If I take that screen saver, I've now given all permission to you to use my compute. So surely that sounds like crypto payment, right? Because thats the easiest way of making machines, machine payments and globalized payment system where youre not having to use currency."
    },
    {
        "speaker": "D",
        "text": "We need to push."
    },
    {
        "speaker": "C",
        "text": "We need to make sure youre a canadian. I dont want your canadian dollars. And ive got no bank account to put them into. So I have to convert them. Its ineffective and it's not fast."
    },
    {
        "speaker": "D",
        "text": "The moving around small amounts of money or value different currency changes going through traditional systems is definitely a bottleneck. Absolutely. But I just want to back up, as you said, some interesting stuff. The idea of having the uber for compute, I think that's a very good top level way to look at remuneration for providing a service access to your excess compute power distributive has a much more holistic vision of this. It's not about, hey, who wants free money? Put your hand up and sign up your computers. That's many companies have tried that. I think it's boring and I think it's unsatisfying to humankind. What we want is for active participants in the innovation journey and sort of like staking a claim or taking a ownership compute is one form of value, but the other one is also like private beta. Your fridge in the future won't just contain your food. It will have a few hard drives in it. It will store and analyze footage from your local security cameras. It will look at if a person is starting to have changes in their gate as they're aging, or if they're dizzy, or if they're couch later, or if they fell or something like that. Like, if you have an ownership say on your data and on the and other results of it and aren't just uploading it to some monolithic cloud services provider, then all of a sudden you're a participant and not just a subject in this digital age. So some people, yes, sure, they can make some money."
    },
    {
        "speaker": "C",
        "text": "You have agency because your data is part of you, right? It's a byproduct of you."
    },
    {
        "speaker": "D",
        "text": "That's it. And so participating in these. In these mesh networks is the best way to stay involved and maintain a voice and some control. And so the future that, since we've met four years ago, that we've made good on producing is one in which participants are truly participating. They're not just getting paid for the computer. They're finding these legendre pairs, and they're elucidating all the formation mechanisms for galaxies dark matter and helping uncover some of these things. Or Cartwright Kellogg's serial sales data. Right?"
    },
    {
        "speaker": "C",
        "text": "So let's say it becomes also cause based, right? Humans love a mission. They love a cause. So I'm gonna say to whoever it is, is running a huge project on something that matters to me, pancreatic cancer and Gillip and genome editing, to remove that. So I can then say, well, you can use my compute for that. So as opposed to giving you money to the pancreatic cancer society, I can say, no, just use my compute as well. And so I just permission then. So I'm now doing a mutual good, societal good out of my own free choice. And it's not about money exchange. It's about, I'm giving you something of mine that's valuable."
    },
    {
        "speaker": "D",
        "text": "Well, a perfect analogy for that. And then I'll come right back to it. Like, I agree 100%. Bank of Montreal gave $5 million cash to the AI hub at University of Toronto. They turned around and they gave that $5 million cash to Microsoft Azure. So Microsoft got 5 million. Bank of Montreal BMO got the $5 million tax receipt, and U of T got to do some AI compute. What if you provided $5 million worth of compute to U of T and the value of that $5 million was the tax receipt. But the green cash, as they call it, never moved. Now BMO has hundreds of thousands of enterprise servers full of excess compute most of the day. They could have donated $5 million of the computing power, or that's the enterprise version. You could ask 5 million people donating a dollar worth of compute real vision as hundreds of thousands of unique visitors per month. Something distributive is done. And I haven't really gone heavy on like the tech and innovation we come, but this is important. We've created five layers of code that we can put in your website that would make all multiple hundred thousand visitors turn into compute nodes. If they accepted, that would provide power subtleties just by putting those five lines of code in the website. So if the New York Times, so."
    },
    {
        "speaker": "C",
        "text": "We would say to our members, let's say, listen, if you want to help us continue to build our AI, which is for the community, by the community, essentially we can either give that money to Azure or you can be truly part of this."
    },
    {
        "speaker": "D",
        "text": "Yeah. While they're watching your content, their computer is basically sleeping, other than what it's displaying on the screen, their processors, some proportion of them could be helping work on real vision's models. And I'm using real, I'm not picking out real vision here, but the same thing in the New York Times Globe and Mail and basically any community with hundreds of thousands or millions of online viewers. I mean, if you put these five lines of code into the New York Times HTML page, you have 6 million compute nodes just like that available. That's more computing power, like I said earlier, than all of Canada's national research infrastructure put together. Just by putting six lines of code in the index HTML file of that website. Think about YouTube. YouTube bought by Google. Every time you upload a video, it's being encoded on Google servers. But instead they could be doing distributing that video encoding into pieces onto computers of people that are already watching YouTube while they're there. And you could use this truly to eliminate ads or provide an alternative six lines of code. Get rid of ads now. Help us run our models on you, the patrons, instead of in the cloud. That'll be far more cost effective than these ads."
    },
    {
        "speaker": "C",
        "text": "And also we could pay people for that as well. We'll say thank you. You get x dollars off your subscription next year because you've lent us compute to help train the model, so you get an economic incentive out of it."
    },
    {
        "speaker": "D",
        "text": "And so everything we've talked about, just to summarize all this, we've talked about a lot of things here. We've talked about the ability to donate, compute, and get a tax receipt from Children's Hospital of eastern Ontario, for example. They're looking to recognize philanthropy, not just in cash, but donation of time and services. And now compute. We're in the digital age. It's time to recognize the donation, the value, the donated value of compute. And thankfully, we have the cloud service providers who've laid out 70 pages plus worth of the actual value of compute. So that I think it would be very easy to recognize the value because it's a market commodity that's been well established. So that's the donation model. But then again, there's this web collaborative online web community model where just being on a page allows you to participate in the content creation or AI model creation that serves you anyway. YouTube, real visual, talk about open mail, anybody with these online presences. And same again, to bring it back to these participatory AI models at the edge. If you want these heterogeneous compute fabrics and sets or fabrics made up of different owners, they all have to be incentivized fairly and they have to trust each other. And it will power the model that again gives value back to them from detecting when roots are ingressing into the water lines, they have to replace certain stretch of pipe, or optimizing the plastroots or what have that. So that's the future that we see. Again, I'm not saying distributive is going to be the one to do it, but I certainly think the future is."
    },
    {
        "speaker": "C",
        "text": "Compute can be a common good."
    },
    {
        "speaker": "D",
        "text": "And people have been saying that for years and years and years. But I think it's more than that. I think it's a deliberate ownership, cultural mindset of the people with their hardware and infrastructure and data, where they're participating in this digital age, and not just passively collecting income, but they're picking a cause and they're dynamically interacting with it. I think it'd be wonderful to have a YouTube powered where all the video content uploaded was being encoded and done by the community of watchers itself. So it becomes a self sustaining thing and we can cut down all these data center costs altogether."
    },
    {
        "speaker": "C",
        "text": "And does it become more decentralized in terms of editing and everything else? In terms of. Sorry. In terms of any centralized entity stopping something. So if the compute for all of the videos is being done on a distributed network, it's almost impossible to shut down the network, right?"
    },
    {
        "speaker": "D",
        "text": "You could shut down individual worker nodes, but the work would just go somewhere else. So it becomes very resilient in that sense. Yeah."
    },
    {
        "speaker": "C",
        "text": "Okay, two final questions. One is, I know a lot of people are going to be listening to this and thinking or going to comment about filecoin. So what are they doing? How is that different? Just so people understand how fundamentally different."
    },
    {
        "speaker": "D",
        "text": "Is, filecoin is tackling an equally gigantic farm, which is more from the storage side of things. So there's a lot of unused storage space out there. And if there's a way to intelligently stitch together those are pockets of excess storage, then you can create a decentralized storage cloud. It's probably a really good way to use them as an analogy. If you want to understand what we're doing, we're on the other side of that fence. We're taking up all the unused pockets of compute excess compute capacity."
    },
    {
        "speaker": "C",
        "text": "Both of these are AWS. They do the compute and they do the storage. And what's happening here is this to distributed models that are attacking the centralized model and more?"
    },
    {
        "speaker": "D",
        "text": "Yeah, I mean, AWS is more than just compute and storage. Their networking and their software layers and platform layers. And there are a whole bunch of things like they built, they've had a lot of time to build a lot of things, but they won't tackle, by definition, they can't tackle the web platform community sharing aspect in real time because they're nothing web based. And b, they would be attacking their own business model by allowing people to use computers and servers that are not theirs. And so they have too much concrete, fiber optic cable and silicone that they've as sunk costs that they won't be able. They won't be, they'll be hesitant to implement technologies that allow people to become self sufficient. Of course, put it one way, and."
    },
    {
        "speaker": "C",
        "text": "There'S a couple of other interesting ones in the crypto space, just because it tends to be more centralized. Hivemapper is one, which is a decentralized version of Google Maps. Super fascinating. And then there's the other one, helium, which is mobile phone networks, wi Fi networks, decentralized. So people, it's this centralization, decentralization megatrend. And we're seeing, and it's healthy."
    },
    {
        "speaker": "D",
        "text": "And it's healthy."
    },
    {
        "speaker": "C",
        "text": "It is healthy. It's good. Final question, how many people are using your technology right now and where you're allowed to discuss it, what kind of users and how are they doing it?"
    },
    {
        "speaker": "D",
        "text": "We have 2000 people right now. I was just looking at the numbers. So are still small, but we're in a dozen universities. I was saying earlier, it's free for academic institutions in Canada, states, Kenya, Brazil, Brazil, for example. It's doing live forest fire detection using all the computers that are on the campus there. There are 8000 cameras across the Amazon. And if you can detect smoke and fire at the earliest onset, then you can fight it more effectively. But if you were to run a thousand cameras persistently on AWS, it would cost you millions of dollars a month. So it's not even. It's not even a. Not even possible, or it's not also worth it. Forest fires create hundreds of millions of dollars of damage. So you could argue it is, but if you could do it for thousands of dollars instead of millions of dollars, then it's. It certainly makes it more palatable. We're in six hospitals creating private compute clusters in hospital in order to optimize surgical schedules. And now starting to get into some genomics. Actually, one more use case here. So I meant to summarize with users, this one is new and it's unique. If we can create a compute cluster by hospital as we happen, and create a compute classified a different hospital, there's ways where you can run models. You've heard of federated machine learning and federated models where you can run analytics on data on computers behind each hospital's firewall, and you can fuse the results, but leave the raw data behind each firewall. Now think of 100 hospitals, think of a thousand hospitals, each with, for example, small patient cohorts with psoriatic arthritis. There are new genomics approaches that allow the right medicine to get to the right person on the first try, unlike the trial and error attempt that we do nowadays. That would save hundreds of millions to billions of dollars worth of the wrong medication going to the wrong person on the first try, because it means they're not going to be working within months, because they're off work while they're going through these treatments. But you can't take all that small patient forward data and put it together, whether it's the cloud or somewhere else, because it's not allowed to leave the building. Data sharing is the biggest barrier to innovation in the precision medicine landscape. So I say again, what if you can send compute to the data, instead of bringing data to the compute, which is the cloud model? So bring compute to the data. Now you have each of these hospitals acting as their own mini clouds, but if they cooperate in a sense where they do, they run their respective pieces of compute and then fuse the results together. Now you have something different. You have hospitals or individuals or whatever maintain ownership of their data, making some revenue from the fact that they're selling the results of those computations, but not giving up the underlying data, and to bring it back to Brazil, we're chopping down the rainforest right now. I think four fifths of medicines around the world come from the materials, the biological materials that we find in the rich forests there, and we're losing that, right? So imagine instead setting up in organizations with some schools, for all we know, for what it matters. And these could be many repositories of collect the genetic material, sample material, and computers. The computers can be used for students and the pursuit of knowledge during the day, and they could be running all kinds of data pipelines, data science pipelines at night on these data things, generating revenue locally to replace deforestation. And so this idea of data ownership, doing the compute, selling the results and creating a revenue stream, it's basically, it's a distributed, decentralized version of a cloud services provider. Imagine a virtual version of a hyperscaler, where everybody gets a piece of the pie, providers of data, providers of compute, the Marshall communication, the organization, the orchestration. This is what I mean by participatory."
    },
    {
        "speaker": "C",
        "text": "So if you think about it, for a pharmaceutical company, it's a lot cheaper for them to distribute out the scientific research to the universities. Everyone's running their own data. They can sell it back to the pharmaceutical company, they just take what they need from that data. They can develop new drugs, etcetera, they pay for it. Everybody's a winner, everyone save costs."
    },
    {
        "speaker": "D",
        "text": "Well, in this model, in the prior model, pharmaceutical companies would just buy the data from the get. The data is collected and refined at the source, they buy the data once and boom, the people who provided that data, they're gone. It's like one, it's just like selling your ip, it's gone. Right? Instead, they could hold on to their genetic sample data, and the pharma companies can just launch jar. They can write the code that they were going to write anyway. They write their analytics pipelines, their AI models, they write their queries, they write whatever it is they were going to do if they had that data and they launch it, and then it runs remotely at those sites, and then they get the results back. Money or revenues generated for the custodians of that data, we're taking care of it. It allows local economies. The pharma companies might not be happy, because the first thought is, hey, if we have the data, we can run all 10,000 analytics now. We have to pay for 10,000 times for the Alexa. We'd only have to pay once to get that data. But if you think about it, they were just going to upload that data to the cloud and then pay the cloud 10,000 times to run it there. So it's still an order of magnitude cheaper for them to not buy the data from where it's coming from, but just pay to deploy these pipelines at a reduced rate, which creates local economies over there. And of course we can expand this use cases, but this is what I mean, let's push away or let's create room for everyone else to participate in this revenue creation opportunity at the local economic level."
    },
    {
        "speaker": "C",
        "text": "You dont have to answer this, but surely youve spoken to Google about this. I mean, surely they would want to put this in every browser and give it a permissioning system and its like its a game changer because theyre the third runner in the cloud providing thing. Theyre big, but not as big as the other two. This is my go to the nuke button, right? Microsoft pressed the new button and said, fuck it, let's do the AI one to overtake Google and destroy search. It feels like somebody, like Google or Microsoft or somebody's going to say, you know what, we might as well just use this technology and just completely take this over."
    },
    {
        "speaker": "D",
        "text": "I mean, in Google specifically, if they find that idea interesting, of leveraging YouTube patrons while they're watching their content in order to do some of the processing for them in lieu of the ads that we keep getting every 20 seconds on YouTube videos, which would free up Google's data center capacity or GCP capacity to sell to more customers. I mean, they're bigger than, I'm kind."
    },
    {
        "speaker": "C",
        "text": "Of thinking bigger than that. If your little code is embedded in every single Chrome browser around the world. So now my computer, every time it goes on screen saver, is available for compute. I give permission. Google takes a slice, they become the world's largest compute provider by doing distributed compute."
    },
    {
        "speaker": "D",
        "text": "It would be massive if they were to do that. And it would have to be an opt in basis because people don't want to inadvertently have compute cycles taken from, even though it's ephemeral, it doesn't touch your data, has nothing to do with pictures or context. It's purely, it's just compute power. It's not storage or files and whatnot. If Google were to do that, it would be the most powerful supercomputer in history, period. Why the hell would, why the hell would they know? Because nobody has invented yet a pure web based distributed computing platform until us."
    },
    {
        "speaker": "C",
        "text": "Well, that's what I mean. I mean, all I'm thinking is like, as you scale this business, you've proven it out, you start to have great success. I'm just thinking through. Okay, well, where's the massive disruptor here? Yeah, you can do every university, you could do all of these research things, but really, if every computer in the world that runs a Chrome browser can do this on an opt in basis and everybody gets paid, including Google, it's like there's free money for everybody, and everybody saves the costs and it destroys Microsoft and it destroys Amazon, which is what they want to do."
    },
    {
        "speaker": "D",
        "text": "Well, I don't want to be con between their wars here, but. No, especially with the current chip shortage and everything else, I think recycle, reuse. I think there's a lot of compute out there. I think it's, in order to tap into it, you need a system that's secure and trusted. Web technology has been around for decades now. And if you're just surfing the web without downloading stuff, it's one of the most secure platforms in terms of executing untrusted code ever developed. It's the most ubiquitous technology on the planet. It's fast with web assembly and everything else. We think it's a no brainer. So, yes, if Google experiment putting some of this code into any of their pages that they host, they would have instantaneously millions and millions of extra compute nodes, and they could remunerate those compute nodes for the participation. So there's a lot of good stuff here. I mean, I look forward to redistributing value of compute. So, computer, if you buy in North America, is $2,000. If you buy it in Kenya, it's still $2,000. The difference there is the average salary per atom. So there are places in the world that are being excluded by cost from participating in digital economies and AI right now, they say the rich get richer, the computer are getting computer. And that's the price of admission for doing AI. So AI is also accelerating the divide. Those who have the means to do it, those who don't. So there is another play. It's not just making people passive income, but it's also making too shoot and therefore available, accessible from an ease of use. Austin, what have you. We're excited. We're very excited about where this guy. Thank you so much for, for the exciting questions, the conversation. Hopefully, we'll avoid Skynet."
    },
    {
        "speaker": "C",
        "text": "Who the hell knows? But one thing I will do is I will check him, check in with you in a year's time or so and see where you are. Because I've been following this journey and it's just a fascinating journey. I just love what you're doing and it's just, its just very, very big and its very disruptive. So I love it. Great to see you, Dan. And as I said, ill get you back soon."
    },
    {
        "speaker": "D",
        "text": "Thanks, Raul. Take care."
    },
    {
        "speaker": "C",
        "text": "Okay, so there was a lot to get our heads around there. Dan is very modest in what hes done, but to understand that any computer via a screensaver can permission decentralized compute, whether it's private or public, that is going to change the structure of how society uses compute, how AI works, how everything works. The scale of this is simply gigantic. And he's just starting in this journey. We're privileged enough to see it early on. As I said, I've been following this journey for about four years now and seen how far he's got and where this is going. And right now we understand that all compute is owned by very few people. But maybe that's not going to be the case. Can he truly disrupt by 92% the cost of computing power? What does that mean for other countries? What does that mean for all of us? But there's some dystopian sides of distributing compute and distributing AI and having it in your fridge, in your neighborhood, in your house, everywhere. What does that mean for humanity? And when you add the quantum computing as well, it means another game changer. Overall, the exponential age is relentless. It's not going to stop. And the game theory that he talked about is going to continue to play out. So it'll only accelerate and there will be regulation on many of these elements here. But it's almost impossible to put a distributed genie back in the bottle. So whether we use it to our advantage or fear it, that's up to us. But anyway, super interesting mind blowing conversation."
    },
    {
        "speaker": "B",
        "text": "What's up revolutionaries? Thanks for tuning in. For more content like this, head over to realvision.com and get unfiltered access to the very best, brightest, and biggest names in finance."
    }
]