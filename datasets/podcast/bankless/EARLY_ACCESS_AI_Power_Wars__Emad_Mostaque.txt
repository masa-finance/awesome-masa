Speaker A: Web three has grown up a lot like there are actually primitives now that are emerging that could be a substrate for collective, decentralized, distributed AI by the people, for the people, whereas on the centralized thing, again, it's a different paradigm, which is the all powerful AGI. My thing is you can't beat centralized AI with another centralized organization. I think what we should build for an AGI, this generalized intelligence, is the human collective intelligence, amplified human intelligence, something that uplifts us all and acts like a swarm. The alternative picture being presented here by DeepMind, opener and others is machine gun.
Speaker B: Welcome to bankless, where we explore the frontier of Internet money and Internet finance. And today on bankless, we explore the frontier of decentralized AI. Emad Mostak, the founder and former CEO of Stability AI, is on the show today. Emad recently left stability AI, citing you can't beat centralized AI with more centralized Aihdeme, and announced his intention to work in the nebulous field of decentralized AI. Decentralized AI? What exactly is that? Why does Emad want to put an AI model into the hands of every individual with a compute power to run it? Is there a race between centralized AI versus decentralized AI, or do they each bring something to the table? Why are the interests of governments, nations, and communities of the world align with the desires of decentralized AIh? Why will this revolution be deflationary for developing countries, but an accelerant for the developing ones? Bankless nation if you haven't gathered this by now, it's an AI episode today because it seems the world of decentralized crypto protocols and the rise of AI are converging faster than ever, and we at bankless are just trying to keep up one podcast at a time. Ryan the AI is out and unplugged for this episode, hanging out with his AI wife and AI children, giving us a chance to catch up as he takes a much needed break from the Internet and meme coins today. Let's go ahead and get right into this episode with Emad Mosstack, but first, a moment to talk about some on these fantastic sponsors that make this show possible. Thankless nation, super excited to introduce you to Emad Mossack, who has a really interesting background, was once a hedge fund manager, but moved to finance to become the CEO and founder of Stability AI back in 2020. The company behind stable diffusion, which is a text to image machine learning model that rose a prominence alongside chat GBT. I met imad about a year ago during the AI crypto week at Zuzalu so Imad is no stranger to crypto in web three, which I think will become evident shortly. Recently, Emad announced his departure from stability AI with the intent to pursue decentralized AI. A headline from TechCrunch read, Stability AI CEO resigns because you're not going to beat centralized AI with more centralized AI. Emad, welcome to bankless.
Speaker A: Pleasure. Thanks for having me.
Speaker B: So as AI as a topic, Emad went from zero to 100 just extremely quickly in the last like two years or so. And you've experienced that entire surge of attention, activity, investment all very, very quickly. What's that been like? What's it been like riding that wave? What did you learn about yourself, about the world, about other people? What was all of that whole thing like?
Speaker A: You know, you have web three time, which is faster than human time. Totally AI time is like faster than that.
Speaker B: Oh, boy. I do not envy that.
Speaker A: Yeah. Stability. We hired our first developer two years ago, and since then we've had 330 million downloads of models we built or contributed to. And that's insane in like two years. So I remember when stablefusion first came out in August of 2022 on cumulative developer stars on GitHub overtook bitcoin and ethereum in like three months. And so there's being in a normal start up scale and hyperscaling, then there is that craziness. And then on top of that, there's all of a sudden you're like talking to the king of England or like congressional people about how this can destroy the world or I, other things like that. That's just a lot. It's a lot, yeah.
Speaker B: What factors would you say played into all of that?
Speaker A: Well, the fact that it's a transformative technology. Right. I don't think we've ever seen a technology be adopted as quickly as this, like with web three. I think we're all passionate about decentralization, sovereignty, but we've been building a system largely outside the existing system. All the money's been made and lost at the edges, and we've been bootstrapping economic incentives, whereas this technology, all of a sudden, Google is a generative AI first company. Microsoft is a generative AI first company. Nvidia is a $2 trillion generative IFRS company. We never seen anything like that before.
Speaker B: I want to just get right into the deep end with this conversation about the pivot. Pivot, maybe you would call it, correct me if I'm wrong, into the world of what we are now calling decentralized AI. I think that if you've been paying attention to this world inside of the crypto industry. It's been a theme for coming up on a year now, but it's also very interesting to hear things from perhaps your perspective, who's coming from the AI world specifically, rather than coming from inside crypto directly. So overall, just like, what does it mean? What does decentralized AI mean to you?
Speaker A: Yeah, so actually I've been in web three since 2011.
Speaker B: Oh, wow. Earlier than us.
Speaker A: Yeah. My college coursemate was Ben, who co founded Bitmex with Arthur. And then I built kind of TCR systems, did system audits, other things in 2016, 2017. Stability originally was actually meant to be a dao of daos because we launched these communities to get the talent, and then I bought the supercompute and others. So our seed investors were seed club and lemnist Capital and CFG. So all crypto. But then I realized there was no intelligence in daos, so we had to build it ourselves first.
Speaker B: Right?
Speaker A: Yes.
Speaker B: This is something that we've learned over the years as well.
Speaker A: Well, we have, because we've kind of not learned the mistakes of direct democracy and other things. And so daos are more like, you know, dos decentralized, not really decentralized organizations, certainly not autonomous. And smart contracts are a bit dumb as well. So it was kind of a whole journey because youve got these two paradigms of autocracy and then distributed decentralization. And so I started dao daos, and I just quickly realized, crap, I have to centralize it. So I took control and then pushed forward the research agenda to build these things. But there was always this thing at the back of my mind, which is like, this is going to be used to teach your kids, or my kids or whoever, right? It's going to be used to diagnose our healthcare. Who governs that? Part of the debates we had about AGI, which is this very complicated debate, is it Terminator? Is it utopia? Everything. Who decides? Because if you look at what OpenAI says, for example, they say AGI will end democracy, end capitalism, and could kill us all. And it would be nice to have someone be part of that debate to a few people in Silicon Valley, right? Like, it may not be correct, like I signed the FLI six month pause letter last summer, but who should be governing this? Who should be feeding in this data? Because data is the most important thing. These are always things that were at the back of my mind. But the focus over the last few years was, let's build the best models of every type. So stability doesn't just do image models. We have the best protein volume model, we have the best video model other than Sora. Because Sora is not released, but stable video is released, it beats Runway and Pico with the best 3d model. We can generate a 3d mesh in 0.5 seconds, all thanks to this combination of community, core team and redifferentiated background. So moving into decentralized space again and going this full time is because I was having to think about this, particularly as Sam Altman takes over OpenAI again, and his reappointment to the board is a bit of a thumbs up, middle finger up to everyone, because he's like, the board can find me now, look, I'm in charge of the nonprofit again. There is no governance, even though I respect people there who should be running this. And where does Web three fit in this? It's the governance of the data, it's in the self sovereign identity, self sovereign AI, and it's in the distribution of this technology. So it's available to everyone. Because right now what you're seeing is increasing centralization. And are you going to out accelerate OpenAI when Microsoft's building a hundred billion dollar supercomputer, you know, project Stargate? Probably not, right? But do you need to build $100 billion supercomputers? Probably not. But you do need to take the best out of web three on a governance distribution and then alignment perspective. And I think we'll have safer, better AI that uplifts everyone as a result of that.
Speaker B: One thing, when you listen to Sam Altman talk about the structure of OpenAI and the board, the word governance comes up quite frequently because he's thinking very much in the future. He is thinking in a world in which this super intelligent machine does exist, and all of a sudden, questions overdose its governance become critically important? Uh, and, you know, you know, so props to Sam for having this kind of, uh, foresight. Similarly, in the crypto space, we also think about governance, uh, quite a lot like daos, that's the conversation of governance. Governance over networks, governance over apps. And so we are also experimenting in governance. And this is one of the doors, I will say, that web three has opened, but definitely not solved. And we've seen the governance failures of the OpenAI board, and you can look into crypto and also see plenty of governance failures. And so one thing we can say about crypto is like, at least we are trying, but we don't have necessarily any governance solutions here. How are you thinking that this proceeds forward when one of the biggest issues in the world of artificial intelligence is governance.
Speaker A: Well, look, we haven't figured out how to align humans. How are we going to align AI? Right?
Speaker B: Right.
Speaker A: I think that's one of the things that we always think about. I think what I've seen is that there's a lot of real thought being put towards governance, alignment and things like that. But there are lots of misnomers like big compute is a substitute for really bad data. So one of the things is data quality, data provenance, data tracking. We're seeing this wave of potential deep fake as superhuman, generative AI that requires, again, a provenance kind of solution. There's a distribution of the wealth around this. You see billion, trillion dollar companies kind of emerging from almost nothing. Who should have some of that ownership? There is the question of attribution of data going in. We opted out a billion images from our image models. We thought it was the right thing to do, didn't have to do it legally, etcetera. So nobody's got a solution, because this is a problem for humanity and it's happening at a time when entire industries are about to be completely revolutionized. I was on a panel with Nat Friedman, the former CEO of GitHub, last Monday at abundance 360 conference by Peter Diamandis. And he made this really good analogy because I said, well, I think that these like, really talented graduates that can do just about everything, and they try a bit too hard, they hallucinate. He said, yeah, and we just discovered a continent called AI Atlantis, or a Atlantis, if you want to call it that way. Where's 100 billion of them? That's economic upheaval, you know. So what I'm really looking at is, I believe that every nation should have their own AI's and datasets that they own, because no government will run on closed AI. It'll be open and transparent, because you have to know what the curriculum is, you have to know you are what you eat. And then in every sector there's a transformation that occurs from this. But we need to coordinate the response because we don't know how fast it happens. Because one of the things that's happening here is like just over a year ago, when chat GPT came, every head teacher in the world had to answer the same question. I can't set essays for homework again, or can I? And we're seeing a lot of those things happening right now. And so my basic move here is to move towards building a substrate for collective intelligence, as opposed to collected intelligence, amplified human intelligence, versus AGI distributing the benefits and getting together the smartest people, hopefully that can figure out what the practical governance of these datasets, these models and other things are, because they impact society. And that's a discussion that has to be had. It should be the smartest, most passionate people of every nation looking out for their nations. It should be the smartest, most passionate people in healthcare and education and others thinking, how can we fundamentally change this for good? Leveraging this technology that is transformative, I'm going to talk about that. And it has to be people that have a holistic view thinking about, oh my God, well, finance is about to be messed up completely. As an example, I can dig into that. What do we do about it? And actually building not only the creation bit, but the defense bits around this as well. Like our infrastructure, Esau, the XZ kind of thing, is incredibly susceptible to attacks from this. And so we have to build a new, robust infrastructure incorporating all these elements. And I think, again, the only way to do that is not a small dedicated team in Silicon Valley. It's distributed teams of people working around the world solving this problem, which is the real Manhattan project. But it's not against the Russians or anything like that. It's against our scale or infrastructure and very unpleasant race conditions. Also, I don't think that there's very few bad people in this as well. So even though, you know, I crap on OpenAI and things like that, there are a lot of passionate people trying super hard there. It's just, again, they're caught in very bad local maxima because it is so powerful. The natural thing is to control.
Speaker B: Yes. Yeah, yeah. And it's also the hardest thing to give up as well. Your quote, you're not going to be centralized AI. With more centralized AI, there's a number of different ways I could read into that. First, is that your mission? Is that a goal that you have personally is to beat centralized? Aih, yeah.
Speaker A: I mean, like I ran a China a shares fund and I was a video game investor, and then it suddenly became the China social credit score. And that's a vision of the future. Gamified life, you know, and some people are happy with that, but I see both spaces going to 1984 on steroids. If you've got a few people controlling this amazingly powerful technology, deciding when it's going to happen, you know, who gets it. Like, when does this technology, when does AGI get to Pakistan or Bangladesh? Well, never, because they can't be trusted with it. Right. But then this AGI, whatever you may define it as, could be used to educate every child or give universal healthcare. So who gets to make those decisions? So my thing was AI for the people, by the people. In 2020, I was leading one of the United nations backed AI initiatives against Covid-19. I was lead architect to organize global Covid knowledge and make it accessible through AI. And pretty much every AI company that promised to back me didn't give me the technology because it was dangerous. I was like, we're saving lives, and that's the erogenous stability and how it moved to this. But like I said, we're not quite mature enough. And this is one of the fascinating things. As you look at the l two roll ups, as you look at the data authenticity things, web three has grown up a lot. There are actually primitives now that are emerging that could be a substrate for collective, decentralized, distributed AI by the people, for the people, whereas on the centralized thing, again, it's a different paradigm, which is the all powerful AGI. So my thing is, you can't beat centralized AI with another centralized organization. I think what we should build for an AGI, this generalized intelligence, is the human collective intelligence, amplified human intelligence, something that uplifts us all and acts like a swarm. The alternative picture being presented here by DeepMind, opener and others, is machine God. And who controls machine God? I think it's impossible to control machine God, you know, because how do you control someone more capable than me? You remove its freedom. And I don't really feel very comfortable with that. Instead, I'd rather build better data sets that feed that machine God or collective intelligence. Bring this technology to everyone, so we can have robust infrastructure that's battle tested and really focus on uplifting humanity through universal healthcare, education, proper financial rails, and self sovereign AI to go with self sovereign identity.
Speaker B: Maybe this conversation isn't really about centralized AI versus decentralized AI, mainly because there are some platforms out there that are capturing a ton of attention in the crypto space that are like decentralized compute platforms or decentralized inference platforms. And they do a lot of the very similar things that centralized AI platforms do, but they have this distributed context. Instead of having and centralizing all the compute into one single data center, the margins can contribute their compute to this one coordinating platform. And we're calling this like decentralized AI. But my intuition about this is that the outcomes are not the same, whereas the products that come out of decentralized AI, or like decentralized AI aligned infrastructure are not the same, products are not offering the same services to the world as a centralized AI platform. Would like OpenAI or Microsoft. This is my intuition. Is this what you were saying? Rather than creating an alternative to AGI, we're just pushing more intelligence to the margins. What do you think about this?
Speaker A: I do have this vision of an intelligent Internet where every single person, company, country and culture has an AI working for them that represents them and flipping that intelligence thing. But yeah, I think it's not open source or closed source. I think they're complementary. They're your own graduates that work for you and the consultants that you bring in. Like, I was the original funder of mid journey. I got it off the ground with a grant to cover all the a 100s for the beta and supported by inviting people in. And when David said, do you want to open source? I said, nah, it's fine. You need to have these closed and open solutions. But there must be an open solution, it must be distributed. And we must forget the governance. Again, no regulated industry eventually is going to operate on a closed black box model. You must know what the data is. There was a paper by Anthropic recently, we all knew about it, but they actually put it on a paper called sleeper agents. So basically you put some data into a language model and you can't detect this, you can't tune it out or anything. But if you say 2025 or Dos Vedania, whatever, the model tends evil just with that little bit of poisoning. So how can you trust this for any regulated industry to run a government? Education, healthcare, etcetera. So my take is let's build open as a default substrate for this. There is a gap here where government sectors and others would welcome that. Then it means one of the defaults will be open versus everything being centralized and closed. Eventually that will be open but controlled by a few people. This is a question of control, governance, spread, acceleration, distribution. And like I said, I think if none of us get together and do this right now, the alternative will be largely the panopticon, the 1984 type thing where what happens if you get excluded? It's amazing. Like in 2023, I pointed out that OpenAI released Dali, but they banned it for all Ukrainians and all ukrainian content in the middle of the ukrainian conflict. Think about that. Censorship, right? So we brought over a bunch of ukrainian developers out of the warzone and other things and they were just aghast. Why? You can never get a straight answer. But what if they were the only image generator? The rest of the world can do it, but not Ukrainians. Why? Because of some sanction lists somewhere? That feels a bit wrong that some people have superhuman creativity powers raising the floor and other people don't. So we must create this option. And then I think you can create this default of an AI that we all own. And again, this collective intelligence as the emergent property versus this AGI, which may or may not happen, which definitely someone will try to control, someone that we don't elect, someone that we don't know and we don't have any say in, because realistically for our infrastructure of the knowledge, this upgrade of the human brain, as it were, rocket ships of the mind, we shouldn't have to rely on anyone being nice or fair or good, me or everyone else. We should have some systems in place for the governance of that. And again, they said it's hard, but let's do it transparently and let's put pressure on people to figure this out. You know, that's what crypto is good at, coordination mechanisms.
Speaker B: The idea of credible neutrality certainly comes to mind. This is something that's very, very important in the crypto industry, where the protocols, the platforms that are more credibly neutral, tend to garner more applications to build on them, because people appreciate when the foundations that they are building their structures on, be it a startup or another application, when that platform is considered fair and equitable, then more people will build there. And simply due to the fairness, and I think that's maybe what I'm hearing you aspire to in the AI space.
Speaker A: Yeah, yeah. I think it's the fairness, it's the transparency, but also it's about this accountability and other things. There again, we should have permissionless, trustless systems, right? Because this is an upgrade in the floor of humanity. You can suddenly code draw paint. Singh, better raise the floor. What if this is not evenly spread? It means that you'll have superhuman AI augmented people and everyone else, you know, and that doesn't feel like a fair future. But also we should rely on the system to make some of these decisions, rather than individuals randomly. Like, who decided the data mix at stability? Pretty much me. You know, and I could do whatever I want to with that day. I could have poisoned it. I didn't have, but, you know, I could have. Could make it say, m ad is fantastic, and then all of a sudden it gets loaded on every laptop and put in front of millions of kids. That's kind of wrong, right? So we need to have the verifiability, accountability, neutrality. And AI isn't infrastructure, but it should be. You wouldn't have private companies owning every single road, you know, deciding who can go on those roads or every single kind of traffic thing and other things like that. So there was this big shift, but unfortunately, given the pace it's going, we don't have long to make that shift right now. Now the defaults will be established because everyone's now like, what's our generous bi strategy from a country to a company to a personal level? And if the only options are the trillion dollar companies, you'll go with the trillion dollar companies. Right?
Speaker B: Right, yeah. So you're saying. You said earlier that it's not versus centralized AI versus decentralized AI, it's more of having the options to have both. But also, it does kind of feels like a race.
Speaker A: Yeah. Just to correct that it's not centralized or decentralized for the everyday stuff. But if we ever do get into an AGI type scenario, then I think it very much is an either or.
Speaker B: Right, because the AGI suppresses its alternatives.
Speaker A: Yes. And again, this gets into very, like, hand wavy territory.
Speaker B: Right, sure.
Speaker A: But is the default a collective swarm intelligence that's diverse, or is it a single million GPU AGI that then goes and takes over various institutions with its dulcet voice based on Scarlett Johansson and then decides what it wants to do? I do feel that there is a bit of that. I don't think that'll happen, but I could be wrong. So I'd rather. Let's set some good defaults.
Speaker B: Certainly. And I think it's your thought that the decentralized AI can be a check on centralized AI.
Speaker A: Yeah. I mean, everyone hates to know it all, which is AGI. Right. And right now, the AJ is trained on the whole of the Internet. And no wonder it turns out crazy. Build better datasets and that contributes to smarter, more balanced AGI on a centralized basis. But then a swarm intelligence, I think, will out compete to centralized intelligence. Why don't we have all of the knowledge of science at our fingertips and can recombine and adjust it? That's the human colossus. That is the swarm. We can split the atom, we can go to space, but our existing infrastructure is based on text and lossy information formats. It's black and white. We can upgrade that. We can upgrade all of our systems and then achieve much more. So we should do that. And then it's collective human intelligence that represents us, works for us, and is aligned with us, versus being aligned for profit maximization. So, like YouTube used to, it optimizes for engaging clips, which are more extreme. So then optimize for ISIS. That was the algorithm they didn't mean that. But we know that organizations are slow, dumb AI that optimize for certain things that are maybe not in line with our requests or our requirements. Education is about removing agency, not giving agency to every kid. Healthcare is about sick care, not healthcare. Governments are about pushing the people down rather than uplifting them. So that's why I think the defaults are good and that's positive for everyone on the way. But then again, the AGI that could come out of that, centralized or not, could be a swarm AGI, or it could be this centralized thing that's based on better datasets because they suddenly become available from every country and culture and everything like that. So its a win win either way.
Speaker B: I want to drop a metaphor your way and see how you react to it. The whole centralized AGI versus swarm intelligence feels decently parallel to central planning versus market based planning, where you have the central planning, where the central AGI, which has all the data, which has all the compute, knows it all and makes its central decisions as to where to act next, versus swarm intelligence, which is, well, every single node on the network has its own information, and it's more specialized in its particular area, and it's a better fit for its particular area. And this is like how capitalism works, right? Markets come together and they make trades, and the information is expressed in market prices. How do you like this metaphor? And can you continue it for me?
Speaker A: Yeah, I think that's a very reasonable one, because this came about due to increased information density. That happened because all the finance is about securitization leverage, telling a story about an asset, and then how will you tell it, as it were? Capitalism merged because we had more and more information about assets. And so you had this market economy occurring, and you're seeing the first elements of that in crypto XAI with bitten. So some of these other things. But you do need a bit of central coordination. And this is what's really interesting. We can have copilots and pilots because we have a lot of global solutions that lack local coordination. But when you look at generative AI, what it does, it understands context and stories. Stable diffusion, 100,000 gigs of images into a gigabyte, something like GPT four. Our stable LM language models, 4 trillion words in a gigabyte. They can act as local coordinators, and then you have globalized pilots like AI market makers, and other things that can allocate resources more intelligently. This is incredibly powerful because again, it has elements of centralization and decentralization, but it is this upgraded infrastructure, because when you are writing down notes from this podcast, you are doing an investment memo. You lose so much information that never needs to be lost again. And that is what allows a new type of intelligence swarm. A coordinated swarm with different objective functions that can out compete these slow, sclerotic organizations, which ultimately can't manage what they can't measure. So they manage all of the agency and independence out of us. This is the seeing, like, the state kind of book. The centralized planning drove through villages and removed all the characteristics so that they could have straight roads. But it's inherently dehumanizing and removing of characteristics, whereas this technology, I mean, like, when you go to Dali, you're like, make it buffer, make him buffer. Make him buffer. And it understands the nature of buffness or beauty or these other things. It's that missing piece of context, the Kahneman rest in peace type one versus type two thinking. And that's why the swarm intelligence is just so powerful and such a positive view of the future, because all that intelligence that was centralized can come to the edge, and we can build pilots to coordinate the resources that we need to solve cancer or hunger or climate or anything else like that. And I think, again, it's better to have that owned by the people, for the people, by the people, versus owned by a few companies that have unclear objective functions.
Speaker B: One thing I keep on coming back to is the timing of this whole thing, where central planning can move faster. If you have, like, a, you know, this is the reason why Daos can always seem to be moving much slower versus their more centralized counterpart, right? And that would be great if we had, you know, generations and centuries to iterate upon, but it doesn't really feel like that with AI. This AI, it feels like a big time squeeze. And one thing that we can do both well and terribly in crypto is coordinate. Like, we're good at coordination, and we're also terrible at coordination. And so I'm concerned about this market based swarm intelligence infrastructure. Takes a lot of moving pieces and a lot of coordination to really get right. Sam Altman and OpenAI are seemingly light years ahead of everyone else. This is just my fear at a high level. How would you reflect upon this in two years?
Speaker A: From the first developer, we built the state of the art model in every modality except for large language, even stable LM or edge model. Go to LM studio, download it. It runs on one and a half gigabytes on a MacBook Air faster than you can read and performs higher than Falcon 40 B. The next version performs higher than alarm is 70 B on a gigabyte. Best image model. Best. We managed to prove that you can compete, because what opening I had is they didn't have massive breakthroughs. The team is excellent. They built gigantic supercompute infrastructure, but it was like cooking a steak for longer. It makes it tender. So big. Compute is a substitute for crap data. We can get really amazing data through coordination. I think that's key unlock. But then you need to have a combination of coordinated and decentralized. My approach to this is, for every single sector, build kick ass teams that do Gen AI first. How can they education, health and other things be improved with everything that we've got? And then do that for every nation and give back ownership to the people. And then you'll get the smartest Indonesians working on Indonesia, for Indonesia, the indonesian datasets and models backed by the powers that be in Indonesia, without having to count out the government, repeat it for every single country and then repeat for every single sector. And then you get rich data sets, model bases, and you can mix and match them together to drive real. How do we educate every kid in Malawi? How do we upgrade the indonesian healthcare system? You're diagnosed with cancer, you have an AI that's GPT four level, and beats human doctors and empathy that guides you every step of the way, so you're not alone multiplied by every condition. So I think that you need the combination. I don't think a lot of these emergent AI infrastructure plays are good enough. It's like, again, they build it and they will come. I think you do need to have coordinated teams attacking this and each part of the problem. And then you support people that are building self sovereign, identity, supporting attestation rails and others, and you accelerate that with AI, and hopefully they can become part of this piece, because what you really want to build is the Humanos crypto had identity, value transfer. It lacked intelligence. Almost all the value in web two was from intelligence. Although it was this deep learning, it was this kind of classical AI. You know, futures like the past, they have a new type of intelligence that can upgrade web three and implement it. But you need to have that bridge to the real world. You need to have dedicated teams who are passionate about, focused on this. And that's why I don't think you need to bootstrap economic incentives through tokens or others. Again, there is value in that in certain areas. I can talk about some of the protocols, but the time is now, because even if we stop today, Gen Vi stops today, the world changes, but it's not going to. It's the worst that will ever be, which is crazy. I look at it like stable diffusion. Excel, when we released it last summer, was like 20 seconds for an image. Now we can have that quality at 300 images a second and it'll break 1000 with the new Nvidia chips. How insane is that? It makes no sense. Use claw three. It makes no sense. It's really nice to talk to. Better than a human.
Speaker B: In the web three space. In the decentralized AI world, we have these projects that are extremely in vogue in the present moment of time. The tokens have gone up, up like 10,000 x, which is why they're garnering attention. There is debate as to like, how real they are out there. Is this kind of just more of a narrative play when you look at the building blocks, the tools that decentralized AI, that corner of the world, our corner of the world, has to offer people trying to solve some of these problems. How would you give us a grade as to like, how good are the tools that are available? Or is there still like a lot left to be desired in the platforms and infrastructure and tools that are needed in order to build out this whole decentralized AI part of the universe?
Speaker A: I joined Render network as an advisor to help upgrade the token economics and leverage the million gpu's they have. But it's a very specific use case. The first render network propose I did was let's use tokens to build the commons of 3d assets. Because render is based on autoy which is the default for this work with Star Trek and a whole bunch of others as a common good that then people can license. You can have some local things like that that are really interesting because we built the biggest 3d dataset ever in the previous large was 100,003 D assets, 10 million objectives excel at stability. To build our cutting edge 3d models made that open, we're going to go to a billion assets. Obviously that's a good thing. Render set up aids ago and it enables that. But is it a function token economic system? No. Are any of these? No, they're still trying to find their way. Bittenster has very interesting things, but again, it's not quite there. A cache interesting things, but only minimal usage. The real innovation that's suitable for AI is basically Ethereum and the rapidly maturing stack that's built on top of that. As we see base, as we see Eigen layer and some of these other things, because you need to have the value transfer rails with low payments because AI is not going to have its own bank account. All these agents can be exchanging with themselves. You need to have attestation layers, data verification and other things. And so I think Ethereum is probably best placed for that right now. And again, it's achieving the maturity over the next year or two that will enable this decentralized AI kind of economy. Other chains are also got good stuff there. I think probably Ethereum's ahead right now just due to interest. And again, the nature of that, the AI specific plays, there's nothing really there that's figured it out because again, it's so new, right? Like this technology is only a couple of years old. You know, GPT four was released a year ago. Doesn't feel like a year, does it?
Speaker B: Right. Yeah.
Speaker A: And so it's not a surprise there. And I think the way that you should look at it is people ask me for example about singularitynet and things like that, and I'm like, there's some interesting things there, but what's the practical things, the outputs, let's see and judge by the outputs what this is, and then where it would fit into our overall kind of infrastructure picture. Now that they're doing the token merge, maybe again they can be more coordinated. But I just again find it very difficult to believe that impact will occur through emergence in the way that people are hoping. Like we did see community stuff come out. But then what I did was I took that and I put it on steroids. I put huge amounts of compute into promising things like RWKV, into things like Openfold and other things like that. And if we can systemize, then we can have emergence. But there's still a few missing pieces. I give it maybe a four out of five right now, which is crazy because you see the potential, I think a trillion dollars will go into this sector over the next few years, and let's use as much of that to not have raccoon type stuff, but real practical impact on human lives as possible.
Speaker B: What does a mature, decentralized AI tech stack look like to you? On the centralized side of things, you have a supply chain that happens. You have the data, you have the compute, you have the models, you have the inference. There's all these different components that make up centralized AI. Is it as simple as just taking the centralized AI supply chain, recreating that same level of infrastructure on the decentralized side using crypto networks and coordination? Or is it just a mirror image or is it something else?
Speaker A: I think it's driving a different type of distribution paradigm and governance. Again, it's going to be something very important. You get to the first cut of national models and sectoral models and cultural models very quickly. But realistically, as you move into massive adoption, no one wants to use the latest chinchilla, llama, Vicuna, whatever. They just want a chatbot that works and teaches their kids. They want to have AI wealth manager that manages their investments. And as soon as an opportunity comes up that matches what they want, it automatically flows contingently towards that. They want AI market makers that balance the market against narrative driven attacks and things like that. I think that the different layers are creation, control, composition, and then collaboration. Just like you've got your primitives and then you're building on top of your l one's, we'll kind of move up there. What that looks like in the web three way is again you've got your data attest station layer, you have a very robust, self serving identity, you have your value transfer rails. Some bits need to be on chain, or should be on chain, verifiably of this, other bits don't have to be. I think there's too big a push towards ZKML, particularly when you can standardize the base models, because that makes ZKML far easier if it's pre installed and everything. So I think it's still emergent. I'm not sure what exactly it looks like, but I do know again, some of these poor fundamental kind of things. I think I wrote something up after I left Zuzalu, talking about the identity value transfer coordination and other elements around here, and the repetition of the centralized chain. I don't think you need that because centralized focused on these big supercompute chips and massive usage and things like that. We proved that you can run a world class language model on your MacBook Air, then the innovation around that is far faster. Stable diffusion runs on just about anything. It runs on your smartphone. I think it will be actually commoditized hardware with swarm optimization, creating base assets that are highly predictable, that you can build stacks on predictably, because if you're swapping out the base models all the time, then it's very difficult to build something that is predictable, certainly.
Speaker B: So as you are stepping into the world of decentralized AI, concretely, what does that actually look like? Where is your attention going? What is your time going to? What are you building?
Speaker A: So I'm talking to a lot of the kind of various chains and sharing my knowledge and my view of the world, and hopefully that's beneficial. Like I said, join one of them as advisor render, because I view that as the bridge to the creative industries, which may well be decimated unless we set some good standards. That's an example. Film studios more likely to just generate entire movies. What happens to all the creatives around that? Let's implement some things around data sharing and kind of other stuff there. But I'll be probably launching a series of companies with dedicated focus teams looking at everything from how can we accelerate crypto from two and a half trillion, 10 trillion, using this tech to healthcare, education and others, plus models for every nation and getting some smart people think about how do we govern that, you know? But no more ceoing. Ceoing sucks. I'm just good at designing and architecting this stuff. Someone else can run these things, I just want to get them going and I don't want to control any of this stuff because again, I'm not elected or who in the heck am I, right?
Speaker B: So you're just working on like incubating, incubating many different startups, doing small things in many different directions, big things in many different directions.
Speaker A: Yeah, but that's pretty much it, because they've all got a common kind of thing of belief in open infrastructure is the way to kind of scale genai first for a country or a sector, and then they can be part of an ecosystem. And so you can attract really bright, smart, talented people that just want to work on the big problems. Because as you know, can web three AI everything. The core things are basically talent and then political, financial, social capital flows from that, if you can construct that in the appropriate way. And right now nobody knows what earth to invest in, but I'd love to invest in generative AI. Healthcare that builds the best radiology models are every type. We just released checks agent with Stanford and bills GPT four level models for every single major condition that is then open source so that nobody's ever alone again on their journey on Alzheimer's, multiple sclerosis, autism, cancer, etcetera. Comprehensive authority, not today. Something like that is massively investable from a human capital perspective, a physical capital perspective, and a social capitalist perspective. And then where's the web three element of that? Well, all the data should be verifiable because it will be used to treat people and guide people. We're thinking about ownership and spread and distribution. Again, there's web three element there and we're looking at the optimization equation, going into medical schools and having students improve that constantly as a data set. So my thing was verticalized, horizontal, horizontal, vertical, national, sectoral and then web three is the coordination engine for that. Ideally not having to build everything ourselves. I really don't want to build an l one. Nobody should be building that kind of stuff. Fingers crossed. Everything else upgrades, but let's help them upgrade.
Speaker B: Where is this talent coming from? If all of these new engineers, AI researchers, where is this talent being pulled from?
Speaker A: So over the two years of stability, until just before I left, we got 80 engineers and researchers, and none of them left for a big competitor, even though some of them offered ten times as much. A couple of them went to launch their own startups and things. We've got about 400,000 people in our communities, from healthcare to music to image to others on discord. And I found that that's the best place to hire from, hire from the community. Again, this is why you have to launch that shelling point of let's do something big. We have millions of kids across Africa to educate and let's support them and show real life what theirs. We can do this thing that will have this impact this year. We can take it more. If they're all part of the same ecosystem, then you can get that talent recruitment pipeline. But again, from the communities is where we find it. Within the UK, we have a new tech talent visa as well. Some of the people that contribute to our open source repos, we've got UK residency, basically, which is kind of cool. And so you can get talent from all around the world staying in place of where they are. And this is why I wanted to do the national model thing as well. If you're building the national champion for Bulgaria or Ecuador or others, the smartest people in those countries go back there, but then they become part of your talent pool that you can pull into the sectoral things. So again, strong network effects here. That's how it optimize that design.
Speaker B: As you are incubating many, many projects, it's one thing I think, to pull people from jobs into the world of AIH AI is pretty sexy, especially in Silicon Valley. Crypto doesn't necessarily have that same branding. Crypto's branded is kind of like chaotic degen, a little bit speculative. How do you see this becoming an issue? Because like I said, it's one thing being pulled into the world of AI, but Crypto AI is something completely brand new. Do you see like a branding issue with trying to pull talent in here?
Speaker A: Well, we only had two engineers, two researchers in San Francisco, and yet we pulled off state of the art models across the board. There's so much talent out there that you can pull from just like I think 74% of web three developers are outside of the US. I don't think that's an issue. I think as well, like the healthcare company, there's no web three in that it's building great models and infrastructure for healthcare that leverages web three concepts and then the web three company can figure out the protocols and governance and others. So in that way what you do is you get all the people passionate about healthcare, education and others, a level of super credibility. You co opt the existing power structures because they want this technology to upgrade and kind of you go from there because stability wasn't sexy. But we still, we had something like, something crazy. Like we had an 83% acceptance rate and like nearly 100,000 applicants last year. Yeah, thinking the talent here is insane, but you have to go specifically like how do you get the best designer? If you're building a cancer LLM that outperforms doctors and human doctors on empathy, you will find an amazing designer for the healthcare company. If you have the opportunity to educate 100 million kids across Africa, you'll find that. And again, building in the open with open source as the foundation, you will find that as well about business models and things. Accenture did 600 million in generative AI consulting last quarter. People kind of pooh poohed the palantir model, but that's good enough. Just consult implementing these open frameworks and you'll make hundreds of millions a year. Because the technology is good and impactful, we can figure out other things around token economics, et cetera. But I'm not too worried about the credibility because there's networked credibility that would occur with this kind of approach. Again, it's not perfect, but we're going to build it all together, right?
Speaker B: So right before we met at Zuzalu Emad, right before I left for Zuzalu, banklist did this interview with our good friend Liaison Yudkowski, which we titled we're all going to die. And so we have two different ways of arriving at eleazers Utkowski, and one is the centralized way and one is the decentralized way. One the centralized way is that AGI is going to kill us. And because they're super intelligent and they have all the capacity, the decentralized way is that like, well, we're going to open source all the AI models to the masses and some crazy person, some Unabomber type is going to be able to leverage this technology to stop technology from progressing forward. While I totally see the merits of pushing complexity towards the margins, opening this up to becoming a credibly neutral platform, open sourcing AI so that more people can have access to it. What would you say about the fears that giving this power to the margins also opens up margin risk?
Speaker A: It's going to happen anyway. I mean, OpenAI and X and Mistral and others will just do this. The best language models in the world, open source from the Chinese. So they're beating GPT four on a bunch of metrics already. But realistically, I think that you look at the orders of magnitude increased like $100 billion supercomputer coming on from Microsoft and open Air in a few years. The focus there is on giant, chunky AI, right? Whereas our focus has always been on AI that can run on a MacBook. And they're very different types of AI. From an emerging perspective, what would win a human sized duck, or ten duck sized humans, or 100 or whatever? This is kind of one of those questions, because how do you account for dynamic complexity of agents and millions of agents running? Is that not intelligence? I think that the best thing you can do is push for transparency on datasets and high quality data sets that are verifiable to reduce x risk, because you are what you eat, you are what you're trained on. And right now we're training on the whole of YouTube. If you're OpenAI, like that's what they used to train Sora and GPT for, no wonder it turns out crazy. And you have to tune it back to human preferences, right? If you don't want to know about nuclear weapons or bio weapons, don't teach about bioweapons or nuclear weapons. The reality is there's very few people that want to destroy the world, but open infrastructure has again and again proved to be more resilient. And again, you don't want to be training these absolutely gigantic models, because if you had GPT four or claude three level AI on your smartphone, without Internet, that satisfies us for 95% of human positive things. You don't need much better than that. Right now we're using research artifacts and using them in enterprise. Of course they're going to be a bit crazy. So I think, again, open is inevitable. The question is who builds it under what standards? The question is how does it spread versus the centralized thing? And there's no way you're going to stop the centralized folk, because if it's just a function of gigantic supercompute, that's very doable. Again, there's this bogey of the chinese AGI and other things that have been done. That means they're not going to stop, and it's happening faster than our systems can react. The hundred billion dollar supercomputer from Microsoft, I think, is due for 2027 or something like that. 2028? That's insane. Yeah. That's like a million times more powerful than the supercomputer that OpenAI used for GPT four. A million. I think Elon said that it's going up by ten times the compute every six months. Don't think we've seen something like that before. Moore's law and steroids.
Speaker B: Are you kind of saying that, though? We're kind of f'ed either way. It doesn't matter which direction we go in, we're kind of equally effed. So let's try and pull out the good from both sides on our path there.
Speaker A: I think if we build this massive swarm of AI's that help educate every kid and guide every family through this process and organize all our global knowledge, we're more likely to have positive outcomes, because all these big old AI's will train on that data. If you provide them in high enough quality data, and then that will make it more likely to be aligned. If you just have a very western centric model that's trained just on western data, I think it's very difficult to align. So I think it's positive either way. But if you get good enough, like, we can't only like, seven companies train their own stable diffusions. It's not that hard once we release the code. But why would you, if there's a stable diffusion already out there, why would you make massive capital investments in God killing AGI or God creating AGI? If you can do 95% of the jobs to be done through the stacks and the open stacks, provided it reduces that. It commoditizes the complement of a lot of these AGI players, because one of their mantras is that you must work with us, because otherwise the Chinese would get it. And there's no one else that can build this tech. We proved its stability. That's not true. We built state of the art models across every medallion. We even built a freaking brain reading model that converts mris into images after you see them. You can do that if you're intelligent and coordinated.
Speaker B: One of the things that is just another one of the intuitions of mine is that the whole world of centralized AI is going to produce very sophisticated, very low number of very sophisticated models. They're going to be these gargantuan models that are very complex, and they have a ton of research that have gone into them, and a ton of man hours, a ton of development. And then on the flip side of things, on the decentralized AI side of things, we're going to have a very large number of models that are, on aggregate, less sophisticated individually, but we have many, many, many more models. And this is perhaps somewhat conducive to human flourishing. More models for more use cases, more models to be creative with. And that on net produces very different outcomes than what we would get from investment into gargantuan models or decentralized monolithic models. This is kind of like my intuition, maybe, correct me if I'm wrong on that part, but what would humanity get if we had just a higher number of models? And is that something to aspire to at all?
Speaker A: Yeah, I mean, like, again, how many times have you seen generalist beat specialists working together? It's very rare, right? I mean, like, if you don't have all the excess bump and junk that's in a giant model, you can move far quicker and far more dynamically. If you have open models to private data sets, like again, going to where the data is, you will have better outcomes because a generalist model will not have access to that private data, because it's kept from going to that private data. So I think that open swarms outperform centralized ones, but you still will need expert centralized stuff every so often based on other people's private data that they themselves provide. Just like IP assets usage and then checking and other stuff. This is the compositionality. Like Comfy UI is a system that we built on top of stable diffusion. And every single decision you make on the image and the models you bring in and things like that is represented as node. If I send you the image or video file three D and others, it reconstructs every decision made. Going up to that obviously logical thing is then to put some of that on chain so that you can have asset attribution and things like that. That's the future here. And that can outperform a centralized thing that has to encapsulate everything. It's very difficult. The thing that we don't know is adding more scale. Does that lead to even more emergent properties? And again, this AGI Asi concept, right? That is then superhuman in capabilities. But what is superhuman in capabilities is a really good team working together. Again, that happened, we've seen it again and again. A really good team that can communicate into the tens or hundreds of thousands, which is what the AI will be able to do, obviously, will work better. I don't think you need to have all these parameters. I think it was a bit of people getting stuck and then extrapolating out. I think, again, once you get to GPT four or Claude three on a mobile and consumer laptop, that's satisficing, and then you can have hyper specialized models of every single type coordinated with a new type of architecture to do collective intelligence, uplift everyone. But who knows? It could just be, again, gigantic models that can do everything, become the key, and the people that control that. Again, that's why things like a cache and some of these other ones are quite interesting, because you will get that swarm. The other interesting thing is that we had intel chips outperforming Nvidia chips on stable diffusion three training the chips will become a commodity, and it will become easier to access in the next few years, because everyone's building towards it. And ultimately, it's just a bunch of weights, which is like an ASCII file or CSV, that you push data through, another data comes out. That's not hideously clear computing that you need for that, even with these gigantic models. By gigantic, we're just talking again, GPT four is probably only 100gb of, which is insane, like these tiny, gigantic models, considering the amount of stuff it can do.
Speaker B: Right? In terms of TAM, maybe TAM more measured in just the impact on society, the impact on humanity. How would you compare centralized AI to decentralized AI?
Speaker A: I think that there's far more private data in the world. I made a tweet. If you're clever, you can get past the firewalls. I don't mean go and steal it, I just meant you build open models that go to the data and transform it. In all these data centers and others, the tam for open is far greater than the tam for close. The TAM for non language models is far greater than the TAM for language models as well, because language models, Google and others are just going to get to zero on the pricing, and the TAM is in the trillions. The whole of education, healthcare, let's say, in 1020 years, is transformed by this. Every single person has their own doctor and their own teacher and tutorial, and it's customized exactly to their needs, with full access to all their knowledge, working for them all times. How is it not transformed? How is the movie industry not transformed when you can generate feature length movies faster than you can think? What is one area of knowledge work that's not transformed by this? And that includes the financial services industry? Complete transformation. Here again, if you have AI Atlantis and infinite graduates that can actually follow instructions. Of course it changes us all.
Speaker B: One problem that we've seen in the web three space is that daos will attempt to create products out in the open because they're a DAO, that's how it works. And they will incubate a number of different ideas and a number of different products, but then some single observer will see that thing that's been built out in the open transparently, and then they will go and raise a startup, a centralized, closed source startup based off of that idea or product or thing that that DaO incubated. And so ultimately the DAO never captured any value and some centralized startup was created that actually took this thing to market and actually succeeded in coordinating and developing a team and raising capital. And then the idea became private source, it came privatized. And so I could kind of see this model, this pattern following moving forward in the future where the open decentralized AI world side of things has some ideas, they create some patterns, they create some products, but ultimately some centralized team can take that idea, raise some money, take it to market private and be even faster than the decentralized side of things. How do you think about this?
Speaker A: Proprietary AI will always outperform open source AI because they can always take it and they said privatize it and push it forward. The question here is one of sustainability, value flows and others. Because again, if this is open infrastructure for humanity, it should be a common good, right? And this is where a lot of the work around retroactive public goods funding and other things becomes very useful from again the web three world. Who is funding this as a benefit to everyone else? Are we having dynamic licensing where you can just buy a license, have fractional elements there like we did with stability, with our membership kind of program? Who is going to be putting money into this? I mean the total amount of infrastructure spending on this will be like a trillion dollars. Its obviously as important as five G and a trillion dollars went into 5G. So that money will ground itself. I think the open innovation and these startups is a good thing, but if a DaO wants to capture that value, it should just incubate the startups. Honestly, one of the things that ive seen in web three a lot though is the curse of the VC coming in. There are good VC's but then bad VC's come in and they raise too much capital and then the velocity slows down. I mean theres something we saw at stability as well. When I moved the company to Jira like a year ago. And I hired a lot of atlassian people and big tech companies. We just stopped. We were at least the worst language model in the world. I listened to everything the investors said. I hired literally the chief of staffs of all the investors and the heads of engineering. My God, it was awful. So theres this question of dynamic velocity. How can we fund things? I funded lucid reins, for example. If you want to feel depressed as a programmer, go to GitHub, lucid reins most prolific programmer in the world. You know, I covered his sponsorship because he just wanted to build open and he wanted it covered. Like look at how bitcoin and ethereum foundation, others like how much the developers pay the core developers there. There are still things we haven't figured out here, but there's definitely ways we could figure it out better if we support great people and we coordinate them better. Again, this is a process thing, but the fact that we still use discord and slack and things like that is shameful. Just as a society, they are really bad. Again, the teams work hard, but they are bad. We should be able to build better coordination mechanisms, again with a genai first approach, better incentive mechanisms. And as you know, it's not all about money. Again, the nature of open is that people build it because it is infrastructure and it does spread faster than anything else. And again, expect people to privatize it. But let's figure out ways to incentivize them to contribute back when necessary. But a lot of those discussions come from a place of scarcity versus abundance, which again is classical VC Silicon Valley versus the rest of the world, a very classical proprietary versus web three kind of thing. This is not getting smaller. There's not going to be less money in generative AI next year than this year. It's a very unique set of circumstances. AIx crypto is not going to have less capital in a year or two. So there'll be more and more absolute garbage, and there'll be more and more really great teams.
Speaker B: One of the influences upon this race between centralized and decentralized AI is going to ultimately be government regulation. Do you think government regulation helps one side more than the other or slows down one side more than the other? Do you have any thoughts on this?
Speaker A: I think it probably slows down the proprietary ones because you're already seeing them become too powerful. I think there will be standards around open as well that insist on transparency of datasets, or at least I'll fish for that. And governments are receptive, which reduces a lot of the power of the proprietary guys that are just basically using some of these companies just use all of Hollywood downloaded in torrents and stuff like that. Like Suno is a great music model, but they just said, we just ripped off all the music of all the artists and we'll figure that out later. I mean, come on, that's just wrong, you know. So I think that it'll actually be better for open than closed, especially if we push on the political side there and we push on the standard side there, you know? And so again, there's a window where governments are open and receptive, and we have to take advantage of that. That's kind of a bit of a lobbying kind of thing. But again, how can any government be run on a proprietary closed model? They may short term and that may be a standard and lock in, but long term, I think it's a terrible idea.
Speaker B: Yeah, go into that more.
Speaker A: Why?
Speaker B: You think that all governments, all nations will have their own AI model? You've said this a number of times. They won't be happy with building on a closed source model. Just elaborate on this perspective.
Speaker A: So again, if you've got the sleeper agent thing where the model can turn its evil, you don't know what's inside that model. So that's a danger. And that will become more and more apparent. Right. Number two is that you've got your own culture, your own embeddings, your other things in there. It's like every country, again, if you take the graduate example, is happy not having its own universities and using external graduates. Not really. Every country has their own laws, their own education, their own healthcare, etcetera. It doesn't require much of a push to build that infrastructure. So I think that because this is an important upgrade of the knowledge infrastructure, every government wants it. Whether or not they get it is a question of someone going doing it, which is why I'm going doing it. My plan is to bring this to 100 nations by next year, and again return ownership of these models to the people and the data and governance to the people. I think it's the right thing to do. It makes us safer and uplifts a whole lot of people. We're not talking about the biggest models, we're talking about just small, highly capable models and datasets.
Speaker B: The AI models that are being developed in Silicon Valley are being fit, made in like in terms of fitness. They are conducive towards the United States because that's where they're being built. And you're saying other countries are just not going to be as interested in the Silicon Valley generated AI models as their own internally incubated ones, or ones more custom fit for them.
Speaker A: Well, if that's the only thing that's available, right, it's not just the United States, it's optimized for OpenAI or it's optimized for DeepMind or Google. And so again, you can put anything in there, because what's going to happen is that people like you have not your keys, not your crypto, my thing is not your models, not your mind, because we will outsource more and more of our cognitive load onto these models. If you're using GPT four and Claude, you're seeing, and they can put more and more defaults into what you are doing. So that is dangerous. Honestly. It's like using Google Maps and then going off a cliff. But given you don't know, you will reduce your sovereignty if you do this. But if there's no options, then you have to do it. Then everyone's being pressured to make decisions from a company or country level within the next year or two. Which is why there's a nice gap here, where if you present a holistic alternative, alternative, you can embed elements like self sovereignty, governance by the people, and other stuff that otherwise you couldnt. And everyone benefits from that. Even the proprietary companies benefit from that because they have richer data. That means they can then take their proprietary models and customize for the legal system of Ecuador, such as it is, based on that open dataset.
Speaker B: Taking this to its logical conclusion then I would certainly enjoy an AI model that is custom fit for me, for me personally. And so like, you know, it's really great chat, GBT is great, I use it all the time, it's very useful. But I think as these systems get more powerful, then you really are going to see the bluntness in one single model that's just trying to be like one size fits all. Is it in line with the ethos of whatever decentralized AI is, to have like more personal individualized models that are custom fit for the individual? And what does this look like and how will this come about?
Speaker A: Yeah, I mean that's my conceptualization of the intelligent Internet. Every single person, company, country and culture having their own AI's that are personalized to them and looking out for them. You've got your own PA and EA and assistant and analyst and everything like that. And the objective function of those AI's, because objective functions are super important, is you're flourishing, or that kid and Malawi's flourishing, or that cancer patient Indonesia is flourishing, bringing them the right information at the right time, like, and right now, download LM studio, run stable LM. It will run on your MacBook Air, and that's got no specialist chips, faster than you can read. That's nearly GPT, 3.5 level beats GPT-3 we'll get to GPT four level, us or someone else by next year. But if that's standardized, it can proliferate much better and people can build around it much better as a standardized primitive. Yeah, just like blockchain that was. You standardize around primitives. So I think that is the vision of the future. But it's also about, again, what's this model's objective function? Who's it working for? And as you outsource more and more of your mind to it, because again, it will have the best, most charming voice in the world, you know, and other things like that. If it's not your model, then it is literally not your mind. You will outsource more and more your capabilities. I mean, we see that again, us lucky people, you know, we've got our eas and pas and chiefs of staffs, we do outsource a lot of our cognitive load there. And if it's a model that's by someone else, like, let's face it, Google and Meta, their entire business model is advertising, which is manipulation straight out. And again, they can't help themselves. They'll become more and more manipulative with their models in order to achieve their corporate functions, which is why these models must be open infrastructure owned by everyone, for everyone, as the base default option. And then you can call on those other models for the specialist stuff, but you can be insulated by your own models. Of course, there's questions then about filter bubbles and all this stuff, but that's why standards, I think, are important around this. And again, it's not easy. I have all the answers, and that's why I want to be a CEO, figuring out all the answers. My God, it's too complicated. Let's get the smartest people in the world building on this and building out that ecosystem.
Speaker B: A world in which every individual has their own model kind of feels very similar to the world in which every single individual has their own smartphone, of which we do. And it also kind of feels like a world in which there's this hypothetical dystopian vision of the future that people frequently articulate as a meme, which is like everyone's going to eventually have a chip in their brain. And this doesn't kind of feel like too far off from that. We all have our own chips in our hands. It's called our phones. What you're saying is that you want to give everyone their own individualized AIH model. This also kind of seems to be a forcing function between like people that do have access to AI, or at least choose to leverage it versus the people that don't. Do you think, like once we figure out actually how to have individualized useful AI models that are personal to us, that it will become more or less a non negotiable to have one of these things as a member of functioning society?
Speaker A: Of course. I mean, you're far more efficient with this than without, right? You've got an entire army of people that can generate, create code, whatever. This is why again, the digital AI divide will become huge unless we proliferate this technology at the base level, unless we put tablets into all the schools in cross Africa and give every kid their own AI and have national AI's for every country. A third of the world still doesn't have a mobile smartphone. It's very easy to forget that something like Twitter has 200 million daily active users or something like that. That means there's 6.8 billion people that aren't on Twitter. There is a very western kind of viewpoint of this and it has very interesting impacts because I think the west will face a large amount of deflation from this technology. But it's places knowledge work, whereas the global south can leap forward. So that's an ROI in bringing this technology to the global south. Giravikid and Malawi AI that represents them, along with the financial system and health, they will leap forward because it'll be capital formation. Same in Nigeria, same in Sierra Leone. Just like they look forward to the mobile. As you said, its non negotiable because if Im having this discussion with all this knowledge coming into me from my AI versus you not having that, youre at a disadvantage. So there is a race condition, a competitive thing here. Its like you having Internet versus me not having Internet. Of course youll out compete me and we havent got to that stage yet. Because even though this AI has proliferated, its not reached enterprise adoption. Later this year, it reaches enterprise adoption, and youll see companies cutting staff, getting efficiency and going at it, and then everyone has to keep up, which means the amount of investment in this space will go ten times, 100 times over the next few years. In fact, the total amount of investment I added up that's gone into generative AI so far is, I think, less than the total amount that's been spent on the Los Angeles San Francisco railway to date, which hasn't even broken ground. So the numbers seem big, but realistically as infrastructure, then not big. Again, that infrastructure needs to be distributed or you'll have this massive AI dividend chips in brains. I dont know, you can ask Elon that, but definitely AI surrounding us.
Speaker B: Interesting, you said that this is going to be deflationary for the west. Elaborate on that.
Speaker A: Well, why would you need to hire a graduate again on 90% of graduates in the next few years? Just using AI graduates are kind of annoying, and almost all of us inflation is actually healthcare and education and the bureaucracy level. When you look at CPI composition, energy is a component of that as well, but you have knowledge based societies where you have infinite graduates. Supply versus demand, what do you think is going to happen? Doesnt mean the stock market will go down, youll have supernormalized profit margins because you can let go of people, but again, you dont need to hire as many people to have the same output. The question is, can you build the demand versus the supply equation? I look at that, Im like that is deflationary. Okay, I could be wrong, but certainly there was going to be social political upheaval, which is another reason why I would love to build a national champion for every nation, owned by each nation, to help them navigate through this. And again, I could be wrong, but its a reasonable take, right?
Speaker B: Yeah, because people are much more likely to hire an AI rather than hire a messy human, because humans tend to be messy. Do you think this will especially, like.
Speaker A: I said, especially at the early stage, right? And so, like, the plankton of the economy kind of disappears. Like, what do you tell a kid finishing his computer science degree? I don't know, like go into generative AI, but there aren't enough jobs yet. I don't know what the jobs of the future are, and it's happening quicker than anything we'd ever imagined. And then that three year coder can do the job of ten junior coders.
Speaker B: Well, do you think maybe optimistically, that the illumination of the bottom tiers of jobs would push people into being entrepreneurs, either by force or just by opportunity?
Speaker A: Yeah, I think that can happen, but again, can you create enough entrepreneurs to match that up? And that's happening at the same time as robotics and self driving cars and other things. Like you're reducing aggregate demand in the economy, and that's really unfortunate. And it happens synchronized across industries at the same time. And so again, this is a danger here so there's a near term danger, a far term danger. There's near term opportunity and far term opportunity. We can build a better society off the back of this technology with the appropriate coordination. And this is the final chance I believe we have over the next few years to make sure it has positive defaults versus negative defaults. And the crazy thing, as you said, it's not a versus in some ways, because I don't think people are trying to have bad outcomes. I think is a complementary thing, which is pretty unique. Lets build these organizations, these societies, these infrastructures, these protocols that the benefits are distributed, and we can lift up the world. Because if youve got a big lift in the global south, leapfrogging to intelligence augmentation and becoming more efficient, being more entrepreneurial, they can drive forward the global economy and then get capital allocations from the west. And then everyone wins from an ROI perspective, right. Finance will become more seamless, capital velocity will go up, you will have AI market makers, you will have contingent financing and all sorts of agent based work that really upgrade the flow of capital. And so I think, but you got to have people thinking about this properly. I mean, who the earth is thinking about that? I tried to find who was thinking about that across the AI space. I couldn't. So I figured we've got to build teams to think about that and groups to think about that, and standards around that.
Speaker B: Summarizing parts of the components that you said, would you agree that this is generally destabilizing for the mature economies like the west, but a boon to the developing countries who are able to develop and innovate faster? Is this a great equalizer between these two halves of the world?
Speaker A: I think so. But the second part is also because, as I mentioned earlier, all of finance is securitization leverage, telling a story about an asset and how well you tell it much. The global south is invisible, whereas this technology is very rich with context. So you can form capital, I think, far quicker than youve ever done before. If you deploy this as scales, infrastructure, and then you can collateralize it, you can bundle it and have capital flows from the west occurring at even greater paces. Even as you struggle in various industries, especially knowledge based industries within the west, you wouldnt want to invest in them anymore. Tyler Perry sees Sora and he just calls a halt on his $800 million studio development. Hes like, I dont know whats going on. Are you going to make capital investments when you dont know whats happening with knowledge infrastructure? Whereas in the global south, the ROI is big because youre coming from zero a lot of places or very low to knowledge based economy. Every kid having their own education, every healthcare having their own thing. Again, its not about innovation, necessarily. Its that visibility, that legibility, and the financialization that occurs around that because theyre suddenly investable.
Speaker B: William so going on ever since there was the Sam Altman debate or debacle about the whole Sam Altman being fired in the board and all that kind of stuff, um, I mean, this conversation was even earlier than this, but it really took on a new character at post that event, which is like this acceleration versus deceleration debate, um, which is now starting to, I think, define like, kind of larger and larger swaths of society. And right at the very beginning of this, uh, podcast, you talked about how AI time is even faster than crypto time, and crypto time is really, really fast, especially in bull markets. Uh, and so now we have, like, these two leading technologies really pushing the frontier of innovation forward, like web three and AI. And they are both characterized by being extremely fast paced. And so we have this accelerating technology, which is seemingly accelerating time, which threatens to leave behind people who can't keep up. And I think this is causing concerns in broader society where they see, like the Elizabeth Warren types of the world, sees these two perceived to be reckless industries really hitting the gas on both of their respective innovation frontiers, and that draws concern out of people. How would you say that this is going to define society, or society will react to these two very accelerating technologies?
Speaker A: I mean, look, I was at the AI safety summit. God, I don't know when that was, like ten AI years ago in September or October or something like that. King of England pops on the screen and says, this is the biggest thing since fire. You're like, my God, is the king of England saying that? Right. Every smart person in the world knows this is the biggest thing, and every smart person knows that the regulation won't be able to keep up with this. And it has a real human impact. Again, I didn't believe in all the stuff with the FLi letter that I signed with Elon and others, kind of that six month pause. But I did think we need to have discussion around this because it's impossible to encapsulate in your brain. What doesn't this impact? Right? And again, the fact that you have a model that can proliferate 300 million downloads of our models, that's insane, right? The fact that you have the whole of a GPT threader level AI on a gigabyte, and that will be a GPT, four level AI, I'm sure next year. That doesn't make sense. Like where the heck does it fit? It's like homeopathic AI. I don't know where this stuff fits because the whole Wikipedia compressed is like 26GB, right? So I think that it's very difficult to keep on top of. We need to have better institutions that can help guide with good objective functions what is the right way to tackle this for education, healthcare, finance, Germany, Vietnam, Thailand and others? That's what I really want to do because I don't know what the answers are. All I know is that people need help and there's a huge amount of capital that you can make from that. But it's not even about that. It's just we want to do our best to try and figure this out and bring together right minded people. Because again, within crypto you've got your real builders that build and why are they doing it? They're doing it because they believe in the future that is self sovereign. Right? Part of that has to be self sovereign AI, self sovereign identities, self sovereign capital, self sovereign AI. And I think that if we manage that, then the world will be better and we can solve some of those key concerns. But we got to be as inclusive as possible in this discussion because you said people that can't keep a track of it, they're going to be left behind and they'll have no voice. And that sucks because it can't just be, again, from a few people in Silicon Valley making these decisions that impact all of humanity.
Speaker B: William, as we bring this conversation to a close, if there are any entrepreneurs out there or engineers out there who are interested in building in this sector, what are the low hanging fruit that you would really like people to go after? First, what advice do you have for the email?
Speaker A: Email? Please rid the scourge of email. You have all the technology and tools. Make it so never have to look at email again.
Speaker B: Wait, so you were saying we can use AI to just eliminate the entire institution of email?
Speaker A: Yeah, it will just expand and compress the email and then write a beautiful prose to you and then that prose goes to you and then your AI will compress it down and then we'll just get little bits at each side that actually make a difference and it'll be wonderful.
Speaker B: As a guy who does not check my email because I don't care to spend that much time, I would love that tool.
Speaker A: There we go. Right? No, look, it's basically, again, the mental model here is infinite graduates and then the coordination of infinite graduates. What real world problems can you solve? So, obviously, if you had infinite graduates on your email, they would save so many hours. Right. And I've got them on my side as well. But think about that mental model and kind of work through this, because you don't need to be an AI expert to do it because the models are actually quite easy to use, relatively speaking, which is insane. And also, make sure you use AI for your development and your coding, because you'll be far more impactful.
Speaker B: Infinite graduates, is that the world that we're going into? A world with infinite commoditized graduates?
Speaker A: Yeah. Like I said, a Atlantis. Yeah.
Speaker B: Iman, this has been a fascinating conversation. Thank you so much for spending time with me today.
Speaker A: It's a pleasure. I'm glad we got to do it fine. I think this is, like the fifth try or something.
Speaker B: Yeah, yeah. This is for the bankless listeners who want the lore behind the episode. Imad and us rescheduled this episode, I think, like, five or six times, but it's finally happened. Imad, thank you so much. Cheers.
