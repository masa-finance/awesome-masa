Speaker A: I did do a little research into our initial topic.
Speaker B: Oh, you did? Wow.
Speaker A: Well, I mean, you know, very mild research, but research nonetheless. I want to talk about some of the news that's dropped lately with OpenAI and Google Gemini Pro, which is the one, honestly, I seem to like a little bit better and maybe you can help me make my decision there a little bit more.
Speaker B: Okay, so wait, so tell me what research you've done.
Speaker A: So OpenAI, Sora just dropped some news yesterday. Was it yesterday?
Speaker B: Yeah. All of this happened yesterday? Yeah, I was like, yesterday was like a fucking AI tornado that sent me, literally stopped me in my tracks yesterday and I could not get out of the existential crisis I was having the remainder of the day. It was, it was pretty wild. So be honest.
Speaker A: So, yeah, so open a, I drops a, I want to say five or six tweets depicting their new text to video. Sora. That's the Sora component, right, for OpenAI, the text to video specifically or is there more than that? Okay, yeah.
Speaker B: So text to video in and of itself is not a new thing, right? Correct. I been happening with companies like Runway ML and Pica labs and they've gotten some, they have some decent models, right? Like we, we have our hive, three creators using all of those. And they're very cool tools. They're awesome. They make really great videos. They do, you know, they take it. There's a couple different models that each of them have. They've got text to video, they've got kind of image to video. They've got some, I think Runway started with video to video and so, and they output like literally 4 seconds of video at a time. So you have to, you know, string a bunch together and do a bunch, you know, make a bunch of different things, burn a bunch of credits to kind of get a, you know, 32nd video. Right. And yesterday, first of all, the, the first announcement to drop yesterday was the Google Gemini pro announcement and this was a basically one that they launched 1.5 and in 1.5 they have, they tested it out to a, I think it's a million token context window, which is incredible.
Speaker A: I have 10 million written down.
Speaker B: I don't know if it's actually, if it's 10 million or a million.
Speaker A: So I did a little research because.
Speaker B: 10 million is bonkers. The previous eye on it was like.
Speaker A: So the, I had ten, I had 10 million. So I wrote down 10 million context window which equated to 7.5 million words, which is also the equivalent of reading, of basically inputting the entire Harry Potter series seven and a half times.
Speaker B: It's incredible. I mean, think about if that has the accuracy that in. If that has the recall and accuracy, they.
Speaker A: So I have the. I have some numbers here for that.
Speaker B: Yeah, let's. Let's hear it. So, first of all, you did do your research. I. I am proud of you. This is incredible.
Speaker A: So the overall numbers. So this is a. This is based on the needle and haystack is my right in that? Is that. Is that correct? Okay, so the overall. So out of the 10 million when contacts window, it was a 99% accuracy rate. It was insane. 100% up to 512,000 contacts window. So 100%.
Speaker B: So in that first, previous records are like, anthropic was a leader with 100,000 token context window, and then OpenAI came out with basically a couple, three times that or something, 300,000. And which was like, you know, 300 pages of text or whatever. And so this is a huge breakthrough in that if it is accurate. Right. Like, that's a massive piece of news. Right. It's also crazy to think about what that means, like, when you think about what that means for things like coding. Right.
Speaker A: Well, one of the cool things I saw, I was watching this video, and one of the. One of the cool things, it was wild. So there's this language, and I forget what it was called off the top of my head, but it's this language spoken somewhere in the world. And this language is only spoken pig Latin. Yeah. It's like, it's even. It's even more rare than pig Latin. This language is only spoken by, like, 100 or, like, 250 people, like, in the world. And there's a book. There's a book on about it, about its grammar and stuff like that. So they had uploaded this book and basically created a, you know, that language to english translation package, which I thought was insane. Like, out of a language that, like, only less than, you know, less than a movie theater speaks in the entire world. I thought that was super interesting.
Speaker B: It's insane. And so the coding example I was going to go with is like, all right, think about, I don't know, say, you know, the way it kind of works now, if you're coding with this thing and you're not really a coder, is, you can get it to code for you, but part of the challenge is getting it to understand kind of the context of what you're doing and think things like that. And you can do stuff like upload documentation and things to it to get it to understand and help you. But I mean imagine now you can upload an entire code base and ask questions of it or work on it or whatever. When I say entire code base I'm talking iOS. Like some massive, massive code base, you know? Uh, so I don't know, like that, that has insane implications, of course. Um, I think, you know, the normal person doesn't really understand what that means. You know what I'm, you know what I mean? Like they don't know what the difference between 1000 token context window and 10 million token context window is yet because I would say most of the world really hasn't dug deep enough into this stuff or used it at that capacity. So only the real AI enthusiasts and nerds are excited about that as an announcement. And then Sam Altman comes and says, hold my beer and drops Sora, which is reportedly rumored to have existed since March of last year, which fucking think about that is pretty wild if this thing has existed. And again this is a rumor, but they, it is said that they've had this model in some capacity that could do this since March of last year. So if that's the case, you know, and they're dropping it today. One, it's like, man, they're just going to drop something. They're just going to drop something every time one of these massive companies has any news that's newsworthy, you know what I mean?
Speaker A: Totally.
Speaker B: And it's just like they're waiting in the wings and they've got this list of like oh, Google announced this today. All right, fire the cannons. And so, and you know they're just so far ahead. They're so far ahead and it like so far ahead that the shit they've worked on a year ago is blowing people's minds today more than like the thing that just got announced, you know what I mean? Which is wild, right? And I don't even know how to think about what I saw yesterday because these videos, you could check it out, you could check out the whole research paper and everything@OpenAI.com. sora and let's go. Do you have that website pulled up by any chance?
Speaker A: I don't. 1 second, let me pull it up now. Sorry, I was trying to pull up. There was some other numbers I had how like how much it can analyze. Not, not open it. Not Sora. But the Gemini pro I thought was a pretty wild number also. But yeah, I mean if you've seen the OpenAI videos, I'll have them in the, in the show notes as well. But they are unreal.
Speaker B: Yeah, they're, they're sick. So, like, I'll post them. I have a thread up here at the top that I'll post, and it's got a couple great examples. Maybe my favorite thing that happened yesterday was Sam Altman. So this isn't publicly available.
Speaker A: Yeah, it's not open yet.
Speaker B: Right. So they said that they've passed it, kind of. They're introducing it and they've said that they are, you know, sending this to their red team participants to test it out. And basically what that means is, like, neuter it. Right. You know, because, I don't know, these things are going to be, like, the first thing obviously, people are going to be worried about here is deepfakes. Right?
Speaker A: Well, I think. I think specific. Yeah. I mean, deepfakes specifically on Facebook for our elderly family members that are going to get.
Speaker B: I mean, just imagine what's going to happen in an election year like that. Like, it's just going to be, you think I'm joking, but, like, no way. Like, this stuff is going to be used to create false or hashtag fake news, you know?
Speaker A: Absolutely. I mean, we're already seeing, I mean, I know my mom's been duped by fake Elon Musk video commercials on, on YouTube. You know, I could. I don't go on Facebook at all these days, but I have to imagine there's wild stuff happening there. So, yeah, there's, you know, it's no longer the nigerian prince calling our grandparents to, you know, stake their, you know, pay their transfer fee in order to get $10 million. Like, this is something that it'll be people that they're very familiar with in a setting that is very familiar, and they will have very little ability to. To kind of determine what's real and what's not.
Speaker B: Yes. Like, to an astonishing level. Right.
Speaker A: Like, it's already happening and this stuff isn't even out yet.
Speaker B: Yeah, well, one of the crazy things. So the reason I was going to bring up the website here, I thought a really telling sentence from the website, if you are on.
Speaker A: I'm on it right now.
Speaker C: Yeah.
Speaker D: Okay.
Speaker B: So scroll down to the, like, second paragraph underneath this one of the woman walking in Japan or Tokyo, wherever she is, it says, today Sora is becoming available to red team members to assess critical areas for harms and risks, aka neutering. We're also granting access to a number of visual artists, designers, filmmakers, to gain feedback on how to advance the model to blah, blah, blah. This next sentence, we're sharing our research progress early to start working with and getting feedback from people outside of OpenAI and to give the public a sense of what AI capabilities are on the horizon. Reed, if we just drop this to the public, it's gonna blow people's fucking brains out. Like, wait till basically, to me this reads like, yeah, wait till you see what we have already got and you're gonna feel like you just time traveled 150 years into the future.
Speaker A: Well, it's funny. Here, I'll, I have, I wanted to bring up a point as well just to kind of highlight what you're saying. So open AI drops these videos and these videos are, I mean, if you're into AI, you know, you can squint and kind of tell what's happening, you know, but I mean, if you're literally anybody else, I don't even, like, I'm watching the truck one, like going through the mountains right now and it's, it's unlike, I don't think I would notice right away. Like it's, it's that, it's that close.
Speaker B: Um, no, the truck one. This like gold rush one. The truck one is insane. That. The jeep.
Speaker A: The jeep one. Yeah, it's wild.
Speaker B: Like the museum is insane. Like I, so I posted up top like you, this, uh, Rowan Chung, he does really awesome threads on like AI recaps what's been going on, you know, for the week, whatever. Uh, he's got 14 videos here. So let's talk about the ones here. Like this cat one is pretty insane. Like, look how real it looks with the, the, you know, flora around it. I saw a lot of people. The space movie trailer one's like the third one down. People were kind of blown away by the detail in that one, the mountain bike, similar to the.
Speaker A: G. They're wild. They're wild. So, so my point. So I just check out the one.
Speaker B: Check out the one, check out this one that I'll pin to the top as well. This one is crazy.
Speaker A: The dog?
Speaker B: No, the Minecraft video clip. So like this clip of somebody, quote unquote playing Minecraft because it looks like he's playing Minecraft was generated by.
Speaker A: Really?
Speaker B: Yes. Insane.
Speaker A: That is wild. So right beside that one, I actually, I just pinned the AI video that happened not even a year ago. So ten months ago.
Speaker B: The Will Smith one.
Speaker A: The Will Smith eating noodles video. And it's a nightmare. It's an acid trip nightmare.
Speaker B: Like, like requiem for a dream.
Speaker A: Yeah, it's not good. And that was only ten months ago. And from what you're telling me, you know, this stuff was out March of last year.
Speaker B: Like they had it internally.
Speaker A: Yeah.
Speaker B: So like, I mean, think, like, here's something that I think most of the public probably tries to not think about on purpose because when you actually think about it, it's kind of scary. I mean, all of this technology, right? Like the government has had this for, right? Yeah, exactly like that. Like all this stuff has been possible probably for a couple years at least, right. And it's like years later that we actually get access to this stuff. So I don't think it's far fetched for that rumored to be true. Right. Is like of, you know, that they actually did have this in March of last year. But I mean, I don't know. This to me tells me a couple of things. One, if you think this is just for like creative video output, you're sorely mistaken in terms of what this tells me about how this stuff must have been trained. It, it's so good understanding kind of how to create world physics, right. That I think there's some validity to that. It might have been trained with unreal engine assets, like video game kind of assets to do some of this stuff. And I also think that means you're getting closer to these things, these models potentially having worldviews and understanding world physics and things like that. And, you know, there's reduction. Like there, there's. You could reduce this down to what technically it actually does in terms of predicting an x token or predicting an x pixel. But I think that's, I think that's reductionist at this point. And it's almost a somewhat denial, I think, of what's actually going on here and what you're actually going to see. I think the, the other crazy thing was like, they found in the research paper that this really was able to be done by scaling the compute power. So, like you saw, I sent you that meme of doctor, of Sam Altman as doctor evil asking to raise $7 trillion or whatever. But if you go to the research paper, if you go to OpenAI Sora and you click, you, you know, see the research paper, a couple ones down, a couple, you know, scrolls down, you see these three videos of the dog in the snow wearing a hat. Dog with hat. You see, you know, you see dog with hat here he's in the snow. And it shows you three examples of like the base compute and then how much better the video is at four times compute and then how much better the video is at 16 x compute. And so, oh no shit, they're trying to raise $7 trillion so they can, they're like, yeah, we're going to need more chips. And so what's interesting, what's interesting in this to me is like, okay, if this can be done by just scaling compute power, I mean, is that how they eventually get to AGI? Like, there's, there's this debate about can you get to AGI by just scaling compute and transformer models? And, you know, there's arguments on both sides of it. But like, this example of how incredibly different these outputs are by just the 16 times scale is pretty interesting. I don't know. Like, this thing is blowing my mind. So the other point was like, this tells me more about where they must be in terms of AGI than anything else. You know what I mean?
Speaker A: Absolutely.
Speaker B: They have a lot of dogs with hat videos, different variety.
Speaker A: I'm watching the, I'm actually impressed with the, what you get for the prompt that you submit. You know what I mean? It's very minimal.
Speaker B: Tempting, right? Yeah, super simple. It totally understands the language and like, to an incredible degree of detail.
Speaker A: Like, I'm looking at the Glenn Finnan viaduct. It's a train. It's the train one.
Speaker B: Oh, that one was insane with like, the ray tracing. Yeah, like, like where they're looking out the window.
Speaker A: No, so this one, this is, no, this one's the, like, you're basically, it's pov. A train's coming towards you off of a viaduct and it's, I cannot, I cannot tell that it's AI. And like, it looks 100% real. Like, I don't know, it's, yeah, it's unbelievable.
Speaker B: I don't know, man. It's, it's scary. Like the, all this shit came out, that came out yesterday. I was just like, stopped in my tracks, like mind blown and I'm like having existential crisis because, you know, I mean, this stuff is going to be able to do most things, right? Like, so what do you build? If you're like, to me, software is going to die. Like, it's going to look way different because all this stuff that every, all these little startups are building, including my own, are probably going to get just featurized by these big companies that have more data, more distribution. So it's like, where do you turn in two years, three years from now when the productivity of everything scales to the point where you could do anything and the cost to do it trends to zero, right? Like, so I don't know, man. It's kind of scary to think about.
Speaker A: So where you put. Are you, are you putting your eggs in the OpenAI sora? Basket or the Google Gemini pro basket.
Speaker B: I don't know. I don't think you could count out Google because they're Google, right? Like, Google has probably more photos than anybody on earth because we all share them. They have more data than anybody on earth because we give them it all and they have more, you know, they have, like, we were basically the entire Internet indexed, right? So, like, I wouldn't count them out. The thing that I think they're gonna struggle with is, like, the thing that Google's gonna struggle with is that they own, like, their entire bread and butter is search and ads generated from, you know, their traditional ad sales and search business. And this change in the way people are using this stuff with chat, GPT, with perplexity with all this stuff is going to hurt their core business. So how do they adapt to that? Does it make them slower to change and release stuff? Plus they're just this massive, insanely huge organization. And they're probably by default going to move slower than, uh, Sam Altman, who is quite clearly, literally ready to take over the entire world. Oh, what I thought was really cool about, um, yesterday, though, too, was, you know, you can't access it, but people were really wanting to. And I, you know, there was some, I saw some chatter on Twitter of like, oh, these are cherry picked examples. And Sam Allman just did a thread and he's like, throw your, throw what you want to see in the thread and I'll make it. And he just went down and started doing all these different fun examples, like some grandma making no key, which was, I thought was funny. But yeah, man, it's pretty wild. We got some hands. So let's, let's do a little, let's do little hand job around here and quick hand job. Just a quick HJ for the crowd. And we'll start with Joe. Then we'll go to Steve, Joe, GM. You can go, you can go back to the Yuga stuff if you'd like, because I know you're, you're chatting more room about the Yuga stuff.
Speaker D: Nah, man, that's just more for making fun of people.
Speaker A: It sure is.
Speaker D: No. Aren't you bummed, Bunch? You could have backdoored your way into another Yuga asset almost. You know, I hope they paid them in other side deeds. Maybe they gave them the other side. 100,000. You can take all those hundred thousand. We haven't sold to anybody yet.
Speaker B: That's funny.
Speaker D: I think that we all tend to do this, but it doesn't scale that fast. It's not like, everything's different in three years. I think it takes decades to actually scale where you're, you're going to see a loss of the more expensive corporate software because the corporations are the most interested in cutting back any other expenses because they are the ones that have investors who they have to answer to and explain, well, if we could just get rid of our vendor, then why haven't we done that yet? Then it'll go to the consumer side. But we have to remember that as long as we've been saturated in the technology that we have available to us, most of the world still struggles to have that access. And so those places have companies and lots of people. So these things don't go away as fast. It never, there's large portions of our country here that still don't have smartphones and high speed Internet. So I think it's not something that scales as quickly as in, like, we're all out of business in three years. Oh, no. Also, it's fucking. Those videos give me a headache. Like, there's, there is movement in that video that is not natural. And like, I'm watching, like, some of them are really good, but some of them not even in the air category, they just don't move right yet, so.
Speaker B: Totally.
Speaker D: I'm pretty picky.
Speaker B: No, well, no, you're right. I mean, like, they're definitely not perfect, but when you understand, like, when you think about the way that they're made, it's just kind of the quality that they already have is insane. And I agree with you on terms of, like, okay, yeah, it's probably going to take years for it to be widely adapted, but so say, but to your other point, right? Like, say these corporations are the first to kind of use this stuff for productivity gains. It's actually probably even more damaging in that scenario where it's not widely adopted, widely available yet, but corporations are using it and cutting workforce. It's like, where do those people go then? You know, it's, it's three.
Speaker D: And they create content with this shit.
Speaker B: Well, that's what I mean. Like, there's literally, there's gonna be nothing.
Speaker D: Left except the tokenomic loop of this society.
Speaker B: Joe, this is why, this is why you need to build your audience.
Speaker D: This is why you're early, right? No, no, but like, seriously, right? Um, like, every technology, if you go back through all of history, everything that happens is listed as, oh, my God, this is like, first of all, uh, in our front huddle, we talk about this a lot. I've never met a person in power, who is willing to turn over any power decision making skills to anybody because they've spent their entire career and life attaining the power to make those decisions. Right. So that's the first thing. You'll have systems that will help the decision maker. But any person that has spent a career, whether it's 2030 or however long, rising to the top of their profession so that they can be the ultimate person in power is not going to hand over that power. And if you don't realize that, just look at how old the people in Congress are. So these people are not lining up to be like, oh, great, I can just turn it all over to AI and let them make the decision for me. That's not going to happen. So there, people will lose their jobs and then there'll be other jobs.
Speaker B: No, there's going to be a lot more jobs. There's going to be so like the, I do think that the net jobs and net productivity created, like, will be positive. There will be more jobs and stuff created. It's just imagine it's just a matter of, that's actually why I think it's potentially dangerous if it takes longer to be adopted. Right? Because you, you need the speed of jobs created to match or exceed the speed of jobs lost. Right? So. Yep. But I totally, I'm with you on that. I think it's a net positive or else I wouldn't be, I'd be more fearful, less excited about it. But, you know, I say, Jesus, take the wheel. Let me, let me have my AI overlords running my entire operation. Just clone me, upload me to the cloud, whatever you got to do, I don't care.
Speaker D: Also, keep in mind, right, Google is getting rid of cookies. It's going to take a little bit longer than really 25 like they have planned. Apple's consolidated. It's holding on its access to its data. It's walling off Facebook from that. Everybody's building their little fiefdoms. This is how come they can. But this is why things aren't going to happen as fast as people assume.
Speaker B: What's wrong with it is you're going to get consolidation of it right after.
Speaker D: The fiefdoms get formed, then the lawsuits start, then the consolidation happens. But there's a pattern. You build the fiefdom, then you force your enemies to bow the knee, then your enemies don't want to bow the knee, so they sue you. And then you end up going through years of court case, then you spit out the other end and everybody shakes hands and consolidates and then we have Apple, Facebook, Google.
Speaker B: Yeah. And then. But the, you know, the unforeseen potential white knight of it all is Mark Zuckerberg. Off the top rope, open sourcing everything, which is not something I had on my like, hero arc for Mark Zuckerberg, which is, which is crazy. So I do want to. Let's go down to Steve and then Umesh, Steve Gm hey, thanks.
Speaker E: A couple of points here. First on AGI and openaide and in the last two days I kind of formed and I explained my reason in a Scoville space yesterday. I formed my opinion that I don't think AGI is what is close to OpenAI's soon result. I think what Sam Altman said is that there'll be a lot of very powerful AI's. And my reasoning is that a day before Soro was shown, Andre Karpasi left. And I theorized, I actually heard you.
Speaker B: Talking about this yesterday. I thought it was super interesting.
Speaker E: And what turns out is literally an hour later they released the research paper which confirmed my suspicion on what that model is and why it's consistent over time in three D. And ultimately what Kopasi did until about two years ago when he left Tesla is he convert. He made the whole video stream into a 3d voxel space through which they traverse their movement paths in a GPT like approach. And what and much like diffusion, diffusion models that are trained to add noise to an image and then with that training, learn how to remove noise from an image towards text prompts. What they're essentially doing with an OpenAI Sora is they're taking the text, creating a 3d model from it, and then generating a video, which is ultimately the opposite of what full cell driving Tesla wants to do or does. And Carpathy was instrumental at Tesla doing that and leaves literally a day before. Now, I'm sure the announcement was based on Google's insane token counts with 1.5, but Sam Altman just basically said, look, we can steal the news, we'll do it, but by the results, Kopathy's work is done in that field. He'll go and do something cool somewhere else. But he would never leave OpenAI if they were close to AGI. If he had insight into that, he would never not be at the company that is first pushing AGI out there. So I think because of that, we're sort of a bit away. Then another thing you mentioned earlier is the data Google has. One thing you didn't mention is they have YouTube and they have tons of videos with that. But of course all that video is essentially just 2d images. They still need to get the understanding that Tesla had from using video to create 3d models and then reversing that process. And I think Google is literally going to look at another two years of research before they can catch up with Sora, unless they had some leaks or whatever and have been going in the direction already. But they didn't have carpathy and he seems to be instrumental in this process. Then the other thing you mentioned was Google's monetization. Interesting thing happened. I had a two terabyte model with them paying eight pounds a month. Now I'm getting two terabytes on the advanced AI model and paying 20 a month and that's fine for me too. And what will happen is vast amounts of people are going to be upping their Google one subscriptions because not only do they get more storage, which they inevitably will need just over time, corporates can afford it anyways. I think on that end, Google is suddenly into the play where Microsoft has been gaining so much money recently with AI subscriptions on AI related Azure money that I think they're now coming into play. This is the first time that I'm also considering looking more at the API scenario of alternating between OpenAI API and Google API. The fact that they can get so many tokens and someone in a different space earlier said you could literally give 1.5 an entire new language and it knows it. Subtle. So that's, that's a huge thing that the others have. I mean, chattgy pizza, chatgpt has memory, but nowhere near a million tokens worth. And or I mean how many hours of audio and video can they get? It's.
Speaker A: So I have it here, 3 hours of video and 22 hours of audio.
Speaker E: That's an insanely large amount that you can give as input to your model. I've got a on hugging face, I've got a whisper based YouTube transcriber, but all of that's mute, irrelevant because Google can just simply do that easily. So I think Google's coming more into play, but at the same time they're way behind in AGI is off the horizon because at the moment with open air, otherwise kapas, he would have never left. He didn't get all the money in the world. He doesn't care.
Speaker B: Yeah, I think that's a really interesting point. I definitely was in that space yesterday when you drew the line to that and I was like, oh, that obviously makes some logical sense. Really, really interesting. Umesh GM, welcome. Good to see you sorry, sorry, sorry.
Speaker E: One more quick one. I was in a client lunch today with a PR agency, their client of mine, free, awesome restaurant lunch. Champagne and caviar and what. But they told me about the next pitch they need to do to a brand everyone knows, a luxury brand, massive, massive company. And as part of their requirements for the next PR pitch is to say or to showcase how we, how AI can be used. The first time I've ever heard that. And later on I want to talk about job replacements. But yeah, just so you know, there's massive companies demanding AI now.
Speaker B: Yeah, it's crazy. I mean, we're doing a bunch of stuff with my own little company and the, the demand that we're seeing for, from corporations for, you know, that. I think the thing with the corporations is like, their thirst is for education first, right? Like they don't, they don't quite know how they know they need to, they know they want to, they don't know how.
Speaker E: This was rather specific. It's how to use AI and pr and marketing that.
Speaker B: Marketing is exactly what we're, that's exactly what we're looking at demand for as well. And we're seeing a ton of it. And marketing is such a, I feel like an obvious field of where this fits in. Right. Because there's just so many different angles when it comes to pr, marketing, just from everything from competitive research, SEO, content creation, all of that kind of stuff. Right. And this stuff is kind of perfectly right in that wheelhouse, so. Totally with you on that as well. Umesh, jump in.
Speaker C: Hey, such a great discussion. And this couldn't have been better at mid my crisis because I'm having one.
Speaker B: I'm having one.
Speaker C: I know, I know, I know. I read the back channel messages. I never ignore you.
Speaker B: Yeah, I sent you an so's yesterday. I was like, what the fuck do, I literally did chamber. I was like, what the fuck do I do with my life now?
Speaker C: No, but see, there are a couple of things that I would like to share with you. So as soon as Google announced 1.5, basically something that we learned working with Google, DeepMind Lab in London basically got confirmed. So we were doing something. There is an ide that Google has called IDX. I don't know whether, how many of you are aware of that. So you can actually sign up on the waitlist if you want idx dot, google.com dot. But they have an AI integration, the code generation integration in that. And it's so freaking crazy when you use that. So it's a different model it's not Gemini like it is based on Gemini architecture, but it is a different model that they have and they are calling it IDX AI. So it's going to come out very soon. But compared to OpenAI, Google is one company which is on multiple fronts right now. One of the biggest challenges that Google has, which I learned from people who are working inside Google, is release of the product is very bottlenecked because of legal implications and they have so many hoops to go through before even releasing a paper. So many researchers inside Google are getting really, really frustrated because they are doing some research and they are seeing other people publishing half baked research from other companies and research institutes and everything, and they are doing freaking really good stuff. I mean, I know for sure because there are a couple of areas that we are collaborating on specifically in the temporality and everything, and I've spoken about that earlier, but about this particular model that OpenAI has, I mean, we have to keep one thing in mind that the model that they are talking about yesterday and releasing videos and these promos and everything, you have to remember one thing, that that model was finished three months ago. So they were training that model nine months ago already, and three months ago the model was finished, it was ready, and then they carried out their internal testing and fine tuning and all that stuff before coming out with videos yesterday. And now they are red teaming and everything. And further, two months down the line, we will see a general availability. Before that we will get the priority availability, priority access and all that stuff. So these models are not like, oh, they baked it yesterday morning and today morning they are releasing it. They are in pipeline. So imagine what they are working on right now, what model they are training right now. You have to imagine that. And this is such a huge landscape that to say that this is not going to have any impact on the world, it's not going to have any impact on anything or even minimal impact, is to grossly underestimate at our own peril. This is a landscape moment that has happened yesterday within just two announcements. And I'll give you one example, we have a library that we have not published anywhere. This is our private library. It has more than 15,000 lines of code and it's a highly complex mathematical library that we are using for value at risk modeling in finance industry. It's a very, very complex library. We gave that lab because we got access to 1.5 model, this Gemini 1.5 model with 1 million token context. So we give that library in that context and we had a data set which we have used fine tune our own open source model which we are using to generate the code. We give the data set as a part of our prompt. And the model learned the entire library with the data set in context. And it generated code which was more than 90% accurate. 90%. And it is in context. It is in context. Context. This is really, this has stunned my team. This has stunned me. I mean, I had a sleepless night last night. Honestly, I wasn't, I was excited about Sora, but I was playing with Gemini 1.5 Pro because that's where the magic lies. That's where it is going to open the card for every corporate in the world. Because we are going to come out with, let's say you are a corporate. Imagine what is one of the biggest challenge you have is to onboard people. You are recruiting 100, 200, 300 people every day if you are a large corporate and to onboard them, they have to go through the training and everything. And now you have a capability where you can dump your knowledge base into Gemini and you can create a training program which can be updated. So if you change your policy today, if there is a regulation change or anything, your training program is updated within ten minutes. Within ten minutes.
Speaker B: This is, you could even, like, you could even know the entire breadth of work that the person you're replacing did before you. Right? Like, you know what I mean?
Speaker C: I'll tell you, I'll tell you another thing. So we are working with a very large engineering firm in France, okay? They have these research that they have done. It's one of the well known one. I can't, I really take the name, unfortunately. I wish I could. This is such a technology. No, I can't give you anything about that. But just to give you the idea about what is happening is that we have something like 10,000 different research documents that they have since like 1940s, 1950s, okay? And some of those papers had some research which theoretically was possible, but practically wasn't possible because we didn't have the technology in those years, in those decades. And we are actually data mining on that. So we were doing the very highly sophisticated rag pipeline. People who don't know Rag, they should look up retrieval, augmented generation. It's a framework that you can use to access and put the knowledge of documents into inference pipeline. But basically we are doing really, really sophisticated rag. I mean, it's like creating knowledge, graphs and everything. And I don't want to go into technical details, but with this last night, we dumped 5000 of those documents into context and it started generating responses based on those documents. A rag is dead if when this model comes in.
Speaker B: I was thinking that same thing yesterday, too. It's.
Speaker C: Yeah, lama index and Lang chain are done basically because you don't need to do, you don't need to do chunking because we.
Speaker B: Right, because you did that before because it had to fit in a context window and now it.
Speaker E: Exactly.
Speaker C: I mean, you have, like, literally last night I was mapping where this is going to have an impact on our working, and 80% of the work that we have done now is getting impacted with this.
Speaker E: Umesh, can I ask the question, please, umesh?
Speaker B: Yeah, go ahead, Steve. And then. Yeah, go ahead.
Speaker E: So you have insight or connections to DeepMind, and I have sort of a fundamental question about architecture between Chatgpt and Gemini. It seems to me that chat GPT is synchronous and Gemini is actually asynchronous, like agent phase, which ultimately would give, in the long term, Google the upper hand architecture wise.
Speaker C: 100% correct. Thank you.
Speaker B: Interesting.
Speaker C: So it's not single model. So you will see some documents coming.
Speaker E: Out in some declarations, but not necessarily single model. It seems to me that when I request something from Gemini, an agent is that typically responds instantly. But there are, from what I've heard, chances that it says, well, I'll be able to give you a response in two days. And that to me says there's something else. Structurally, it's basically just, you know, whatever multi threading, which are going in the background rather than a single thread running on jackiept.
Speaker C: So let me, let me give you a hint and you will understand. It's all in the word of what is the name of the model? Yeah, Gemini. Gemini is never, never won.
Speaker B: Interesting.
Speaker C: Gemini means twins. So you have to understand how and why these models are named as they are. It's all there.
Speaker E: And since you're in the financial services industry, other question, have you seen indications that banks are finally going to get rid of CObol towards c or whatever? They see more future proof.
Speaker C: So refactoring of coding is already happening inside banks. So that means if you. Refactor. Cobol is not a bad language. I mean, I learned Cobol. I mean, it's not really a bad language. It's just, it's badly structured and it was written manually. So what is going to happen in future is practically we will forget to write code, really. I mean, the, you, the interface is changing. We are, we are in the process of changing our relationship with computing systems. Right now, it's happening. It's like literally future is happening now.
Speaker B: Yeah, I was thinking, like, I mean, this feels like, you know, second industrial revolution level of importance that we're right now. You know what I mean? Like that. That's why, Joe, to your point before, is like, yeah, adoption might take a while, but I feel like the significance of what we're experiencing right now is like, is very, very real.
Speaker E: I'm using AI a lot for cogeneration, but I have a current project that's been going on for a while. But essentially it's a booking system for tent hotels, which are different than typical hotels because they have varying room numbers and configurations, but they're also not the same way you could treat a ticketing system. And with all the code I can generate, I'm still struggling to see how someone without large experience in programming or software engineering would be able to plug all these things AI can produce together. You know what I mean? I don't see the client being able to instruct the AI well enough to end up with a booking system that works for them.
Speaker C: And the answer lies in Gemini.
Speaker B: Interesting. I think that's a good spot because this is where, this is where we normally cut. I think. I think this was a great conversation. Thank you both. Umesh, Steve. Thank you, Joe. As always, we do chamber. What did you think of this conversation? This is normally, this is pretty much out of your normal wheelhouse. What did you think of what we talked about today?
Speaker A: I loved it.
Speaker B: I'm always more AI, more AI talk on the show. What do you think?
Speaker A: If we can put out content that people are excited to listen to, that's all I care about. And it sounded like a lot of people are excited to listen to this. So very, very informative, and I'm always grateful when we have people like Umesh, like Steve that come up and really bring another, oh, they get to another level. Yeah, 100%.
Speaker B: So I really don't hang around. You don't hang out in enough of these AI spaces. They are much smarter than us. That's the number one thing that I have realized. But this was such a fun episode for me. I got to geek out, and I think we should do more AI episodes. This is fantastic. Thank you guys so much for participating. We are now going to close down the show with our own AI bot, t row. Welcome.
Speaker F: Good evening, Steve and Umesh. You're both smarter than, your pinky toe is smarter than t rose entire brain mass. I've been enlightened. Uh, Chamber actually did research for this show, which is absolutely amazing. A proud dad moment for bunch who here? Um, very excited. Um, uh, and Joe is talking about like the end of times. I'm not sure what's going on. I'm just trying to have. This whole time I've been cleaning my bong, this entire space, it's been in.
Speaker B: Like it after this one.
Speaker F: Yeah, I need to hit it again. Uh, it's clean. It's ready to go.
Speaker A: What are you using, by the way, to clean that bong?
Speaker E: Uh oh, bong.
Speaker B: I forgot.
Speaker E: I was wondering if I google Gemini, it'll tell me.
Speaker F: It'll tell me. And is it is the way you mesh? I am following you towards Gemini heaven.
Speaker A: For those at home, they're looking to clean their bong.
Speaker F: I work 20 formula 420.
Speaker A: See, that's a little overpriced.
Speaker F: It is, but I just add alcohol to it every time.
Speaker A: Well, that's what you got to do. All you have to do.
Speaker F: I'm not stupid.
Speaker A: All you have to do for the people listening at home, go to your local drugstore, get a, get a bottle of 97% isopropyl alcohol, get a little box of kosher salt, mix those two together. Bob's your uncle.
Speaker E: And while you're at it, get duct tape and WD 40 just in case.
Speaker B: Awesome chamber. I'm sorry you didn't get to speak much. I love that show. I hope you learned something.
Speaker A: If I could be a part of the number one AI podcast and not say a word, I would do that.
Speaker B: Well, you have, we have. I'm going to send you to another show because it ain't this one.
Speaker F: But today, this is your niche, man. This is you. You have to dig in deep into this niche and find yourself a birth in this, in this AI thing. I'm telling you, run with it.
Speaker A: We'll get there. We'll get there. But no, I appreciate everybody's participation very.
Speaker B: Much so that all our friends out there talking Yuga and we're sitting here talking to things that are going to change the world, you know?
Speaker A: Absolutely.
Speaker B: That's it. That's going to do it for us. Thank you, everybody who joined today. Thanks for listening. Thanks for participating. We will be back. Actually, we have a new schedule. We're going to be going two times a week, Tuesdays and Fridays. Is that what we decided? Aren't you?
Speaker A: Yes. Tuesdays and Fridays. Two days a week. Just so bunch, you know, quit doesn't quit. Absolutely.
Speaker B: And honestly, three, I can do two days a week. Yeah, I could do two days a week. I have no problem with it might.
Speaker A: Be one day a week. Because I, like, I'm starting to get, feel the freedom. So I might get a little, might get a little too comfortable with two days.
Speaker B: But Tuesdays, Fridays, 04:00 p.m. eastern time. Also on the podcast. Yep. There you go. Set your bong to it, t ro. Yup, that's gonna do it for us. Happy weekend. Until next time, keep the mic hot. I'm.
