Speaker A: Are you blind today, or did you make it? Did you stare directly at the sun? Were you in the path of totality?
Speaker B: I. Yeah, I was. I thought I had messed up. Like, there's, I don't know if anybody else felt this. That was close to the, the eclipse yesterday. But I'm like, I looked at it, like, not looked at it. You know, you kind of, like, like a quick, you know, quick move, you know what I'm saying? I also had, like, the glasses. Like, I had the, the eclipse glasses. But as we were coming closer to the time, like, you know, you just kind of give a quick look, and I'm like, maybe I did it too many times because after the eclipse, you know, maybe like an hour or 2 hours after, and I'm like, I'm like, my eyes kind of felt funny, but I'm like, maybe it's just psychosomatic, you know what I mean? Like, maybe I'm just in my own head. Like, maybe I, like, did I fuck up my eyes? But I woke up this morning feeling pretty fine, so I think it was just in my head.
Speaker A: I'm totally blind.
Speaker B: Did you look directly at it?
Speaker A: No. My neighbors, actually, who I don't really interact with a ton, but they were out in the back. Everybody was out in the backyard yesterday, and they had set up a couple really high tech telescopes, so we got to see a very cool version of it. And, you know, we were also doing the eclipse glasses, etcetera. I did also have that similar experience where afterwards for a little while, I was like, oh, no, I really screwed it up, you know?
Speaker B: And did you even really look at the sun that much?
Speaker A: Not without the glasses on, no.
Speaker B: Yeah. Like, I. I was worried also that, like, I had the shit glasses that.
Speaker A: They were just gonna burn through your.
Speaker B: Yeah, like, I was looking through, like, when I had the glasses on, I was really. And, and I'm like, maybe I look too much like, you know, but everything seems to be okay today.
Speaker A: Yeah. Well, there you go. Did you, like, did you get the totality of it?
Speaker B: Yeah, we got full darkness here for three minutes or so.
Speaker A: Wow.
Speaker B: Yeah, I mean, the streetlights came on. The birds, like, you know, started doing the nighttime chirping, and it was, it was great. It got cold, too. I got. I was surprised with how cold it got because it was such a nice day yesterday as it was happening at, like, you know, 330 yesterday. Whatever it was, it got surprisingly cold for, like, five minutes.
Speaker A: Fascinating. Now, I mean, I get why the, you know, past humans thought this was such a well, I was.
Speaker B: It's funny, I was looking up, like, the time, like, times that full eclipses kind of made it into the record, like the human records. And there's this ancient cave painting where you see the moon kind of coming over the sun. But there's this one battle that was happening for six years back in, I think it was the, there was this battle ongoing and the two sides were fighting for, I think it was five or six years, and this total eclipse happened and they were just like, well, I guess we're done. And then just literally packed it up and never fought again.
Speaker A: Wow, interesting.
Speaker B: I'm like, that was pretty, that seems pretty wild. Yeah. So, like a six year war just ended because the eclipse happened.
Speaker A: Very interesting. Yeah, well, I mean, I enjoyed it. I actually didn't plan to, like, full on experience it. I was kind of like, this is whatever it is what it is. And then I was like, oh, it's not coming again till 2044. I should probably go. Go and do it. And so I brought the kids outside, taught them how to look directly into the sun. It was a real good bonding moment for us. And, you know, that was fun.
Speaker B: That's great.
Speaker A: Yeah.
Speaker B: Yeah, it is fun.
Speaker A: You, you know, we're living up to our podcast category today on the topic that you have approached me to discuss. And I, very serendipitously, I had a total unrelated interaction to this today, which was, I assume you'll be. This is actually going to get you very excited. It supports your theory. And so you wanted to talk about something called the dead Internet theory today.
Speaker B: Yes, I did.
Speaker A: And the other day, you texted me and you said, have you heard of this? And I said, no. And you sent me, you sent me three TikToks to go look at as research, one of which looks like it was videoed by a guy who's actually never been outside, or the albino guy. Yeah, that guy. Never been outside. Solar eclipse or not, he is not going outside. The second two videos you showed me, I'm not really quite sure that they support or can be used as evidence. So let's talk about what it is that the dead Internet theory is. And I'm going to, here's how we're going to run this. You're going to tell us about it and what your thoughts are on it, and I'm going to try to either devil's advocate or agree or add some sort of insight. So this is the conspiracy theory quota for the week for us.
Speaker B: So this one actually fits in great because it has to do with social media has to do with, obviously, you know, web. It kind of has to do with web three stuff as well. Like AI.
Speaker A: Totally.
Speaker B: I would argue also cryptocurrency, which we'll get to as well. But I'll start off by reading the. The description for the dead Internet theory on Wikipedia. So the dead Internet theory is an online conspiracy theory that asserts that the Internet now consists of mainly. That consists mainly of bot activity and automatically generated content manipulated by algorithmic curation, marginalizing organic human activity to manipulate the population. So basically, long story short, the Internet is now mainly consisting of bots that basically make up the vast majority of all traffic on the Internet.
Speaker A: Okay, now let's pause here, because that statement, in and of itself, I don't think, is necessarily untrue.
Speaker B: I agree.
Speaker A: Where I get lost in this theory, having done the required ten minutes of research that you sent me, is in the albino video. He states that the Internet has actually died and been replaced by said bots, and that it is. And he goes one or two levels deeper on the conspiracy, that it is all coordinated. And so I think there's a big difference between the statement that the Internet is mostly bots and auto generated content, which I think is potentially true, and the fact that it's all this coordinated, orchestrated thing. So, like, where do you land on that?
Speaker B: So a conspiracy theory can have many different levels. Right? So this one I don't really think is that much of a conspiracy just to kind of give you some history on, you know, on where the term comes from. This online personality named Illuminati pirate back in 2021.
Speaker A: AP.
Speaker B: Yeah, yeah. Coined the term, you know, coined the term dead Internet theory. And basically what he said was in between 2016, 2017, that the Internet hit a tipping point, essentially called the inversion, where there was essentially more bots than user.
Speaker A: Than human users, specifically citing 2013 with YouTube.
Speaker B: Correct. YouTube being kind of the first one where the algorithm was based on comments. And when the majority of comments are coming from bots, the algorithm then gets confused on how to tailor, you know, how to tailor itself to humans, because they're now thinking that bots are the humans and humans are the bots. And that being kind of that tipping point, that inversion point, you know, some. Some other, like, obviously, you know, you mentioned YouTube. Facebook back in 2019 had deleted. Had deleted 5.4 billion fake accounts off of.
Speaker A: See, like, all of that stuff, I believe is true.
Speaker B: So.
Speaker A: And it's only going to get worse.
Speaker B: In some of the other videos I sent you, it was really this self generating AI content. So I believe it was Instagram. Like, it was a TikTok, but I think they were showing Instagram. It was Facebook, or it was a Facebook. Okay.
Speaker A: Yeah.
Speaker B: And they had these images that would. I think this one account started off by generating images that people would interact with so they could get followers. And what was happening, it was your typical America, Jesus kind of stuff that Facebook users love. And what was happening was every time it would post, a certain amount of bots would respond, and it would kind of tweak the algorithm for what to create based on the responses they were getting from the bots. More and more bots would then come in on the next one, and then it's getting to a point where the content created is so far from anything anyone would actually interact with, that it's kind of, you know, it's creating this self perpetuating acidity trip of content. Hey, everybody. Just want to take a quick minute to thank you for listening to this show. If you're interested in joining the conversation, you can follow us on Twitter Ed Mike Crisis. We do a live show every Tuesday and Friday at 04:00 p.m. eastern. Please subscribe to the show on Apple, podcast, Spotify, or wherever. You're listening to this right now. Let's get back to the show.
Speaker A: Right? And so this specific example you're talking about in the video is talking about the specific phenomenon of, like, Jesus content and how, like, a picture or an AI generated picture of Jesus being made in the sand on a beach gets a bunch of likes. The algorithm then says, I should create Jesus content. All the comments that our bots say, amen. Next thing you know, you've got this new Jesus picture, which is Jesus with a half shark head on an airplane because it's mashed all of the comments and original content together as, like, feedback, right? So it's. The idea is, okay, it's taking the comments as, you know, human reinforcement learning in AI, right? Like, because it assumes the bot. The bot comments are true and correct. They are people. So it's saying, oh, people like this. Let me make more of it. And the distortion just starts to exponentially multiply, right? Where it's then now you're getting millions of comments and likes on something that isn't even a cohesive image.
Speaker B: Right, right, exactly.
Speaker A: And that just compounds and you get a whole Internet full of trash.
Speaker B: Yeah. I mean, just to add to the Facebook stuff, too, there was actually a class action lawsuit back in 2018 because of all of these bots. Obviously, ad revenue or ads on Facebook is a. Is a. Is a vehicle that a ton of companies spend billions and billions of dollars on. Ad revenue in 2018 for Facebook was about $84 billion. And there was a class action lawsuit from these advertisers saying, like, hey, you're telling us, like, these are your numbers, but, like, we're actually paying. Like, the numbers you're giving us are 150% to 900% over exaggerated. Like, it's. It. We're not getting the value for the dollar that you're telling us.
Speaker A: Well, this was. This was also what Elon was trying to do when he was buying Twitter, right? Was he was saying, oh, the valuation is too high because all of your population is bots. And then there was the whole thing that he couldn't get the right or the real number of what was bots and what wasn't, etc, etc. Do you remember all that?
Speaker B: Oh, yeah. Yeah. I mean, I would argue there's probably more bots since Elon's taken over, but I might be wrong.
Speaker A: Yeah. So our wonderful producer, Payne, who is just phenome, sent us a Reddit link, which is the eli five. What is the dead Internet theory? He says, this thread is hilarious. Didn't get any good information, only laughs. But. So the original post here is, what is that Internet theory? It's a term I've heard come up a lot in recent times, but I can't find any simplified explanation of what it is. The first comment is, the idea is the entire Internet is all bots talking to each other. There are no people on the Internet. You're here all alone, being besieged by bots while thinking that you're surrounded by people. The next comment says, sounds like something a bot would say. That person replies, no, I love breathing this air and inserting food into my primary orifice. It is yummy. And I enjoy eating of substances, even if they have no nutritional value. And then the next one says, excuse me, while I lubricate my organs. Fellow bots drinks water, and it keeps going on and on and on like that. And it's pretty funny. Primary. I love all of my orifices equally.
Speaker B: Yeah.
Speaker A: Yeah. Very good, very good. Thanks. Pain, it's. So, how do you explain us talking to each other right now?
Speaker B: I mean, we've never met each other.
Speaker A: That's very true. Shit. Shit.
Speaker B: We've never met each other, all right?
Speaker A: But I've met Steve, I've met Cass.
Speaker B: I mean, in this situation, I would be the Aihdeende or the. You know what I mean?
Speaker A: Yeah, you're the dead Internet yeah, I mean, I. I.
Speaker B: Maybe. I don't know for sure that I'm.
Speaker A: Not, but I've met many people that are here, though.
Speaker B: Yeah. They could be, you know, CIA operatives.
Speaker A: Well, you know, we're all very small. The. The people here in this room are very small representation of, you know, the overall Internet. There's.
Speaker B: That is true.
Speaker A: There's clearly some real people out there.
Speaker B: Correct. There are some real people here. It's just that the overwhelming majority. Some people saying up to two thirds of the majority of the Internet is just bots, which, you know, that explains that.
Speaker A: The similar divorce rate. You actually married a bot, and then by the time you figure it out, you have to get divorced. So.
Speaker B: That's a good point.
Speaker A: There you go.
Speaker B: Good point. We have circles up here, supposedly. Supposedly, yes. It's funny, actually, some of the. Well, before you speak circles, some of the videos I was watching, the bots would take form in single word names, so single word usernames with lights with pink or purple backgrounds.
Speaker A: So all the doodles are fake. No wonder there's no utility for their holders.
Speaker B: That makes a lot more sense. A circle is definitely your profile. Mirrors what bots normally do.
Speaker C: You may speak. If the sai emoji were a thing, then I would be using it quite frequently. I came up to say that I have always been a strong proponent that chamber is an aih. Give you a look at.
Speaker A: That is true. That's very true.
Speaker C: Like, nobody has ever met chamber. I've always claimed that he has to be AI. Some have met me.
Speaker B: Has anybody met pain?
Speaker A: Yeah. You've met pain.
Speaker B: I know I have met pain, but somebody.
Speaker A: Cap and Steve have met pain at Vikon.
Speaker C: What you're telling me.
Speaker B: Interesting.
Speaker A: Payne was at VCoN.
Speaker B: I believe pain is Elon Musk, maybe.
Speaker A: Is that true? Pain? You've methadone people on this stage, correct? Outside of chamber? On the stage? No. Oh, sorry. In the audience. So you've met cap, Steve. Those. Those folks? Correct.
Speaker C: I've actually met Charlie down there as well.
Speaker A: Charlie. Well, there you go. So, Charlie confirmed, not AI, you have met chamber, but there is also something called the dead cracker barrel theory, in which all cracker barrels do not exist and is only inhabited by AI's. And actually, I thought that was waffle house. The core loop is really just finding yourself stuck in the gift shop over and over and over again. That's how. That's how they actually found this. It glitched, and somebody just could never leave the gift shop. That's.
Speaker B: It makes a lot of sense when you say it out loud.
Speaker A: Yeah. So, like. So do you want to hear the crazy thing that supports.
Speaker B: Yeah, absolutely. Yes, I do.
Speaker A: Wrecked, son. Sorry. Noob didn't silence my phone did. So you want to hear the thing that I came across today in natural conversation that supports your theory?
Speaker B: Absolutely.
Speaker A: Okay. So I'm actually. You don't even know about this. So it's going to be totally. It's going to confirm everything you think. I. So I'm currently down a rabbit hole trying to create a spec for a project, a specific AI project that is the creation and operation of an AI influencer.
Speaker B: Okay. All right. I have some notes on this.
Speaker A: Okay, so, AI influencer, right? So the concept is simple. It is a. A generated person, right, that you can create from a model or a image or whatever. And the AI tools are so good now that you can actually give them a personality. You can have them talk, and it looks real and all this stuff. So you can create a fake person, essentially, and you can actually even automate the content they put out by using these agents or bots. Right. You can have a series of agents that are connected to this AI personality model that you create, and it could go and be an influencer in a specific niche. Let's say I wanted to be an AI influencer on the topic of AI. I create this model, and then I can create agents that go out and scour the web for the hottest AI topics, that passes it to another AI bot that will write me a script, I for a video, that passes it back to my influencer to create the video. And then you can go post it on the Internet, and it's all, quote unquote fake. Right? So I was having a call with a friend today who's very well versed in, like, how to actually put stuff like this together. And by the way, you probably all did. You probably also did not know this either. Hive three is currently running a challenge for the community to begin the process of helping us create an AI spokesperson for Hive three. So unbelievable. What about the timing, huh?
Speaker B: Unreal.
Speaker A: Yeah. Literally. The live challenge that went live yesterday that you did not know about is called the Hive three's next AI influencer, and it is to design a virtual AI influencer in the test.
Speaker B: This is exactly what the AI algorithm would create. As soon as I discover this, this.
Speaker A: Conspiracy theory, I'm going to drop a link in the bot.
Speaker B: Of course you are in the bot. Yeah. See how you said bot, guys?
Speaker A: Well, I was going to say, bottom. Payne, grab that link that I just put in our chat and throw it in the bottom of the.
Speaker B: Freaking out right now, guys.
Speaker A: Freaking out. But so, like, this is a thing that we are doing with Hive three that you did not know about. Anyway, so I'm on this call with a buddy of mine who's very well versed in Hive three and or, sorry, in AI, and he's helping me kind of walk through the workflow, et cetera, et cetera. And he's showing me, like, some of these simulations that he has built. And there was this, I don't know if you remember, but back, I don't know. It's got to be six months ago now. Stanford University posted that research paper followed by actually open sourcing the code for it, but it was called AI town, and the AI town project was basically a simulation of these agents, and you gave them all personalities and goals and all this stuff, and you could actually watch them interact with each other. And the results were pretty crazy. Like, they got together, started working together as a community and planning parties and all this stuff, and two of the agents fell in love and tried to get married, et cetera, et cetera, all of this stuff. And it's really fascinating. So he's showing me this. He kind of recreated it, but he was talking to me about how he created one of these avatars and then put the avatar into this model that could create content. And the literal thing he said to me was, well, he goes, Twitter UI is open source. You can go and find the code for that and recreate it. I was like, I didn't know that. He goes, yeah. So I went and open source, or use the open source Twitter UI and put all these bots into a Twitter interface, and all they do is interact with each other. And this is literally today, about 3 hours ago, I'm on the call with them, and he says this, as I know we are about to talk to about this. And I was like, oh, that's wild. So what are your thoughts hearing all of this?
Speaker B: I'm gonna be honest with you. Since you dropped the 51 year old Rebecca with the heavy naturals, I have been having trouble paying attention to. That's AI sugar mama right there. Sure is. Yeah, that's. That's all right. No, I think as we peel back this stinky on you. Wait.
Speaker A: This tweet says, I met some guy last night in Miami who admitted to me that he spends 10,000 a month on AI girlfriends.
Speaker B: It was me.
Speaker A: That's funny.
Speaker B: But yeah, no, this the coincidence on top of all of this, is definitely. Yeah, the algorithm digests. It's difficult to digest. I don't even know it's real anymore. Ever since, honestly, my mind started breaking apartheid during the, you know, the Sinbad genie movie stuff it's slowly devolving into madness. And so this AI, this dead Internet theory is just kind of another level. On top of that, I also heard, by the way, the theory. So, like, obviously the matrix is used a lot in a lot of these analogies. And I was watching something that was basically making the case, like, you know, how, like, back in the day you would see, like, oh, well, the bad guy in karate kid is Ralph Macchio. Not like the. You know, not the who they make you think the bad guy is. He's actually the good guy. And the same thing just happened with the Matrix. They're like, well, Morpheus is the bad guy. And, you know, the agents are the good guys. Like, they're like, well, you know, humans obviously got to a point where they wanted to use the Matrix to give themselves some semblance of normalcy. And because of the world that, you know, if, for those of you familiar with the Matrix the world isn't great in real times in, you know, in the movie. So they've. They've incorporated this. This matrix, this AI, whatever you want to call it to give them some semblance of normalcy. And the machines kind of keep everything in check, keep everything rolling so all the humans can appreciate and interact within the matrix. And it's a good thing. But Neo and Morpheus get out and are trying to dismantle and they're actually the bad guys. I don't know if you're Morpheus in this scenario bunch.
Speaker A: I'm the bad guy because I'm creating these? Is that.
Speaker B: I don't know. Maybe you're the hot chick that seduces me. I'm not sure. Somebody.
Speaker A: Well, listen, pain needs proof that I'm not some big, natural AI. So he told me that I had to say the safe word, which is. Now, that's what our safe word is.
Speaker B: Big naturals.
Speaker A: Yeah.
Speaker B: So, you know, for the record, I said heavy natural.
Speaker A: Oh, sorry. Okay. That's.
Speaker B: Which I think is funnier.
Speaker C: It is.
Speaker A: It's way funnier. No, that is. That's way funnier. It's. By the way, this tweet, it literally is. It's all AI girlfriends that, you know, qualify. So.
Speaker B: Speaking of AI girlfriends. So there's other. I tried to write down as much as I could to kind of show where the Internet could be. And I think like, one of the videos I was watching, they were basically saying, like, the dead Internet theory is it can essentially only be three things. It's either just absurd and stupid, it's either true, or it's a foreshadow of what's to come of the Internet down the road. And I think that's really where I land on it, is like, oh, like this is as the algorithm, as AI gets implemented and it gets smarter and algorithms get better and more precise, we could find ourselves in a absolutely zero human interaction Internet. Now we'll be able to use AI, what do you call them, your AI scripts, to interact with the Internet, but it will be the AI interacting with the Internet and spitting something back out to you.
Speaker A: Yeah, probably.
Speaker B: Which I think is interesting. I don't know if that's 1015, 2030 years down the road, but there could be a point in time where literally.
Speaker A: Nobody'S way sooner than that.
Speaker B: Yeah, I mean, hey, I'm here for it, dude.
Speaker A: But yes. Like, so the only part of this I don't. So let's put it this way. There are real people, right? And there are real people on the Internet. Like that is, that is a fact. You would. I am real and you are on the Internet, right? Yeah, right. Same. I am real. At least I believe to be real. I am on the Internet to a fault. Right. I am mad online, as the youths.
Speaker B: Would say, giving social media guy.
Speaker A: Yeah, right. Exactly. Now the question is like, what's the ratio? Right, right. Is it ten to one? Is it 100 to one? Is it a thousand to one? And I think, like, that is the part that is just going to be exponentially bigger and bigger and bigger. Let's put it this way. We for forum three have the honor of writing a book with Harvard Business Review that my co founders, Adam and Andy are writing on kind of how AI is going to change brand marketing. And in this book, we get to speak to a lot of the, you know, world leaders and thought leaders in AI. You know, we've talked to Sam Altman, we've talked to Bill Gates, we've talked to Mustafa Salomon, etcetera. And the, the one thing that one of the people said, and it's literally all they wanted to talk about in the interview, was AI influencers and how prolific it is about to be to the point where like, there's 50 million people in the world apparently, that classify themselves as an influencer, which you are. One of the, the number of AI, quote unquote, influencers is going to be exponentially larger than that based on this conversation that we had.
Speaker B: So is there value in creating an AI influencer?
Speaker A: It's funny that we're talking about this because I've actually spent too much time recently, and you didn't even know this. I'm actually doing all this research in the background right now for this type of project. I think there is a massive. I think there's a massive market for it, because you think about, like, what are the problems of a normal influencer model, right? And there's a couple of things. It's one, it's a total hamster wheel of content. If you are an influencer, it's impossible to get off the hamster wheel, and it only works for you until the day you decide you're tired of making content. Well, in the new world, all of that can and will be automated. Right. And, okay, so what does that mean? Well, that means it's easier to make content and it's faster to make content. So then it becomes, okay, well, who's making it? Well, I don't need to be in front of the camera all the time. I can create the gorillas of influencers, and I could have an avatar be doing it with a real personality.
Speaker B: Or we talked about. You talking about gorillas. The band.
Speaker A: Yeah. They don't exist.
Speaker B: I think that's a great analogy. I never.
Speaker A: It is. I mean, you're gonna have all of that stuff, and the difference will be, does it have enough of a personality? Is it entertaining enough? Does it cover specific information that you're looking for? And can you kind of. And can you verify, like, is it real or not? Right? Like, I think there's gonna be a massive market for this. Um, you've already kind of seen it with, like, virtual influencers that are not necessarily AI, but they're, like, rigged avatars or things like that. They have, like.
Speaker B: Right.
Speaker A: There's some that have millions of followers. Now, the problem with that is there's massive overhead to create those, right? You're hiring an actor to wear a suit, to be rigged up every single time you're making that content. So what if that overhead was gone? Which it is, right? Like, what if all of that part is gone?
Speaker B: And have we, like, have we crossed? Like, you would know this better than me, but with AI, specifically with, when they create human imagery, have we crossed over the uncanny valley? Like, are we past it now?
Speaker A: I think somewhat, yes. So I think that's the thing, right? Is, like, whomever can create the ones that look most realistic win.
Speaker B: Because Rebecca first looks very real to me.
Speaker A: She does. I mean.
Speaker B: Yeah, no, she. I'm looking.
Speaker A: Yeah, she looks pretty real.
Speaker B: She looks pretty real. Yeah. And I was.
Speaker A: She's certainly exaggerated in some areas.
Speaker B: Yeah.
Speaker A: Yes. She's, she's very hyper realistic, human looking.
Speaker B: Yes. Like, if you were just.
Speaker A: The answer is yes. You're not going to be able to. There's. Yes. And this is the worst it's ever going to be is my point. Right. So. Well, right, so, okay, but you may like Rebecca. You may like what she has to say. She may be.
Speaker B: I probably won't like what she has to say.
Speaker A: Well, you may not, but others might. And, but you might like, you know, some AI basketball influencer that does content on the Lakers that you don't even have to know it's a fake person at some point, right. You just enjoy the content and you're there for it. Right. So, like, there's just going to be so, so much of that and the difference, like, I've got this crazy idea that. So how do you, so what's the difference then? And who wins and how in a world where anybody can create an influencer, anybody can automate content, etc. Etc. It's like, all right, well, then he who has the biggest real organic audience wins the day. So, you know, tying this back to web three and all this stuff, it's like, okay, well, how do you incentivize growth? Like, my thought is, well, what if you build a token economy around this, right? And it's like, okay, you're farming tokens for likes, follows, retweets, shares, all that stuff. And now you've grown this fake thing to millions of followers that are real. That are real followers.
Speaker B: Right.
Speaker A: I, because of the shared incentive. And then from there, you run a normal influencer playbook and without any of the overhead and you're building network value because people own the token.
Speaker B: I mean, these are all, I mean, this is not a bad idea. It's not a bad idea, but you're.
Speaker A: Going to live in a world where all of this stuff literally lives on the blockchain. Like, you're going to have AI agents that live on the blockchain that, uh, interact in machine currency, which is your crypto, right. And that's like, there's going to be full AI economies this way. And it's like, that's where the world's going and it's going to be crazy.
Speaker B: Well, there's like lots of polling out right now that some people have higher trust, like higher AI trust than human trust, like, especially I do after the past politics and stuff. Yeah. But it's specifically within politics. And I think we even talked about it in the past where the idea of AI, AI generated political landscape or not. I guess political in the sense that, like, governmental landscape as opposed to political, because political seems sidey, but, like, just an AI generated government, which is programmed to do, which is programmed to have the interest of the. You would essentially tier the importances of different topics, whether it's the country, whether it's the world stage, whether. You know what I mean? And have that implemented. Some people would prefer that to the human alternative, which I'm not necessarily opposed to.
Speaker A: Yeah, it's gonna be. I mean. Yes. Right. Like, think about a world in which, you know, there was none of that bias in it. Now, the AI, that assumes the AI in and of itself has no bias, which probably isn't true. Right. Because it's biased on how it. Whatever the trained on. Right. However it's trained. So, yeah, you can have Trump bot. Right? Like, but you could also have this automatic AI town type of thing ruling your government.
Speaker B: Couldn't you have the AI scan, like, basically survey the Internet and pull the data on what's most important to the majority of people and rank it that way?
Speaker A: Yeah, but then that even has somewhat of an inherent bias to who. To whom's on the Internet. Right?
Speaker B: Yeah, but, like, everybody's on the. I would.
Speaker A: Well, not really. They're all bots.
Speaker B: Well, I would say, you know, obviously trying to figure out in this scenario, they would be able to tell the difference between a bot and a human interactor. And I would argue that older people spend less time on the Internet. And in my opinion, older people are less important in the political and governmental landscape. You obviously want to. I had this argument with my parents in the past where, like, I don't give a shit who you're voting for. You should be voting for my kids, who can't vote yet. Like, this is. You're voting for the future. I don't give a shit about the next 15 years of your life. You know what I mean? Like, this is who you should be. Like, I don't care about your political opinion. I have a political opinion because I'm going to be probably alive for another 40, 50 years, God willing. Hopefully. Yeah. So my, you know, my vote counts for my, you know, for my future for the next 40, 50 years. But I think if you're over 60, 65 years old, you should be 100% voting for someone in your life that can't vote that you're representing. And I think if AI could scan the Internet, you would have that same. You know what I mean? Younger people are more on the Internet, so their opinions would probably be more prominent in a data poll than older people. So maybe. I don't know. That's kind of my thought.
Speaker A: I think that's probably accurate. Dude, it's going to get crazy. Like, you think it's weird now. Just wait. Like I want to.
Speaker B: Me and Rebecca are going to have our golden years. She's still going to be 51.
Speaker A: Yeah, that's the thing about AI. It's like the reverse. Yeah, exactly. It's exactly right. Except all your AI girlfriends will stay the same age.
Speaker B: A very reasonable 51 years old.
Speaker A: Yeah, it's.
Speaker B: Yeah, 51 is the new 41, so good for them, at least in AI.
Speaker A: Terms, unless you're a zoomer. And in which case, 20 is the new 50.
Speaker B: Right. Yeah. They are aging shittily.
Speaker A: Are you happy with the way you're aging?
Speaker B: I am. I actually, I was noticing I had the sun beaming on my face in.
Speaker A: The car the other day, and you're, like, feeling cute. My delete.
Speaker B: No, I noticed I. A little bit more like smile lines in my, you know, and I just noticed I was getting older, but I'm very happy with what I look like at this age compared to. Cause I mean, I was a. I was almost an adult when my dad turned 40. Like, I was 818 when my dad turned 40. No, 19. I was an adult when my dad turned 40. I remember, like, he was. It was ain't. He was ancient. Uh, and I feel decades younger than he did at 40.
Speaker A: What do your kids think you look like? My kid, definitely. Like a soccer look old. Yeah, my kid thinks I look old. Yeah.
Speaker B: My youngest likes to slap my bald head. Uh, and then she calls me bald head. Yeah.
Speaker A: So that, yeah, accurate. Yeah, yeah, it's. It's crazy. Let's go to circles, and then we'll start to wrap up circles. Thoughts?
Speaker C: So, two thoughts that I think are fairly related. The first is, I remember reading, I want to say it was like on an Apple news article. So it's entering the streamlined media area of somebody basically programming a GPT or whatever to filter through their dating matches and just have it even reply, oh.
Speaker A: My God, I saw this.
Speaker C: You've already got this kind of entering the mainstream of the idea of utilizing AI to help improve your dating matches and just, like, automate the stuff, and then you can just come home and see, oh, it did this for me or did that for me. So that was the one thing.
Speaker A: Oh, I have a date tonight.
Speaker C: Automated exactly. And then it's a question of, is your AI just talking to their AI? And is it actually a good match or does it just. It thinks it's a good match because it.
Speaker A: That's exactly the whole theory here. I think you're totally not too far off from that, right? Where eventually it's just we're all just going to have our own personalized AI agents that go out and use the Internet for us, like you said, chamber. And then you're going to come back with a bunch of results and things done for you and all that stuff. It's going to get real weird. It's going to get real weird.
Speaker B: Like Frank Reynolds last few years is on earth. You know what I mean?
Speaker A: Well, dude, I'll tell you. Yeah, I mean, speaking of, like, the book and stuff that we were talking about, um, when we. When Adam and Andy talked to Sam Altman, and I was hearing about their conversation afterwards, that was, like, the first time I had the existential crisis of, oh, this is going to eat everything. And, like, what do you even do about it? Like, what do you even do? And what they, like, what they asked him was like, hey, what do you, you know, what's your purpose? And he's like, oh, our. Our soul focus is creating AGI. And then it was, okay, cool, what's AGI? Define it. And he said that AGI is creating novel science. So think about what that means. That's like AI curing cancer, right? I mean, and so, like, in a world where machines can create new science, and, like, we're talking new science, not like, not like, read an x ray. We're talking.
Speaker B: Yeah, novel means new.
Speaker A: Yeah.
Speaker B: Like a different kind.
Speaker A: Exactly. In a world where that is possible. So then it was like, okay, well, when is that coming? Is it ten years from now? And the answer was sooner than that. So, like, this stuff's coming at us really fast, and it's gonna be weird.
Speaker B: Well, I was getting into a. There's this one guy I hate follow on TikTok.
Speaker A: You hate follow?
Speaker B: Yeah, yeah, I hate following. And he usually just talks about, like, movies and stuff, and he's just, like, a meathead from, like, who's about the same age as us that just talks about, like, old movie, like, old comedies and stuff that he likes, like, you know, stepbrothers and stuff like that. Movies that I love. But I hate it when guys our age talk about it for some reason. Like, it's the only thing they like, they don't watch anything new. So I hate follow this guy, but what he, a couple of things I always get on him because he always says skits instead of sketches when referring to Saturday Night Live, which is a pet peeve of mine. But the other day there's a movie that's coming out that I'm very excited to see. It's called like Late Night with the Devil. Some along those lines. And it's, it's a horror movie about like a seventies, like, like late night show, like a Johnny Carson type show where it's, I guess it's failing. It's all taking place at the same time. It's like you're a member of the audience when you're watching it. And anyways, looks fantastic. But within the movie, there's three, like, you know, we'll be going to break and then there's like a break image, like an old timey break image that appears and three of them were AI generated. And this guy was on TikTok and he's like, oh, you know, like they're taking, this is an independent australian movie, by the way. It's not a big budget, like Marvel movie, and it was three AI images that were just created. It's just saying, like, you know, we'll be back in five minutes or whatever it is. And, you know, he's, he's basically ripping these, this movie for, like, not hiring people that could have made these. And, and my argument was like, well, obviously somebody was hired to work the AI in order to get those image generated, and it's only three image. Like, how much work are we taking away from, like, three images being created? You know, I'm saying, like, one person. You know what I mean? Right. So if we're replacing it with one person, what's the big deal? And my question to you is, how much do you see that sort of thing being affected in the future? And when I'm arguing with thumbs on the Internet, is there like, is there kind of like a ratio that I should be using? Like, for every, you know, like, I always kind of, I harken it to, like, when CGI came in, right? Like, a lot of people that did practical effects, they lost their jobs, but there was a ton of new CGI people that could, you know, crazy.
Speaker A: The, the thing you're going to run into is, I think at least, is because this will eat jobs. It's going to eat jobs. It's going to eat a lot of jobs.
Speaker B: How much? What's the ratio like, well, that's what I mean.
Speaker A: It's just, it's, it's also going to be, I think, a net positive on jobs as well. I think the difficult thing is, what's the timeframe? What's the timeframe in which it eats jobs versus creates jobs? And how long of a gap is that? Do you know what I mean?
Speaker B: Totally.
Speaker A: That's, I think, where there's going to be some interesting stuff going on, right? Cause like once this stuff gets adopted, as in like accepted, you're gonna see businesses use it and you're gonna see them use it for productivity. And I'm sure that's gonna replace knowledge work jobs, right? Like you can see it now, it makes me ten x more productive just using chat GPT every day. And eventually, I'm sure form three will replace me with a version of myself. Yeah, like that's the world you're headed to. And so it's like, okay, well, it's definitely going to eat jobs. It's getting knowledge work jobs, which is scary because that's typically in these kind of technical revolutions, not the types of jobs that it affects. Right. It usually affects more kind of labor, blue collar stuff. This is going to be maybe the first time that it's impacting kind of your knowledge work stuff. And then what? And so, yeah, that's it. But I, you know, I do think it'll create more than it will, but like places are already using this in replacement of. But you're going to see what you will see. And I think this is your question is you're going to see new business models appear because of it. You're going to see businesses that can be run by two people with the assistance of AI that might have normally taken twelve people and millions of dollars in funding. Right. So you're going to see like this boon in that type of stuff, even though it is going to replace a lot of probably individual knowledge based tasks. Does that make sense? That's my theory, at least. And like, you're going to see new business models. There's going to be stuff, even in the content creation space that has been either too expensive to do in the past, so doesn't exist, or I something of that nature that will be possible now with this type of stuff. And so you're going to see this new creation of business models, new business jobs and all that kind of stuff. So that's where I think it's headed. So the best thing you can do as somebody, if you're not into this stuff yet, I is like, get involved, use chat, GBT, go explore stuff and start to be that kind of, like, expert in it, because you'll. It's also job protection to be the one that actually understands it. You know what I mean?
Speaker B: I do know what you mean. I don't know if the listeners can hear, but the bunch who, the bunch you bought is possibly self realizing that it's in fact AI generated and slowly inverting on itself, but I'm self destructing.
Speaker A: Is that what's happening?
Speaker B: Yeah, I think that's what's happening.
Speaker A: I don't know what happened. I have this weird beeping now in my ears. I don't know.
Speaker B: I think it's just the battery on the mic.
Speaker A: Is that the time? Is this time to shut it down?
Speaker B: Then that's the time to shut it down.
Speaker A: All right.
Speaker B: Bot needs to be recharged.
Speaker A: We got to cover the. We got to cover the magic, Internet cat magic minute here and give the people an update because we've had a rough week. So the, you know, we were. We were firing on all cylinders when we last had this show. Turns out in crypto there, you could be dealing with bad actors that you don't even realize. And we've been. We've been dealing with a couple of those in the past week that we're shaking the tree on and we're going to regroup and come back stronger than ever. But we've got, you know, we had a literal, specific instance of somebody who held a lot of supply telling us that they weren't selling, and meanwhile, behind our backs, they were selling the whole time. And look at that. So we are regrouping. We will be back stronger than ever. Not giving up on the middle.
Speaker B: It only adds to the lore.
Speaker A: That's absolutely right. Wait, just wait. And now we are working on some new stuff here, but we will be back stronger than ever. But had to give. Yeah, you got to give the update. We are a mic podcast now, you know.
Speaker B: That's right.
Speaker A: That's right. So that's going to do it for us today. What are we talking about on Friday? Are there any other weird conspiracy theories? I actually have a feeling this will be a high performing episode because it was, you know, a conspiracy episode. And I think there's some good takes and content in here, especially the part.
Speaker C: Where you start to sound like a robot. That's really going to add into it.
Speaker B: It's unbelievably uncanny how great this episode is going to be.
Speaker A: All right. That's going to do it for us. Until next time, keep the mic hot.
